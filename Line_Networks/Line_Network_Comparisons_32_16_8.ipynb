{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7e32b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load modules\n",
    "\n",
    "import pickle\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms\n",
    "import sys\n",
    "import os\n",
    "sys.path.append('..')\n",
    "from types import SimpleNamespace\n",
    "from field_of_junctions import FieldOfJunctions\n",
    "import nbimporter\n",
    "\n",
    "from torchsummary import summary\n",
    "\n",
    "from Dataset_Maker_Lines import make_random_line_set, make_grey_transform\n",
    "\n",
    "# %load_ext autoreload\n",
    "# %reload_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd29a732",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b1049ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LineDataset(torch.utils.data.Dataset):\n",
    "    \"\"\" Dataset with support of transforms.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, images, params, boundaries, wedges, transform=None):\n",
    "        self.images = images\n",
    "        self.params = params\n",
    "        self.boundaries = boundaries\n",
    "        self.wedges = wedges\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        image = self.images[index]\n",
    "        wedge = self.wedges[index]\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        param = self.params[index].squeeze()\n",
    "        boundary = self.boundaries[index]\n",
    "        \n",
    "        return image, param, boundary, wedge\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eede54fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init_uniform(m):\n",
    "    classname = m.__class__.__name__\n",
    "    # for every Linear layer in a model..\n",
    "    if classname.find('LazyLinear') != -1:\n",
    "        # apply a uniform distribution to the weights and a bias=0\n",
    "        m.weight.data.uniform_(0.0, 1.0)\n",
    "        m.bias.data.fill_(0) \n",
    "    if classname.find('Linear') != -1:\n",
    "        # apply a uniform distribution to the weights and a bias=0\n",
    "        m.weight.data.uniform_(0.0, 1.0)\n",
    "        m.bias.data.fill_(0)\n",
    "    if classname.find('Conv2d') != -1:\n",
    "        # apply a uniform distribution to the weights and a bias=0\n",
    "        m.weight.data.uniform_(0.0, 1.0)\n",
    "        m.bias.data.fill_(0)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d533e21b",
   "metadata": {},
   "source": [
    "#  -------- 32x32  --------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da7648d4",
   "metadata": {},
   "source": [
    "## 1) noiseless, multicolor images - 88 parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "54ac30ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA2cAAAElCAYAAABgRJorAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4xLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvDW2N/gAAGgpJREFUeJzt3XuUXWd5H+DfOyNZlrCwjA3mYmIKBgykNWlaCIRbY5JAAoG0XS0lITVdaYhNm6bBGBwoEAcaSqA4EEwILELAcWvHlIZLnAsJTkts0phyyYXGMRBjg++WLF+QLM3s/rG37GMtnX1GmhnNZ+l51prlmXnP3vs7ks+n8zt77++trusCAADA2ppb6wEAAAAgnAEAADRBOAMAAGiAcAYAANAA4QwAAKABwhkAAEADhDMADhtV9aGqevNajwNgX6rq76rqucvY/o6qevRKjomDSzg7BA0v7G8PL9DrhzcjR+31mH9UVZ+sqq1Vta2q/rqq3lJVxwz106pqYdjHHVX1tao6feSYz6mqa1f7uQFrq6peUlV/VlV3VtWNw/dnVFWt9dhWW1V1VXXSWo8DWHl7vXfaWlWfqqpHrvW49lfXdUd1Xfe1tR4HB044O3S9sOu6o5I8Ocl3JTl7T6Gqnp7k0iR/muTkruu2JHlekt1JTpnYx+XDi/yoJP8syduq6rsO0viBxlTVq5L8SpJfTvLQJMcn+ekk35vkiCnbzB+0AQIsz573Tg9LckOSd6/xeJasqtat9RhYGcLZIa7ruuuT/H76kLbH25L8Rtd1v9R13Q3D477Rdd0bu667dMp+vpDkK0mesJTjVtWlVfXmqrps+BTqE1V1bFX9VlVtr6o/r6pHTTz+V6rqmqH2+ap65kRtY1X95vBJ1leq6qzJs3RV9fCq+mhV3VRVX6+qn1nyHxCwJFV1dJJzkpzRdd3FXdfd3vW+0HXdj3Vdt3N43Ieq6r1V9btVdWeSf1JVP1xVXxhe39dU1Zsm9vupqvr3ex3ry1X1o9V753CGbntV/UVVfefwmI1V9Y6qurqqbquqz1bVxqH228NVA7dV1f+qqieNPK8XVNUXhysILquqf7DEP483Dcc5v6puH8b2uKo6exjvNVX1AxOPf/kwf90+XInwir32d1ZVXVdV36qqn5w8S1dVG6rq7VX1jaq6oap+bc9zBVZe13U7klyc5IlJP/9V1YeH9xlXV9Xrq2puqL2pqs7fs21VPWp4/a4bfr60qn6xqv50eP3/QVUdN/H4lw37vKWqXjc5jqp6SlVdPsxP11XVr1bVERP1rqpeWVV/m+RvJ343c+6oquOqv4JqW1XdWlX/e89zYm35SzjEVdUJSZ6f5Krh5wckeVqSj+7nfv5xkscluWI/NntJkpcleUSSxyS5PMlvJHlQ+qD3xonH/nn6APmgJBck+e2qOnKovTHJo5I8Osn3J/nxiXHNJflEki8Nxzk1yc9W1Q/uz/MDZnpakg1JfmcJj31pkrck2Zzks0nuTPITSbYk+eEkp1fVi4fH/mbu+5o+Jf1r+VNJfiDJs9LPPUcn+RdJbhke+vYk353k6ennjbOSLA61S5I8NslDkvzfJL+1r0FWfyXAB5O8IsmxSd6X5ONVtWEJzzFJXpjkI0mOSfKF9B+EzQ3jP2fY3x43JnlBkgcmeXmSd1bVPxzG8bwkP5fkuUlOSvKcvY7z1uHP4MlD/RFJ3rDEMQL7qao2JfmXST43/Ord6eegRyd5dvr57OX7scuXDo9/SPqrDM4cjvPEJO9N/17p4ennoRMmtltI8h+THJd+Dj41yRl77fvFSZ6aIUjuZWzueFWSa5M8OP1VED+fpNuP58Rq6brO1yH2leTvktyR5Pb0L7Q/SrJlqJ0w/O7kice/Lcm29G+gXj/87rT0lzlum9jPu5PUlGM+J8m1Ez9fmuR1Ez+/I8klEz+/MMkXR57D1iSnDN9/LckPTtR+cs+x0k9I39hr27PTnxlc878LX74Ola/0Aer6vX532TBHfDvJs4bffSjJh2fs69wk7xy+P3J4vT92+PntSc4bvv++JFcm+Z4kcxPbzw3HPGUJ494yzF9HT4zvzcP3703yi3s9/m+SPHvKvrokJw3fvynJH07UXjjMu/PDz5uHx2+Zsq//meQ/DN9/MMkvTdRO2nOsJDXMzY+ZqD8tydfX+v8JX74Opa/c+95pW5JdSb6V5O8nmU9yd5InTjz2FUkuHb5/U5LzJ2qPGl6/64afL83w3mr4+Ywkvzd8/4Yk/32i9oDhWM+dMsafTfKxiZ+7JN+312OWNHek/wDpd/bMab7a+XLm7ND14q7rNqcPTSen/9Ql6d8ELaa/njpJ0nXdWV1/39nHkkxes/y5ruu2DPt5aJInJfnP+zGGGya+//Y+fr5nkZKqOnO45Oe2qtqW/hOqPWN+eJJrJrad/P7EJA8fTstvG7b9+fSfAgEr55Ykx9XEfQ1d1z19mDtuyX2vxJh8jaaqnlpVnxkuCbot/X1qxw372JHkwiQ/PpwJ/1fpz0al67o/TvKrSd6T5Maq+vWqeuCw7ZFJvrr3IKtqvqreWlVfrart6d9wJffOJ5NOTPKqveaPR6afc5Zi7znt5q7rFiZ+ToZ5rqqeX1WfGy4f2pbkh7K0Oe7BSTYl+fzEGH9v+D2wsl48zGlHJvl3Sf4k/Yfa65NcPfG4q9OfhVqq6ye+vyv3vv+5z2u/67o7c+/VARkulf7kcJn29vTvwfaey67Jvs2aO345/VVVfzBcav3a/Xg+rCLh7BDXdd2fpP+k+O3Dz3cm+bMk/3Q/93ND+kshX7jCQ0z195edlf6SpWOGifG29J/6JMl1ue9p/snVk65J/ynQlomvzV3X/dBKjxMOc5cn2ZnkRUt47N6XxlyQ5ONJHtl13dFJfi33vr6T/tLGH0t/yc5dXdddfs+Ouu5dXdd9d/pLdh6X5NVJbk6yI/3l0nt76TDG56b/kOdRw+/3tZrkNUnestf8sanruv+2hOe4ZMNlkh9NPw8fP8xxv5ulzXE3pw96T5oY49Fdv2gBsAq6rlvouu5/pL+s8HvSn0k7ceIh35Hkm8P3d6YPQXs8dD8OdV0mXu/D5ZTHTtTfm+T/pb+y4IHpP3zeey6bdini6NzR9fcNv6rrukcn+ZEkP1dVp+7H2Fklwtnh4dwk3z/cy5H0QejfVNVrq+ohyT33pv29aTuoqmOT/GiSv1qF8W1OfwnlTUnWVdUb0t+XscdFSc6uqmOq6hHpP83a4/8kub2qXlP9AgHzVfWdwz1ywArpum5bkl9Icl5V/fOq2lxVc1X15PSX4ozZnOTWrut2VNVT0geoyX1fnv6M/jsynDVL+ntdh7Nu69O/AdqRZLHrusX0lwL+1+oXBJqvqqcNIWhz+hB5S/o3TGNn+9+f5KeHY1RVPaD6xUs2L/kPZmmOSH+/3k1JdlfV89PfT7fHRUleXlVPGN6c/ac9heG5vj/9PWp75utHuK8WVs8wH7wo/f2kf5n+NfqWYd47Mf09onsWAflikmdV1XdUv3DS2fvc6b5dnOQFVfWMYaGPc3Lf9+abk2xPckdVnZxkakujvc2aO6pfDOmkqqr0H4gv5N77dllDwtlhoOu6m5J8OMNNoF3XfTb9vRzPSnLlxKnuS3PfZWOfVkOfs/QLeNyU5D6rqq2Q3x+Of2X6SwV25L6n6c9Jf9Pq15N8Ov1ktnN4Lgvpb7J/8lC/OckH0n9iDqygruvelv5NyVnpL+m7If2iF69Jf//ZNGckOaeqbk8/D120j8d8OP39HedP/O6B6d9cbE0/N9yS/lKcpL+h/i/SLyZ0a5L/kv7ftA8Pj/1mkr/OvTf07+v5XJHk36a/dHJr+kt8Tht5Hgek67rbk/xM+ue9NX04/fhE/ZIk70rymWEMe8a8c/jva/b8fri06dNJHr/S4wTyieE9z/b0ixr9667r/ir9e587098D/9n0VwN8MEm6rvvD9JdmfznJ55N8cqkHG/b9ymF/16WfHyZ7xp6Zfr64Pf1ceOF+Pp+xueOxw893pL8y4ryu6z6zn/tnFVTXWZiF+5fqm2G/pOu6Z6/1WICVUVU/keSnuq57xlqPZa1V1RPSf1q/oeu63Ws9HgAOHmfOaF5VPayqvne4hOrx6Zd//dhajwtYGcOlfGck+fW1Hstaqb6v24aqOib9WcBPCGYAhx/hjPuDI9JfOnV7kj9Ov/TreWs6ImBFDPc/3JT+EskL1ng4a+kV6XuhfTX9vR9LvrcEgEOHyxoBAAAa4MwZAABAA4QzAACABqw7mAerrtbuGsr76dWb1e2rb+oKmfFnUovjx57bPT3bP/C68f6o15y0c7R+RO4erdfI4MdqK2G1939/VN1q/o+6+rZt2+YvdT+t5iXxs/Y9q76wsDC1duutt45u+573vGe0Pjc3/plm3zKIVpx77rmHwl+I+ekQMjZ/bd26dXTbzZvHWzCuX7/+gMbEmtnn/OTMGQAAQAOEMwAAgAYIZwAAAA0QzgAAABognAEAADRAOAMAAGjAQV1KnzUwsgDvrGX6ZzU+GFtq/2FfPm5027lcM75zgAM0tlT11VdfPbqtpfCB1TQ2P1166aWj277oRS9a4dHQImfOAAAAGiCcAQAANEA4AwAAaIBwBgAA0ADhDAAAoAHCGQAAQAMspc+I8SWl50aW0n/vaRvHt83iAY0IYGwp6iRZXJw+v1x44YWj2x511FEHNCaApRibv6688srRbbX6ODw4cwYAANAA4QwAAKABwhkAAEADhDMAAIAGCGcAAAANEM4AAAAaIJwBAAA04NDpczbe9oYDMePPdG7X9Gx/8u3fHN22Zux8uXWgbWO9fmb1MZtVX1hYmFrbsGHD+MAAVtFYH8bTTjttdFt9zg4PzpwBAAA0QDgDAABogHAGAADQAOEMAACgAcIZAABAA4QzAACABghnAAAADTh0+pyx/2a0CqtuvJ/Guh3T//c5stt5ICNqgh5qMLuXWMvuvvvuqbX5+fnRbfURApZj1ty5a9euqbWjjz56pYfD/ZAzZwAAAA0QzgAAABognAEAADRAOAMAAGiAcAYAANAA4QwAAKABwhkAAEAD9DlbY7N6ic20iq2IanF8bA+4eePU2rrcPr5vvcSAAzSrj9D27dun1pbbx0wfNGA5brzxxqm1E044YXRb88/hwZkzAACABghnAAAADRDOAAAAGiCcAQAANEA4AwAAaIBwBgAA0ABL6R/ixpbqn7WM/6yl9E9932On1uZyxfjAAKaYtVT+4uLiaP3Tn/701JqlqIHVNGv+evWrXz21duGFF670cLgfcuYMAACgAcIZAABAA4QzAACABghnAAAADRDOAAAAGiCcAQAANEA4AwAAaMD9p8/ZeNsIDsSMP9NaGO8HdM77r5m+7Yydz6oD92+zev0sx6w+Z1deeeXU2pFHHrnSwwG4x6y578wzz5xa04eRxJkzAACAJghnAAAADRDOAAAAGiCcAQAANEA4AwAAaIBwBgAA0ADhDAAAoAH3nz5nrLhZ3TTmd82P1h+0+7aRfS+vx5E+aLD6VrMX2XKOPWtcu3fvHq2vWzf9nzZ9hIDlmDU/LSwsjNZPPvnklRwOhyBnzgAAABognAEAADRAOAMAAGiAcAYAANAA4QwAAKABwhkAAEADLKV/EFS3hks3j634ujg+riPuWD9aX5+7p9ZaXgq/5bEBs5eq3rFjx2h9bs7njsDauOuuu0brmzZtmlrT6oPEmTMAAIAmCGcAAAANEM4AAAAaIJwBAAA0QDgDAABogHAGAADQAOEMAACgAfqctW5GS67l9FCbte1xV20Zrc/n+gM+NsA0s/qcXXfddaP15fQK0mcIWI4vfelLo/VnPOMZB2kk3F85cwYAANAA4QwAAKABwhkAAEADhDMAAIAGCGcAAAANEM4AAAAaIJwBAAA0QJ+zQ9xYL7NaGO/n846XHT++73zrgMYEMNbLbHFxcXTb888/f7S+cePGAxoTwCyz+jBecMEFo/VnPvOZKzkcDkHOnAEAADRAOAMAAGiAcAYAANAA4QwAAKABwhkAAEADhDMAAIAGCGcAAAANaKvP2XjrCA7EyJ/p3O7xbP7Um742Wq+RnY/VllIH2jar189yLCwsjNbn5+dX7dgAY2b1YXz9618/Wq8a7zELzpwBAAA0QDgDAABogHAGAADQAOEMAACgAcIZAABAA4QzAACABrS1lD77b8Zq1tVNX7J13c7x5ag3Le4Y3/f4odeMZfqht5rL3S/32GP1Xbt2jW47Nzf+uaKlqoHlWM78dOyxx670cDjMOHMGAADQAOEMAACgAcIZAABAA4QzAACABghnAAAADRDOAAAAGiCcAQAANECfsxUw1ktszY20Gtq49cjRTedz52hdPzHgQI31EbrjjjtGt52fH+/ROEYPNGA5tm7dOlp/8IMfPFo3BzGLM2cAAAANEM4AAAAaIJwBAAA0QDgDAABogHAGAADQAOEMAACgAcIZAABAA/Q5W2szWoXN6qE2qz63OL3+5I+fOLrtfP5ytA4wzVgfsyRZXFycWrviiitGt9UnCFhNY/PXueeeO7rtW9/61pUeDocZZ84AAAAaIJwBAAA0QDgDAABogHAGAADQAOEMAACgAcIZAABAAw7uUvozlo1n5dXC9Pz9rjduHd92xl/YrDpw/zVrKfzlGltK/7LLLhvdduPGjSs9HIB7jM1/p5566ui2Wn2wXM6cAQAANEA4AwAAaIBwBgAA0ADhDAAAoAHCGQAAQAOEMwAAgAYIZwAAAA04uH3OWHkzWhHN75qevx+ya3l9zlZrW6B9s/qgzaovLCxMra1fv350W32EgNU0Nj895SlPOYgj4XDkzBkAAEADhDMAAIAGCGcAAAANEM4AAAAaIJwBAAA0QDgDAABogHAGAADQAH3OlqC6NeypM6NdWC2Oj239XdP7BW3o7l7ewdeQPmowu5fYWpo1tp07d06tzc353BBYPbPmpx07dkytbdq0aaWHA/fhX0AAAIAGCGcAAAANEM4AAAAaIJwBAAA0QDgDAABogHAGAADQAOEMAACgAfqcHQwj7TRqmW2KZvVg2/KNzVNr87l5fN8HNCKA2X2Ebrrppqm1quXNPsvdHji8XXXVVVNrp5xyyui25h+Wy5kzAACABghnAAAADRDOAAAAGiCcAQAANEA4AwAAaIBwBgAA0ABL6a+58SVXZy2VXwvj9df+1KNHjjx9KWuAMbOWyp9V/8hHPjK1tm6df5qA1TNrfjr77LOn1i655JKVHg7chzNnAAAADRDOAAAAGiCcAQAANEA4AwAAaIBwBgAA0ADhDAAAoAHCGQAAQAM0k2ndeCuOzC2M5+sf+Zsrp9Zqxs6XWwfaNqvXz3Ls3r17tL64uLhqxwYYM2v+Oe+886bWqsb7y8JyOXMGAADQAOEMAACgAcIZAABAA4QzAACABghnAAAADRDOAAAAGiCcAQAANECfs7U2o81QdeP9NOZ3zo/Wj1q8a/q+G+5T1vLY4GBazV5kyznurPqsPmdzc9M/G9RHCFiO5c5Pxx9//EoOB/aLM2cAAAANEM4AAAAaIJwBAAA0QDgDAABogHAGAADQAOEMAACgAcIZAABAA/Q5G8zqJ7ZmZrQ4OvK2DaP1dfn21JpeYsCBmtVH6K67pvdYTJL5+fEejWP0QQOWY/v27aP1Y445ZmrN/MNqc+YMAACgAcIZAABAA4QzAACABghnAAAADRDOAAAAGiCcAQAANMBS+ithxor0Y8v0z1rCvxbH64+57KGj9blcNVoHOBCzltL/yle+Mlq3HDWwWmbNTxdddNFo/fTTT1/J4cB+ceYMAACgAcIZAABAA4QzAACABghnAAAADRDOAAAAGiCcAQAANEA4AwAAaIA+Z42bWxjPz+975e7x7Wc1YQPYh1l9ghYXF0frl1xyyWh906ZN+z0mgKWYNX9t2bJltK4PI2vJmTMAAIAGCGcAAAANEM4AAAAaIJwBAAA0QDgDAABogHAGAADQAOEMAACgAfqcrbUZbcjmdo/n50fuuGm0XiMHGKstpQ60bVavn7H6rG137x7vsXjEEUeM1vURAlbLrD6Mz3ve80br5ifWkjNnAAAADRDOAAAAGiCcAQAANEA4AwAAaIBwBgAA0ADhDAAAoAGW0j8YRlakrm58udb13x7/K9rQ7TyQEa05y/RDb9aS9a26++67R+tzcz77A1bHrHlz587x90ZHHXXUSg4HVpR/PQEAABognAEAADRAOAMAAGiAcAYAANAA4QwAAKABwhkAAEADhDMAAIAGHDZ9zmb1Exu1im2IanF8XJuvf8BofT7bxvevnxhwABYXF0frW7duHa1XHficu5xtAa699trR+kknnTRaNwexlpw5AwAAaIBwBgAA0ADhDAAAoAHCGQAAQAOEMwAAgAYIZwAAAA0QzgAAABpw2PQ5W02zeqiN1Wf1OXvZ6x4/Wp/L5aN1gGm6bnofxLFaklx88cWjdX2CgNUya3467bTTRuuXXXbZCo4GVpYzZwAAAA0QzgAAABognAEAADRAOAMAAGiAcAYAANAA4QwAAKABwhkAAEAD9Dk7GEbaccztHu8FdPofXTlar7Gdz6yPbwu0bVavn+XYvXv3aH3r1q2j9Q0bNqzkcADusbi4OFr/wAc+MFrXh5GWOXMGAADQAOEMAACgAcIZAABAA4QzAACABghnAAAADRDOAAAAGmAp/YOguulLts7vmh/d9uiFO8b3vYzl8Fd3IVnL9EOyusvdL/fYY/WFhYXRbefnx+cuS1UDy7Gc+enEE09c6eHAQePMGQAAQAOEMwAAgAYIZwAAAA0QzgAAABognAEAADRAOAMAAGiAcAYAANCAWssePAAAAPScOQMAAGiAcAYAANAA4QwAAKABwhkAAEADhDMAAIAGCGcAAAANEM4AAAAaIJwBAAA0QDgDAABogHAGAADQAOEMAACgAcIZAABAA4QzAACABghnAAAADRDOAAAAGiCcAQAANEA4AwAAaIBwBgAA0ADhDAAAoAHCGQAAQAOEMwAAgAYIZwAAAA0QzgAAABrw/wETz01+d3gJIAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 1080x1080 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# What about if the centers are allowed to move within 25% of the center?\n",
    "\n",
    "data_folder = 'foj_data/grayscale_lines/'\n",
    "\n",
    "with open(data_folder + 'line_data_32_20000_grey_multicolor_uncentered.pkl','rb') as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "# wedges = data['wedges']\n",
    "wedges_grey = data['wedges_grey']\n",
    "params = data['params']\n",
    "boundaries = data['boundaries']\n",
    "wedges = data['wedges']\n",
    "\n",
    "img_show = 0\n",
    "plt.figure(figsize=[15, 15])\n",
    "plt.subplot(131)\n",
    "plt.imshow(wedges[img_show,:,:].squeeze().permute(1,2,0).cpu())\n",
    "plt.title('RGB Image')\n",
    "plt.axis('off');\n",
    "plt.subplot(132)\n",
    "plt.imshow(wedges_grey[img_show,:,:].squeeze().cpu(),cmap='gray', vmin=0, vmax=1)\n",
    "plt.title('Grayscale Image')\n",
    "plt.axis('off');\n",
    "plt.subplot(133)\n",
    "plt.imshow(boundaries[img_show,:,:].squeeze().cpu(),cmap='gray', vmin=0, vmax=1)\n",
    "plt.title('Boundaries')\n",
    "plt.axis('off');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "b104b38f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000\n"
     ]
    }
   ],
   "source": [
    "line_data = LineDataset(wedges_grey, params, boundaries, wedges)#, transform=trainTransform)\n",
    "data_size = len(line_data)\n",
    "\n",
    "print(data_size)\n",
    "\n",
    "train_proportion = .85\n",
    "# Split dataset into training and testing\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(line_data, [int(data_size*train_proportion), int(data_size*(1-train_proportion))], generator=torch.Generator().manual_seed(42))\n",
    "\n",
    "# Create loaders for the training and testing data\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=len(test_dataset), shuffle=False) #len(test_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "e34d0b66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1            [-1, 1, 30, 30]              10\n",
      "         MaxPool2d-2            [-1, 1, 15, 15]               0\n",
      "         AvgPool2d-3              [-1, 1, 5, 5]               0\n",
      "            Linear-4                    [-1, 3]              78\n",
      "================================================================\n",
      "Total params: 88\n",
      "Trainable params: 88\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.01\n",
      "Params size (MB): 0.00\n",
      "Estimated Total Size (MB): 0.01\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "class offCenterLineNet(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "                \n",
    "        self.conv1 = nn.Conv2d(1, 1, kernel_size=3)\n",
    "        self.fc = nn.LazyLinear(3)\n",
    "        self.maxpool = nn.MaxPool2d(2)\n",
    "        self.avgpool = nn.AvgPool2d(3)\n",
    "    \n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.conv1(x)\n",
    "#         x = F.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.shape[0],-1)\n",
    "        \n",
    "        x = self.fc(x)\n",
    "         \n",
    "        # We're defining\n",
    "        # a = - sin(theta)\n",
    "        # b = cos(theta)\n",
    "        # c = -cy*cos(theta)+cx*sin(theta)\n",
    "        # Hence, we want to normalize the vector by 1/sqrt(a^2 + b^2)\n",
    "        norm_factor = (torch.norm(x[:,:2],p=2,dim=1)).unsqueeze(1)        \n",
    "        out = x/(norm_factor)#+eps)\n",
    "#         print('Output shape=',x.shape)\n",
    "\n",
    "#         out = x\n",
    "        \n",
    "        return out\n",
    "    \n",
    "model = offCenterLineNet()\n",
    "model = model.to(dev)\n",
    "summary(model, input_size=(1, H, W))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "4b2a4986",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Avg. Train Loss: 0.01968317733843648, Avg. Test Loss: 0.0004927481641061604\n",
      "Epoch: 2, Avg. Train Loss: 0.0003345760451885784, Avg. Test Loss: 0.00020098901586607099\n",
      "Epoch: 3, Avg. Train Loss: 0.00022616768468911426, Avg. Test Loss: 0.00016619430971331894\n",
      "Epoch: 4, Avg. Train Loss: 0.00014948587009794414, Avg. Test Loss: 0.00015737272042315453\n",
      "Epoch: 5, Avg. Train Loss: 0.00011425629524904464, Avg. Test Loss: 9.761840919964015e-05\n",
      "Epoch: 6, Avg. Train Loss: 0.00011361142927292766, Avg. Test Loss: 0.00011767601972678676\n",
      "Epoch: 7, Avg. Train Loss: 0.0001109654560860875, Avg. Test Loss: 0.0001046477336785756\n",
      "Epoch: 8, Avg. Train Loss: 0.00011424617141734019, Avg. Test Loss: 9.272374154534191e-05\n",
      "Epoch: 9, Avg. Train Loss: 0.00011141200940942224, Avg. Test Loss: 8.591970254201442e-05\n",
      "Epoch: 10, Avg. Train Loss: 0.0001273873459994272, Avg. Test Loss: 0.0001468933915020898\n",
      "Epoch: 11, Avg. Train Loss: 9.52789573295062e-05, Avg. Test Loss: 9.649438288761303e-05\n",
      "Epoch: 12, Avg. Train Loss: 9.30986511399593e-05, Avg. Test Loss: 9.974546264857054e-05\n",
      "Epoch: 13, Avg. Train Loss: 9.156365214087265e-05, Avg. Test Loss: 8.122118742903695e-05\n",
      "Epoch: 14, Avg. Train Loss: 9.449746249130047e-05, Avg. Test Loss: 0.00010114481847267598\n",
      "Epoch: 15, Avg. Train Loss: 9.396074273853512e-05, Avg. Test Loss: 9.275299089495093e-05\n",
      "Epoch: 16, Avg. Train Loss: 9.437087070332757e-05, Avg. Test Loss: 9.57711017690599e-05\n",
      "Epoch: 17, Avg. Train Loss: 9.119870258001541e-05, Avg. Test Loss: 8.343080844497308e-05\n",
      "Epoch: 18, Avg. Train Loss: 9.137389037948053e-05, Avg. Test Loss: 9.37523873290047e-05\n",
      "Epoch: 19, Avg. Train Loss: 8.97117254003787e-05, Avg. Test Loss: 8.955677185440436e-05\n",
      "Epoch: 20, Avg. Train Loss: 9.142693315674875e-05, Avg. Test Loss: 8.615430124336854e-05\n",
      "Epoch: 21, Avg. Train Loss: 9.35087022353537e-05, Avg. Test Loss: 8.404942491324618e-05\n",
      "Epoch: 22, Avg. Train Loss: 9.216314100555785e-05, Avg. Test Loss: 9.300112287746742e-05\n",
      "Epoch: 23, Avg. Train Loss: 9.01830371936343e-05, Avg. Test Loss: 8.793638698989525e-05\n",
      "Epoch: 24, Avg. Train Loss: 9.03169814461892e-05, Avg. Test Loss: 0.00010389515955466777\n",
      "Epoch: 25, Avg. Train Loss: 9.050943745912667e-05, Avg. Test Loss: 9.31441827560775e-05\n",
      "Epoch: 26, Avg. Train Loss: 9.021005482787942e-05, Avg. Test Loss: 7.936501788208261e-05\n",
      "Epoch: 27, Avg. Train Loss: 9.084013294669515e-05, Avg. Test Loss: 9.624276572139934e-05\n",
      "Epoch: 28, Avg. Train Loss: 8.891596637550905e-05, Avg. Test Loss: 9.62145350058563e-05\n",
      "Epoch: 29, Avg. Train Loss: 8.805333384641147e-05, Avg. Test Loss: 8.462485857307911e-05\n",
      "Epoch: 30, Avg. Train Loss: 9.02794661779172e-05, Avg. Test Loss: 8.871062891557813e-05\n",
      "Epoch: 31, Avg. Train Loss: 8.920374864117589e-05, Avg. Test Loss: 8.428352157352492e-05\n",
      "Epoch: 32, Avg. Train Loss: 8.717778937831386e-05, Avg. Test Loss: 8.9117260358762e-05\n",
      "Epoch: 33, Avg. Train Loss: 9.130638131625203e-05, Avg. Test Loss: 9.912156383506954e-05\n",
      "Epoch: 34, Avg. Train Loss: 8.953061713232034e-05, Avg. Test Loss: 7.816453580744565e-05\n",
      "Epoch: 35, Avg. Train Loss: 8.848151690855095e-05, Avg. Test Loss: 8.984260057331994e-05\n",
      "Epoch: 36, Avg. Train Loss: 8.867799295645331e-05, Avg. Test Loss: 0.00011117071699118242\n",
      "Epoch: 37, Avg. Train Loss: 9.00447590483827e-05, Avg. Test Loss: 9.489297372056171e-05\n",
      "Epoch: 38, Avg. Train Loss: 8.700488349421718e-05, Avg. Test Loss: 8.15085440990515e-05\n",
      "Epoch: 39, Avg. Train Loss: 8.816952179456296e-05, Avg. Test Loss: 8.349517884198576e-05\n",
      "Epoch: 40, Avg. Train Loss: 8.974220383292173e-05, Avg. Test Loss: 8.023116242839023e-05\n",
      "Epoch: 41, Avg. Train Loss: 8.917374285183062e-05, Avg. Test Loss: 9.105132630793378e-05\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-186-f59f64d95e96>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mnum_batches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;31m# get the input images and their corresponding labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/torch_cuda9/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/torch_cuda9/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    559\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/torch_cuda9/lib/python3.6/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/torch_cuda9/lib/python3.6/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/torch_cuda9/lib/python3.6/site-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    361\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-11f9726a70a2>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mparam\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0mboundary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mboundaries\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Now let's train the initial network \n",
    "\n",
    "model = offCenterLineNet()\n",
    "model = model.to(dev)\n",
    "model.apply(weights_init_uniform)\n",
    "\n",
    "model.train();\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=.01) \n",
    "# scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=500, gamma=0.1)\n",
    "\n",
    "n_epochs = 1400\n",
    "\n",
    "mse_loss = nn.MSELoss()\n",
    "ce_loss = nn.CrossEntropyLoss()\n",
    "\n",
    "for epoch in range(0,n_epochs):  # loop over the dataset multiple times\n",
    "    \n",
    "    if epoch == 0:\n",
    "        train_loss_over_time = [] # to track the loss as the network trains\n",
    "        test_loss_over_time = []\n",
    "        \n",
    "    if epoch == 10:\n",
    "        optimizer = torch.optim.Adam(model.parameters(),lr=.002) \n",
    "        \n",
    "    running_loss = 0\n",
    "    num_batches = 0\n",
    "    \n",
    "    for batch_i, data in enumerate(train_loader):\n",
    "        \n",
    "        # get the input images and their corresponding labels\n",
    "        num_batches += 1\n",
    "\n",
    "        inputs, output_gt, _, _ = data\n",
    "        inputs, output_gt = inputs.to(dev), output_gt.to(dev)\n",
    "        \n",
    "        # zero the parameter (weight) gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # forward pass to get outputs\n",
    "        output_line_params = model(inputs)\n",
    "        \n",
    "\n",
    "        # make the ground truth\n",
    "        c = -output_gt[:,2]*torch.cos(output_gt[:,0]) + output_gt[:,1]*torch.sin(output_gt[:,0])\n",
    "        gt_line_params = torch.stack((-torch.sin(output_gt[:,0]),torch.cos(output_gt[:,0]),c),dim=1)\n",
    "        \n",
    "        # calculate the loss\n",
    "#         print(output_line_params[:,:,0,50])\n",
    "        \n",
    "        loss = mse_loss(output_line_params,gt_line_params)\n",
    "        \n",
    "        # backward pass to calculate the parameter gradients\n",
    "        loss.backward()\n",
    "\n",
    "        # update the parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        # to convert loss into a scalar and add it to running_loss, we use .item()\n",
    "        running_loss += loss.item()\n",
    "      \n",
    "\n",
    "#     scheduler.step()\n",
    "    \n",
    "    # Calculate test data loss after each epoch\n",
    "    with torch.no_grad():\n",
    "        test_loss = 0\n",
    "        num_batches_test = 0\n",
    "        for batch_i, data in enumerate(test_loader):\n",
    "            num_batches_test += 1\n",
    "\n",
    "            # Add code here\n",
    "            inputs, output_gt, _, _ = data\n",
    "            inputs, output_gt = inputs.to(dev), output_gt.to(dev)\n",
    "\n",
    "\n",
    "            # zero the parameter (weight) gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward pass to get outputs\n",
    "            output_line_params = model(inputs)\n",
    "\n",
    "            # make the ground truth\n",
    "            c = -output_gt[:,2]*torch.cos(output_gt[:,0]) + output_gt[:,1]*torch.sin(output_gt[:,0])\n",
    "            gt_line_params = torch.stack((-torch.sin(output_gt[:,0]),torch.cos(output_gt[:,0]),c),dim=1)\n",
    "    \n",
    "\n",
    "            # calculate the loss\n",
    "    #         print(output_line_params[:,:,0,50])\n",
    "\n",
    "            loss = mse_loss(output_line_params,gt_line_params)\n",
    "            \n",
    "            test_loss += loss\n",
    "                    \n",
    "        test_loss_over_time.append(test_loss/num_batches_test)\n",
    "\n",
    "    # Calculate model loss:\n",
    "    avg_loss = running_loss/num_batches\n",
    "    train_loss_over_time.append(avg_loss)\n",
    "    \n",
    "#     print('Epoch: {}, Avg. Train Loss: {},'.format(epoch + 1, train_loss_over_time[-1]))\n",
    "\n",
    "\n",
    "    print('Epoch: {}, Avg. Train Loss: {}, Avg. Test Loss: {}'.format(epoch + 1, train_loss_over_time[-1], test_loss_over_time[-1]))\n",
    "    \n",
    "print('Finished Training')\n",
    "\n",
    "plt.figure()\n",
    "plt.semilogy(np.arange(0,n_epochs),train_loss_over_time[0:])\n",
    "plt.semilogy(np.arange(0,n_epochs),test_loss_over_time[0:])\n",
    "plt.legend(['Training loss', 'Testing loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "de4a1cea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor(0.1974)]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1080 with 9 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the Results\n",
    "\n",
    "plt.figure()\n",
    "plt.semilogy(np.arange(0,epoch),train_loss_over_time[:epoch])\n",
    "plt.semilogy(np.arange(0,epoch),test_loss_over_time[:epoch])\n",
    "plt.legend(['Training loss', 'Testing loss'])\n",
    "\n",
    "model.eval();\n",
    "\n",
    "ang_loss_all = []\n",
    "\n",
    "for batch_i, data in enumerate(test_loader):\n",
    "    # get the input images and their corresponding labels\n",
    "    inputs, output_gt, _, _ = data\n",
    "    inputs, output_gt = inputs.to(dev), output_gt.to(dev)\n",
    "    \n",
    "\n",
    "    # forward pass to get outputs\n",
    "    outputs = model(inputs).squeeze().detach().cpu()\n",
    "    \n",
    "    gt = output_gt.cpu().squeeze()\n",
    "    \n",
    "    c = -output_gt[:,2]*torch.cos(output_gt[:,0]) + output_gt[:,1]*torch.sin(output_gt[:,0])\n",
    "    angle_params = torch.stack((-torch.sin(output_gt[:,0]),torch.cos(output_gt[:,0]),c),axis=1).detach().cpu()\n",
    "  \n",
    "    # Calculate angular loss\n",
    "    ang_loss = torch.mean(torch.abs(torch.rad2deg(torch.atan2(-angle_params[:,0]*outputs[:,1] + angle_params[:,1]*outputs[:,0]\n",
    "                                         ,angle_params[:,1]*outputs[:,1]+angle_params[:,0]*outputs[:,0]).cpu())))\n",
    "\n",
    "    ang_loss_all.append(ang_loss)\n",
    "\n",
    "    \n",
    "print(ang_loss_all)\n",
    "\n",
    "plt.figure(figsize=[15, 15])\n",
    "\n",
    "for ii in range(9):\n",
    "    \n",
    "    plt.subplot(3,3,ii+1)\n",
    "    plt.imshow(inputs[ii].cpu().squeeze(),cmap='gray', vmin=0, vmax=1)\n",
    "    \n",
    "    # Plot the ground truth lines\n",
    "    x_sample = torch.linspace(-1,1,inputs.shape[-1])\n",
    "    y_sample = -angle_params[ii,0]/angle_params[ii,1]*x_sample - angle_params[ii,2]/angle_params[ii,1]\n",
    "    \n",
    "    plt.plot(x_sample*W/2+W/2,y_sample*W/2+W/2,'b')\n",
    "    plt.xlim([0,W])\n",
    "    plt.ylim(([0,W]))\n",
    "    \n",
    "    # Plot the estimated lines\n",
    "    y_est = -outputs[ii,0]/outputs[ii,1]*x_sample - outputs[ii,2]/outputs[ii,1]\n",
    "    plt.plot(x_sample*W/2+W/2,y_est*W/2+W/2,'r')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16dd8ecb",
   "metadata": {},
   "source": [
    "## 2) noisy (variable noise per image), multicolor images - 808 parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "7feb4047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50000, 1, 32, 32])\n",
      "50000\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1080 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load dataset \n",
    "\n",
    "data_folder = 'foj_data/grayscale_lines/'\n",
    "\n",
    "with open(data_folder + 'line_data_32_50000_grey_multicolor_noise_random_uncentered.pkl','rb') as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "# wedges = data['wedges']\n",
    "wedges_grey = data['wedges_grey']\n",
    "params = data['params']\n",
    "boundaries = data['boundaries']\n",
    "wedges = data['wedges']\n",
    "\n",
    "\n",
    "line_data = LineDataset(wedges_grey, params, boundaries, wedges)#, transform=trainTransform)\n",
    "data_size = len(line_data)\n",
    "\n",
    "print(wedges_grey.shape)\n",
    "print(data_size)\n",
    "\n",
    "train_proportion = .85\n",
    "# Split dataset into training and testing\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(line_data, [int(data_size*train_proportion), int(data_size*(1-train_proportion))], generator=torch.Generator().manual_seed(42))\n",
    "\n",
    "# Create loaders for the training and testing data\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=1000, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=500, shuffle=False) #len(test_dataset)\n",
    "\n",
    "\n",
    "W,H = 32,32\n",
    "\n",
    "img_show = 0\n",
    "plt.figure(figsize=[15, 15])\n",
    "plt.subplot(131)\n",
    "plt.imshow(wedges[img_show,:,:].squeeze().permute(1,2,0).cpu())\n",
    "plt.title('RGB Image')\n",
    "plt.axis('off');\n",
    "plt.subplot(132)\n",
    "plt.imshow(wedges_grey[img_show,:,:].squeeze().cpu(),cmap='gray', vmin=0, vmax=1)\n",
    "plt.title('Grayscale Image')\n",
    "plt.axis('off');\n",
    "plt.subplot(133)\n",
    "plt.imshow(boundaries[img_show,:,:].squeeze().cpu(),cmap='gray', vmin=0, vmax=1)\n",
    "plt.title('Boundaries')\n",
    "plt.axis('off');\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "b144d367",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1            [-1, 4, 30, 30]              40\n",
      "              ReLU-2            [-1, 4, 30, 30]               0\n",
      "            Conv2d-3            [-1, 4, 28, 28]             148\n",
      "              ReLU-4            [-1, 4, 28, 28]               0\n",
      "            Conv2d-5            [-1, 4, 26, 26]             148\n",
      "              ReLU-6            [-1, 4, 26, 26]               0\n",
      "            Conv2d-7            [-1, 1, 24, 24]              37\n",
      "         MaxPool2d-8            [-1, 1, 12, 12]               0\n",
      "         AvgPool2d-9              [-1, 1, 4, 4]               0\n",
      "           Linear-10                    [-1, 3]              51\n",
      "================================================================\n",
      "Total params: 424\n",
      "Trainable params: 424\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.15\n",
      "Params size (MB): 0.00\n",
      "Estimated Total Size (MB): 0.16\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "class offCenterLineNet(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "                \n",
    "        self.conv1 = nn.Conv2d(1, 4, kernel_size=3) #64 is good\n",
    "        self.conv2 = nn.Conv2d(4, 4, kernel_size=3)\n",
    "        self.conv3 = nn.Conv2d(4, 4, kernel_size=3)\n",
    "        self.conv4 = nn.Conv2d(4, 1, kernel_size=3)\n",
    "#         self.conv5 = nn.Conv2d(4, 1, kernel_size=3)\n",
    "        self.fc = nn.LazyLinear(3)\n",
    "        self.maxpool = nn.MaxPool2d(2)\n",
    "        self.avgpool = nn.AvgPool2d(3)\n",
    "        self.activate = nn.ReLU()\n",
    "#         self.batchnorm = nn.BatchNorm2d(128)\n",
    "    \n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.conv1(x)\n",
    "#         x = F.relu(x)\n",
    "        x = self.activate(x)\n",
    "#         x = self.maxpool(x)\n",
    "#         x = self.batchnorm(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.activate(x)\n",
    "#         x = F.relu(x)\n",
    "#         x = self.batchnorm(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.activate(x)\n",
    "        x = self.conv4(x)\n",
    "#         x = self.activate(x)\n",
    "#         x = self.conv5(x)\n",
    "        \n",
    "        x = self.maxpool(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.shape[0],-1)\n",
    "        \n",
    "        x = self.fc(x)\n",
    "         \n",
    "        # We're defining\n",
    "        # a = - sin(theta)\n",
    "        # b = cos(theta)\n",
    "        # c = -cy*cos(theta)+cx*sin(theta)\n",
    "        # Hence, we want to normalize the vector by 1/sqrt(a^2 + b^2)\n",
    "        norm_factor = (torch.norm(x[:,:2],p=2,dim=1)).unsqueeze(1)       \n",
    "        out = x/(norm_factor)#+eps)\n",
    "#         print('Output shape=',x.shape)\n",
    "\n",
    "#         out = x\n",
    "        \n",
    "        return out\n",
    "    \n",
    "model = offCenterLineNet()\n",
    "model = model.to(dev)\n",
    "summary(model, input_size=(1, H, W))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "0f59a52a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Avg. Train Loss: 0.6788065863210101, Avg. Test Loss: 0.5675531029701233\n",
      "Epoch: 2, Avg. Train Loss: 0.4215945878694224, Avg. Test Loss: 0.44449251890182495\n",
      "Epoch: 3, Avg. Train Loss: 0.4045008088267127, Avg. Test Loss: 0.3137219548225403\n",
      "Epoch: 4, Avg. Train Loss: 0.192260776148286, Avg. Test Loss: 0.13447639346122742\n",
      "Epoch: 5, Avg. Train Loss: 0.07950862540408622, Avg. Test Loss: 0.05487624555826187\n",
      "Epoch: 6, Avg. Train Loss: 0.04511219566298086, Avg. Test Loss: 0.03786630183458328\n",
      "Epoch: 7, Avg. Train Loss: 0.03278923381206601, Avg. Test Loss: 0.0285464096814394\n",
      "Epoch: 8, Avg. Train Loss: 0.024978281193694402, Avg. Test Loss: 0.021947406232357025\n",
      "Epoch: 9, Avg. Train Loss: 0.019289766849820002, Avg. Test Loss: 0.017035609111189842\n",
      "Epoch: 10, Avg. Train Loss: 0.015105392610610918, Avg. Test Loss: 0.013446365483105183\n",
      "Epoch: 11, Avg. Train Loss: 0.0086152711450014, Avg. Test Loss: 0.006125062704086304\n",
      "Epoch: 12, Avg. Train Loss: 0.00497179162190404, Avg. Test Loss: 0.004004119895398617\n",
      "Epoch: 13, Avg. Train Loss: 0.0034080459898727577, Avg. Test Loss: 0.002880111802369356\n",
      "Epoch: 14, Avg. Train Loss: 0.0025767008015929265, Avg. Test Loss: 0.0022608425933867693\n",
      "Epoch: 15, Avg. Train Loss: 0.0020804692812393917, Avg. Test Loss: 0.00190803874284029\n",
      "Epoch: 16, Avg. Train Loss: 0.0017707536137814438, Avg. Test Loss: 0.0016892459243535995\n",
      "Epoch: 17, Avg. Train Loss: 0.0015709955315647084, Avg. Test Loss: 0.001473227865062654\n",
      "Epoch: 18, Avg. Train Loss: 0.001418560607965256, Avg. Test Loss: 0.0014028880978003144\n",
      "Epoch: 19, Avg. Train Loss: 0.0013207879491410283, Avg. Test Loss: 0.0012500201119109988\n",
      "Epoch: 20, Avg. Train Loss: 0.0012245416332599382, Avg. Test Loss: 0.0011788953561335802\n",
      "Epoch: 21, Avg. Train Loss: 0.0011469432488517013, Avg. Test Loss: 0.0011116234818473458\n",
      "Epoch: 22, Avg. Train Loss: 0.0010929569699476625, Avg. Test Loss: 0.0010550972074270248\n",
      "Epoch: 23, Avg. Train Loss: 0.0010466526646903435, Avg. Test Loss: 0.0010296060936525464\n",
      "Epoch: 24, Avg. Train Loss: 0.0010287694397469072, Avg. Test Loss: 0.001004983438178897\n",
      "Epoch: 25, Avg. Train Loss: 0.001007590701446197, Avg. Test Loss: 0.0009994960855692625\n",
      "Epoch: 26, Avg. Train Loss: 0.0009852915103438981, Avg. Test Loss: 0.0009862082079052925\n",
      "Epoch: 27, Avg. Train Loss: 0.0009726826480568148, Avg. Test Loss: 0.0009721153182908893\n",
      "Epoch: 28, Avg. Train Loss: 0.0009680115171101723, Avg. Test Loss: 0.0009558885358273983\n",
      "Epoch: 29, Avg. Train Loss: 0.0009617170692573107, Avg. Test Loss: 0.0009698352077975869\n",
      "Epoch: 30, Avg. Train Loss: 0.0009486210508120441, Avg. Test Loss: 0.0009460914297960699\n",
      "Epoch: 31, Avg. Train Loss: 0.0009491150592302167, Avg. Test Loss: 0.000929762318264693\n",
      "Epoch: 32, Avg. Train Loss: 0.0009379539825563687, Avg. Test Loss: 0.000930926704313606\n",
      "Epoch: 33, Avg. Train Loss: 0.0009342111703983053, Avg. Test Loss: 0.0009647483238950372\n",
      "Epoch: 34, Avg. Train Loss: 0.0009369954458697764, Avg. Test Loss: 0.0009165120427496731\n",
      "Epoch: 35, Avg. Train Loss: 0.0009243147891707891, Avg. Test Loss: 0.0009291517781093717\n",
      "Epoch: 36, Avg. Train Loss: 0.000925571228604937, Avg. Test Loss: 0.0009272651514038444\n",
      "Epoch: 37, Avg. Train Loss: 0.0009252773719666482, Avg. Test Loss: 0.0009044174221344292\n",
      "Epoch: 38, Avg. Train Loss: 0.0009231042850567678, Avg. Test Loss: 0.0009104185155592859\n",
      "Epoch: 39, Avg. Train Loss: 0.0009172739986286954, Avg. Test Loss: 0.0008954009390436113\n",
      "Epoch: 40, Avg. Train Loss: 0.0009144075975623415, Avg. Test Loss: 0.0009070807718671858\n",
      "Epoch: 41, Avg. Train Loss: 0.0009215122703354546, Avg. Test Loss: 0.0009207904222421348\n",
      "Epoch: 42, Avg. Train Loss: 0.0009146812331299623, Avg. Test Loss: 0.0009197251056320965\n",
      "Epoch: 43, Avg. Train Loss: 0.0009237741103915628, Avg. Test Loss: 0.0009008805500343442\n",
      "Epoch: 44, Avg. Train Loss: 0.0009041947642947699, Avg. Test Loss: 0.0008938658284023404\n",
      "Epoch: 45, Avg. Train Loss: 0.0009131673655775917, Avg. Test Loss: 0.0009141869959421456\n",
      "Epoch: 46, Avg. Train Loss: 0.0009146680470642656, Avg. Test Loss: 0.0009032053640112281\n",
      "Epoch: 47, Avg. Train Loss: 0.0009101913919737346, Avg. Test Loss: 0.0008800719515420496\n",
      "Epoch: 48, Avg. Train Loss: 0.0008985670120996791, Avg. Test Loss: 0.0008928602328523993\n",
      "Epoch: 49, Avg. Train Loss: 0.0008972100358521349, Avg. Test Loss: 0.0008895318023860455\n",
      "Epoch: 50, Avg. Train Loss: 0.0008986899277281969, Avg. Test Loss: 0.0008779624477028847\n",
      "Epoch: 51, Avg. Train Loss: 0.00089182069276048, Avg. Test Loss: 0.0008792089647613466\n",
      "Epoch: 52, Avg. Train Loss: 0.0008950426654760228, Avg. Test Loss: 0.0009022130398079753\n",
      "Epoch: 53, Avg. Train Loss: 0.0009027642095028314, Avg. Test Loss: 0.0008906080038286746\n",
      "Epoch: 54, Avg. Train Loss: 0.0008961988090494172, Avg. Test Loss: 0.0008796045440249145\n",
      "Epoch: 55, Avg. Train Loss: 0.0009061403391168041, Avg. Test Loss: 0.0008933115168474615\n",
      "Epoch: 56, Avg. Train Loss: 0.0009028415146911906, Avg. Test Loss: 0.0008738766773603857\n",
      "Epoch: 57, Avg. Train Loss: 0.0008915119891076587, Avg. Test Loss: 0.0008856601198203862\n",
      "Epoch: 58, Avg. Train Loss: 0.0009005493525047462, Avg. Test Loss: 0.0008680792525410652\n",
      "Epoch: 59, Avg. Train Loss: 0.000882720711456915, Avg. Test Loss: 0.0008652828400954604\n",
      "Epoch: 60, Avg. Train Loss: 0.0008826855540297233, Avg. Test Loss: 0.0008762559737078846\n",
      "Epoch: 61, Avg. Train Loss: 0.0008808829318082263, Avg. Test Loss: 0.0008711633854545653\n",
      "Epoch: 62, Avg. Train Loss: 0.0008729880981602122, Avg. Test Loss: 0.0008616094128228724\n",
      "Epoch: 63, Avg. Train Loss: 0.0008754398427405503, Avg. Test Loss: 0.0008476749644614756\n",
      "Epoch: 64, Avg. Train Loss: 0.0008664533893880976, Avg. Test Loss: 0.0008444164413958788\n",
      "Epoch: 65, Avg. Train Loss: 0.0008604653953942795, Avg. Test Loss: 0.0008573256782256067\n",
      "Epoch: 66, Avg. Train Loss: 0.0008560712936572558, Avg. Test Loss: 0.0008612169185653329\n",
      "Epoch: 67, Avg. Train Loss: 0.0008622422884759861, Avg. Test Loss: 0.0008341887150891125\n",
      "Epoch: 68, Avg. Train Loss: 0.0008585795727666727, Avg. Test Loss: 0.0008385044056922197\n",
      "Epoch: 69, Avg. Train Loss: 0.0008509363126291265, Avg. Test Loss: 0.000827004318125546\n",
      "Epoch: 70, Avg. Train Loss: 0.0008514881374985846, Avg. Test Loss: 0.0008242781623266637\n",
      "Epoch: 71, Avg. Train Loss: 0.0008520391068507939, Avg. Test Loss: 0.0008376265759579837\n",
      "Epoch: 72, Avg. Train Loss: 0.0008507941871188408, Avg. Test Loss: 0.0008239105227403343\n",
      "Epoch: 73, Avg. Train Loss: 0.0008492234723404223, Avg. Test Loss: 0.0008289975812658668\n",
      "Epoch: 74, Avg. Train Loss: 0.000859692185131703, Avg. Test Loss: 0.0008254326530732214\n",
      "Epoch: 75, Avg. Train Loss: 0.0008458754502583382, Avg. Test Loss: 0.000820656365249306\n",
      "Epoch: 76, Avg. Train Loss: 0.00085283252194004, Avg. Test Loss: 0.0008226103964261711\n",
      "Epoch: 77, Avg. Train Loss: 0.0008466518213322689, Avg. Test Loss: 0.0008227608632296324\n",
      "Epoch: 78, Avg. Train Loss: 0.0008473254992020164, Avg. Test Loss: 0.0008235357236117125\n",
      "Epoch: 79, Avg. Train Loss: 0.0008458262620775332, Avg. Test Loss: 0.0008333600708283484\n",
      "Epoch: 80, Avg. Train Loss: 0.000845519948999809, Avg. Test Loss: 0.0008292730199173093\n",
      "Epoch: 81, Avg. Train Loss: 0.0008513969057889352, Avg. Test Loss: 0.0008453732007183135\n",
      "Epoch: 82, Avg. Train Loss: 0.0008484018346576323, Avg. Test Loss: 0.0008244740311056376\n",
      "Epoch: 83, Avg. Train Loss: 0.0008532795730198539, Avg. Test Loss: 0.000857237377204001\n",
      "Epoch: 84, Avg. Train Loss: 0.0008445768441116913, Avg. Test Loss: 0.0008212053216993809\n",
      "Epoch: 85, Avg. Train Loss: 0.0008360006397070233, Avg. Test Loss: 0.0008273792336694896\n",
      "Epoch: 86, Avg. Train Loss: 0.0008474005234622678, Avg. Test Loss: 0.0008236310677602887\n",
      "Epoch: 87, Avg. Train Loss: 0.0008485458674840629, Avg. Test Loss: 0.0008264407515525818\n",
      "Epoch: 88, Avg. Train Loss: 0.0008506934594384633, Avg. Test Loss: 0.0008144177845679224\n",
      "Epoch: 89, Avg. Train Loss: 0.0008388034658246609, Avg. Test Loss: 0.0008150516077876091\n",
      "Epoch: 90, Avg. Train Loss: 0.0008553920102543956, Avg. Test Loss: 0.000817090563941747\n",
      "Epoch: 91, Avg. Train Loss: 0.0008409271587964234, Avg. Test Loss: 0.0008219804149121046\n",
      "Epoch: 92, Avg. Train Loss: 0.0008355841259905245, Avg. Test Loss: 0.000816499232314527\n",
      "Epoch: 93, Avg. Train Loss: 0.0008364039362234951, Avg. Test Loss: 0.0008302450878545642\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 94, Avg. Train Loss: 0.0008520339859303, Avg. Test Loss: 0.0008466509752906859\n",
      "Epoch: 95, Avg. Train Loss: 0.0008407411758441392, Avg. Test Loss: 0.000829652592074126\n",
      "Epoch: 96, Avg. Train Loss: 0.000833242094729009, Avg. Test Loss: 0.0008239588350988925\n",
      "Epoch: 97, Avg. Train Loss: 0.0008355383923667115, Avg. Test Loss: 0.0008177379495464265\n",
      "Epoch: 98, Avg. Train Loss: 0.0008384599242099496, Avg. Test Loss: 0.0008168435888364911\n",
      "Epoch: 99, Avg. Train Loss: 0.0008382649921682165, Avg. Test Loss: 0.0008265840588137507\n",
      "Epoch: 100, Avg. Train Loss: 0.0008415478013650795, Avg. Test Loss: 0.0008177451090887189\n",
      "Epoch: 101, Avg. Train Loss: 0.0008451139762846016, Avg. Test Loss: 0.0008165845065377653\n",
      "Epoch: 102, Avg. Train Loss: 0.0008356644891115815, Avg. Test Loss: 0.000823759357444942\n",
      "Epoch: 103, Avg. Train Loss: 0.0008346507823917755, Avg. Test Loss: 0.000818306056316942\n",
      "Epoch: 104, Avg. Train Loss: 0.0008364685765077728, Avg. Test Loss: 0.0008202730678021908\n",
      "Epoch: 105, Avg. Train Loss: 0.000833278969959031, Avg. Test Loss: 0.0008163858437910676\n",
      "Epoch: 106, Avg. Train Loss: 0.0008296935283037466, Avg. Test Loss: 0.0008193925605155528\n",
      "Epoch: 107, Avg. Train Loss: 0.0008331378096129832, Avg. Test Loss: 0.0008220339077524841\n",
      "Epoch: 108, Avg. Train Loss: 0.0008384936995436112, Avg. Test Loss: 0.0008370974683202803\n",
      "Epoch: 109, Avg. Train Loss: 0.0008354119044122134, Avg. Test Loss: 0.000824295508209616\n",
      "Epoch: 110, Avg. Train Loss: 0.0008258280211648103, Avg. Test Loss: 0.0008144719176925719\n",
      "Epoch: 111, Avg. Train Loss: 0.0008286624946523198, Avg. Test Loss: 0.0008118844707496464\n",
      "Epoch: 112, Avg. Train Loss: 0.0008323707125084691, Avg. Test Loss: 0.0008149456116370857\n",
      "Epoch: 113, Avg. Train Loss: 0.0008323012017320062, Avg. Test Loss: 0.0008114773081615567\n",
      "Epoch: 114, Avg. Train Loss: 0.0008263620331363622, Avg. Test Loss: 0.0008196338894777\n",
      "Epoch: 115, Avg. Train Loss: 0.0008229721448557495, Avg. Test Loss: 0.0008317366591654718\n",
      "Epoch: 116, Avg. Train Loss: 0.0008381347708014208, Avg. Test Loss: 0.0008219362352974713\n",
      "Epoch: 117, Avg. Train Loss: 0.0008294722308989528, Avg. Test Loss: 0.0008032253826968372\n",
      "Epoch: 118, Avg. Train Loss: 0.0008224515301218732, Avg. Test Loss: 0.0008248334052041173\n",
      "Epoch: 119, Avg. Train Loss: 0.0008308155405291811, Avg. Test Loss: 0.0008300213376060128\n",
      "Epoch: 120, Avg. Train Loss: 0.0008254626787505871, Avg. Test Loss: 0.0008086235029622912\n",
      "Epoch: 121, Avg. Train Loss: 0.0008283532170448886, Avg. Test Loss: 0.0008448370499536395\n",
      "Epoch: 122, Avg. Train Loss: 0.0008339264543813675, Avg. Test Loss: 0.0008327457471750677\n",
      "Epoch: 123, Avg. Train Loss: 0.0008292734950542623, Avg. Test Loss: 0.0008026650175452232\n",
      "Epoch: 124, Avg. Train Loss: 0.0008289295107905948, Avg. Test Loss: 0.0008302959613502026\n",
      "Epoch: 125, Avg. Train Loss: 0.0008310846981679111, Avg. Test Loss: 0.000807263539172709\n",
      "Epoch: 126, Avg. Train Loss: 0.0008268029155577858, Avg. Test Loss: 0.0008062144042924047\n",
      "Epoch: 127, Avg. Train Loss: 0.0008293331145893696, Avg. Test Loss: 0.0008336107130162418\n",
      "Epoch: 128, Avg. Train Loss: 0.000825325274829168, Avg. Test Loss: 0.0008647639770060778\n",
      "Epoch: 129, Avg. Train Loss: 0.0008291670670841149, Avg. Test Loss: 0.0008308992255479097\n",
      "Epoch: 130, Avg. Train Loss: 0.0008238911991505775, Avg. Test Loss: 0.0008117252145893872\n",
      "Epoch: 131, Avg. Train Loss: 0.0008301342049678571, Avg. Test Loss: 0.0008059975225478411\n",
      "Epoch: 132, Avg. Train Loss: 0.0008253640235336714, Avg. Test Loss: 0.0008181286393664777\n",
      "Epoch: 133, Avg. Train Loss: 0.0008251864522652224, Avg. Test Loss: 0.0008237097645178437\n",
      "Epoch: 134, Avg. Train Loss: 0.0008204774971683185, Avg. Test Loss: 0.0008042932604439557\n",
      "Epoch: 135, Avg. Train Loss: 0.0008211399274228444, Avg. Test Loss: 0.0008039684616960585\n",
      "Epoch: 136, Avg. Train Loss: 0.0008174122451956189, Avg. Test Loss: 0.0008043075213208795\n",
      "Epoch: 137, Avg. Train Loss: 0.0008186355766537058, Avg. Test Loss: 0.000812274927739054\n",
      "Epoch: 138, Avg. Train Loss: 0.0008177590884030038, Avg. Test Loss: 0.0008152350201271474\n",
      "Epoch: 139, Avg. Train Loss: 0.0008277780265374065, Avg. Test Loss: 0.00081736093852669\n",
      "Epoch: 140, Avg. Train Loss: 0.0008175577372745719, Avg. Test Loss: 0.0008237166330218315\n",
      "Epoch: 141, Avg. Train Loss: 0.0008195949878088783, Avg. Test Loss: 0.0008217875147238374\n",
      "Epoch: 142, Avg. Train Loss: 0.0008174461802619315, Avg. Test Loss: 0.0008115824311971664\n",
      "Epoch: 143, Avg. Train Loss: 0.0008158005197359205, Avg. Test Loss: 0.0008072974160313606\n",
      "Epoch: 144, Avg. Train Loss: 0.0008195499797503269, Avg. Test Loss: 0.0008231768733821809\n",
      "Epoch: 145, Avg. Train Loss: 0.000816615812783671, Avg. Test Loss: 0.0008033254998736084\n",
      "Epoch: 146, Avg. Train Loss: 0.0008167065246853718, Avg. Test Loss: 0.0008020248496904969\n",
      "Epoch: 147, Avg. Train Loss: 0.0008190446844606032, Avg. Test Loss: 0.000815784209407866\n",
      "Epoch: 148, Avg. Train Loss: 0.0008158640324159764, Avg. Test Loss: 0.0008154611568897963\n",
      "Epoch: 149, Avg. Train Loss: 0.0008157553059200561, Avg. Test Loss: 0.0008024148410186172\n",
      "Epoch: 150, Avg. Train Loss: 0.0008187865632651157, Avg. Test Loss: 0.0007999158115126193\n",
      "Epoch: 151, Avg. Train Loss: 0.0008130970513881293, Avg. Test Loss: 0.0008079065009951591\n",
      "Epoch: 152, Avg. Train Loss: 0.0008187904997273933, Avg. Test Loss: 0.000820192217361182\n",
      "Epoch: 153, Avg. Train Loss: 0.0008186029018509354, Avg. Test Loss: 0.0008039741078391671\n",
      "Epoch: 154, Avg. Train Loss: 0.0008151022416842712, Avg. Test Loss: 0.0008053987403400242\n",
      "Epoch: 155, Avg. Train Loss: 0.0008134810283758439, Avg. Test Loss: 0.0008304903167299926\n",
      "Epoch: 156, Avg. Train Loss: 0.0008163468081092592, Avg. Test Loss: 0.0008177895797416568\n",
      "Epoch: 157, Avg. Train Loss: 0.0008123504298435914, Avg. Test Loss: 0.0008425834821537137\n",
      "Epoch: 158, Avg. Train Loss: 0.000815148216260727, Avg. Test Loss: 0.0008091560448519886\n",
      "Epoch: 159, Avg. Train Loss: 0.0008064923363976008, Avg. Test Loss: 0.0008100564009509981\n",
      "Epoch: 160, Avg. Train Loss: 0.000816549886516187, Avg. Test Loss: 0.0008143927552737296\n",
      "Epoch: 161, Avg. Train Loss: 0.0008206740576708906, Avg. Test Loss: 0.0008356124744750559\n",
      "Epoch: 162, Avg. Train Loss: 0.000818738846519832, Avg. Test Loss: 0.0008149645291268826\n",
      "Epoch: 163, Avg. Train Loss: 0.0008133020736601983, Avg. Test Loss: 0.0008200646261684597\n",
      "Epoch: 164, Avg. Train Loss: 0.0008112477831715762, Avg. Test Loss: 0.0008091716445051134\n",
      "Epoch: 165, Avg. Train Loss: 0.0008102106092887563, Avg. Test Loss: 0.0008118754485622048\n",
      "Epoch: 166, Avg. Train Loss: 0.0008093702855931465, Avg. Test Loss: 0.0008256469736807048\n",
      "Epoch: 167, Avg. Train Loss: 0.0008092223677437666, Avg. Test Loss: 0.0008059228421188891\n",
      "Epoch: 168, Avg. Train Loss: 0.0008108258317766148, Avg. Test Loss: 0.0008162005105987191\n",
      "Epoch: 169, Avg. Train Loss: 0.0008097753879007731, Avg. Test Loss: 0.0008076028898358345\n",
      "Epoch: 170, Avg. Train Loss: 0.0008088617401500774, Avg. Test Loss: 0.0008131263311952353\n",
      "Epoch: 171, Avg. Train Loss: 0.000806610187959619, Avg. Test Loss: 0.0008138719713315368\n",
      "Epoch: 172, Avg. Train Loss: 0.0008061302901613851, Avg. Test Loss: 0.0008160294964909554\n",
      "Epoch: 173, Avg. Train Loss: 0.0008097083570413984, Avg. Test Loss: 0.0008264128118753433\n",
      "Epoch: 174, Avg. Train Loss: 0.0008056020637605946, Avg. Test Loss: 0.0008038394735194743\n",
      "Epoch: 175, Avg. Train Loss: 0.0008052869383137414, Avg. Test Loss: 0.0007985725533217192\n",
      "Epoch: 176, Avg. Train Loss: 0.0008050322635532465, Avg. Test Loss: 0.0008203827310353518\n",
      "Epoch: 177, Avg. Train Loss: 0.0008097531755866353, Avg. Test Loss: 0.0008264757343567908\n",
      "Epoch: 178, Avg. Train Loss: 0.0008083475363809009, Avg. Test Loss: 0.0008006754796952009\n",
      "Epoch: 179, Avg. Train Loss: 0.0008024538997127566, Avg. Test Loss: 0.000798437453340739\n",
      "Epoch: 180, Avg. Train Loss: 0.0008044239691307032, Avg. Test Loss: 0.0008078990504145622\n",
      "Epoch: 181, Avg. Train Loss: 0.0008176481919796314, Avg. Test Loss: 0.0008196645649150014\n",
      "Epoch: 182, Avg. Train Loss: 0.0008020054895517438, Avg. Test Loss: 0.0008201990858651698\n",
      "Epoch: 183, Avg. Train Loss: 0.0007991433159859721, Avg. Test Loss: 0.0007998002110980451\n",
      "Epoch: 184, Avg. Train Loss: 0.0007973369698278433, Avg. Test Loss: 0.0007903214427642524\n",
      "Epoch: 185, Avg. Train Loss: 0.0007931788067528328, Avg. Test Loss: 0.0007960650254972279\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 186, Avg. Train Loss: 0.0008012973838810657, Avg. Test Loss: 0.0007913447334431112\n",
      "Epoch: 187, Avg. Train Loss: 0.0007928887701614998, Avg. Test Loss: 0.0008143113227561116\n",
      "Epoch: 188, Avg. Train Loss: 0.0007929448133096272, Avg. Test Loss: 0.0008504340657964349\n",
      "Epoch: 189, Avg. Train Loss: 0.0007926897784738346, Avg. Test Loss: 0.0007810751558281481\n",
      "Epoch: 190, Avg. Train Loss: 0.0007823665875421707, Avg. Test Loss: 0.0007907641702331603\n",
      "Epoch: 191, Avg. Train Loss: 0.0007785455835441691, Avg. Test Loss: 0.0007754757534712553\n",
      "Epoch: 192, Avg. Train Loss: 0.000775143104811134, Avg. Test Loss: 0.0007880437769927084\n",
      "Epoch: 193, Avg. Train Loss: 0.0007767108929625084, Avg. Test Loss: 0.0007906421087682247\n",
      "Epoch: 194, Avg. Train Loss: 0.0007718279957771301, Avg. Test Loss: 0.0007639590185135603\n",
      "Epoch: 195, Avg. Train Loss: 0.000769539141951692, Avg. Test Loss: 0.0007723097805865109\n",
      "Epoch: 196, Avg. Train Loss: 0.0007706122800469571, Avg. Test Loss: 0.000788825040217489\n",
      "Epoch: 197, Avg. Train Loss: 0.0007648881021237304, Avg. Test Loss: 0.0007492039003409445\n",
      "Epoch: 198, Avg. Train Loss: 0.0007634236271558113, Avg. Test Loss: 0.0007515337783843279\n",
      "Epoch: 199, Avg. Train Loss: 0.0007579832183478703, Avg. Test Loss: 0.0007553520845249295\n",
      "Epoch: 200, Avg. Train Loss: 0.0007505522009396795, Avg. Test Loss: 0.0007406696677207947\n",
      "Epoch: 201, Avg. Train Loss: 0.000746434268834026, Avg. Test Loss: 0.0007347385981120169\n",
      "Epoch: 202, Avg. Train Loss: 0.0007415621617245813, Avg. Test Loss: 0.0007473864825442433\n",
      "Epoch: 203, Avg. Train Loss: 0.0007427967421515564, Avg. Test Loss: 0.000732489163056016\n",
      "Epoch: 204, Avg. Train Loss: 0.000738696564736148, Avg. Test Loss: 0.0007301454315893352\n",
      "Epoch: 205, Avg. Train Loss: 0.0007358376101893915, Avg. Test Loss: 0.0007300939760170877\n",
      "Epoch: 206, Avg. Train Loss: 0.0007313980861718572, Avg. Test Loss: 0.0007265144377015531\n",
      "Epoch: 207, Avg. Train Loss: 0.0007331723165914936, Avg. Test Loss: 0.0007294557872228324\n",
      "Epoch: 208, Avg. Train Loss: 0.0007310517654797538, Avg. Test Loss: 0.0007232570205815136\n",
      "Epoch: 209, Avg. Train Loss: 0.0007283119687832199, Avg. Test Loss: 0.0007235697703436017\n",
      "Epoch: 210, Avg. Train Loss: 0.0007311845276786318, Avg. Test Loss: 0.0007344599580392241\n",
      "Epoch: 211, Avg. Train Loss: 0.0007259360620167193, Avg. Test Loss: 0.0007187667652033269\n",
      "Epoch: 212, Avg. Train Loss: 0.0007263205019583882, Avg. Test Loss: 0.0007194448262453079\n",
      "Epoch: 213, Avg. Train Loss: 0.0007306561144718597, Avg. Test Loss: 0.0007148419972509146\n",
      "Epoch: 214, Avg. Train Loss: 0.0007194241814770151, Avg. Test Loss: 0.0007229361799545586\n",
      "Epoch: 215, Avg. Train Loss: 0.0007250353905134076, Avg. Test Loss: 0.0007101611699908972\n",
      "Epoch: 216, Avg. Train Loss: 0.0007202105371952924, Avg. Test Loss: 0.0007111066370271146\n",
      "Epoch: 217, Avg. Train Loss: 0.0007131239358703931, Avg. Test Loss: 0.0007079066708683968\n",
      "Epoch: 218, Avg. Train Loss: 0.0007083544326231403, Avg. Test Loss: 0.000692771456670016\n",
      "Epoch: 219, Avg. Train Loss: 0.0007056440714053637, Avg. Test Loss: 0.0006933792610652745\n",
      "Epoch: 220, Avg. Train Loss: 0.0006989762782617364, Avg. Test Loss: 0.0006912993267178535\n",
      "Epoch: 221, Avg. Train Loss: 0.0006939552610653431, Avg. Test Loss: 0.000676443800330162\n",
      "Epoch: 222, Avg. Train Loss: 0.0006824889339419991, Avg. Test Loss: 0.0006770344916731119\n",
      "Epoch: 223, Avg. Train Loss: 0.0006780157347621266, Avg. Test Loss: 0.0006686855340376496\n",
      "Epoch: 224, Avg. Train Loss: 0.000669470083964772, Avg. Test Loss: 0.0006768782041035593\n",
      "Epoch: 225, Avg. Train Loss: 0.0006634927216679031, Avg. Test Loss: 0.0006643073866143823\n",
      "Epoch: 226, Avg. Train Loss: 0.0006619119139518155, Avg. Test Loss: 0.0006535329739563167\n",
      "Epoch: 227, Avg. Train Loss: 0.0006514258647532484, Avg. Test Loss: 0.0006498898146674037\n",
      "Epoch: 228, Avg. Train Loss: 0.0006497707082565095, Avg. Test Loss: 0.0006444395403377712\n",
      "Epoch: 229, Avg. Train Loss: 0.000642749578367139, Avg. Test Loss: 0.0006709887529723346\n",
      "Epoch: 230, Avg. Train Loss: 0.0006424695805668138, Avg. Test Loss: 0.0006556899170391262\n",
      "Epoch: 231, Avg. Train Loss: 0.0006402103964044431, Avg. Test Loss: 0.0006380901322700083\n",
      "Epoch: 232, Avg. Train Loss: 0.0006327193560685183, Avg. Test Loss: 0.0006316657527349889\n",
      "Epoch: 233, Avg. Train Loss: 0.0006318316323855936, Avg. Test Loss: 0.0006336566875688732\n",
      "Epoch: 234, Avg. Train Loss: 0.0006296254442679848, Avg. Test Loss: 0.0006422107690013945\n",
      "Epoch: 235, Avg. Train Loss: 0.0006229781632333301, Avg. Test Loss: 0.0006169502157717943\n",
      "Epoch: 236, Avg. Train Loss: 0.0006202677952472207, Avg. Test Loss: 0.0006307626026682556\n",
      "Epoch: 237, Avg. Train Loss: 0.0006209036354300414, Avg. Test Loss: 0.0006159233744256198\n",
      "Epoch: 238, Avg. Train Loss: 0.0006191409734445949, Avg. Test Loss: 0.0006265710107982159\n",
      "Epoch: 239, Avg. Train Loss: 0.0006202254336067411, Avg. Test Loss: 0.0006113721756264567\n",
      "Epoch: 240, Avg. Train Loss: 0.0006139805258879828, Avg. Test Loss: 0.0006285916897468269\n",
      "Epoch: 241, Avg. Train Loss: 0.0006174777910589825, Avg. Test Loss: 0.0006101927137933671\n",
      "Epoch: 242, Avg. Train Loss: 0.0006127929325800303, Avg. Test Loss: 0.0006087150541134179\n",
      "Epoch: 243, Avg. Train Loss: 0.0006094966571084982, Avg. Test Loss: 0.0006066839559935033\n",
      "Epoch: 244, Avg. Train Loss: 0.0006073233238313088, Avg. Test Loss: 0.0006037374841980636\n",
      "Epoch: 245, Avg. Train Loss: 0.0006060501354811496, Avg. Test Loss: 0.0006045873742550611\n",
      "Epoch: 246, Avg. Train Loss: 0.0006050242755432115, Avg. Test Loss: 0.0006049688090570271\n",
      "Epoch: 247, Avg. Train Loss: 0.0006084645791033413, Avg. Test Loss: 0.0006056517013348639\n",
      "Epoch: 248, Avg. Train Loss: 0.0006048888019502683, Avg. Test Loss: 0.0006138152675703168\n",
      "Epoch: 249, Avg. Train Loss: 0.0006084352715460714, Avg. Test Loss: 0.0006106642540544271\n",
      "Epoch: 250, Avg. Train Loss: 0.0006059297823433786, Avg. Test Loss: 0.0006031405064277351\n",
      "Epoch: 251, Avg. Train Loss: 0.0006045322827345063, Avg. Test Loss: 0.0006015386898070574\n",
      "Epoch: 252, Avg. Train Loss: 0.0006019092478984317, Avg. Test Loss: 0.0006092243129387498\n",
      "Epoch: 253, Avg. Train Loss: 0.0006010987752572049, Avg. Test Loss: 0.0006070553208701313\n",
      "Epoch: 254, Avg. Train Loss: 0.0006003211019560695, Avg. Test Loss: 0.0006039855070412159\n",
      "Epoch: 255, Avg. Train Loss: 0.0006009734731145896, Avg. Test Loss: 0.000598620914388448\n",
      "Epoch: 256, Avg. Train Loss: 0.0005989409807181462, Avg. Test Loss: 0.0006015350809320807\n",
      "Epoch: 257, Avg. Train Loss: 0.0005972891623630773, Avg. Test Loss: 0.0006082106847316027\n",
      "Epoch: 258, Avg. Train Loss: 0.0005987598005747206, Avg. Test Loss: 0.0005996516556479037\n",
      "Epoch: 259, Avg. Train Loss: 0.0005975820132271322, Avg. Test Loss: 0.0006053617689758539\n",
      "Epoch: 260, Avg. Train Loss: 0.0006011795363562225, Avg. Test Loss: 0.0006062917527742684\n",
      "Epoch: 261, Avg. Train Loss: 0.0006050148350728112, Avg. Test Loss: 0.0006132483831606805\n",
      "Epoch: 262, Avg. Train Loss: 0.000603968814979199, Avg. Test Loss: 0.0006002958980388939\n",
      "Epoch: 263, Avg. Train Loss: 0.0005994182510496398, Avg. Test Loss: 0.0006021743174642324\n",
      "Epoch: 264, Avg. Train Loss: 0.0005980666826998945, Avg. Test Loss: 0.0006071618990972638\n",
      "Epoch: 265, Avg. Train Loss: 0.0005967473641016282, Avg. Test Loss: 0.000612084346357733\n",
      "Epoch: 266, Avg. Train Loss: 0.0005948062387814876, Avg. Test Loss: 0.0006005923496559262\n",
      "Epoch: 267, Avg. Train Loss: 0.0005994072660457256, Avg. Test Loss: 0.0006025725742802024\n",
      "Epoch: 268, Avg. Train Loss: 0.0005966473146081838, Avg. Test Loss: 0.000607490015681833\n",
      "Epoch: 269, Avg. Train Loss: 0.0005911976358918256, Avg. Test Loss: 0.0005982065922580659\n",
      "Epoch: 270, Avg. Train Loss: 0.0005931712207817581, Avg. Test Loss: 0.0006050358060747385\n",
      "Epoch: 271, Avg. Train Loss: 0.0006003555256960004, Avg. Test Loss: 0.0006032880628481507\n",
      "Epoch: 272, Avg. Train Loss: 0.0005950693739578128, Avg. Test Loss: 0.0005970654892735183\n",
      "Epoch: 273, Avg. Train Loss: 0.0005956141922492967, Avg. Test Loss: 0.0006007194751873612\n",
      "Epoch: 274, Avg. Train Loss: 0.000594242061704917, Avg. Test Loss: 0.0006024987087585032\n",
      "Epoch: 275, Avg. Train Loss: 0.0005971430286461877, Avg. Test Loss: 0.0006038443534635007\n",
      "Epoch: 276, Avg. Train Loss: 0.0005931403639531413, Avg. Test Loss: 0.0005961539573036134\n",
      "Epoch: 277, Avg. Train Loss: 0.0005909532368139819, Avg. Test Loss: 0.0005959784029982984\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 278, Avg. Train Loss: 0.0005903077490497814, Avg. Test Loss: 0.0005990809295326471\n",
      "Epoch: 279, Avg. Train Loss: 0.000592771947362222, Avg. Test Loss: 0.0006009694770909846\n",
      "Epoch: 280, Avg. Train Loss: 0.0005902781240577095, Avg. Test Loss: 0.0006172434659674764\n",
      "Epoch: 281, Avg. Train Loss: 0.0005915091660003676, Avg. Test Loss: 0.0005993511294946074\n",
      "Epoch: 282, Avg. Train Loss: 0.0005980074787404129, Avg. Test Loss: 0.000608747941441834\n",
      "Epoch: 283, Avg. Train Loss: 0.0005954324584562591, Avg. Test Loss: 0.0006022357847541571\n",
      "Epoch: 284, Avg. Train Loss: 0.0005937919188507421, Avg. Test Loss: 0.0005993524682708085\n",
      "Epoch: 285, Avg. Train Loss: 0.0005884017188881719, Avg. Test Loss: 0.000597361708059907\n",
      "Epoch: 286, Avg. Train Loss: 0.0005903832308493208, Avg. Test Loss: 0.0006098818266764283\n",
      "Epoch: 287, Avg. Train Loss: 0.0005888245596420453, Avg. Test Loss: 0.000602894346229732\n",
      "Epoch: 288, Avg. Train Loss: 0.0005907490362174982, Avg. Test Loss: 0.0006016740808263421\n",
      "Epoch: 289, Avg. Train Loss: 0.0005869768873983344, Avg. Test Loss: 0.0005968633340671659\n",
      "Epoch: 290, Avg. Train Loss: 0.0005891728918826164, Avg. Test Loss: 0.000596197263803333\n",
      "Epoch: 291, Avg. Train Loss: 0.0005865300948688284, Avg. Test Loss: 0.0006241766968742013\n",
      "Epoch: 292, Avg. Train Loss: 0.0005951548525846975, Avg. Test Loss: 0.0006178303738124669\n",
      "Epoch: 293, Avg. Train Loss: 0.0005969010093141088, Avg. Test Loss: 0.0005988042685203254\n",
      "Epoch: 294, Avg. Train Loss: 0.0005935653475611362, Avg. Test Loss: 0.0005984114832244813\n",
      "Epoch: 295, Avg. Train Loss: 0.0005857014627910631, Avg. Test Loss: 0.0005923104472458363\n",
      "Epoch: 296, Avg. Train Loss: 0.0005833826922584152, Avg. Test Loss: 0.0005980621208436787\n",
      "Epoch: 297, Avg. Train Loss: 0.0005860466910742743, Avg. Test Loss: 0.0005983763257972896\n",
      "Epoch: 298, Avg. Train Loss: 0.0005864730242878026, Avg. Test Loss: 0.0006035746773704886\n",
      "Epoch: 299, Avg. Train Loss: 0.0005905399042138354, Avg. Test Loss: 0.0005981611320748925\n",
      "Epoch: 300, Avg. Train Loss: 0.0005835346934428915, Avg. Test Loss: 0.0005978884873911738\n",
      "Epoch: 301, Avg. Train Loss: 0.0005863191394763457, Avg. Test Loss: 0.0005960469716228545\n",
      "Epoch: 302, Avg. Train Loss: 0.0005868892361366645, Avg. Test Loss: 0.0005940594710409641\n",
      "Epoch: 303, Avg. Train Loss: 0.0005903941684749064, Avg. Test Loss: 0.0005981725407764316\n",
      "Epoch: 304, Avg. Train Loss: 0.0005893100555282259, Avg. Test Loss: 0.00060471665346995\n",
      "Epoch: 305, Avg. Train Loss: 0.0005844762010045003, Avg. Test Loss: 0.0005974668893031776\n",
      "Epoch: 306, Avg. Train Loss: 0.0005915097846259731, Avg. Test Loss: 0.0006123001221567392\n",
      "Epoch: 307, Avg. Train Loss: 0.0005855588878634884, Avg. Test Loss: 0.0005912862252444029\n",
      "Epoch: 308, Avg. Train Loss: 0.0005831897670273171, Avg. Test Loss: 0.0005991830839775503\n",
      "Epoch: 309, Avg. Train Loss: 0.0005842212243763686, Avg. Test Loss: 0.0005970026249997318\n",
      "Epoch: 310, Avg. Train Loss: 0.0005891723720746678, Avg. Test Loss: 0.0006135361618362367\n",
      "Epoch: 311, Avg. Train Loss: 0.0005835976199853386, Avg. Test Loss: 0.0005956917302682996\n",
      "Epoch: 312, Avg. Train Loss: 0.0005810213259009775, Avg. Test Loss: 0.0005940305418334901\n",
      "Epoch: 313, Avg. Train Loss: 0.0005840073003931794, Avg. Test Loss: 0.000596353318542242\n",
      "Epoch: 314, Avg. Train Loss: 0.0005849631981068658, Avg. Test Loss: 0.0005946591845713556\n",
      "Epoch: 315, Avg. Train Loss: 0.000583769530220347, Avg. Test Loss: 0.0006036515114828944\n",
      "Epoch: 316, Avg. Train Loss: 0.0005822858744744904, Avg. Test Loss: 0.000597397971432656\n",
      "Epoch: 317, Avg. Train Loss: 0.0005811200880575492, Avg. Test Loss: 0.0005978133995085955\n",
      "Epoch: 318, Avg. Train Loss: 0.0005817039366161754, Avg. Test Loss: 0.0005949842161498964\n",
      "Epoch: 319, Avg. Train Loss: 0.0005859199174961378, Avg. Test Loss: 0.0005923184216953814\n",
      "Epoch: 320, Avg. Train Loss: 0.0005848466386195532, Avg. Test Loss: 0.0005971036734990776\n",
      "Epoch: 321, Avg. Train Loss: 0.0005817789622300933, Avg. Test Loss: 0.0006055693957023323\n",
      "Epoch: 322, Avg. Train Loss: 0.0005820034163852417, Avg. Test Loss: 0.0005971312639303505\n",
      "Epoch: 323, Avg. Train Loss: 0.0005810503119624458, Avg. Test Loss: 0.0005945419543422759\n",
      "Epoch: 324, Avg. Train Loss: 0.000580595891522027, Avg. Test Loss: 0.0005998393171466887\n",
      "Epoch: 325, Avg. Train Loss: 0.0005813949148517188, Avg. Test Loss: 0.0005975438398309052\n",
      "Epoch: 326, Avg. Train Loss: 0.0005772041013399356, Avg. Test Loss: 0.0006063026376068592\n",
      "Epoch: 327, Avg. Train Loss: 0.000580792741032404, Avg. Test Loss: 0.0005917366943322122\n",
      "Epoch: 328, Avg. Train Loss: 0.000579100823690465, Avg. Test Loss: 0.0005950417253188789\n",
      "Epoch: 329, Avg. Train Loss: 0.0005789553816971737, Avg. Test Loss: 0.0005959829431958497\n",
      "Epoch: 330, Avg. Train Loss: 0.0005845395092809097, Avg. Test Loss: 0.0005977129330858588\n",
      "Epoch: 331, Avg. Train Loss: 0.000581967128646495, Avg. Test Loss: 0.0005929650506004691\n",
      "Epoch: 332, Avg. Train Loss: 0.0005824824491905612, Avg. Test Loss: 0.0005904727149754763\n",
      "Epoch: 333, Avg. Train Loss: 0.000580830795305976, Avg. Test Loss: 0.0005934116197749972\n",
      "Epoch: 334, Avg. Train Loss: 0.0005820242601425148, Avg. Test Loss: 0.0005947360186837614\n",
      "Epoch: 335, Avg. Train Loss: 0.0005814707486045569, Avg. Test Loss: 0.0005907207378186285\n",
      "Epoch: 336, Avg. Train Loss: 0.0005786858071291516, Avg. Test Loss: 0.0005881613469682634\n",
      "Epoch: 337, Avg. Train Loss: 0.0005807917535326682, Avg. Test Loss: 0.0006009649368934333\n",
      "Epoch: 338, Avg. Train Loss: 0.0005828917086081103, Avg. Test Loss: 0.0005921141128055751\n",
      "Epoch: 339, Avg. Train Loss: 0.0005822687966175118, Avg. Test Loss: 0.0005904023419134319\n",
      "Epoch: 340, Avg. Train Loss: 0.0005807909981867429, Avg. Test Loss: 0.000592283031437546\n",
      "Epoch: 341, Avg. Train Loss: 0.0005801729478894971, Avg. Test Loss: 0.0005932531785219908\n",
      "Epoch: 342, Avg. Train Loss: 0.0005812143628095644, Avg. Test Loss: 0.0005974721279926598\n",
      "Epoch: 343, Avg. Train Loss: 0.0005842018466399507, Avg. Test Loss: 0.0005951341590844095\n",
      "Epoch: 344, Avg. Train Loss: 0.0005797787466584596, Avg. Test Loss: 0.0005961292190477252\n",
      "Epoch: 345, Avg. Train Loss: 0.0005831448049934278, Avg. Test Loss: 0.0005902688717469573\n",
      "Epoch: 346, Avg. Train Loss: 0.000576861270400154, Avg. Test Loss: 0.0005949001060798764\n",
      "Epoch: 347, Avg. Train Loss: 0.0005792773418063515, Avg. Test Loss: 0.0006032258970662951\n",
      "Epoch: 348, Avg. Train Loss: 0.000581857114813702, Avg. Test Loss: 0.0006034602993167937\n",
      "Epoch: 349, Avg. Train Loss: 0.0005767546691606905, Avg. Test Loss: 0.0005976904649287462\n",
      "Epoch: 350, Avg. Train Loss: 0.0005761291317338514, Avg. Test Loss: 0.000600330182351172\n",
      "Epoch: 351, Avg. Train Loss: 0.0005771195459136263, Avg. Test Loss: 0.0005863523692823946\n",
      "Epoch: 352, Avg. Train Loss: 0.0005780535264124791, Avg. Test Loss: 0.0005924411816522479\n",
      "Epoch: 353, Avg. Train Loss: 0.0005771760425400422, Avg. Test Loss: 0.0005956754321232438\n",
      "Epoch: 354, Avg. Train Loss: 0.0005773643362010981, Avg. Test Loss: 0.0005972447106614709\n",
      "Epoch: 355, Avg. Train Loss: 0.0005891130016142026, Avg. Test Loss: 0.0005866123246960342\n",
      "Epoch: 356, Avg. Train Loss: 0.0005792154061478065, Avg. Test Loss: 0.0005868077860213816\n",
      "Epoch: 357, Avg. Train Loss: 0.0005794260650873184, Avg. Test Loss: 0.0005903679993934929\n",
      "Epoch: 358, Avg. Train Loss: 0.0005750174127887328, Avg. Test Loss: 0.0005926358862780035\n",
      "Epoch: 359, Avg. Train Loss: 0.0005793021612822317, Avg. Test Loss: 0.0006062983884476125\n",
      "Epoch: 360, Avg. Train Loss: 0.0005789372053398036, Avg. Test Loss: 0.000591364863794297\n",
      "Epoch: 361, Avg. Train Loss: 0.0005744084469475892, Avg. Test Loss: 0.000588340568356216\n",
      "Epoch: 362, Avg. Train Loss: 0.0005758276972703116, Avg. Test Loss: 0.000587904010899365\n",
      "Epoch: 363, Avg. Train Loss: 0.0005763049378211415, Avg. Test Loss: 0.0005878026131540537\n",
      "Epoch: 364, Avg. Train Loss: 0.0005805141598441054, Avg. Test Loss: 0.0005925840814597905\n",
      "Epoch: 365, Avg. Train Loss: 0.0005772136852989883, Avg. Test Loss: 0.0005885453429073095\n",
      "Epoch: 366, Avg. Train Loss: 0.0005774586969109382, Avg. Test Loss: 0.0005861768149770796\n",
      "Epoch: 367, Avg. Train Loss: 0.000574344084841784, Avg. Test Loss: 0.0005891307955607772\n",
      "Epoch: 368, Avg. Train Loss: 0.0005774254204033939, Avg. Test Loss: 0.0006037793355062604\n",
      "Epoch: 369, Avg. Train Loss: 0.0005778937132184416, Avg. Test Loss: 0.0005923786084167659\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 370, Avg. Train Loss: 0.0005736174813179343, Avg. Test Loss: 0.0005897050141356885\n",
      "Epoch: 371, Avg. Train Loss: 0.000582831674851044, Avg. Test Loss: 0.000620310369413346\n",
      "Epoch: 372, Avg. Train Loss: 0.0005766612621089227, Avg. Test Loss: 0.000587271701078862\n",
      "Epoch: 373, Avg. Train Loss: 0.0005754232325396219, Avg. Test Loss: 0.0005895608919672668\n",
      "Epoch: 374, Avg. Train Loss: 0.0005769692909589774, Avg. Test Loss: 0.0005973984370939434\n",
      "Epoch: 375, Avg. Train Loss: 0.0005767616892753299, Avg. Test Loss: 0.0005987865151837468\n",
      "Epoch: 376, Avg. Train Loss: 0.0005781645101473428, Avg. Test Loss: 0.0006034462130628526\n",
      "Epoch: 377, Avg. Train Loss: 0.0005783190393040693, Avg. Test Loss: 0.0005881533725187182\n",
      "Epoch: 378, Avg. Train Loss: 0.0005740685981351796, Avg. Test Loss: 0.0005918879178352654\n",
      "Epoch: 379, Avg. Train Loss: 0.0005751090749643396, Avg. Test Loss: 0.0005868768785148859\n",
      "Epoch: 380, Avg. Train Loss: 0.0005736165642088582, Avg. Test Loss: 0.0005890020402148366\n",
      "Epoch: 381, Avg. Train Loss: 0.0005759339519711428, Avg. Test Loss: 0.0006051066447980702\n",
      "Epoch: 382, Avg. Train Loss: 0.0005773067133241268, Avg. Test Loss: 0.0005932532949373126\n",
      "Epoch: 383, Avg. Train Loss: 0.0005763602466051748, Avg. Test Loss: 0.0005918627139180899\n",
      "Epoch: 384, Avg. Train Loss: 0.0005738692274208853, Avg. Test Loss: 0.0005922943819314241\n",
      "Epoch: 385, Avg. Train Loss: 0.0005753097553510046, Avg. Test Loss: 0.0005994103266857564\n",
      "Epoch: 386, Avg. Train Loss: 0.0005794822463094321, Avg. Test Loss: 0.0006010061479173601\n",
      "Epoch: 387, Avg. Train Loss: 0.0005735239801863425, Avg. Test Loss: 0.0005864175618626177\n",
      "Epoch: 388, Avg. Train Loss: 0.0005744563329011895, Avg. Test Loss: 0.0005928829195909202\n",
      "Epoch: 389, Avg. Train Loss: 0.0005733576924052782, Avg. Test Loss: 0.0005892851040698588\n",
      "Epoch: 390, Avg. Train Loss: 0.0005739099132221971, Avg. Test Loss: 0.0005895335925742984\n",
      "Epoch: 391, Avg. Train Loss: 0.0005731353276344233, Avg. Test Loss: 0.0005863240803591907\n",
      "Epoch: 392, Avg. Train Loss: 0.0005748919170718034, Avg. Test Loss: 0.0005971443024463952\n",
      "Epoch: 393, Avg. Train Loss: 0.0005757453632107828, Avg. Test Loss: 0.0005986912874504924\n",
      "Epoch: 394, Avg. Train Loss: 0.000574012280192746, Avg. Test Loss: 0.0006041353917680681\n",
      "Epoch: 395, Avg. Train Loss: 0.0005774864545200279, Avg. Test Loss: 0.0005869638989679515\n",
      "Epoch: 396, Avg. Train Loss: 0.0005710082572646612, Avg. Test Loss: 0.0005851613823324442\n",
      "Epoch: 397, Avg. Train Loss: 0.000574190651478116, Avg. Test Loss: 0.0005846553249284625\n",
      "Epoch: 398, Avg. Train Loss: 0.0005756632044510699, Avg. Test Loss: 0.0005932462518103421\n",
      "Epoch: 399, Avg. Train Loss: 0.0005744418283642898, Avg. Test Loss: 0.0005866957944817841\n",
      "Epoch: 400, Avg. Train Loss: 0.0005723167810491611, Avg. Test Loss: 0.0005871489993296564\n",
      "Epoch: 401, Avg. Train Loss: 0.0005701348154404915, Avg. Test Loss: 0.0005832819151692092\n",
      "Epoch: 402, Avg. Train Loss: 0.0005690095117748823, Avg. Test Loss: 0.0006038665887899697\n",
      "Epoch: 403, Avg. Train Loss: 0.00057575655397201, Avg. Test Loss: 0.0005847423453815281\n",
      "Epoch: 404, Avg. Train Loss: 0.0005687313928637047, Avg. Test Loss: 0.0005839829100295901\n",
      "Epoch: 405, Avg. Train Loss: 0.0005706741940230131, Avg. Test Loss: 0.0005863987025804818\n",
      "Epoch: 406, Avg. Train Loss: 0.0005693982482541266, Avg. Test Loss: 0.0005826588021591306\n",
      "Epoch: 407, Avg. Train Loss: 0.0005723404099753257, Avg. Test Loss: 0.000593601493164897\n",
      "Epoch: 408, Avg. Train Loss: 0.0005739438164773462, Avg. Test Loss: 0.0005934709333814681\n",
      "Epoch: 409, Avg. Train Loss: 0.0005696493520423077, Avg. Test Loss: 0.0005926414160057902\n",
      "Epoch: 410, Avg. Train Loss: 0.0005729644637836447, Avg. Test Loss: 0.0005954292719252408\n",
      "Epoch: 411, Avg. Train Loss: 0.0005721897726098812, Avg. Test Loss: 0.0005878637894056737\n",
      "Epoch: 412, Avg. Train Loss: 0.0005731890424761142, Avg. Test Loss: 0.0005842780810780823\n",
      "Epoch: 413, Avg. Train Loss: 0.0005723564285882424, Avg. Test Loss: 0.0005850597517564893\n",
      "Epoch: 414, Avg. Train Loss: 0.0005709138011213306, Avg. Test Loss: 0.0005878719384782016\n",
      "Epoch: 415, Avg. Train Loss: 0.0005746252271671627, Avg. Test Loss: 0.0005882292753085494\n",
      "Epoch: 416, Avg. Train Loss: 0.0005693942671208534, Avg. Test Loss: 0.000596490572206676\n",
      "Epoch: 417, Avg. Train Loss: 0.0005724310311813687, Avg. Test Loss: 0.0005941626732237637\n",
      "Epoch: 418, Avg. Train Loss: 0.0005730774110118144, Avg. Test Loss: 0.0005959958070889115\n",
      "Epoch: 419, Avg. Train Loss: 0.0005740398245993568, Avg. Test Loss: 0.000588779104873538\n",
      "Epoch: 420, Avg. Train Loss: 0.0005747094130425086, Avg. Test Loss: 0.0005845755804330111\n",
      "Epoch: 421, Avg. Train Loss: 0.0005699270750060244, Avg. Test Loss: 0.000584413530305028\n",
      "Epoch: 422, Avg. Train Loss: 0.000574706444451802, Avg. Test Loss: 0.0005941935814917088\n",
      "Epoch: 423, Avg. Train Loss: 0.0005719989205190782, Avg. Test Loss: 0.0005900039104744792\n",
      "Epoch: 424, Avg. Train Loss: 0.0005677957635990149, Avg. Test Loss: 0.0005903661949560046\n",
      "Epoch: 425, Avg. Train Loss: 0.0005691555351679495, Avg. Test Loss: 0.0005864202394150198\n",
      "Epoch: 426, Avg. Train Loss: 0.0005694884444088783, Avg. Test Loss: 0.000590891984757036\n",
      "Epoch: 427, Avg. Train Loss: 0.0005728849257223395, Avg. Test Loss: 0.0005859120865352452\n",
      "Epoch: 428, Avg. Train Loss: 0.0005695599423678116, Avg. Test Loss: 0.0005887695006094873\n",
      "Epoch: 429, Avg. Train Loss: 0.000571886551306518, Avg. Test Loss: 0.0005939390393905342\n",
      "Epoch: 430, Avg. Train Loss: 0.0005715474443033685, Avg. Test Loss: 0.0005914421635679901\n",
      "Epoch: 431, Avg. Train Loss: 0.000571581834201636, Avg. Test Loss: 0.0005845162668265402\n",
      "Epoch: 432, Avg. Train Loss: 0.0005732155905841568, Avg. Test Loss: 0.0006009081844240427\n",
      "Epoch: 433, Avg. Train Loss: 0.0005724613458665391, Avg. Test Loss: 0.0005839800578542054\n",
      "Epoch: 434, Avg. Train Loss: 0.0005720059920730459, Avg. Test Loss: 0.0005885197897441685\n",
      "Epoch: 435, Avg. Train Loss: 0.0005682386738129047, Avg. Test Loss: 0.0005915921065025032\n",
      "Epoch: 436, Avg. Train Loss: 0.0005686303917426875, Avg. Test Loss: 0.0005913518252782524\n",
      "Epoch: 437, Avg. Train Loss: 0.0005703502291337003, Avg. Test Loss: 0.0005830667214468122\n",
      "Epoch: 438, Avg. Train Loss: 0.0005694025420843688, Avg. Test Loss: 0.000580062682274729\n",
      "Epoch: 439, Avg. Train Loss: 0.0005702521275663965, Avg. Test Loss: 0.0005894813220947981\n",
      "Epoch: 440, Avg. Train Loss: 0.0005676202032022005, Avg. Test Loss: 0.0005872930632904172\n",
      "Epoch: 441, Avg. Train Loss: 0.0005686134336851971, Avg. Test Loss: 0.0005933928187005222\n",
      "Epoch: 442, Avg. Train Loss: 0.0005710646699637522, Avg. Test Loss: 0.0005855269846506417\n",
      "Epoch: 443, Avg. Train Loss: 0.0005673109621437656, Avg. Test Loss: 0.0005884005804546177\n",
      "Epoch: 444, Avg. Train Loss: 0.0005684368742824813, Avg. Test Loss: 0.0005936992238275707\n",
      "Epoch: 445, Avg. Train Loss: 0.0005671739426636418, Avg. Test Loss: 0.0005924102151766419\n",
      "Epoch: 446, Avg. Train Loss: 0.0005716888665838904, Avg. Test Loss: 0.0005872384645044804\n",
      "Epoch: 447, Avg. Train Loss: 0.0005674931291100937, Avg. Test Loss: 0.000593002128880471\n",
      "Epoch: 448, Avg. Train Loss: 0.000570635458855175, Avg. Test Loss: 0.0005840558442287147\n",
      "Epoch: 449, Avg. Train Loss: 0.0005695086587112138, Avg. Test Loss: 0.0005827329005114734\n",
      "Epoch: 450, Avg. Train Loss: 0.0005675274357578695, Avg. Test Loss: 0.0005940060946159065\n",
      "Epoch: 451, Avg. Train Loss: 0.0005695318916899174, Avg. Test Loss: 0.0005877660005353391\n",
      "Epoch: 452, Avg. Train Loss: 0.0005653224381899764, Avg. Test Loss: 0.0005806421977467835\n",
      "Epoch: 453, Avg. Train Loss: 0.0005673760714734969, Avg. Test Loss: 0.0005828817957080901\n",
      "Epoch: 454, Avg. Train Loss: 0.0005666267432727267, Avg. Test Loss: 0.0005801459192298353\n",
      "Epoch: 455, Avg. Train Loss: 0.0005677058476532354, Avg. Test Loss: 0.0005847741267643869\n",
      "Epoch: 456, Avg. Train Loss: 0.0005671765186910539, Avg. Test Loss: 0.0005852649337612092\n",
      "Epoch: 457, Avg. Train Loss: 0.0005660100128003504, Avg. Test Loss: 0.0005820076330564916\n",
      "Epoch: 458, Avg. Train Loss: 0.0005673710500474933, Avg. Test Loss: 0.0005821320810355246\n",
      "Epoch: 459, Avg. Train Loss: 0.0005695334876627597, Avg. Test Loss: 0.0005909284227527678\n",
      "Epoch: 460, Avg. Train Loss: 0.0005660990123138871, Avg. Test Loss: 0.0005802998784929514\n",
      "Epoch: 461, Avg. Train Loss: 0.0005711674443879273, Avg. Test Loss: 0.0005834414623677731\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 462, Avg. Train Loss: 0.000566131820452811, Avg. Test Loss: 0.0005954605294391513\n",
      "Epoch: 463, Avg. Train Loss: 0.0005695743927580499, Avg. Test Loss: 0.0005843349499627948\n",
      "Epoch: 464, Avg. Train Loss: 0.0005706378724426031, Avg. Test Loss: 0.0005884633865207434\n",
      "Epoch: 465, Avg. Train Loss: 0.0005661494641424005, Avg. Test Loss: 0.00058410142082721\n",
      "Epoch: 466, Avg. Train Loss: 0.0005662010963681306, Avg. Test Loss: 0.0005943627329543233\n",
      "Epoch: 467, Avg. Train Loss: 0.0005714178192266805, Avg. Test Loss: 0.0005949115147814155\n",
      "Epoch: 468, Avg. Train Loss: 0.0005698442536265437, Avg. Test Loss: 0.000593754171859473\n",
      "Epoch: 469, Avg. Train Loss: 0.0005740177503592053, Avg. Test Loss: 0.0005855548079125583\n",
      "Epoch: 470, Avg. Train Loss: 0.0005673907513102127, Avg. Test Loss: 0.0005850275629200041\n",
      "Epoch: 471, Avg. Train Loss: 0.0005701626772819043, Avg. Test Loss: 0.0005970792262814939\n",
      "Epoch: 472, Avg. Train Loss: 0.0005644781435135925, Avg. Test Loss: 0.0005861329264007509\n",
      "Epoch: 473, Avg. Train Loss: 0.0005676830559698215, Avg. Test Loss: 0.0005959567497484386\n",
      "Epoch: 474, Avg. Train Loss: 0.0005641740226988183, Avg. Test Loss: 0.0005817881319671869\n",
      "Epoch: 475, Avg. Train Loss: 0.0005626225029118359, Avg. Test Loss: 0.000596374913584441\n",
      "Epoch: 476, Avg. Train Loss: 0.0005671562989740524, Avg. Test Loss: 0.0005858198856003582\n",
      "Epoch: 477, Avg. Train Loss: 0.0005656343100993179, Avg. Test Loss: 0.0005832373863086104\n",
      "Epoch: 478, Avg. Train Loss: 0.0005654818852172169, Avg. Test Loss: 0.0005828692810609937\n",
      "Epoch: 479, Avg. Train Loss: 0.0005682654933310872, Avg. Test Loss: 0.0005854013143107295\n",
      "Epoch: 480, Avg. Train Loss: 0.0005686590231435243, Avg. Test Loss: 0.0005819015786983073\n",
      "Epoch: 481, Avg. Train Loss: 0.0005685518161382873, Avg. Test Loss: 0.0005981564172543585\n",
      "Epoch: 482, Avg. Train Loss: 0.0005673969578712659, Avg. Test Loss: 0.0005914723151363432\n",
      "Epoch: 483, Avg. Train Loss: 0.0005706127517759194, Avg. Test Loss: 0.0005865340935997665\n",
      "Epoch: 484, Avg. Train Loss: 0.0005658196324623342, Avg. Test Loss: 0.0005845087580382824\n",
      "Epoch: 485, Avg. Train Loss: 0.0005673095692209033, Avg. Test Loss: 0.0005964107112959027\n",
      "Epoch: 486, Avg. Train Loss: 0.0005682515546267982, Avg. Test Loss: 0.0005969016347080469\n",
      "Epoch: 487, Avg. Train Loss: 0.0005702245330741239, Avg. Test Loss: 0.0005865709390491247\n",
      "Epoch: 488, Avg. Train Loss: 0.0005643823269353963, Avg. Test Loss: 0.000586430134717375\n",
      "Epoch: 489, Avg. Train Loss: 0.0005609133134617709, Avg. Test Loss: 0.0005782881053164601\n",
      "Epoch: 490, Avg. Train Loss: 0.0005606815725196759, Avg. Test Loss: 0.0005797414924018085\n",
      "Epoch: 491, Avg. Train Loss: 0.0005625775720122768, Avg. Test Loss: 0.0005778730264864862\n",
      "Epoch: 492, Avg. Train Loss: 0.0005632233657051137, Avg. Test Loss: 0.0006011801888234913\n",
      "Epoch: 493, Avg. Train Loss: 0.0005641357856802642, Avg. Test Loss: 0.0005811971495859325\n",
      "Epoch: 494, Avg. Train Loss: 0.0005648913624057502, Avg. Test Loss: 0.0005930679035373032\n",
      "Epoch: 495, Avg. Train Loss: 0.0005695936351278147, Avg. Test Loss: 0.0005928773898631334\n",
      "Epoch: 496, Avg. Train Loss: 0.0005642920542984854, Avg. Test Loss: 0.0005860601086169481\n",
      "Epoch: 497, Avg. Train Loss: 0.0005648492464557463, Avg. Test Loss: 0.0005820597871206701\n",
      "Epoch: 498, Avg. Train Loss: 0.0005678009610016678, Avg. Test Loss: 0.000584130291827023\n",
      "Epoch: 499, Avg. Train Loss: 0.0005645267983497835, Avg. Test Loss: 0.000583432090934366\n",
      "Epoch: 500, Avg. Train Loss: 0.0005619409203063697, Avg. Test Loss: 0.000585129193495959\n",
      "Epoch: 501, Avg. Train Loss: 0.000567780994420308, Avg. Test Loss: 0.0005835784249939024\n",
      "Epoch: 502, Avg. Train Loss: 0.0005629359186778582, Avg. Test Loss: 0.0005831902381032705\n",
      "Epoch: 503, Avg. Train Loss: 0.0005626518937195976, Avg. Test Loss: 0.000586833106353879\n",
      "Epoch: 504, Avg. Train Loss: 0.0005643128005917682, Avg. Test Loss: 0.0005823949468322098\n",
      "Epoch: 505, Avg. Train Loss: 0.0005609741729554222, Avg. Test Loss: 0.0005927095771767199\n",
      "Epoch: 506, Avg. Train Loss: 0.0005665140992658602, Avg. Test Loss: 0.000580818101298064\n",
      "Epoch: 507, Avg. Train Loss: 0.0005659205340888611, Avg. Test Loss: 0.0005830310401506722\n",
      "Epoch: 508, Avg. Train Loss: 0.0005635921342493316, Avg. Test Loss: 0.0005802622763440013\n",
      "Epoch: 509, Avg. Train Loss: 0.0005597445266429594, Avg. Test Loss: 0.0005821769591420889\n",
      "Epoch: 510, Avg. Train Loss: 0.0005632066783809298, Avg. Test Loss: 0.0005797254852950573\n",
      "Epoch: 511, Avg. Train Loss: 0.0005643785075652738, Avg. Test Loss: 0.0005762078217230737\n",
      "Epoch: 512, Avg. Train Loss: 0.0005622300688924571, Avg. Test Loss: 0.0005813411553390324\n",
      "Epoch: 513, Avg. Train Loss: 0.0005631977908833083, Avg. Test Loss: 0.0005817597848363221\n",
      "Epoch: 514, Avg. Train Loss: 0.000561562656468257, Avg. Test Loss: 0.0005883182748220861\n",
      "Epoch: 515, Avg. Train Loss: 0.0005620603258775677, Avg. Test Loss: 0.0005837267963215709\n",
      "Epoch: 516, Avg. Train Loss: 0.000560044964807931, Avg. Test Loss: 0.0005810338188894093\n",
      "Epoch: 517, Avg. Train Loss: 0.0005617828465738269, Avg. Test Loss: 0.0005827242275699973\n",
      "Epoch: 518, Avg. Train Loss: 0.0005617686371362313, Avg. Test Loss: 0.0005776453181169927\n",
      "Epoch: 519, Avg. Train Loss: 0.0005610116113107218, Avg. Test Loss: 0.0005830478039570153\n",
      "Epoch: 520, Avg. Train Loss: 0.0005635379997710156, Avg. Test Loss: 0.000575117242988199\n",
      "Epoch: 521, Avg. Train Loss: 0.0005611100154224956, Avg. Test Loss: 0.0005863804835826159\n",
      "Epoch: 522, Avg. Train Loss: 0.0005613636370304279, Avg. Test Loss: 0.0005787169793620706\n",
      "Epoch: 523, Avg. Train Loss: 0.0005636610778395173, Avg. Test Loss: 0.0005776114412583411\n",
      "Epoch: 524, Avg. Train Loss: 0.0005628098882626483, Avg. Test Loss: 0.0005840757512487471\n",
      "Epoch: 525, Avg. Train Loss: 0.0005598617115242104, Avg. Test Loss: 0.0005742398789152503\n",
      "Epoch: 526, Avg. Train Loss: 0.0005603271548712062, Avg. Test Loss: 0.0005789377610199153\n",
      "Epoch: 527, Avg. Train Loss: 0.0005595363225777049, Avg. Test Loss: 0.0005798069178126752\n",
      "Epoch: 528, Avg. Train Loss: 0.0005642715293296808, Avg. Test Loss: 0.0005880232201889157\n",
      "Epoch: 529, Avg. Train Loss: 0.000562699977985345, Avg. Test Loss: 0.0005803725798614323\n",
      "Epoch: 530, Avg. Train Loss: 0.000563967740163207, Avg. Test Loss: 0.0005848650471307337\n",
      "Epoch: 531, Avg. Train Loss: 0.0005633266518152383, Avg. Test Loss: 0.000592328782659024\n",
      "Epoch: 532, Avg. Train Loss: 0.0005612677473542389, Avg. Test Loss: 0.0005734104779548943\n",
      "Epoch: 533, Avg. Train Loss: 0.0005591095257333891, Avg. Test Loss: 0.0005755831371061504\n",
      "Epoch: 534, Avg. Train Loss: 0.0005618277077595595, Avg. Test Loss: 0.0005784380482509732\n",
      "Epoch: 535, Avg. Train Loss: 0.0005603630480161587, Avg. Test Loss: 0.0005901330732740462\n",
      "Epoch: 536, Avg. Train Loss: 0.0005613516259472817, Avg. Test Loss: 0.0005730526754632592\n",
      "Epoch: 537, Avg. Train Loss: 0.0005605652722595043, Avg. Test Loss: 0.0005781313520856202\n",
      "Epoch: 538, Avg. Train Loss: 0.0005566707817664326, Avg. Test Loss: 0.0005808400455862284\n",
      "Epoch: 539, Avg. Train Loss: 0.0005582613981502174, Avg. Test Loss: 0.0005742816138081253\n",
      "Epoch: 540, Avg. Train Loss: 0.0005599995750154174, Avg. Test Loss: 0.000575986981857568\n",
      "Epoch: 541, Avg. Train Loss: 0.0005578760471909718, Avg. Test Loss: 0.0005765297100879252\n",
      "Epoch: 542, Avg. Train Loss: 0.0005583265189861142, Avg. Test Loss: 0.0005743394722230732\n",
      "Epoch: 543, Avg. Train Loss: 0.0005598365631073627, Avg. Test Loss: 0.0005794433527626097\n",
      "Epoch: 544, Avg. Train Loss: 0.0005556602439799801, Avg. Test Loss: 0.0005742226494476199\n",
      "Epoch: 545, Avg. Train Loss: 0.0005602070352409121, Avg. Test Loss: 0.0005744388909079134\n",
      "Epoch: 546, Avg. Train Loss: 0.0005665892379109336, Avg. Test Loss: 0.0005764575325883925\n",
      "Epoch: 547, Avg. Train Loss: 0.0005634882680930976, Avg. Test Loss: 0.0005860243109054863\n",
      "Epoch: 548, Avg. Train Loss: 0.0005614669468297168, Avg. Test Loss: 0.0005782890948466957\n",
      "Epoch: 549, Avg. Train Loss: 0.0005653957629218957, Avg. Test Loss: 0.0005902590928599238\n",
      "Epoch: 550, Avg. Train Loss: 0.0005594815742116162, Avg. Test Loss: 0.0005732973804697394\n",
      "Epoch: 551, Avg. Train Loss: 0.0005583004764725216, Avg. Test Loss: 0.0005709335091523826\n",
      "Epoch: 552, Avg. Train Loss: 0.0005566034815274179, Avg. Test Loss: 0.0005727288662455976\n",
      "Epoch: 553, Avg. Train Loss: 0.0005640221426674966, Avg. Test Loss: 0.0005778212216682732\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 554, Avg. Train Loss: 0.0005608096564470162, Avg. Test Loss: 0.0005752056022174656\n",
      "Epoch: 555, Avg. Train Loss: 0.0005597398307737569, Avg. Test Loss: 0.0005750433774664998\n",
      "Epoch: 556, Avg. Train Loss: 0.0005582369211519701, Avg. Test Loss: 0.0005921024712733924\n",
      "Epoch: 557, Avg. Train Loss: 0.0005589160150415156, Avg. Test Loss: 0.0005778162740170956\n",
      "Epoch: 558, Avg. Train Loss: 0.000557016467588932, Avg. Test Loss: 0.000577435246668756\n",
      "Epoch: 559, Avg. Train Loss: 0.0005571326527874483, Avg. Test Loss: 0.0005821554223075509\n",
      "Epoch: 560, Avg. Train Loss: 0.0005611239669866167, Avg. Test Loss: 0.0005812288145534694\n",
      "Epoch: 561, Avg. Train Loss: 0.000556859444978452, Avg. Test Loss: 0.0005766699905507267\n",
      "Epoch: 562, Avg. Train Loss: 0.0005573992479354316, Avg. Test Loss: 0.0005745679372921586\n",
      "Epoch: 563, Avg. Train Loss: 0.0005614249953501966, Avg. Test Loss: 0.0005745143280364573\n",
      "Epoch: 564, Avg. Train Loss: 0.0005599308933597058, Avg. Test Loss: 0.0005814969190396369\n",
      "Epoch: 565, Avg. Train Loss: 0.0005582227022387087, Avg. Test Loss: 0.0005764333182014525\n",
      "Epoch: 566, Avg. Train Loss: 0.0005593981721091929, Avg. Test Loss: 0.000576478079892695\n",
      "Epoch: 567, Avg. Train Loss: 0.0005593078751062844, Avg. Test Loss: 0.0005805076798424125\n",
      "Epoch: 568, Avg. Train Loss: 0.0005617509521598127, Avg. Test Loss: 0.0005779008497484028\n",
      "Epoch: 569, Avg. Train Loss: 0.0005580986657743017, Avg. Test Loss: 0.0005780601059086621\n",
      "Epoch: 570, Avg. Train Loss: 0.0005546864947888914, Avg. Test Loss: 0.0005718688480556011\n",
      "Epoch: 571, Avg. Train Loss: 0.0005546165941564669, Avg. Test Loss: 0.0005703528295271099\n",
      "Epoch: 572, Avg. Train Loss: 0.0005567445538851411, Avg. Test Loss: 0.0005732832360081375\n",
      "Epoch: 573, Avg. Train Loss: 0.0005560283668252618, Avg. Test Loss: 0.0005722757778130472\n",
      "Epoch: 574, Avg. Train Loss: 0.0005572451492446627, Avg. Test Loss: 0.0005810781731270254\n",
      "Epoch: 575, Avg. Train Loss: 0.0005594398027697448, Avg. Test Loss: 0.0005751249846071005\n",
      "Epoch: 576, Avg. Train Loss: 0.000558313280804256, Avg. Test Loss: 0.000579571002162993\n",
      "Epoch: 577, Avg. Train Loss: 0.0005552437248488152, Avg. Test Loss: 0.0005727446405217052\n",
      "Epoch: 578, Avg. Train Loss: 0.0005546310201807078, Avg. Test Loss: 0.0005686570075340569\n",
      "Epoch: 579, Avg. Train Loss: 0.0005538543790503037, Avg. Test Loss: 0.0005722016212530434\n",
      "Epoch: 580, Avg. Train Loss: 0.0005561760843319949, Avg. Test Loss: 0.0005777626065537333\n",
      "Epoch: 581, Avg. Train Loss: 0.0005557244754569649, Avg. Test Loss: 0.0005696054431609809\n",
      "Epoch: 582, Avg. Train Loss: 0.0005580301404670748, Avg. Test Loss: 0.0005745624075643718\n",
      "Epoch: 583, Avg. Train Loss: 0.0005539200318771479, Avg. Test Loss: 0.0005736876046285033\n",
      "Epoch: 584, Avg. Train Loss: 0.0005538425026569775, Avg. Test Loss: 0.000576504971832037\n",
      "Epoch: 585, Avg. Train Loss: 0.0005548356904994783, Avg. Test Loss: 0.000574001285713166\n",
      "Epoch: 586, Avg. Train Loss: 0.0005569391718762385, Avg. Test Loss: 0.0005765579408034682\n",
      "Epoch: 587, Avg. Train Loss: 0.0005541742829400179, Avg. Test Loss: 0.0005749001284129918\n",
      "Epoch: 588, Avg. Train Loss: 0.0005559029293159932, Avg. Test Loss: 0.0005736601888202131\n",
      "Epoch: 589, Avg. Train Loss: 0.0005551374992518144, Avg. Test Loss: 0.0005719382897950709\n",
      "Epoch: 590, Avg. Train Loss: 0.0005540957811104437, Avg. Test Loss: 0.0005757460021413863\n",
      "Epoch: 591, Avg. Train Loss: 0.000554598888198217, Avg. Test Loss: 0.0005697189480997622\n",
      "Epoch: 592, Avg. Train Loss: 0.000553287137949536, Avg. Test Loss: 0.0005821399972774088\n",
      "Epoch: 593, Avg. Train Loss: 0.000554841898414198, Avg. Test Loss: 0.0005805217078886926\n",
      "Epoch: 594, Avg. Train Loss: 0.000554016879272409, Avg. Test Loss: 0.000572273216675967\n",
      "Epoch: 595, Avg. Train Loss: 0.0005546018067032619, Avg. Test Loss: 0.0005712024285458028\n",
      "Epoch: 596, Avg. Train Loss: 0.0005567526528720072, Avg. Test Loss: 0.0005711125559173524\n",
      "Epoch: 597, Avg. Train Loss: 0.0005551941095862191, Avg. Test Loss: 0.0005750034470111132\n",
      "Epoch: 598, Avg. Train Loss: 0.000553710396986368, Avg. Test Loss: 0.0005772558506578207\n",
      "Epoch: 599, Avg. Train Loss: 0.0005572708513111223, Avg. Test Loss: 0.0005715270526707172\n",
      "Epoch: 600, Avg. Train Loss: 0.0005557065535889029, Avg. Test Loss: 0.0005710332770831883\n",
      "Epoch: 601, Avg. Train Loss: 0.0005509359897439216, Avg. Test Loss: 0.0005732306162826717\n",
      "Epoch: 602, Avg. Train Loss: 0.0005546349085878234, Avg. Test Loss: 0.0005795920733362436\n",
      "Epoch: 603, Avg. Train Loss: 0.0005551041266339463, Avg. Test Loss: 0.0005784599343314767\n",
      "Epoch: 604, Avg. Train Loss: 0.000555767811060515, Avg. Test Loss: 0.0005731280543841422\n",
      "Epoch: 605, Avg. Train Loss: 0.0005557754531849262, Avg. Test Loss: 0.0005715842125937343\n",
      "Epoch: 606, Avg. Train Loss: 0.0005537576318263661, Avg. Test Loss: 0.0005727572715841234\n",
      "Epoch: 607, Avg. Train Loss: 0.0005578881347562771, Avg. Test Loss: 0.0005835678894072771\n",
      "Epoch: 608, Avg. Train Loss: 0.0005509369643838253, Avg. Test Loss: 0.0005656179855577648\n",
      "Epoch: 609, Avg. Train Loss: 0.0005519931802937631, Avg. Test Loss: 0.0005685164360329509\n",
      "Epoch: 610, Avg. Train Loss: 0.000550019225176034, Avg. Test Loss: 0.0005711558042094111\n",
      "Epoch: 611, Avg. Train Loss: 0.0005545677829717914, Avg. Test Loss: 0.0005741463392041624\n",
      "Epoch: 612, Avg. Train Loss: 0.0005575610686169374, Avg. Test Loss: 0.0005669597303494811\n",
      "Epoch: 613, Avg. Train Loss: 0.0005531937836907631, Avg. Test Loss: 0.0005698102177120745\n",
      "Epoch: 614, Avg. Train Loss: 0.0005531223804884871, Avg. Test Loss: 0.0005648686201311648\n",
      "Epoch: 615, Avg. Train Loss: 0.0005512603871296918, Avg. Test Loss: 0.0005643401527777314\n",
      "Epoch: 616, Avg. Train Loss: 0.0005576357591983884, Avg. Test Loss: 0.0005655714776366949\n",
      "Epoch: 617, Avg. Train Loss: 0.0005530551668841305, Avg. Test Loss: 0.0005643123877234757\n",
      "Epoch: 618, Avg. Train Loss: 0.0005544541575566887, Avg. Test Loss: 0.0005679177702404559\n",
      "Epoch: 619, Avg. Train Loss: 0.0005535830244107908, Avg. Test Loss: 0.0005656397552229464\n",
      "Epoch: 620, Avg. Train Loss: 0.0005517553769561007, Avg. Test Loss: 0.0005697596934624016\n",
      "Epoch: 621, Avg. Train Loss: 0.0005520766582015123, Avg. Test Loss: 0.0005641175084747374\n",
      "Epoch: 622, Avg. Train Loss: 0.0005513894213309381, Avg. Test Loss: 0.0005718556931242347\n",
      "Epoch: 623, Avg. Train Loss: 0.000549387647012292, Avg. Test Loss: 0.000566234695725143\n",
      "Epoch: 624, Avg. Train Loss: 0.0005541532212424331, Avg. Test Loss: 0.0005695635336451232\n",
      "Epoch: 625, Avg. Train Loss: 0.0005497225725395215, Avg. Test Loss: 0.0005671960534527898\n",
      "Epoch: 626, Avg. Train Loss: 0.0005513288224180944, Avg. Test Loss: 0.0005692042177543044\n",
      "Epoch: 627, Avg. Train Loss: 0.0005551298374992384, Avg. Test Loss: 0.0005638840375468135\n",
      "Epoch: 628, Avg. Train Loss: 0.000557803841264442, Avg. Test Loss: 0.0005726983654312789\n",
      "Epoch: 629, Avg. Train Loss: 0.0005532476271307746, Avg. Test Loss: 0.0005624758778139949\n",
      "Epoch: 630, Avg. Train Loss: 0.0005509791473403226, Avg. Test Loss: 0.000565292953979224\n",
      "Epoch: 631, Avg. Train Loss: 0.0005539753379538482, Avg. Test Loss: 0.0005722669302485883\n",
      "Epoch: 632, Avg. Train Loss: 0.0005508524157258487, Avg. Test Loss: 0.0005636551650241017\n",
      "Epoch: 633, Avg. Train Loss: 0.0005479339594129732, Avg. Test Loss: 0.0005712809506803751\n",
      "Epoch: 634, Avg. Train Loss: 0.0005517859704965769, Avg. Test Loss: 0.0005593917449004948\n",
      "Epoch: 635, Avg. Train Loss: 0.0005506944482561287, Avg. Test Loss: 0.0005652230465784669\n",
      "Epoch: 636, Avg. Train Loss: 0.0005513943087439551, Avg. Test Loss: 0.0005622123717330396\n",
      "Epoch: 637, Avg. Train Loss: 0.0005485736927407426, Avg. Test Loss: 0.0005658428417518735\n",
      "Epoch: 638, Avg. Train Loss: 0.0005488605793500536, Avg. Test Loss: 0.0005630989908240736\n",
      "Epoch: 639, Avg. Train Loss: 0.0005503680474438899, Avg. Test Loss: 0.0005691108526661992\n",
      "Epoch: 640, Avg. Train Loss: 0.0005527673232325808, Avg. Test Loss: 0.0005636092973873019\n",
      "Epoch: 641, Avg. Train Loss: 0.0005505048591362009, Avg. Test Loss: 0.0005662761977873743\n",
      "Epoch: 642, Avg. Train Loss: 0.0005470169044836143, Avg. Test Loss: 0.0005644874763675034\n",
      "Epoch: 643, Avg. Train Loss: 0.0005524156799236702, Avg. Test Loss: 0.0005673241103067994\n",
      "Epoch: 644, Avg. Train Loss: 0.0005505082419488665, Avg. Test Loss: 0.0005637251306325197\n",
      "Epoch: 645, Avg. Train Loss: 0.0005466570593091811, Avg. Test Loss: 0.0005697900778613985\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 646, Avg. Train Loss: 0.000551786890312986, Avg. Test Loss: 0.0005728839314542711\n",
      "Epoch: 647, Avg. Train Loss: 0.0005498788851519051, Avg. Test Loss: 0.0005636228015646338\n",
      "Epoch: 648, Avg. Train Loss: 0.0005501788515640899, Avg. Test Loss: 0.0005691830301657319\n",
      "Epoch: 649, Avg. Train Loss: 0.0005485432541950844, Avg. Test Loss: 0.0005688410601578653\n",
      "Epoch: 650, Avg. Train Loss: 0.0005519301853911562, Avg. Test Loss: 0.0005615429836325347\n",
      "Epoch: 651, Avg. Train Loss: 0.0005516812088899314, Avg. Test Loss: 0.0005801201332360506\n",
      "Epoch: 652, Avg. Train Loss: 0.000550031736438964, Avg. Test Loss: 0.0005610113148577511\n",
      "Epoch: 653, Avg. Train Loss: 0.0005475794497151795, Avg. Test Loss: 0.0005673788255080581\n",
      "Epoch: 654, Avg. Train Loss: 0.0005483002778207667, Avg. Test Loss: 0.0005770951975136995\n",
      "Epoch: 655, Avg. Train Loss: 0.0005547844955080384, Avg. Test Loss: 0.0005601375596597791\n",
      "Epoch: 656, Avg. Train Loss: 0.0005516886323971977, Avg. Test Loss: 0.0005668012308888137\n",
      "Epoch: 657, Avg. Train Loss: 0.0005498412789419553, Avg. Test Loss: 0.0005625994526781142\n",
      "Epoch: 658, Avg. Train Loss: 0.0005510145958058189, Avg. Test Loss: 0.0005647447542287409\n",
      "Epoch: 659, Avg. Train Loss: 0.0005526651444216801, Avg. Test Loss: 0.0005615024128928781\n",
      "Epoch: 660, Avg. Train Loss: 0.0005528290558411459, Avg. Test Loss: 0.0005679790629073977\n",
      "Epoch: 661, Avg. Train Loss: 0.0005510672195922843, Avg. Test Loss: 0.0005671308608725667\n",
      "Epoch: 662, Avg. Train Loss: 0.0005481750007209823, Avg. Test Loss: 0.0005734921433031559\n",
      "Epoch: 663, Avg. Train Loss: 0.0005510138648258912, Avg. Test Loss: 0.0005584733444266021\n",
      "Epoch: 664, Avg. Train Loss: 0.0005480542408064181, Avg. Test Loss: 0.000557578110601753\n",
      "Epoch: 665, Avg. Train Loss: 0.0005476699666888995, Avg. Test Loss: 0.0005652456311509013\n",
      "Epoch: 666, Avg. Train Loss: 0.0005484067700900744, Avg. Test Loss: 0.0005655154818668962\n",
      "Epoch: 667, Avg. Train Loss: 0.000550483662748796, Avg. Test Loss: 0.0005615734844468534\n",
      "Epoch: 668, Avg. Train Loss: 0.0005475729419633226, Avg. Test Loss: 0.0005744448862969875\n",
      "Epoch: 669, Avg. Train Loss: 0.0005506429933607145, Avg. Test Loss: 0.0005689989193342626\n",
      "Epoch: 670, Avg. Train Loss: 0.0005493344499480499, Avg. Test Loss: 0.0005596901755779982\n",
      "Epoch: 671, Avg. Train Loss: 0.0005466694758154538, Avg. Test Loss: 0.0005559105193242431\n",
      "Epoch: 672, Avg. Train Loss: 0.0005505623182195217, Avg. Test Loss: 0.0005751951830461621\n",
      "Epoch: 673, Avg. Train Loss: 0.0005537886707231316, Avg. Test Loss: 0.000567351293284446\n",
      "Epoch: 674, Avg. Train Loss: 0.000547148855836239, Avg. Test Loss: 0.0005627929931506515\n",
      "Epoch: 675, Avg. Train Loss: 0.0005531411964532941, Avg. Test Loss: 0.0005573141970671713\n",
      "Epoch: 676, Avg. Train Loss: 0.0005490219756571012, Avg. Test Loss: 0.0005661646137014031\n",
      "Epoch: 677, Avg. Train Loss: 0.0005521667135749446, Avg. Test Loss: 0.0005768648697994649\n",
      "Epoch: 678, Avg. Train Loss: 0.0005501904166141135, Avg. Test Loss: 0.0005617787246592343\n",
      "Epoch: 679, Avg. Train Loss: 0.0005468428662848161, Avg. Test Loss: 0.000567492563277483\n",
      "Epoch: 680, Avg. Train Loss: 0.0005470150100273016, Avg. Test Loss: 0.0005649647209793329\n",
      "Epoch: 681, Avg. Train Loss: 0.0005472687852763852, Avg. Test Loss: 0.0005695611471310258\n",
      "Epoch: 682, Avg. Train Loss: 0.0005457845352709207, Avg. Test Loss: 0.0005615503177978098\n",
      "Epoch: 683, Avg. Train Loss: 0.0005467811857924125, Avg. Test Loss: 0.0005702759372070432\n",
      "Epoch: 684, Avg. Train Loss: 0.0005464571132866102, Avg. Test Loss: 0.0005602408782579005\n",
      "Epoch: 685, Avg. Train Loss: 0.000544851147001176, Avg. Test Loss: 0.0005568278138525784\n",
      "Epoch: 686, Avg. Train Loss: 0.0005471477735798459, Avg. Test Loss: 0.0005588029744103551\n",
      "Epoch: 687, Avg. Train Loss: 0.0005461065657707581, Avg. Test Loss: 0.0005565378232859075\n",
      "Epoch: 688, Avg. Train Loss: 0.0005451729636217012, Avg. Test Loss: 0.0005692261038348079\n",
      "Epoch: 689, Avg. Train Loss: 0.0005491323854373551, Avg. Test Loss: 0.0005636992864310741\n",
      "Epoch: 690, Avg. Train Loss: 0.0005486947856572738, Avg. Test Loss: 0.0005619817529805005\n",
      "Epoch: 691, Avg. Train Loss: 0.0005495179401234139, Avg. Test Loss: 0.0005668856319971383\n",
      "Epoch: 692, Avg. Train Loss: 0.0005466595168907715, Avg. Test Loss: 0.0005564338061958551\n",
      "Epoch: 693, Avg. Train Loss: 0.0005445031904030678, Avg. Test Loss: 0.0005641338066197932\n",
      "Epoch: 694, Avg. Train Loss: 0.0005446491082101454, Avg. Test Loss: 0.000561082037165761\n",
      "Epoch: 695, Avg. Train Loss: 0.0005459619197333882, Avg. Test Loss: 0.0005649934755638242\n",
      "Epoch: 696, Avg. Train Loss: 0.000544674551049464, Avg. Test Loss: 0.0005559301935136318\n",
      "Epoch: 697, Avg. Train Loss: 0.0005453163399198634, Avg. Test Loss: 0.0005626732017844915\n",
      "Epoch: 698, Avg. Train Loss: 0.0005461139561131943, Avg. Test Loss: 0.000557448307517916\n",
      "Epoch: 699, Avg. Train Loss: 0.0005480755265358143, Avg. Test Loss: 0.0005610554362647235\n",
      "Epoch: 700, Avg. Train Loss: 0.0005501441645360184, Avg. Test Loss: 0.0005578425480052829\n",
      "Epoch: 701, Avg. Train Loss: 0.0005446852504297398, Avg. Test Loss: 0.0005577855044975877\n",
      "Epoch: 702, Avg. Train Loss: 0.0005433818820842303, Avg. Test Loss: 0.0005611529923044145\n",
      "Epoch: 703, Avg. Train Loss: 0.0005444001479529191, Avg. Test Loss: 0.0005581464502029121\n",
      "Epoch: 704, Avg. Train Loss: 0.0005451968727568381, Avg. Test Loss: 0.0005742450011894107\n",
      "Epoch: 705, Avg. Train Loss: 0.0005457810225062679, Avg. Test Loss: 0.0005581857985816896\n",
      "Epoch: 706, Avg. Train Loss: 0.0005431181465567977, Avg. Test Loss: 0.0005589438951574266\n",
      "Epoch: 707, Avg. Train Loss: 0.0005465222936838345, Avg. Test Loss: 0.0005644317134283483\n",
      "Epoch: 708, Avg. Train Loss: 0.0005463107859954065, Avg. Test Loss: 0.0005594764370471239\n",
      "Epoch: 709, Avg. Train Loss: 0.000546390111531066, Avg. Test Loss: 0.0005604529287666082\n",
      "Epoch: 710, Avg. Train Loss: 0.000544027286597939, Avg. Test Loss: 0.0005614269757643342\n",
      "Epoch: 711, Avg. Train Loss: 0.0005453588964883238, Avg. Test Loss: 0.0005658570444211364\n",
      "Epoch: 712, Avg. Train Loss: 0.0005434975813164614, Avg. Test Loss: 0.0005592181114479899\n",
      "Epoch: 713, Avg. Train Loss: 0.0005445532198876229, Avg. Test Loss: 0.0005559870623983443\n",
      "Epoch: 714, Avg. Train Loss: 0.0005447543537525763, Avg. Test Loss: 0.0005645998171530664\n",
      "Epoch: 715, Avg. Train Loss: 0.000544956621313251, Avg. Test Loss: 0.0005666182842105627\n",
      "Epoch: 716, Avg. Train Loss: 0.0005454142113638566, Avg. Test Loss: 0.0005596684059128165\n",
      "Epoch: 717, Avg. Train Loss: 0.00054467583906317, Avg. Test Loss: 0.0005623676697723567\n",
      "Epoch: 718, Avg. Train Loss: 0.0005413330678535669, Avg. Test Loss: 0.000563625362701714\n",
      "Epoch: 719, Avg. Train Loss: 0.0005483207885760727, Avg. Test Loss: 0.0005573229282163084\n",
      "Epoch: 720, Avg. Train Loss: 0.0005431765220723613, Avg. Test Loss: 0.0005710685509257019\n",
      "Epoch: 721, Avg. Train Loss: 0.0005469235353345095, Avg. Test Loss: 0.0005588797503151\n",
      "Epoch: 722, Avg. Train Loss: 0.0005460177442643705, Avg. Test Loss: 0.000558155938051641\n",
      "Epoch: 723, Avg. Train Loss: 0.000546856764379109, Avg. Test Loss: 0.0005629959050565958\n",
      "Epoch: 724, Avg. Train Loss: 0.0005453445645439071, Avg. Test Loss: 0.0005640472518280149\n",
      "Epoch: 725, Avg. Train Loss: 0.0005441161764644866, Avg. Test Loss: 0.0005618451396003366\n",
      "Epoch: 726, Avg. Train Loss: 0.0005431183157651143, Avg. Test Loss: 0.0005610497901216149\n",
      "Epoch: 727, Avg. Train Loss: 0.0005444804048111532, Avg. Test Loss: 0.000566748552955687\n",
      "Epoch: 728, Avg. Train Loss: 0.0005442500710054192, Avg. Test Loss: 0.0005564822349697351\n",
      "Epoch: 729, Avg. Train Loss: 0.0005419945796453502, Avg. Test Loss: 0.0005551102804020047\n",
      "Epoch: 730, Avg. Train Loss: 0.0005439414120235936, Avg. Test Loss: 0.0005622117314487696\n",
      "Epoch: 731, Avg. Train Loss: 0.0005422046138677573, Avg. Test Loss: 0.0005552798975259066\n",
      "Epoch: 732, Avg. Train Loss: 0.0005436907346403702, Avg. Test Loss: 0.0005550240748561919\n",
      "Epoch: 733, Avg. Train Loss: 0.000545772276466799, Avg. Test Loss: 0.0005656271241605282\n",
      "Epoch: 734, Avg. Train Loss: 0.0005438720643639478, Avg. Test Loss: 0.0005603408208116889\n",
      "Epoch: 735, Avg. Train Loss: 0.000547303696336268, Avg. Test Loss: 0.0005545207532122731\n",
      "Epoch: 736, Avg. Train Loss: 0.0005509903590833812, Avg. Test Loss: 0.0005603032768703997\n",
      "Epoch: 737, Avg. Train Loss: 0.0005430401327240086, Avg. Test Loss: 0.0005541114369407296\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 738, Avg. Train Loss: 0.0005433453269963434, Avg. Test Loss: 0.0005504879518412054\n",
      "Epoch: 739, Avg. Train Loss: 0.0005433686249510407, Avg. Test Loss: 0.0005565080791711807\n",
      "Epoch: 740, Avg. Train Loss: 0.0005417996286522856, Avg. Test Loss: 0.0005683492636308074\n",
      "Epoch: 741, Avg. Train Loss: 0.0005446988818517258, Avg. Test Loss: 0.0005710279219783843\n",
      "Epoch: 742, Avg. Train Loss: 0.0005443422678793066, Avg. Test Loss: 0.0005600865697488189\n",
      "Epoch: 743, Avg. Train Loss: 0.0005461913452288786, Avg. Test Loss: 0.0005614029360003769\n",
      "Epoch: 744, Avg. Train Loss: 0.000541077341294176, Avg. Test Loss: 0.0005510629271157086\n",
      "Epoch: 745, Avg. Train Loss: 0.0005427275582617365, Avg. Test Loss: 0.0005546253523789346\n",
      "Epoch: 746, Avg. Train Loss: 0.0005400090987339269, Avg. Test Loss: 0.0005573623348027468\n",
      "Epoch: 747, Avg. Train Loss: 0.0005414823143266488, Avg. Test Loss: 0.0005545180756598711\n",
      "Epoch: 748, Avg. Train Loss: 0.0005424515436251843, Avg. Test Loss: 0.000552909797988832\n",
      "Epoch: 749, Avg. Train Loss: 0.00055018198665578, Avg. Test Loss: 0.0005536681856028736\n",
      "Epoch: 750, Avg. Train Loss: 0.0005433014411273477, Avg. Test Loss: 0.0005544789601117373\n",
      "Epoch: 751, Avg. Train Loss: 0.0005419917098723005, Avg. Test Loss: 0.0005671280669048429\n",
      "Epoch: 752, Avg. Train Loss: 0.0005425428694146577, Avg. Test Loss: 0.000557420018594712\n",
      "Epoch: 753, Avg. Train Loss: 0.0005418625084932374, Avg. Test Loss: 0.0005522363935597241\n",
      "Epoch: 754, Avg. Train Loss: 0.000542788011655428, Avg. Test Loss: 0.0005590039072558284\n",
      "Epoch: 755, Avg. Train Loss: 0.0005443624510473116, Avg. Test Loss: 0.000561433145776391\n",
      "Epoch: 756, Avg. Train Loss: 0.0005425803334896214, Avg. Test Loss: 0.0005546569009311497\n",
      "Epoch: 757, Avg. Train Loss: 0.0005396492765718248, Avg. Test Loss: 0.0005548089975491166\n",
      "Epoch: 758, Avg. Train Loss: 0.0005406895307228403, Avg. Test Loss: 0.0005537819233722985\n",
      "Epoch: 759, Avg. Train Loss: 0.0005425782251539965, Avg. Test Loss: 0.0005613371031358838\n",
      "Epoch: 760, Avg. Train Loss: 0.0005425018715932099, Avg. Test Loss: 0.0005577838164754212\n",
      "Epoch: 761, Avg. Train Loss: 0.0005463659472297877, Avg. Test Loss: 0.0005569948698394\n",
      "Epoch: 762, Avg. Train Loss: 0.0005416429146777752, Avg. Test Loss: 0.0005641116295009851\n",
      "Epoch: 763, Avg. Train Loss: 0.00054364210687751, Avg. Test Loss: 0.0005550018395297229\n",
      "Epoch: 764, Avg. Train Loss: 0.0005390527204686212, Avg. Test Loss: 0.000553502410184592\n",
      "Epoch: 765, Avg. Train Loss: 0.0005401001104727647, Avg. Test Loss: 0.0005593218374997377\n",
      "Epoch: 766, Avg. Train Loss: 0.0005382339545893808, Avg. Test Loss: 0.0005579882999882102\n",
      "Epoch: 767, Avg. Train Loss: 0.0005392135678638899, Avg. Test Loss: 0.0005614299443550408\n",
      "Epoch: 768, Avg. Train Loss: 0.0005413805937318695, Avg. Test Loss: 0.0005528131150640547\n",
      "Epoch: 769, Avg. Train Loss: 0.000538876441274878, Avg. Test Loss: 0.0005565535975620151\n",
      "Epoch: 770, Avg. Train Loss: 0.0005430308147604296, Avg. Test Loss: 0.0005514267249964178\n",
      "Epoch: 771, Avg. Train Loss: 0.0005387786950450391, Avg. Test Loss: 0.0005526976310648024\n",
      "Epoch: 772, Avg. Train Loss: 0.00054262520212052, Avg. Test Loss: 0.0005681428592652082\n",
      "Epoch: 773, Avg. Train Loss: 0.0005459381100927415, Avg. Test Loss: 0.0005685247597284615\n",
      "Epoch: 774, Avg. Train Loss: 0.0005449996712931627, Avg. Test Loss: 0.0005553329247049987\n",
      "Epoch: 775, Avg. Train Loss: 0.0005442482848424292, Avg. Test Loss: 0.0005549954366870224\n",
      "Epoch: 776, Avg. Train Loss: 0.0005386288103181869, Avg. Test Loss: 0.0005589674110524356\n",
      "Epoch: 777, Avg. Train Loss: 0.0005451331766549671, Avg. Test Loss: 0.0005586192128248513\n",
      "Epoch: 778, Avg. Train Loss: 0.000539959920705621, Avg. Test Loss: 0.0005610689986497164\n",
      "Epoch: 779, Avg. Train Loss: 0.0005407122222349307, Avg. Test Loss: 0.0005599216092377901\n",
      "Epoch: 780, Avg. Train Loss: 0.0005390899226091109, Avg. Test Loss: 0.0005514568765647709\n",
      "Epoch: 781, Avg. Train Loss: 0.0005440389064714572, Avg. Test Loss: 0.000559240928851068\n",
      "Epoch: 782, Avg. Train Loss: 0.0005433917584352542, Avg. Test Loss: 0.000554449507035315\n",
      "Epoch: 783, Avg. Train Loss: 0.000543773424037364, Avg. Test Loss: 0.0005501086125150323\n",
      "Epoch: 784, Avg. Train Loss: 0.0005387176345319076, Avg. Test Loss: 0.0005598072311840951\n",
      "Epoch: 785, Avg. Train Loss: 0.000540947413673018, Avg. Test Loss: 0.0005554318777285516\n",
      "Epoch: 786, Avg. Train Loss: 0.000541775984158956, Avg. Test Loss: 0.0005643139593303204\n",
      "Epoch: 787, Avg. Train Loss: 0.0005437381183836868, Avg. Test Loss: 0.0005544442101381719\n",
      "Epoch: 788, Avg. Train Loss: 0.0005413632952272459, Avg. Test Loss: 0.000555673148483038\n",
      "Epoch: 789, Avg. Train Loss: 0.0005417249502538336, Avg. Test Loss: 0.0005563658196479082\n",
      "Epoch: 790, Avg. Train Loss: 0.0005435701561171215, Avg. Test Loss: 0.0005597107810899615\n",
      "Epoch: 791, Avg. Train Loss: 0.0005410601030277132, Avg. Test Loss: 0.0005497565143741667\n",
      "Epoch: 792, Avg. Train Loss: 0.0005426057885119388, Avg. Test Loss: 0.0005544586456380785\n",
      "Epoch: 793, Avg. Train Loss: 0.0005393623926698469, Avg. Test Loss: 0.0005721905035898089\n",
      "Epoch: 794, Avg. Train Loss: 0.0005414956093625013, Avg. Test Loss: 0.0005522461724467576\n",
      "Epoch: 795, Avg. Train Loss: 0.0005395448195401493, Avg. Test Loss: 0.0005502352141775191\n",
      "Epoch: 796, Avg. Train Loss: 0.0005413448244474049, Avg. Test Loss: 0.0005567727494053543\n",
      "Epoch: 797, Avg. Train Loss: 0.0005406547293099466, Avg. Test Loss: 0.0005577474366873503\n",
      "Epoch: 798, Avg. Train Loss: 0.0005395356606323878, Avg. Test Loss: 0.0005657271831296384\n",
      "Epoch: 799, Avg. Train Loss: 0.000540104589755322, Avg. Test Loss: 0.0005573894595727324\n",
      "Epoch: 800, Avg. Train Loss: 0.0005409824452092221, Avg. Test Loss: 0.000571047596167773\n",
      "Epoch: 801, Avg. Train Loss: 0.0005405900443546733, Avg. Test Loss: 0.0005571177462115884\n",
      "Epoch: 802, Avg. Train Loss: 0.0005441290099000514, Avg. Test Loss: 0.0005553485825657845\n",
      "Epoch: 803, Avg. Train Loss: 0.0005387015522966637, Avg. Test Loss: 0.000556151382625103\n",
      "Epoch: 804, Avg. Train Loss: 0.0005410030893006817, Avg. Test Loss: 0.0005514850490726531\n",
      "Epoch: 805, Avg. Train Loss: 0.000540757920663414, Avg. Test Loss: 0.0005578903947025537\n",
      "Epoch: 806, Avg. Train Loss: 0.0005437765977085503, Avg. Test Loss: 0.0005681305774487555\n",
      "Epoch: 807, Avg. Train Loss: 0.0005409417323345794, Avg. Test Loss: 0.0005566215259023011\n",
      "Epoch: 808, Avg. Train Loss: 0.0005427389703474419, Avg. Test Loss: 0.0005533280782401562\n",
      "Epoch: 809, Avg. Train Loss: 0.0005411189685705616, Avg. Test Loss: 0.0005563014419749379\n",
      "Epoch: 810, Avg. Train Loss: 0.0005427189056252585, Avg. Test Loss: 0.0005628201179206371\n",
      "Epoch: 811, Avg. Train Loss: 0.0005411362738435179, Avg. Test Loss: 0.0005623953184112906\n",
      "Epoch: 812, Avg. Train Loss: 0.0005396148115450647, Avg. Test Loss: 0.0005649853846989572\n",
      "Epoch: 813, Avg. Train Loss: 0.0005387402759583364, Avg. Test Loss: 0.0005561072612181306\n",
      "Epoch: 814, Avg. Train Loss: 0.0005390348222897236, Avg. Test Loss: 0.000563881651032716\n",
      "Epoch: 815, Avg. Train Loss: 0.000540601784704513, Avg. Test Loss: 0.0005556163378059864\n",
      "Epoch: 816, Avg. Train Loss: 0.0005402656794569, Avg. Test Loss: 0.000555365055333823\n",
      "Epoch: 817, Avg. Train Loss: 0.0005418953633336567, Avg. Test Loss: 0.0005711286794394255\n",
      "Epoch: 818, Avg. Train Loss: 0.0005415503699115889, Avg. Test Loss: 0.0005530805792659521\n",
      "Epoch: 819, Avg. Train Loss: 0.0005418630668806822, Avg. Test Loss: 0.0005575874238274992\n",
      "Epoch: 820, Avg. Train Loss: 0.0005411741507867741, Avg. Test Loss: 0.000563048233743757\n",
      "Epoch: 821, Avg. Train Loss: 0.0005371755206968288, Avg. Test Loss: 0.0005561088910326362\n",
      "Epoch: 822, Avg. Train Loss: 0.0005386616292864431, Avg. Test Loss: 0.0005583564634434879\n",
      "Epoch: 823, Avg. Train Loss: 0.0005415941644080936, Avg. Test Loss: 0.000551402335986495\n",
      "Epoch: 824, Avg. Train Loss: 0.0005370455836000051, Avg. Test Loss: 0.000555553415324539\n",
      "Epoch: 825, Avg. Train Loss: 0.000540496899914213, Avg. Test Loss: 0.0005580650176852942\n",
      "Epoch: 826, Avg. Train Loss: 0.0005384038505685883, Avg. Test Loss: 0.0005515402881428599\n",
      "Epoch: 827, Avg. Train Loss: 0.0005384734818213728, Avg. Test Loss: 0.0005515607772395015\n",
      "Epoch: 828, Avg. Train Loss: 0.0005402429006333182, Avg. Test Loss: 0.0005619197618216276\n",
      "Epoch: 829, Avg. Train Loss: 0.0005403783823482606, Avg. Test Loss: 0.0005516546661965549\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 830, Avg. Train Loss: 0.0005385266843002809, Avg. Test Loss: 0.0005590587970800698\n",
      "Epoch: 831, Avg. Train Loss: 0.0005424250774139669, Avg. Test Loss: 0.0005653216503560543\n",
      "Epoch: 832, Avg. Train Loss: 0.0005379101541705516, Avg. Test Loss: 0.0005589451757259667\n",
      "Epoch: 833, Avg. Train Loss: 0.0005437279773908559, Avg. Test Loss: 0.0005618294235318899\n",
      "Epoch: 834, Avg. Train Loss: 0.0005389897174440151, Avg. Test Loss: 0.0005567825282923877\n",
      "Epoch: 835, Avg. Train Loss: 0.0005389619848777562, Avg. Test Loss: 0.0005523959407582879\n",
      "Epoch: 836, Avg. Train Loss: 0.0005405744311648832, Avg. Test Loss: 0.000555375765543431\n",
      "Epoch: 837, Avg. Train Loss: 0.0005402302282840706, Avg. Test Loss: 0.000558136438485235\n",
      "Epoch: 838, Avg. Train Loss: 0.0005440733586383853, Avg. Test Loss: 0.0005632195970974863\n",
      "Epoch: 839, Avg. Train Loss: 0.0005384138291214354, Avg. Test Loss: 0.0005522125866264105\n",
      "Epoch: 840, Avg. Train Loss: 0.0005424893704827788, Avg. Test Loss: 0.0005561885191127658\n",
      "Epoch: 841, Avg. Train Loss: 0.000541751754204851, Avg. Test Loss: 0.0005537143442779779\n",
      "Epoch: 842, Avg. Train Loss: 0.000540925960765805, Avg. Test Loss: 0.0005589309148490429\n",
      "Epoch: 843, Avg. Train Loss: 0.0005428076161309904, Avg. Test Loss: 0.0005550715723074973\n",
      "Epoch: 844, Avg. Train Loss: 0.000539790224392227, Avg. Test Loss: 0.0005656832363456488\n",
      "Epoch: 845, Avg. Train Loss: 0.0005419782733782953, Avg. Test Loss: 0.0005572955124080181\n",
      "Epoch: 846, Avg. Train Loss: 0.0005400328427217467, Avg. Test Loss: 0.0005563717568293214\n",
      "Epoch: 847, Avg. Train Loss: 0.0005401922430474917, Avg. Test Loss: 0.0005526288878172636\n",
      "Epoch: 848, Avg. Train Loss: 0.0005380785820984043, Avg. Test Loss: 0.0005521845887415111\n",
      "Epoch: 849, Avg. Train Loss: 0.000537970048499965, Avg. Test Loss: 0.0005587697378359735\n",
      "Epoch: 850, Avg. Train Loss: 0.0005366561147871666, Avg. Test Loss: 0.0005498281680047512\n",
      "Epoch: 851, Avg. Train Loss: 0.0005398170384957433, Avg. Test Loss: 0.0005565126775763929\n",
      "Epoch: 852, Avg. Train Loss: 0.0005398060778578267, Avg. Test Loss: 0.0005534457159228623\n",
      "Epoch: 853, Avg. Train Loss: 0.0005397548436100573, Avg. Test Loss: 0.0005512823699973524\n",
      "Epoch: 854, Avg. Train Loss: 0.000537095119673109, Avg. Test Loss: 0.0005492956261150539\n",
      "Epoch: 855, Avg. Train Loss: 0.0005373923313738995, Avg. Test Loss: 0.0005488136666826904\n",
      "Epoch: 856, Avg. Train Loss: 0.0005351174264052493, Avg. Test Loss: 0.0005510965129360557\n",
      "Epoch: 857, Avg. Train Loss: 0.0005360464105209292, Avg. Test Loss: 0.000556368671823293\n",
      "Epoch: 858, Avg. Train Loss: 0.0005385683724916605, Avg. Test Loss: 0.0005522581632249057\n",
      "Epoch: 859, Avg. Train Loss: 0.0005411850092228675, Avg. Test Loss: 0.0005529971676878631\n",
      "Epoch: 860, Avg. Train Loss: 0.0005380640254453431, Avg. Test Loss: 0.0005549967172555625\n",
      "Epoch: 861, Avg. Train Loss: 0.0005409540439316959, Avg. Test Loss: 0.0005530372727662325\n",
      "Epoch: 862, Avg. Train Loss: 0.0005393959243435326, Avg. Test Loss: 0.0005550073110498488\n",
      "Epoch: 863, Avg. Train Loss: 0.0005402060944402894, Avg. Test Loss: 0.0005531354108825326\n",
      "Epoch: 864, Avg. Train Loss: 0.0005417571404439852, Avg. Test Loss: 0.000562452943995595\n",
      "Epoch: 865, Avg. Train Loss: 0.0005375728928917196, Avg. Test Loss: 0.0005516704404726624\n",
      "Epoch: 866, Avg. Train Loss: 0.0005376921962610944, Avg. Test Loss: 0.0005500832921825349\n",
      "Epoch: 867, Avg. Train Loss: 0.0005386961951613599, Avg. Test Loss: 0.0005496232770383358\n",
      "Epoch: 868, Avg. Train Loss: 0.0005383761213864958, Avg. Test Loss: 0.0005476252408698201\n",
      "Epoch: 869, Avg. Train Loss: 0.0005385857772591069, Avg. Test Loss: 0.0005552805960178375\n",
      "Epoch: 870, Avg. Train Loss: 0.0005371454733607987, Avg. Test Loss: 0.0005537908291444182\n",
      "Epoch: 871, Avg. Train Loss: 0.000539025777089951, Avg. Test Loss: 0.0005668598460033536\n",
      "Epoch: 872, Avg. Train Loss: 0.0005443883886517481, Avg. Test Loss: 0.0005531309871003032\n",
      "Epoch: 873, Avg. Train Loss: 0.000537486748937734, Avg. Test Loss: 0.0005512947682291269\n",
      "Epoch: 874, Avg. Train Loss: 0.0005395881429607005, Avg. Test Loss: 0.000561821972951293\n",
      "Epoch: 875, Avg. Train Loss: 0.0005406788259278983, Avg. Test Loss: 0.0005522576975636184\n",
      "Epoch: 876, Avg. Train Loss: 0.0005376375622798277, Avg. Test Loss: 0.0005518206744454801\n",
      "Epoch: 877, Avg. Train Loss: 0.0005372111241571432, Avg. Test Loss: 0.0005503089632838964\n",
      "Epoch: 878, Avg. Train Loss: 0.0005363450381569131, Avg. Test Loss: 0.0005556395626626909\n",
      "Epoch: 879, Avg. Train Loss: 0.0005426491626949851, Avg. Test Loss: 0.0005579009302891791\n",
      "Epoch: 880, Avg. Train Loss: 0.0005412949357441691, Avg. Test Loss: 0.0005536205135285854\n",
      "Epoch: 881, Avg. Train Loss: 0.0005384965015975975, Avg. Test Loss: 0.0005508207250386477\n",
      "Epoch: 882, Avg. Train Loss: 0.0005366451507650836, Avg. Test Loss: 0.0005530869239009917\n",
      "Epoch: 883, Avg. Train Loss: 0.0005389990286392615, Avg. Test Loss: 0.000551701697986573\n",
      "Epoch: 884, Avg. Train Loss: 0.0005371979793782757, Avg. Test Loss: 0.0005533280200324953\n",
      "Epoch: 885, Avg. Train Loss: 0.0005398188077379018, Avg. Test Loss: 0.0005478807725012302\n",
      "Epoch: 886, Avg. Train Loss: 0.0005358587950468063, Avg. Test Loss: 0.0005556108080781996\n",
      "Epoch: 887, Avg. Train Loss: 0.000537573239430352, Avg. Test Loss: 0.0005611306405626237\n",
      "Epoch: 888, Avg. Train Loss: 0.0005375152280510858, Avg. Test Loss: 0.000548729847650975\n",
      "Epoch: 889, Avg. Train Loss: 0.0005398140929173678, Avg. Test Loss: 0.0005572774680331349\n",
      "Epoch: 890, Avg. Train Loss: 0.0005386693857956764, Avg. Test Loss: 0.0005543753504753113\n",
      "Epoch: 891, Avg. Train Loss: 0.000536798765520067, Avg. Test Loss: 0.000550907279830426\n",
      "Epoch: 892, Avg. Train Loss: 0.0005371346981751971, Avg. Test Loss: 0.0005737972096540034\n",
      "Epoch: 893, Avg. Train Loss: 0.0005389787710195971, Avg. Test Loss: 0.0005555343232117593\n",
      "Epoch: 894, Avg. Train Loss: 0.0005378397310228455, Avg. Test Loss: 0.0005598876741714776\n",
      "Epoch: 895, Avg. Train Loss: 0.0005365055498428816, Avg. Test Loss: 0.000551024975720793\n",
      "Epoch: 896, Avg. Train Loss: 0.0005364883623389138, Avg. Test Loss: 0.0005607560742646456\n",
      "Epoch: 897, Avg. Train Loss: 0.0005394116140154819, Avg. Test Loss: 0.0005547998589463532\n",
      "Epoch: 898, Avg. Train Loss: 0.0005387264157667063, Avg. Test Loss: 0.0005532253999263048\n",
      "Epoch: 899, Avg. Train Loss: 0.0005398584099291543, Avg. Test Loss: 0.000557777239009738\n",
      "Epoch: 900, Avg. Train Loss: 0.0005434098325908011, Avg. Test Loss: 0.000551769626326859\n",
      "Epoch: 901, Avg. Train Loss: 0.0005368655330913011, Avg. Test Loss: 0.0005518909310922027\n",
      "Epoch: 902, Avg. Train Loss: 0.0005376434913392417, Avg. Test Loss: 0.0005531292408704758\n",
      "Epoch: 903, Avg. Train Loss: 0.0005365561580198795, Avg. Test Loss: 0.0005521536222659051\n",
      "Epoch: 904, Avg. Train Loss: 0.0005368978647396055, Avg. Test Loss: 0.0005511784693226218\n",
      "Epoch: 905, Avg. Train Loss: 0.0005357230568120559, Avg. Test Loss: 0.0005580063443630934\n",
      "Epoch: 906, Avg. Train Loss: 0.0005362947040973881, Avg. Test Loss: 0.000548057840205729\n",
      "Epoch: 907, Avg. Train Loss: 0.0005336318315320843, Avg. Test Loss: 0.0005566405015997589\n",
      "Epoch: 908, Avg. Train Loss: 0.0005376751691666107, Avg. Test Loss: 0.0005495382356457412\n",
      "Epoch: 909, Avg. Train Loss: 0.0005367966801967731, Avg. Test Loss: 0.0005533994408324361\n",
      "Epoch: 910, Avg. Train Loss: 0.0005354095077098803, Avg. Test Loss: 0.000547312549315393\n",
      "Epoch: 911, Avg. Train Loss: 0.0005387537706600026, Avg. Test Loss: 0.0005564109887927771\n",
      "Epoch: 912, Avg. Train Loss: 0.0005398852585511672, Avg. Test Loss: 0.0005510846385732293\n",
      "Epoch: 913, Avg. Train Loss: 0.0005339626919987156, Avg. Test Loss: 0.0005507813184522092\n",
      "Epoch: 914, Avg. Train Loss: 0.000537731806574346, Avg. Test Loss: 0.0005524691077880561\n",
      "Epoch: 915, Avg. Train Loss: 0.0005385567072703135, Avg. Test Loss: 0.0005496101803146303\n",
      "Epoch: 916, Avg. Train Loss: 0.0005387522180044893, Avg. Test Loss: 0.0005535069503821433\n",
      "Epoch: 917, Avg. Train Loss: 0.00053720137640444, Avg. Test Loss: 0.0005523355794139206\n",
      "Epoch: 918, Avg. Train Loss: 0.0005354926126824995, Avg. Test Loss: 0.00054900161921978\n",
      "Epoch: 919, Avg. Train Loss: 0.0005374299842853446, Avg. Test Loss: 0.0005490593030117452\n",
      "Epoch: 920, Avg. Train Loss: 0.0005377139016271157, Avg. Test Loss: 0.0005513199721463025\n",
      "Epoch: 921, Avg. Train Loss: 0.0005394566667450289, Avg. Test Loss: 0.0005516016390174627\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 922, Avg. Train Loss: 0.0005384312528402133, Avg. Test Loss: 0.0005505910376086831\n",
      "Epoch: 923, Avg. Train Loss: 0.0005353015893528802, Avg. Test Loss: 0.0005550830392166972\n",
      "Epoch: 924, Avg. Train Loss: 0.0005383238360166636, Avg. Test Loss: 0.0005494935903698206\n",
      "Epoch: 925, Avg. Train Loss: 0.0005363530004234595, Avg. Test Loss: 0.0005558508564718068\n",
      "Epoch: 926, Avg. Train Loss: 0.0005379916279749989, Avg. Test Loss: 0.0005542868748307228\n",
      "Epoch: 927, Avg. Train Loss: 0.0005351898644855896, Avg. Test Loss: 0.0005539450794458389\n",
      "Epoch: 928, Avg. Train Loss: 0.0005370770150600651, Avg. Test Loss: 0.0005547364708036184\n",
      "Epoch: 929, Avg. Train Loss: 0.0005384950958149032, Avg. Test Loss: 0.0005505788722075522\n",
      "Epoch: 930, Avg. Train Loss: 0.0005406462154242882, Avg. Test Loss: 0.0005529562477022409\n",
      "Epoch: 931, Avg. Train Loss: 0.000537201086719802, Avg. Test Loss: 0.0005636292044073343\n",
      "Epoch: 932, Avg. Train Loss: 0.0005383878204495062, Avg. Test Loss: 0.0005628929939121008\n",
      "Epoch: 933, Avg. Train Loss: 0.0005426269084171847, Avg. Test Loss: 0.0005483123823069036\n",
      "Epoch: 934, Avg. Train Loss: 0.0005385866442825212, Avg. Test Loss: 0.0005528333131223917\n",
      "Epoch: 935, Avg. Train Loss: 0.0005346635853341066, Avg. Test Loss: 0.0005525717278942466\n",
      "Epoch: 936, Avg. Train Loss: 0.0005384867186495645, Avg. Test Loss: 0.0005609064246527851\n",
      "Epoch: 937, Avg. Train Loss: 0.0005364064073060141, Avg. Test Loss: 0.0005562374135479331\n",
      "Epoch: 938, Avg. Train Loss: 0.0005411083030319491, Avg. Test Loss: 0.0005466610309667885\n",
      "Epoch: 939, Avg. Train Loss: 0.0005367840910980175, Avg. Test Loss: 0.0005557817639783025\n",
      "Epoch: 940, Avg. Train Loss: 0.0005383227862482674, Avg. Test Loss: 0.0005594666581600904\n",
      "Epoch: 941, Avg. Train Loss: 0.0005374721279855125, Avg. Test Loss: 0.0005534021183848381\n",
      "Epoch: 942, Avg. Train Loss: 0.0005359362890716469, Avg. Test Loss: 0.000551036384422332\n",
      "Epoch: 943, Avg. Train Loss: 0.0005383276594477858, Avg. Test Loss: 0.0005562418373301625\n",
      "Epoch: 944, Avg. Train Loss: 0.0005397409062594348, Avg. Test Loss: 0.0005584836471825838\n",
      "Epoch: 945, Avg. Train Loss: 0.0005364120886444526, Avg. Test Loss: 0.0005500082042999566\n",
      "Epoch: 946, Avg. Train Loss: 0.0005368468430174818, Avg. Test Loss: 0.0005532169598154724\n",
      "Epoch: 947, Avg. Train Loss: 0.0005374395662138975, Avg. Test Loss: 0.0005507736932486296\n",
      "Epoch: 948, Avg. Train Loss: 0.0005339886275726523, Avg. Test Loss: 0.0005511664203368127\n",
      "Epoch: 949, Avg. Train Loss: 0.0005353591228878602, Avg. Test Loss: 0.0005544043960981071\n",
      "Epoch: 950, Avg. Train Loss: 0.0005341064683053383, Avg. Test Loss: 0.0005495898658409715\n",
      "Epoch: 951, Avg. Train Loss: 0.000534465872861315, Avg. Test Loss: 0.0005494000506587327\n",
      "Epoch: 952, Avg. Train Loss: 0.0005362881949918648, Avg. Test Loss: 0.0005497538368217647\n",
      "Epoch: 953, Avg. Train Loss: 0.000534641353391804, Avg. Test Loss: 0.0005606772028841078\n",
      "Epoch: 954, Avg. Train Loss: 0.0005360422777770043, Avg. Test Loss: 0.0005525817978195846\n",
      "Epoch: 955, Avg. Train Loss: 0.0005324470497895205, Avg. Test Loss: 0.0005491686169989407\n",
      "Epoch: 956, Avg. Train Loss: 0.0005345058547560299, Avg. Test Loss: 0.0005568354390561581\n",
      "Epoch: 957, Avg. Train Loss: 0.000535764136530329, Avg. Test Loss: 0.000557105930056423\n",
      "Epoch: 958, Avg. Train Loss: 0.0005374866474127441, Avg. Test Loss: 0.000552668992895633\n",
      "Epoch: 959, Avg. Train Loss: 0.0005387379578043988, Avg. Test Loss: 0.0005554927047342062\n",
      "Epoch: 960, Avg. Train Loss: 0.0005366348324419367, Avg. Test Loss: 0.0005488179158419371\n",
      "Epoch: 961, Avg. Train Loss: 0.0005364262913137154, Avg. Test Loss: 0.0005488800816237926\n",
      "Epoch: 962, Avg. Train Loss: 0.0005373624545998524, Avg. Test Loss: 0.0005680365720763803\n",
      "Epoch: 963, Avg. Train Loss: 0.0005427649167507108, Avg. Test Loss: 0.0005545144667848945\n",
      "Epoch: 964, Avg. Train Loss: 0.0005384237718021194, Avg. Test Loss: 0.0005476291407831013\n",
      "Epoch: 965, Avg. Train Loss: 0.0005369186489355512, Avg. Test Loss: 0.0005483231507241726\n",
      "Epoch: 966, Avg. Train Loss: 0.0005397320160544802, Avg. Test Loss: 0.0005533979274332523\n",
      "Epoch: 967, Avg. Train Loss: 0.0005400232479333618, Avg. Test Loss: 0.0005495481891557574\n",
      "Epoch: 968, Avg. Train Loss: 0.0005372799696065052, Avg. Test Loss: 0.000547437637578696\n",
      "Epoch: 969, Avg. Train Loss: 0.0005406321988841735, Avg. Test Loss: 0.0005516787059605122\n",
      "Epoch: 970, Avg. Train Loss: 0.0005382773253882607, Avg. Test Loss: 0.000553562946151942\n",
      "Epoch: 971, Avg. Train Loss: 0.0005387362650443995, Avg. Test Loss: 0.0005483608692884445\n",
      "Epoch: 972, Avg. Train Loss: 0.0005359637130019363, Avg. Test Loss: 0.0005571501096710563\n",
      "Epoch: 973, Avg. Train Loss: 0.0005355255487429108, Avg. Test Loss: 0.00055975082796067\n",
      "Epoch: 974, Avg. Train Loss: 0.0005361381911423577, Avg. Test Loss: 0.0005509263137355447\n",
      "Epoch: 975, Avg. Train Loss: 0.000536513242729788, Avg. Test Loss: 0.0005449725431390107\n",
      "Epoch: 976, Avg. Train Loss: 0.0005407695581345971, Avg. Test Loss: 0.0005581981386058033\n",
      "Epoch: 977, Avg. Train Loss: 0.0005349830513126975, Avg. Test Loss: 0.0005493915523402393\n",
      "Epoch: 978, Avg. Train Loss: 0.000534925282916574, Avg. Test Loss: 0.0005543466540984809\n",
      "Epoch: 979, Avg. Train Loss: 0.0005391693449319276, Avg. Test Loss: 0.0005569799686782062\n",
      "Epoch: 980, Avg. Train Loss: 0.0005327832403181251, Avg. Test Loss: 0.0005526209133677185\n",
      "Epoch: 981, Avg. Train Loss: 0.0005352440801838976, Avg. Test Loss: 0.0005523617146536708\n",
      "Epoch: 982, Avg. Train Loss: 0.0005358738349588198, Avg. Test Loss: 0.0005477188969962299\n",
      "Epoch: 983, Avg. Train Loss: 0.0005348836698536869, Avg. Test Loss: 0.0005598904681392014\n",
      "Epoch: 984, Avg. Train Loss: 0.0005392685950852844, Avg. Test Loss: 0.0005565244355238974\n",
      "Epoch: 985, Avg. Train Loss: 0.0005354322350941339, Avg. Test Loss: 0.0005482942215166986\n",
      "Epoch: 986, Avg. Train Loss: 0.0005358914353310802, Avg. Test Loss: 0.0005496596568264067\n",
      "Epoch: 987, Avg. Train Loss: 0.0005379470997912333, Avg. Test Loss: 0.0005549493944272399\n",
      "Epoch: 988, Avg. Train Loss: 0.0005375365131036487, Avg. Test Loss: 0.0005472233751788735\n",
      "Epoch: 989, Avg. Train Loss: 0.0005340165273167279, Avg. Test Loss: 0.0005530318012461066\n",
      "Epoch: 990, Avg. Train Loss: 0.000534639727638298, Avg. Test Loss: 0.0005579691496677697\n",
      "Epoch: 991, Avg. Train Loss: 0.0005362608455132346, Avg. Test Loss: 0.0005463745328597724\n",
      "Epoch: 992, Avg. Train Loss: 0.0005353482251954373, Avg. Test Loss: 0.0005502260173670948\n",
      "Epoch: 993, Avg. Train Loss: 0.0005337805609045506, Avg. Test Loss: 0.0005493552889674902\n",
      "Epoch: 994, Avg. Train Loss: 0.0005351290564312664, Avg. Test Loss: 0.0005486090085469186\n",
      "Epoch: 995, Avg. Train Loss: 0.0005380758240028437, Avg. Test Loss: 0.0005498843383975327\n",
      "Epoch: 996, Avg. Train Loss: 0.0005330504933480433, Avg. Test Loss: 0.0005491715855896473\n",
      "Epoch: 997, Avg. Train Loss: 0.0005353056036509833, Avg. Test Loss: 0.0005540585261769593\n",
      "Epoch: 998, Avg. Train Loss: 0.0005341743269317978, Avg. Test Loss: 0.0005535425152629614\n",
      "Epoch: 999, Avg. Train Loss: 0.0005355706928449488, Avg. Test Loss: 0.0005523964646272361\n",
      "Epoch: 1000, Avg. Train Loss: 0.0005359619640647759, Avg. Test Loss: 0.0005603015306405723\n",
      "Epoch: 1001, Avg. Train Loss: 0.0005384430500440472, Avg. Test Loss: 0.0005462432745844126\n",
      "Epoch: 1002, Avg. Train Loss: 0.0005337770873962273, Avg. Test Loss: 0.0005478415987454355\n",
      "Epoch: 1003, Avg. Train Loss: 0.0005337720050552296, Avg. Test Loss: 0.0005502342246472836\n",
      "Epoch: 1004, Avg. Train Loss: 0.0005338864480849183, Avg. Test Loss: 0.00055046466877684\n",
      "Epoch: 1005, Avg. Train Loss: 0.0005338450380720112, Avg. Test Loss: 0.000550547381862998\n",
      "Epoch: 1006, Avg. Train Loss: 0.0005354534795367007, Avg. Test Loss: 0.000546601542737335\n",
      "Epoch: 1007, Avg. Train Loss: 0.000537713503649155, Avg. Test Loss: 0.0005563810700550675\n",
      "Epoch: 1008, Avg. Train Loss: 0.000534738706381515, Avg. Test Loss: 0.0005486521986313164\n",
      "Epoch: 1009, Avg. Train Loss: 0.0005342758932085924, Avg. Test Loss: 0.0005588713684119284\n",
      "Epoch: 1010, Avg. Train Loss: 0.0005384650139603764, Avg. Test Loss: 0.0005460802931338549\n",
      "Epoch: 1011, Avg. Train Loss: 0.0005355770672606521, Avg. Test Loss: 0.0005499288090504706\n",
      "Epoch: 1012, Avg. Train Loss: 0.0005326238487912125, Avg. Test Loss: 0.0005449500749818981\n",
      "Epoch: 1013, Avg. Train Loss: 0.0005350127148842656, Avg. Test Loss: 0.0005467088194563985\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1014, Avg. Train Loss: 0.0005389678009060147, Avg. Test Loss: 0.0005551836220547557\n",
      "Epoch: 1015, Avg. Train Loss: 0.0005344508234736358, Avg. Test Loss: 0.000558628118596971\n",
      "Epoch: 1016, Avg. Train Loss: 0.0005343201208783877, Avg. Test Loss: 0.0005513778887689114\n",
      "Epoch: 1017, Avg. Train Loss: 0.0005338120891517678, Avg. Test Loss: 0.0005525244050659239\n",
      "Epoch: 1018, Avg. Train Loss: 0.0005353082460080555, Avg. Test Loss: 0.0005456125363707542\n",
      "Epoch: 1019, Avg. Train Loss: 0.0005376465052777771, Avg. Test Loss: 0.0005470642354339361\n",
      "Epoch: 1020, Avg. Train Loss: 0.0005373003612391564, Avg. Test Loss: 0.0005637889262288809\n",
      "Epoch: 1021, Avg. Train Loss: 0.0005354104133127907, Avg. Test Loss: 0.0005490774055942893\n",
      "Epoch: 1022, Avg. Train Loss: 0.0005364136101656355, Avg. Test Loss: 0.0005457789520733058\n",
      "Epoch: 1023, Avg. Train Loss: 0.0005343767034626285, Avg. Test Loss: 0.0005552173824980855\n",
      "Epoch: 1024, Avg. Train Loss: 0.0005313114014042672, Avg. Test Loss: 0.0005462646950036287\n",
      "Epoch: 1025, Avg. Train Loss: 0.0005343866204236482, Avg. Test Loss: 0.0005560651188716292\n",
      "Epoch: 1026, Avg. Train Loss: 0.0005354112755983721, Avg. Test Loss: 0.0005475924117490649\n",
      "Epoch: 1027, Avg. Train Loss: 0.000534128091097701, Avg. Test Loss: 0.0005463120760396123\n",
      "Epoch: 1028, Avg. Train Loss: 0.0005326242846718361, Avg. Test Loss: 0.0005550577188841999\n",
      "Epoch: 1029, Avg. Train Loss: 0.0005403204406828208, Avg. Test Loss: 0.0005446462891995907\n",
      "Epoch: 1030, Avg. Train Loss: 0.0005369343216866688, Avg. Test Loss: 0.0005541763384826481\n",
      "Epoch: 1031, Avg. Train Loss: 0.0005341289797797799, Avg. Test Loss: 0.0005514360964298248\n",
      "Epoch: 1032, Avg. Train Loss: 0.0005340652904462416, Avg. Test Loss: 0.0005472911871038377\n",
      "Epoch: 1033, Avg. Train Loss: 0.000533499329914014, Avg. Test Loss: 0.0005567830521613359\n",
      "Epoch: 1034, Avg. Train Loss: 0.0005378214971346478, Avg. Test Loss: 0.0005477674421854317\n",
      "Epoch: 1035, Avg. Train Loss: 0.0005377225332817626, Avg. Test Loss: 0.0005500895204022527\n",
      "Epoch: 1036, Avg. Train Loss: 0.000534760934262818, Avg. Test Loss: 0.0005517631070688367\n",
      "Epoch: 1037, Avg. Train Loss: 0.0005372391809265368, Avg. Test Loss: 0.0005630150553770363\n",
      "Epoch: 1038, Avg. Train Loss: 0.0005364215264075197, Avg. Test Loss: 0.0005483229761011899\n",
      "Epoch: 1039, Avg. Train Loss: 0.0005356447600629614, Avg. Test Loss: 0.0005483495187945664\n",
      "Epoch: 1040, Avg. Train Loss: 0.0005340132345228867, Avg. Test Loss: 0.0005486805457621813\n",
      "Epoch: 1041, Avg. Train Loss: 0.000533673657120617, Avg. Test Loss: 0.0005496624507941306\n",
      "Epoch: 1042, Avg. Train Loss: 0.0005395320341597463, Avg. Test Loss: 0.0005560145946219563\n",
      "Epoch: 1043, Avg. Train Loss: 0.0005348160724848682, Avg. Test Loss: 0.0005524097359739244\n",
      "Epoch: 1044, Avg. Train Loss: 0.0005340980721886681, Avg. Test Loss: 0.000553192978259176\n",
      "Epoch: 1045, Avg. Train Loss: 0.0005342672216207829, Avg. Test Loss: 0.0005466828006319702\n",
      "Epoch: 1046, Avg. Train Loss: 0.0005349846533770392, Avg. Test Loss: 0.0005497964448295534\n",
      "Epoch: 1047, Avg. Train Loss: 0.0005370299467210506, Avg. Test Loss: 0.000546183146070689\n",
      "Epoch: 1048, Avg. Train Loss: 0.0005334397584340687, Avg. Test Loss: 0.0005529578775167465\n",
      "Epoch: 1049, Avg. Train Loss: 0.00053521275904766, Avg. Test Loss: 0.0005527794710360467\n",
      "Epoch: 1050, Avg. Train Loss: 0.0005340797327144808, Avg. Test Loss: 0.0005482265260070562\n",
      "Epoch: 1051, Avg. Train Loss: 0.0005346122549760133, Avg. Test Loss: 0.0005508452886715531\n",
      "Epoch: 1052, Avg. Train Loss: 0.0005318499562807034, Avg. Test Loss: 0.0005559925921261311\n",
      "Epoch: 1053, Avg. Train Loss: 0.0005400960670708311, Avg. Test Loss: 0.0005560981226153672\n",
      "Epoch: 1054, Avg. Train Loss: 0.0005340374786904905, Avg. Test Loss: 0.0005465286667458713\n",
      "Epoch: 1055, Avg. Train Loss: 0.0005380712689149605, Avg. Test Loss: 0.0005465525318868458\n",
      "Epoch: 1056, Avg. Train Loss: 0.0005315115234034872, Avg. Test Loss: 0.000547241885215044\n",
      "Epoch: 1057, Avg. Train Loss: 0.0005323079402482701, Avg. Test Loss: 0.000554903584998101\n",
      "Epoch: 1058, Avg. Train Loss: 0.0005345472945496007, Avg. Test Loss: 0.000547597068361938\n",
      "Epoch: 1059, Avg. Train Loss: 0.0005326511948856764, Avg. Test Loss: 0.0005461666150949895\n",
      "Epoch: 1060, Avg. Train Loss: 0.0005340695463738209, Avg. Test Loss: 0.0005514362128451467\n",
      "Epoch: 1061, Avg. Train Loss: 0.0005317467615430699, Avg. Test Loss: 0.0005433134501799941\n",
      "Epoch: 1062, Avg. Train Loss: 0.0005379636767915948, Avg. Test Loss: 0.0005498419632203877\n",
      "Epoch: 1063, Avg. Train Loss: 0.0005362068917494008, Avg. Test Loss: 0.0005449441378004849\n",
      "Epoch: 1064, Avg. Train Loss: 0.0005309224097588814, Avg. Test Loss: 0.0005504865548573434\n",
      "Epoch: 1065, Avg. Train Loss: 0.0005340366949175679, Avg. Test Loss: 0.0005503425491042435\n",
      "Epoch: 1066, Avg. Train Loss: 0.0005372940321712819, Avg. Test Loss: 0.000553998164832592\n",
      "Epoch: 1067, Avg. Train Loss: 0.0005373235854190276, Avg. Test Loss: 0.0005621715099550784\n",
      "Epoch: 1068, Avg. Train Loss: 0.0005351116455723207, Avg. Test Loss: 0.0005503335269168019\n",
      "Epoch: 1069, Avg. Train Loss: 0.0005331037520041126, Avg. Test Loss: 0.0005497385864146054\n",
      "Epoch: 1070, Avg. Train Loss: 0.0005343720096239257, Avg. Test Loss: 0.0005484992288984358\n",
      "Epoch: 1071, Avg. Train Loss: 0.0005360045131880704, Avg. Test Loss: 0.0005481308326125145\n",
      "Epoch: 1072, Avg. Train Loss: 0.0005381792366807891, Avg. Test Loss: 0.0005433972692117095\n",
      "Epoch: 1073, Avg. Train Loss: 0.000532690103999664, Avg. Test Loss: 0.0005647070938721299\n",
      "Epoch: 1074, Avg. Train Loss: 0.0005370082758735259, Avg. Test Loss: 0.0005479721585288644\n",
      "Epoch: 1075, Avg. Train Loss: 0.0005340258838598032, Avg. Test Loss: 0.0005501046543940902\n",
      "Epoch: 1076, Avg. Train Loss: 0.0005349033494577418, Avg. Test Loss: 0.0005459367530420423\n",
      "Epoch: 1077, Avg. Train Loss: 0.0005331661675374435, Avg. Test Loss: 0.0005456313956528902\n",
      "Epoch: 1078, Avg. Train Loss: 0.0005363861442716836, Avg. Test Loss: 0.0005464608548209071\n",
      "Epoch: 1079, Avg. Train Loss: 0.0005364534357118659, Avg. Test Loss: 0.0005559184937737882\n",
      "Epoch: 1080, Avg. Train Loss: 0.0005367833343984256, Avg. Test Loss: 0.000545819872058928\n",
      "Epoch: 1081, Avg. Train Loss: 0.0005333149693310694, Avg. Test Loss: 0.0005569186178036034\n",
      "Epoch: 1082, Avg. Train Loss: 0.0005334177613529095, Avg. Test Loss: 0.0005532706854864955\n",
      "Epoch: 1083, Avg. Train Loss: 0.0005322085411915945, Avg. Test Loss: 0.0005462130648083985\n",
      "Epoch: 1084, Avg. Train Loss: 0.0005371316233216677, Avg. Test Loss: 0.0005513079231604934\n",
      "Epoch: 1085, Avg. Train Loss: 0.000536593888090317, Avg. Test Loss: 0.0005556609248742461\n",
      "Epoch: 1086, Avg. Train Loss: 0.0005330047928890603, Avg. Test Loss: 0.000544819631613791\n",
      "Epoch: 1087, Avg. Train Loss: 0.0005353037748474975, Avg. Test Loss: 0.0005484579014591873\n",
      "Epoch: 1088, Avg. Train Loss: 0.0005336775807230625, Avg. Test Loss: 0.0005480676190927625\n",
      "Epoch: 1089, Avg. Train Loss: 0.0005343747196643246, Avg. Test Loss: 0.0005514224176295102\n",
      "Epoch: 1090, Avg. Train Loss: 0.0005335830656952377, Avg. Test Loss: 0.0005423385300673544\n",
      "Epoch: 1091, Avg. Train Loss: 0.0005322737892721455, Avg. Test Loss: 0.0005609199870377779\n",
      "Epoch: 1092, Avg. Train Loss: 0.0005367061483327213, Avg. Test Loss: 0.0005467705195769668\n",
      "Epoch: 1093, Avg. Train Loss: 0.0005319066945365955, Avg. Test Loss: 0.000546997063793242\n",
      "Epoch: 1094, Avg. Train Loss: 0.0005327899984982904, Avg. Test Loss: 0.0005448691663332283\n",
      "Epoch: 1095, Avg. Train Loss: 0.0005309284620019499, Avg. Test Loss: 0.000546493916772306\n",
      "Epoch: 1096, Avg. Train Loss: 0.0005336048218237539, Avg. Test Loss: 0.0005436008214019239\n",
      "Epoch: 1097, Avg. Train Loss: 0.0005339284828149302, Avg. Test Loss: 0.0005503874272108078\n",
      "Epoch: 1098, Avg. Train Loss: 0.000536829803063166, Avg. Test Loss: 0.0005469346651807427\n",
      "Epoch: 1099, Avg. Train Loss: 0.000533678641320791, Avg. Test Loss: 0.0005545750609599054\n",
      "Epoch: 1100, Avg. Train Loss: 0.0005338288400982788, Avg. Test Loss: 0.0005501945270225406\n",
      "Epoch: 1101, Avg. Train Loss: 0.0005355036674002402, Avg. Test Loss: 0.0005656130379065871\n",
      "Epoch: 1102, Avg. Train Loss: 0.0005334900748959287, Avg. Test Loss: 0.0005476344376802444\n",
      "Epoch: 1103, Avg. Train Loss: 0.0005329830015652141, Avg. Test Loss: 0.0005508384783752263\n",
      "Epoch: 1104, Avg. Train Loss: 0.0005339270614650707, Avg. Test Loss: 0.0005542220897041261\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1105, Avg. Train Loss: 0.0005367705503716892, Avg. Test Loss: 0.0005490915500558913\n",
      "Epoch: 1106, Avg. Train Loss: 0.0005335624405551095, Avg. Test Loss: 0.0005465499125421047\n",
      "Epoch: 1107, Avg. Train Loss: 0.0005332699186320222, Avg. Test Loss: 0.0005477716913446784\n",
      "Epoch: 1108, Avg. Train Loss: 0.0005326084115780717, Avg. Test Loss: 0.0005430901073850691\n",
      "Epoch: 1109, Avg. Train Loss: 0.00053454126464203, Avg. Test Loss: 0.0005518415127880871\n",
      "Epoch: 1110, Avg. Train Loss: 0.0005332476988727183, Avg. Test Loss: 0.000545801711268723\n",
      "Epoch: 1111, Avg. Train Loss: 0.0005321668394635496, Avg. Test Loss: 0.0005465874564833939\n",
      "Epoch: 1112, Avg. Train Loss: 0.0005326399459167882, Avg. Test Loss: 0.0005487229791469872\n",
      "Epoch: 1113, Avg. Train Loss: 0.0005309067640810946, Avg. Test Loss: 0.0005462754634208977\n",
      "Epoch: 1114, Avg. Train Loss: 0.0005308017121129778, Avg. Test Loss: 0.0005479187238961458\n",
      "Epoch: 1115, Avg. Train Loss: 0.0005327244844222658, Avg. Test Loss: 0.0005577951669692993\n",
      "Epoch: 1116, Avg. Train Loss: 0.0005333518770490881, Avg. Test Loss: 0.0005519617698155344\n",
      "Epoch: 1117, Avg. Train Loss: 0.0005356214093152693, Avg. Test Loss: 0.0005441733519546688\n",
      "Epoch: 1118, Avg. Train Loss: 0.0005382912451412182, Avg. Test Loss: 0.0005434969789348543\n",
      "Epoch: 1119, Avg. Train Loss: 0.0005325626068867657, Avg. Test Loss: 0.0005451440811157227\n",
      "Epoch: 1120, Avg. Train Loss: 0.0005319712136677185, Avg. Test Loss: 0.0005455720820464194\n",
      "Epoch: 1121, Avg. Train Loss: 0.0005329938396963096, Avg. Test Loss: 0.0005482219276018441\n",
      "Epoch: 1122, Avg. Train Loss: 0.000534594934135892, Avg. Test Loss: 0.0005542967119254172\n",
      "Epoch: 1123, Avg. Train Loss: 0.0005332151614671009, Avg. Test Loss: 0.0005538305267691612\n",
      "Epoch: 1124, Avg. Train Loss: 0.0005370855282688903, Avg. Test Loss: 0.000546750146895647\n",
      "Epoch: 1125, Avg. Train Loss: 0.0005331105142452776, Avg. Test Loss: 0.0005484936409629881\n",
      "Epoch: 1126, Avg. Train Loss: 0.0005329992198439445, Avg. Test Loss: 0.0005460256361402571\n",
      "Epoch: 1127, Avg. Train Loss: 0.0005325254561856042, Avg. Test Loss: 0.0005496841622516513\n",
      "Epoch: 1128, Avg. Train Loss: 0.0005321129736880404, Avg. Test Loss: 0.0005421023815870285\n",
      "Epoch: 1129, Avg. Train Loss: 0.0005347739294615336, Avg. Test Loss: 0.0005516241071745753\n",
      "Epoch: 1130, Avg. Train Loss: 0.0005373982990128097, Avg. Test Loss: 0.0005475895013660192\n",
      "Epoch: 1131, Avg. Train Loss: 0.0005330755659595652, Avg. Test Loss: 0.0005547730252146721\n",
      "Epoch: 1132, Avg. Train Loss: 0.0005323648835846418, Avg. Test Loss: 0.0005446243449114263\n",
      "Epoch: 1133, Avg. Train Loss: 0.0005321766203810829, Avg. Test Loss: 0.0005409146542660892\n",
      "Epoch: 1134, Avg. Train Loss: 0.000533851365786219, Avg. Test Loss: 0.0005536358221434057\n",
      "Epoch: 1135, Avg. Train Loss: 0.0005315832277965667, Avg. Test Loss: 0.0005440569366328418\n",
      "Epoch: 1136, Avg. Train Loss: 0.0005324279272192439, Avg. Test Loss: 0.0005393051542341709\n",
      "Epoch: 1137, Avg. Train Loss: 0.0005374872876970141, Avg. Test Loss: 0.0005497816600836813\n",
      "Epoch: 1138, Avg. Train Loss: 0.0005337246158972469, Avg. Test Loss: 0.0005486220470629632\n",
      "Epoch: 1139, Avg. Train Loss: 0.0005337239160516494, Avg. Test Loss: 0.0005469964235089719\n",
      "Epoch: 1140, Avg. Train Loss: 0.0005327004927134705, Avg. Test Loss: 0.000546996365301311\n",
      "Epoch: 1141, Avg. Train Loss: 0.0005330648104021282, Avg. Test Loss: 0.0005569580825977027\n",
      "Epoch: 1142, Avg. Train Loss: 0.0005333264186426044, Avg. Test Loss: 0.0005470821051858366\n",
      "Epoch: 1143, Avg. Train Loss: 0.0005316165435604404, Avg. Test Loss: 0.0005398233188316226\n",
      "Epoch: 1144, Avg. Train Loss: 0.0005318385008776691, Avg. Test Loss: 0.0005493382923305035\n",
      "Epoch: 1145, Avg. Train Loss: 0.0005348793381207817, Avg. Test Loss: 0.0005492234486155212\n",
      "Epoch: 1146, Avg. Train Loss: 0.000538030774657463, Avg. Test Loss: 0.0005628005019389093\n",
      "Epoch: 1147, Avg. Train Loss: 0.0005328365043888605, Avg. Test Loss: 0.0005486649461090565\n",
      "Epoch: 1148, Avg. Train Loss: 0.0005310636783982519, Avg. Test Loss: 0.000553284480702132\n",
      "Epoch: 1149, Avg. Train Loss: 0.0005362404484659174, Avg. Test Loss: 0.000543550937436521\n",
      "Epoch: 1150, Avg. Train Loss: 0.0005337973233572272, Avg. Test Loss: 0.0005472862394526601\n",
      "Epoch: 1151, Avg. Train Loss: 0.0005323718096194572, Avg. Test Loss: 0.0005492546479217708\n",
      "Epoch: 1152, Avg. Train Loss: 0.0005345202591216061, Avg. Test Loss: 0.0005395746557042003\n",
      "Epoch: 1153, Avg. Train Loss: 0.0005349160698621512, Avg. Test Loss: 0.0005492006312124431\n",
      "Epoch: 1154, Avg. Train Loss: 0.0005313784573064727, Avg. Test Loss: 0.0005495809018611908\n",
      "Epoch: 1155, Avg. Train Loss: 0.0005307953038556112, Avg. Test Loss: 0.000548223964869976\n",
      "Epoch: 1156, Avg. Train Loss: 0.0005307127315507726, Avg. Test Loss: 0.0005479882238432765\n",
      "Epoch: 1157, Avg. Train Loss: 0.000532047945578301, Avg. Test Loss: 0.0005502725834958255\n",
      "Epoch: 1158, Avg. Train Loss: 0.0005331464831955558, Avg. Test Loss: 0.0005441265529952943\n",
      "Epoch: 1159, Avg. Train Loss: 0.0005307628429321528, Avg. Test Loss: 0.0005461522378027439\n",
      "Epoch: 1160, Avg. Train Loss: 0.0005338918079275551, Avg. Test Loss: 0.0005453504272736609\n",
      "Epoch: 1161, Avg. Train Loss: 0.000534921764737255, Avg. Test Loss: 0.000553625519387424\n",
      "Epoch: 1162, Avg. Train Loss: 0.0005354961910999792, Avg. Test Loss: 0.0005449116579256952\n",
      "Epoch: 1163, Avg. Train Loss: 0.0005314607412803398, Avg. Test Loss: 0.0005465359427034855\n",
      "Epoch: 1164, Avg. Train Loss: 0.0005318324526956002, Avg. Test Loss: 0.000545699498616159\n",
      "Epoch: 1165, Avg. Train Loss: 0.0005319666646713347, Avg. Test Loss: 0.0005464789574034512\n",
      "Epoch: 1166, Avg. Train Loss: 0.000533459383214629, Avg. Test Loss: 0.0005517423851415515\n",
      "Epoch: 1167, Avg. Train Loss: 0.0005346264589989428, Avg. Test Loss: 0.0005424426053650677\n",
      "Epoch: 1168, Avg. Train Loss: 0.0005347224637367871, Avg. Test Loss: 0.0005455374484881759\n",
      "Epoch: 1169, Avg. Train Loss: 0.0005332553964974575, Avg. Test Loss: 0.000558716943487525\n",
      "Epoch: 1170, Avg. Train Loss: 0.0005326192558006665, Avg. Test Loss: 0.0005435905186459422\n",
      "Epoch: 1171, Avg. Train Loss: 0.0005334224457159465, Avg. Test Loss: 0.0005530612543225288\n",
      "Epoch: 1172, Avg. Train Loss: 0.0005326199569999305, Avg. Test Loss: 0.0005566797335632145\n",
      "Epoch: 1173, Avg. Train Loss: 0.0005330688727553934, Avg. Test Loss: 0.0005530209164135158\n",
      "Epoch: 1174, Avg. Train Loss: 0.0005338574363037857, Avg. Test Loss: 0.000545296526979655\n",
      "Epoch: 1175, Avg. Train Loss: 0.0005312496349540387, Avg. Test Loss: 0.0005428033764474094\n",
      "Epoch: 1176, Avg. Train Loss: 0.0005335625617082642, Avg. Test Loss: 0.000543678761459887\n",
      "Epoch: 1177, Avg. Train Loss: 0.0005322846876414017, Avg. Test Loss: 0.0005444739945232868\n",
      "Epoch: 1178, Avg. Train Loss: 0.0005317105502864822, Avg. Test Loss: 0.0005433999467641115\n",
      "Epoch: 1179, Avg. Train Loss: 0.0005307927054927012, Avg. Test Loss: 0.0005418381770141423\n",
      "Epoch: 1180, Avg. Train Loss: 0.0005323121718098518, Avg. Test Loss: 0.0005503817228600383\n",
      "Epoch: 1181, Avg. Train Loss: 0.0005335730072760651, Avg. Test Loss: 0.0005427492433227599\n",
      "Epoch: 1182, Avg. Train Loss: 0.0005327274448909732, Avg. Test Loss: 0.0005447339499369264\n",
      "Epoch: 1183, Avg. Train Loss: 0.0005349820347091313, Avg. Test Loss: 0.0005491072661243379\n",
      "Epoch: 1184, Avg. Train Loss: 0.0005340346447896039, Avg. Test Loss: 0.0005393371684476733\n",
      "Epoch: 1185, Avg. Train Loss: 0.0005353815260689792, Avg. Test Loss: 0.0005578160053119063\n",
      "Epoch: 1186, Avg. Train Loss: 0.0005396102490120156, Avg. Test Loss: 0.0005484460270963609\n",
      "Epoch: 1187, Avg. Train Loss: 0.0005307817164277875, Avg. Test Loss: 0.0005422965041361749\n",
      "Epoch: 1188, Avg. Train Loss: 0.0005301770532157186, Avg. Test Loss: 0.0005489461473189294\n",
      "Epoch: 1189, Avg. Train Loss: 0.0005359712942113536, Avg. Test Loss: 0.0005418697837740183\n",
      "Epoch: 1190, Avg. Train Loss: 0.0005304324955051375, Avg. Test Loss: 0.0005495216464623809\n",
      "Epoch: 1191, Avg. Train Loss: 0.0005331951251719147, Avg. Test Loss: 0.0005529262125492096\n",
      "Epoch: 1192, Avg. Train Loss: 0.0005334814689609461, Avg. Test Loss: 0.0005404677358455956\n",
      "Epoch: 1193, Avg. Train Loss: 0.0005306541875037256, Avg. Test Loss: 0.0005648513906635344\n",
      "Epoch: 1194, Avg. Train Loss: 0.0005344207774912722, Avg. Test Loss: 0.0005464766290970147\n",
      "Epoch: 1195, Avg. Train Loss: 0.0005348811493266027, Avg. Test Loss: 0.00054723653011024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1196, Avg. Train Loss: 0.0005314000103850091, Avg. Test Loss: 0.0005431346362456679\n",
      "Epoch: 1197, Avg. Train Loss: 0.000531598818650859, Avg. Test Loss: 0.0005447135772556067\n",
      "Epoch: 1198, Avg. Train Loss: 0.0005326527861206857, Avg. Test Loss: 0.0005428387667052448\n",
      "Epoch: 1199, Avg. Train Loss: 0.0005348894209059519, Avg. Test Loss: 0.0005501598352566361\n",
      "Epoch: 1200, Avg. Train Loss: 0.0005342275673133689, Avg. Test Loss: 0.0005436953506432474\n",
      "Epoch: 1201, Avg. Train Loss: 0.0005324764311216165, Avg. Test Loss: 0.0005479598767124116\n",
      "Epoch: 1202, Avg. Train Loss: 0.0005341115804269996, Avg. Test Loss: 0.0005462240660563111\n",
      "Epoch: 1203, Avg. Train Loss: 0.0005304735901137424, Avg. Test Loss: 0.0005411380552686751\n",
      "Epoch: 1204, Avg. Train Loss: 0.0005345692584659298, Avg. Test Loss: 0.0005489968461915851\n",
      "Epoch: 1205, Avg. Train Loss: 0.0005323452364685837, Avg. Test Loss: 0.0005413292674347758\n",
      "Epoch: 1206, Avg. Train Loss: 0.0005299544718582183, Avg. Test Loss: 0.0005448543233796954\n",
      "Epoch: 1207, Avg. Train Loss: 0.0005330087212293387, Avg. Test Loss: 0.0005455631762742996\n",
      "Epoch: 1208, Avg. Train Loss: 0.0005345324908523972, Avg. Test Loss: 0.00054616027045995\n",
      "Epoch: 1209, Avg. Train Loss: 0.0005342331904441465, Avg. Test Loss: 0.0005441481480374932\n",
      "Epoch: 1210, Avg. Train Loss: 0.000530911709024939, Avg. Test Loss: 0.0005455351783894002\n",
      "Epoch: 1211, Avg. Train Loss: 0.0005312115766194671, Avg. Test Loss: 0.0005406801356002688\n",
      "Epoch: 1212, Avg. Train Loss: 0.0005308836624080445, Avg. Test Loss: 0.0005496199592016637\n",
      "Epoch: 1213, Avg. Train Loss: 0.0005308014190441734, Avg. Test Loss: 0.0005466724978759885\n",
      "Epoch: 1214, Avg. Train Loss: 0.0005350195610527555, Avg. Test Loss: 0.000549095799215138\n",
      "Epoch: 1215, Avg. Train Loss: 0.0005322086203810867, Avg. Test Loss: 0.0005461222608573735\n",
      "Epoch: 1216, Avg. Train Loss: 0.0005328608223312902, Avg. Test Loss: 0.0005487195448949933\n",
      "Epoch: 1217, Avg. Train Loss: 0.0005331678819561074, Avg. Test Loss: 0.0005471511976793408\n",
      "Epoch: 1218, Avg. Train Loss: 0.0005330047827365613, Avg. Test Loss: 0.000553448626305908\n",
      "Epoch: 1219, Avg. Train Loss: 0.0005410243885667431, Avg. Test Loss: 0.0005401429953053594\n",
      "Epoch: 1220, Avg. Train Loss: 0.0005342129686966452, Avg. Test Loss: 0.0005479503306560218\n",
      "Epoch: 1221, Avg. Train Loss: 0.0005330005213943158, Avg. Test Loss: 0.0005537010147236288\n",
      "Epoch: 1222, Avg. Train Loss: 0.0005326749158611651, Avg. Test Loss: 0.0005447407020255923\n",
      "Epoch: 1223, Avg. Train Loss: 0.0005306848927216907, Avg. Test Loss: 0.0005444460548460484\n",
      "Epoch: 1224, Avg. Train Loss: 0.0005311933501764353, Avg. Test Loss: 0.0005596534465439618\n",
      "Epoch: 1225, Avg. Train Loss: 0.0005323810700522086, Avg. Test Loss: 0.0005442003603093326\n",
      "Epoch: 1226, Avg. Train Loss: 0.0005302439128362768, Avg. Test Loss: 0.0005432342295534909\n",
      "Epoch: 1227, Avg. Train Loss: 0.0005322646675902138, Avg. Test Loss: 0.0005434851627796888\n",
      "Epoch: 1228, Avg. Train Loss: 0.0005308885741870591, Avg. Test Loss: 0.0005417304928414524\n",
      "Epoch: 1229, Avg. Train Loss: 0.0005319416211636434, Avg. Test Loss: 0.0005458627128973603\n",
      "Epoch: 1230, Avg. Train Loss: 0.0005327473261913415, Avg. Test Loss: 0.0005443181726150215\n",
      "Epoch: 1231, Avg. Train Loss: 0.000535271227289381, Avg. Test Loss: 0.0005447596777230501\n",
      "Epoch: 1232, Avg. Train Loss: 0.0005291319278956846, Avg. Test Loss: 0.000549947377294302\n",
      "Epoch: 1233, Avg. Train Loss: 0.0005335032772056239, Avg. Test Loss: 0.0005425550043582916\n",
      "Epoch: 1234, Avg. Train Loss: 0.0005332907217792994, Avg. Test Loss: 0.0005575523828156292\n",
      "Epoch: 1235, Avg. Train Loss: 0.000530311391759274, Avg. Test Loss: 0.0005416435888037086\n",
      "Epoch: 1236, Avg. Train Loss: 0.0005322989085851627, Avg. Test Loss: 0.0005504894070327282\n",
      "Epoch: 1237, Avg. Train Loss: 0.000535040108357058, Avg. Test Loss: 0.0005480821710079908\n",
      "Epoch: 1238, Avg. Train Loss: 0.000534688948983933, Avg. Test Loss: 0.0005424875416792929\n",
      "Epoch: 1239, Avg. Train Loss: 0.0005316029195836203, Avg. Test Loss: 0.0005452105542644858\n",
      "Epoch: 1240, Avg. Train Loss: 0.0005314925781635264, Avg. Test Loss: 0.0005475201178342104\n",
      "Epoch: 1241, Avg. Train Loss: 0.0005352551626518022, Avg. Test Loss: 0.0005450301105156541\n",
      "Epoch: 1242, Avg. Train Loss: 0.0005328727156454481, Avg. Test Loss: 0.0005475410143844783\n",
      "Epoch: 1243, Avg. Train Loss: 0.0005315634121490253, Avg. Test Loss: 0.0005446412833407521\n",
      "Epoch: 1244, Avg. Train Loss: 0.0005346489224182225, Avg. Test Loss: 0.0005459914682433009\n",
      "Epoch: 1245, Avg. Train Loss: 0.0005298868494465688, Avg. Test Loss: 0.0005478567909449339\n",
      "Epoch: 1246, Avg. Train Loss: 0.0005320041470207967, Avg. Test Loss: 0.0005445179413072765\n",
      "Epoch: 1247, Avg. Train Loss: 0.0005320773174347312, Avg. Test Loss: 0.0005437407526187599\n",
      "Epoch: 1248, Avg. Train Loss: 0.0005339070522432151, Avg. Test Loss: 0.0005476213991641998\n",
      "Epoch: 1249, Avg. Train Loss: 0.0005326356771293768, Avg. Test Loss: 0.000538953929208219\n",
      "Epoch: 1250, Avg. Train Loss: 0.0005315177435012058, Avg. Test Loss: 0.0005389323923736811\n",
      "Epoch: 1251, Avg. Train Loss: 0.0005310434011504227, Avg. Test Loss: 0.0005437631043605506\n",
      "Epoch: 1252, Avg. Train Loss: 0.0005310198087732546, Avg. Test Loss: 0.0005581430741585791\n",
      "Epoch: 1253, Avg. Train Loss: 0.0005341872266970228, Avg. Test Loss: 0.0005593928508460522\n",
      "Epoch: 1254, Avg. Train Loss: 0.0005327342734617982, Avg. Test Loss: 0.0005405376432463527\n",
      "Epoch: 1255, Avg. Train Loss: 0.0005339492981452061, Avg. Test Loss: 0.0005428367294371128\n",
      "Epoch: 1256, Avg. Train Loss: 0.000534186269654784, Avg. Test Loss: 0.0005497935926541686\n",
      "Epoch: 1257, Avg. Train Loss: 0.000530699655132065, Avg. Test Loss: 0.0005424573319032788\n",
      "Epoch: 1258, Avg. Train Loss: 0.0005317526263033235, Avg. Test Loss: 0.0005522204446606338\n",
      "Epoch: 1259, Avg. Train Loss: 0.0005333053603291858, Avg. Test Loss: 0.0005510992486961186\n",
      "Epoch: 1260, Avg. Train Loss: 0.000531720291947686, Avg. Test Loss: 0.0005440927343443036\n",
      "Epoch: 1261, Avg. Train Loss: 0.000530775313585087, Avg. Test Loss: 0.0005442507681436837\n",
      "Epoch: 1262, Avg. Train Loss: 0.000532286680238538, Avg. Test Loss: 0.0005414169281721115\n",
      "Epoch: 1263, Avg. Train Loss: 0.0005287514440444579, Avg. Test Loss: 0.0005432943580672145\n",
      "Epoch: 1264, Avg. Train Loss: 0.000531149597643593, Avg. Test Loss: 0.0005405063857324421\n",
      "Epoch: 1265, Avg. Train Loss: 0.0005289811544867536, Avg. Test Loss: 0.0005383625975809991\n",
      "Epoch: 1266, Avg. Train Loss: 0.0005297756538628926, Avg. Test Loss: 0.0005405133124440908\n",
      "Epoch: 1267, Avg. Train Loss: 0.0005310990456437562, Avg. Test Loss: 0.0005476947408169508\n",
      "Epoch: 1268, Avg. Train Loss: 0.0005333983199941644, Avg. Test Loss: 0.0005392285529524088\n",
      "Epoch: 1269, Avg. Train Loss: 0.0005313540906320478, Avg. Test Loss: 0.0005495980731211603\n",
      "Epoch: 1270, Avg. Train Loss: 0.0005320857514540643, Avg. Test Loss: 0.0005458394880406559\n",
      "Epoch: 1271, Avg. Train Loss: 0.0005327262489265914, Avg. Test Loss: 0.000552173878531903\n",
      "Epoch: 1272, Avg. Train Loss: 0.0005296877000567525, Avg. Test Loss: 0.0005483836284838617\n",
      "Epoch: 1273, Avg. Train Loss: 0.0005328961442289657, Avg. Test Loss: 0.0005400971276685596\n",
      "Epoch: 1274, Avg. Train Loss: 0.0005329589326974264, Avg. Test Loss: 0.0005480970139615238\n",
      "Epoch: 1275, Avg. Train Loss: 0.0005315240096235864, Avg. Test Loss: 0.0005433191545307636\n",
      "Epoch: 1276, Avg. Train Loss: 0.0005301363789205721, Avg. Test Loss: 0.0005406927666626871\n",
      "Epoch: 1277, Avg. Train Loss: 0.0005339393256838586, Avg. Test Loss: 0.0005524441949091852\n",
      "Epoch: 1278, Avg. Train Loss: 0.0005308419214236702, Avg. Test Loss: 0.0005434549530036747\n",
      "Epoch: 1279, Avg. Train Loss: 0.0005340210668374459, Avg. Test Loss: 0.0005473846686072648\n",
      "Epoch: 1280, Avg. Train Loss: 0.0005334023390301005, Avg. Test Loss: 0.0005503796855919063\n",
      "Epoch: 1281, Avg. Train Loss: 0.0005323937816577855, Avg. Test Loss: 0.0005406270502135158\n",
      "Epoch: 1282, Avg. Train Loss: 0.0005305545183905768, Avg. Test Loss: 0.0005470282630994916\n",
      "Epoch: 1283, Avg. Train Loss: 0.0005325873918441492, Avg. Test Loss: 0.0005481083644554019\n",
      "Epoch: 1284, Avg. Train Loss: 0.0005317498844517612, Avg. Test Loss: 0.0005425265408121049\n",
      "Epoch: 1285, Avg. Train Loss: 0.0005306825650920875, Avg. Test Loss: 0.0005413857870735228\n",
      "Epoch: 1286, Avg. Train Loss: 0.000530463206814602, Avg. Test Loss: 0.000558242667466402\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1287, Avg. Train Loss: 0.0005344178928278906, Avg. Test Loss: 0.0005393851897679269\n",
      "Epoch: 1288, Avg. Train Loss: 0.0005296635973473015, Avg. Test Loss: 0.0005451672477647662\n",
      "Epoch: 1289, Avg. Train Loss: 0.0005284250161588885, Avg. Test Loss: 0.0005416475469246507\n",
      "Epoch: 1290, Avg. Train Loss: 0.0005300628958096684, Avg. Test Loss: 0.0005452833720482886\n",
      "Epoch: 1291, Avg. Train Loss: 0.0005323121278156894, Avg. Test Loss: 0.0005500229308381677\n",
      "Epoch: 1292, Avg. Train Loss: 0.0005308036972649482, Avg. Test Loss: 0.0005422073299996555\n",
      "Epoch: 1293, Avg. Train Loss: 0.0005305660144036072, Avg. Test Loss: 0.000546927098184824\n",
      "Epoch: 1294, Avg. Train Loss: 0.0005317739946063781, Avg. Test Loss: 0.0005483657587319613\n",
      "Epoch: 1295, Avg. Train Loss: 0.0005310735933287719, Avg. Test Loss: 0.000544749025721103\n",
      "Epoch: 1296, Avg. Train Loss: 0.0005306283994794412, Avg. Test Loss: 0.0005434132181107998\n",
      "Epoch: 1297, Avg. Train Loss: 0.0005287621197355694, Avg. Test Loss: 0.0005402066744863987\n",
      "Epoch: 1298, Avg. Train Loss: 0.0005313451049936026, Avg. Test Loss: 0.0005472009652294219\n",
      "Epoch: 1299, Avg. Train Loss: 0.0005318608072716309, Avg. Test Loss: 0.0005398275679908693\n",
      "Epoch: 1300, Avg. Train Loss: 0.0005318260078892371, Avg. Test Loss: 0.00054121611174196\n",
      "Epoch: 1301, Avg. Train Loss: 0.0005304446791807666, Avg. Test Loss: 0.0005450366297736764\n",
      "Epoch: 1302, Avg. Train Loss: 0.0005367136239561491, Avg. Test Loss: 0.0005441508255898952\n",
      "Epoch: 1303, Avg. Train Loss: 0.0005301111019054038, Avg. Test Loss: 0.0005493056960403919\n",
      "Epoch: 1304, Avg. Train Loss: 0.0005307876691763657, Avg. Test Loss: 0.0005507699097506702\n",
      "Epoch: 1305, Avg. Train Loss: 0.0005340405400073545, Avg. Test Loss: 0.0005428080912679434\n",
      "Epoch: 1306, Avg. Train Loss: 0.0005335798338163903, Avg. Test Loss: 0.0005436701467260718\n",
      "Epoch: 1307, Avg. Train Loss: 0.0005340447011782766, Avg. Test Loss: 0.0005477115628309548\n",
      "Epoch: 1308, Avg. Train Loss: 0.0005317653000062375, Avg. Test Loss: 0.0005463538691401482\n",
      "Epoch: 1309, Avg. Train Loss: 0.0005325889783413258, Avg. Test Loss: 0.0005429072771221399\n",
      "Epoch: 1310, Avg. Train Loss: 0.0005303955701894538, Avg. Test Loss: 0.0005433995393104851\n",
      "Epoch: 1311, Avg. Train Loss: 0.000528946868820809, Avg. Test Loss: 0.0005461809341795743\n",
      "Epoch: 1312, Avg. Train Loss: 0.0005318101429174719, Avg. Test Loss: 0.0005456176004372537\n",
      "Epoch: 1313, Avg. Train Loss: 0.000529232723936222, Avg. Test Loss: 0.0005399937508627772\n",
      "Epoch: 1314, Avg. Train Loss: 0.0005306583507051475, Avg. Test Loss: 0.0005415373598225415\n",
      "Epoch: 1315, Avg. Train Loss: 0.0005319217466316078, Avg. Test Loss: 0.0005403259419836104\n",
      "Epoch: 1316, Avg. Train Loss: 0.0005303385476635899, Avg. Test Loss: 0.0005478927050717175\n",
      "Epoch: 1317, Avg. Train Loss: 0.0005318572437444832, Avg. Test Loss: 0.0005473502678796649\n",
      "Epoch: 1318, Avg. Train Loss: 0.000532114872882186, Avg. Test Loss: 0.0005535937962122262\n",
      "Epoch: 1319, Avg. Train Loss: 0.0005308565613272232, Avg. Test Loss: 0.0005454212659969926\n",
      "Epoch: 1320, Avg. Train Loss: 0.0005308827791406318, Avg. Test Loss: 0.0005408672732301056\n",
      "Epoch: 1321, Avg. Train Loss: 0.0005318369502526556, Avg. Test Loss: 0.0005537854740396142\n",
      "Epoch: 1322, Avg. Train Loss: 0.0005330297294570956, Avg. Test Loss: 0.0005424538976512849\n",
      "Epoch: 1323, Avg. Train Loss: 0.0005305377647367328, Avg. Test Loss: 0.0005440308596007526\n",
      "Epoch: 1324, Avg. Train Loss: 0.0005329351555447766, Avg. Test Loss: 0.000545762712135911\n",
      "Epoch: 1325, Avg. Train Loss: 0.0005327836558937507, Avg. Test Loss: 0.0005449663149192929\n",
      "Epoch: 1326, Avg. Train Loss: 0.0005310139724399981, Avg. Test Loss: 0.0005532386712729931\n",
      "Epoch: 1327, Avg. Train Loss: 0.0005300405034578817, Avg. Test Loss: 0.0005447154981084168\n",
      "Epoch: 1328, Avg. Train Loss: 0.0005318454594004813, Avg. Test Loss: 0.0005501437117345631\n",
      "Epoch: 1329, Avg. Train Loss: 0.0005303830122250284, Avg. Test Loss: 0.0005398899083957076\n",
      "Epoch: 1330, Avg. Train Loss: 0.0005307053818183323, Avg. Test Loss: 0.0005432525067590177\n",
      "Epoch: 1331, Avg. Train Loss: 0.0005304474223859955, Avg. Test Loss: 0.0005498707760125399\n",
      "Epoch: 1332, Avg. Train Loss: 0.0005296661801430461, Avg. Test Loss: 0.0005395615007728338\n",
      "Epoch: 1333, Avg. Train Loss: 0.0005310998422765108, Avg. Test Loss: 0.0005387659184634686\n",
      "Epoch: 1334, Avg. Train Loss: 0.0005286417503538, Avg. Test Loss: 0.0005412216996774077\n",
      "Epoch: 1335, Avg. Train Loss: 0.00052989031009506, Avg. Test Loss: 0.0005446288269013166\n",
      "Epoch: 1336, Avg. Train Loss: 0.0005321506320141515, Avg. Test Loss: 0.0005405873525887728\n",
      "Epoch: 1337, Avg. Train Loss: 0.000533723447683029, Avg. Test Loss: 0.0005463681882247329\n",
      "Epoch: 1338, Avg. Train Loss: 0.0005330570782588925, Avg. Test Loss: 0.0005399537621997297\n",
      "Epoch: 1339, Avg. Train Loss: 0.0005284326386551351, Avg. Test Loss: 0.0005415657651610672\n",
      "Epoch: 1340, Avg. Train Loss: 0.0005325783364918776, Avg. Test Loss: 0.000548465468455106\n",
      "Epoch: 1341, Avg. Train Loss: 0.0005304009889165849, Avg. Test Loss: 0.0005587113555520773\n",
      "Epoch: 1342, Avg. Train Loss: 0.0005324988674675656, Avg. Test Loss: 0.0005440509994514287\n",
      "Epoch: 1343, Avg. Train Loss: 0.0005322492926457333, Avg. Test Loss: 0.0005382283707149327\n",
      "Epoch: 1344, Avg. Train Loss: 0.0005311247301125509, Avg. Test Loss: 0.0005454699858091772\n",
      "Epoch: 1345, Avg. Train Loss: 0.0005351455021259743, Avg. Test Loss: 0.0005612754612229764\n",
      "Epoch: 1346, Avg. Train Loss: 0.0005315981594152576, Avg. Test Loss: 0.000542967754881829\n",
      "Epoch: 1347, Avg. Train Loss: 0.0005306977410475876, Avg. Test Loss: 0.0005436622886918485\n",
      "Epoch: 1348, Avg. Train Loss: 0.0005299629464875473, Avg. Test Loss: 0.000542704772669822\n",
      "Epoch: 1349, Avg. Train Loss: 0.0005315673039403072, Avg. Test Loss: 0.0005599544965662062\n",
      "Epoch: 1350, Avg. Train Loss: 0.0005297159077599645, Avg. Test Loss: 0.0005423416732810438\n",
      "Epoch: 1351, Avg. Train Loss: 0.000529371555299, Avg. Test Loss: 0.000546686933375895\n",
      "Epoch: 1352, Avg. Train Loss: 0.0005313782210916628, Avg. Test Loss: 0.0005431829486042261\n",
      "Epoch: 1353, Avg. Train Loss: 0.0005311720116540443, Avg. Test Loss: 0.000547860050573945\n",
      "Epoch: 1354, Avg. Train Loss: 0.0005308418083925147, Avg. Test Loss: 0.0005403009126894176\n",
      "Epoch: 1355, Avg. Train Loss: 0.0005298412863847388, Avg. Test Loss: 0.0005429002339951694\n",
      "Epoch: 1356, Avg. Train Loss: 0.0005313810306265517, Avg. Test Loss: 0.0005518872640095651\n",
      "Epoch: 1357, Avg. Train Loss: 0.0005301300369928656, Avg. Test Loss: 0.0005451774341054261\n",
      "Epoch: 1358, Avg. Train Loss: 0.0005318043086147153, Avg. Test Loss: 0.0005389361176639795\n",
      "Epoch: 1359, Avg. Train Loss: 0.0005305284440658207, Avg. Test Loss: 0.0005472407792694867\n",
      "Epoch: 1360, Avg. Train Loss: 0.0005323457427398669, Avg. Test Loss: 0.0005436594947241247\n",
      "Epoch: 1361, Avg. Train Loss: 0.000528086501384847, Avg. Test Loss: 0.0005391740123741329\n",
      "Epoch: 1362, Avg. Train Loss: 0.0005297874003042315, Avg. Test Loss: 0.000543788424693048\n",
      "Epoch: 1363, Avg. Train Loss: 0.0005303095927364518, Avg. Test Loss: 0.0005394672625698149\n",
      "Epoch: 1364, Avg. Train Loss: 0.0005301721773088671, Avg. Test Loss: 0.0005496604135259986\n",
      "Epoch: 1365, Avg. Train Loss: 0.0005313452146405918, Avg. Test Loss: 0.0005415977211669087\n",
      "Epoch: 1366, Avg. Train Loss: 0.0005286942705847756, Avg. Test Loss: 0.0005483804270625114\n",
      "Epoch: 1367, Avg. Train Loss: 0.0005328286497388035, Avg. Test Loss: 0.0005434089107438922\n",
      "Epoch: 1368, Avg. Train Loss: 0.0005327294293661104, Avg. Test Loss: 0.0005387120763771236\n",
      "Epoch: 1369, Avg. Train Loss: 0.0005304455976435092, Avg. Test Loss: 0.0005410673911683261\n",
      "Epoch: 1370, Avg. Train Loss: 0.0005292370719131255, Avg. Test Loss: 0.0005421714740805328\n",
      "Epoch: 1371, Avg. Train Loss: 0.0005357323172448073, Avg. Test Loss: 0.0005484757130034268\n",
      "Epoch: 1372, Avg. Train Loss: 0.0005321406785041353, Avg. Test Loss: 0.0005429435987025499\n",
      "Epoch: 1373, Avg. Train Loss: 0.0005311850271577579, Avg. Test Loss: 0.0005476268706843257\n",
      "Epoch: 1374, Avg. Train Loss: 0.0005296363541314942, Avg. Test Loss: 0.0005451107281260192\n",
      "Epoch: 1375, Avg. Train Loss: 0.0005282137825879333, Avg. Test Loss: 0.0005474270437844098\n",
      "Epoch: 1376, Avg. Train Loss: 0.0005300398476064465, Avg. Test Loss: 0.0005397967179305851\n",
      "Epoch: 1377, Avg. Train Loss: 0.0005312648142937051, Avg. Test Loss: 0.000537317362613976\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1378, Avg. Train Loss: 0.0005302802438923525, Avg. Test Loss: 0.0005420970264822245\n",
      "Epoch: 1379, Avg. Train Loss: 0.0005286593514028937, Avg. Test Loss: 0.000540867738891393\n",
      "Epoch: 1380, Avg. Train Loss: 0.0005303556539475658, Avg. Test Loss: 0.0005427008145488799\n",
      "Epoch: 1381, Avg. Train Loss: 0.0005305907702571604, Avg. Test Loss: 0.0005390167352743447\n",
      "Epoch: 1382, Avg. Train Loss: 0.0005323847966961736, Avg. Test Loss: 0.0005462597473524511\n",
      "Epoch: 1383, Avg. Train Loss: 0.0005312384929248067, Avg. Test Loss: 0.0005528818583115935\n",
      "Epoch: 1384, Avg. Train Loss: 0.0005287537987473919, Avg. Test Loss: 0.0005420860834419727\n",
      "Epoch: 1385, Avg. Train Loss: 0.0005320347243172745, Avg. Test Loss: 0.0005419536028057337\n",
      "Epoch: 1386, Avg. Train Loss: 0.0005295800456647263, Avg. Test Loss: 0.000546202645637095\n",
      "Epoch: 1387, Avg. Train Loss: 0.0005264300406304036, Avg. Test Loss: 0.0005391394370235503\n",
      "Epoch: 1388, Avg. Train Loss: 0.0005292716181598777, Avg. Test Loss: 0.0005449939053505659\n",
      "Epoch: 1389, Avg. Train Loss: 0.000530997658050944, Avg. Test Loss: 0.0005396341439336538\n",
      "Epoch: 1390, Avg. Train Loss: 0.0005300062976582626, Avg. Test Loss: 0.0005426228744909167\n",
      "Epoch: 1391, Avg. Train Loss: 0.000529985198734848, Avg. Test Loss: 0.000541664834599942\n",
      "Epoch: 1392, Avg. Train Loss: 0.00052982633446105, Avg. Test Loss: 0.0005409303121268749\n",
      "Epoch: 1393, Avg. Train Loss: 0.0005298933917169221, Avg. Test Loss: 0.0005423024413175881\n",
      "Epoch: 1394, Avg. Train Loss: 0.0005291683225740873, Avg. Test Loss: 0.0005452943150885403\n",
      "Epoch: 1395, Avg. Train Loss: 0.0005292473340591113, Avg. Test Loss: 0.0005439527449198067\n",
      "Epoch: 1396, Avg. Train Loss: 0.0005277837179926072, Avg. Test Loss: 0.0005433832993730903\n",
      "Epoch: 1397, Avg. Train Loss: 0.0005304300629663779, Avg. Test Loss: 0.0005611844826489687\n",
      "Epoch: 1398, Avg. Train Loss: 0.0005315334270816556, Avg. Test Loss: 0.0005470445030368865\n",
      "Epoch: 1399, Avg. Train Loss: 0.0005335533648978399, Avg. Test Loss: 0.00054342852672562\n",
      "Epoch: 1400, Avg. Train Loss: 0.0005299631502143605, Avg. Test Loss: 0.000542862864676863\n",
      "Finished Training\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2accc07f1f60>"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Now let's train the initial network \n",
    "\n",
    "model = offCenterLineNet()\n",
    "model = model.to(dev)\n",
    "model.apply(weights_init_uniform)\n",
    "\n",
    "model.train();\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=.01) \n",
    "# scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=500, gamma=0.1)\n",
    "\n",
    "n_epochs = 1400\n",
    "\n",
    "mse_loss = nn.MSELoss()\n",
    "ce_loss = nn.CrossEntropyLoss()\n",
    "\n",
    "for epoch in range(0,n_epochs):  # loop over the dataset multiple times\n",
    "    \n",
    "    if epoch == 0:\n",
    "        train_loss_over_time = [] # to track the loss as the network trains\n",
    "        test_loss_over_time = []\n",
    "        \n",
    "    if epoch == 10:\n",
    "        optimizer = torch.optim.Adam(model.parameters(),lr=.002) \n",
    "        \n",
    "    running_loss = 0\n",
    "    num_batches = 0\n",
    "    \n",
    "    for batch_i, data in enumerate(train_loader):\n",
    "        \n",
    "        # get the input images and their corresponding labels\n",
    "        num_batches += 1\n",
    "\n",
    "        inputs, output_gt, _, _ = data\n",
    "        inputs, output_gt = inputs.to(dev), output_gt.to(dev)\n",
    "        \n",
    "        # zero the parameter (weight) gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # forward pass to get outputs\n",
    "        output_line_params = model(inputs)\n",
    "        \n",
    "\n",
    "        # make the ground truth\n",
    "        c = -output_gt[:,2]*torch.cos(output_gt[:,0]) + output_gt[:,1]*torch.sin(output_gt[:,0])\n",
    "        gt_line_params = torch.stack((-torch.sin(output_gt[:,0]),torch.cos(output_gt[:,0]),c),dim=1)\n",
    "        \n",
    "        # calculate the loss\n",
    "#         print(output_line_params[:,:,0,50])\n",
    "        \n",
    "        loss = mse_loss(output_line_params,gt_line_params)\n",
    "        \n",
    "        # backward pass to calculate the parameter gradients\n",
    "        loss.backward()\n",
    "\n",
    "        # update the parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        # to convert loss into a scalar and add it to running_loss, we use .item()\n",
    "        running_loss += loss.item()\n",
    "      \n",
    "\n",
    "#     scheduler.step()\n",
    "    \n",
    "    # Calculate test data loss after each epoch\n",
    "    with torch.no_grad():\n",
    "        test_loss = 0\n",
    "        num_batches_test = 0\n",
    "        for batch_i, data in enumerate(test_loader):\n",
    "            num_batches_test += 1\n",
    "\n",
    "            # Add code here\n",
    "            inputs, output_gt, _, _ = data\n",
    "            inputs, output_gt = inputs.to(dev), output_gt.to(dev)\n",
    "\n",
    "\n",
    "            # zero the parameter (weight) gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward pass to get outputs\n",
    "            output_line_params = model(inputs)\n",
    "\n",
    "            # make the ground truth\n",
    "            c = -output_gt[:,2]*torch.cos(output_gt[:,0]) + output_gt[:,1]*torch.sin(output_gt[:,0])\n",
    "            gt_line_params = torch.stack((-torch.sin(output_gt[:,0]),torch.cos(output_gt[:,0]),c),dim=1)\n",
    "    \n",
    "\n",
    "            # calculate the loss\n",
    "    #         print(output_line_params[:,:,0,50])\n",
    "\n",
    "            loss = mse_loss(output_line_params,gt_line_params)\n",
    "            \n",
    "            test_loss += loss\n",
    "                    \n",
    "        test_loss_over_time.append(test_loss/num_batches_test)\n",
    "\n",
    "    # Calculate model loss:\n",
    "    avg_loss = running_loss/num_batches\n",
    "    train_loss_over_time.append(avg_loss)\n",
    "    \n",
    "#     print('Epoch: {}, Avg. Train Loss: {},'.format(epoch + 1, train_loss_over_time[-1]))\n",
    "\n",
    "\n",
    "    print('Epoch: {}, Avg. Train Loss: {}, Avg. Test Loss: {}'.format(epoch + 1, train_loss_over_time[-1], test_loss_over_time[-1]))\n",
    "    \n",
    "print('Finished Training')\n",
    "\n",
    "plt.figure()\n",
    "plt.semilogy(np.arange(0,n_epochs),train_loss_over_time[0:])\n",
    "plt.semilogy(np.arange(0,n_epochs),test_loss_over_time[0:])\n",
    "plt.legend(['Training loss', 'Testing loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "f0601c51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor(1.0105), tensor(1.1114), tensor(1.0789), tensor(1.1080), tensor(1.1280), tensor(1.0390), tensor(1.0820), tensor(1.1257), tensor(1.1319), tensor(1.0466), tensor(1.0259), tensor(1.0624), tensor(1.1279), tensor(1.1362), tensor(1.0710)]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1080 with 9 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the Results\n",
    "\n",
    "plt.figure()\n",
    "plt.semilogy(np.arange(0,epoch),train_loss_over_time[:epoch])\n",
    "plt.semilogy(np.arange(0,epoch),test_loss_over_time[:epoch])\n",
    "plt.legend(['Training loss', 'Testing loss'])\n",
    "\n",
    "model.eval();\n",
    "\n",
    "ang_loss_all = []\n",
    "\n",
    "for batch_i, data in enumerate(test_loader):\n",
    "    # get the input images and their corresponding labels\n",
    "    inputs, output_gt, _, _ = data\n",
    "    inputs, output_gt = inputs.to(dev), output_gt.to(dev)\n",
    "    \n",
    "\n",
    "    # forward pass to get outputs\n",
    "    outputs = model(inputs).squeeze().detach().cpu()\n",
    "    \n",
    "    gt = output_gt.cpu().squeeze()\n",
    "    \n",
    "    c = -output_gt[:,2]*torch.cos(output_gt[:,0]) + output_gt[:,1]*torch.sin(output_gt[:,0])\n",
    "    angle_params = torch.stack((-torch.sin(output_gt[:,0]),torch.cos(output_gt[:,0]),c),axis=1).detach().cpu()\n",
    "  \n",
    "    # Calculate angular loss\n",
    "    ang_loss = torch.mean(torch.abs(torch.rad2deg(torch.atan2(-angle_params[:,0]*outputs[:,1] + angle_params[:,1]*outputs[:,0]\n",
    "                                         ,angle_params[:,1]*outputs[:,1]+angle_params[:,0]*outputs[:,0]).cpu())))\n",
    "\n",
    "    ang_loss_all.append(ang_loss)\n",
    "\n",
    "    \n",
    "print(ang_loss_all)\n",
    "\n",
    "plt.figure(figsize=[15, 15])\n",
    "\n",
    "for ii in range(9):\n",
    "    \n",
    "    plt.subplot(3,3,ii+1)\n",
    "    plt.imshow(inputs[ii].cpu().squeeze(),cmap='gray', vmin=0, vmax=1)\n",
    "    \n",
    "    # Plot the ground truth lines\n",
    "    x_sample = torch.linspace(-1,1,inputs.shape[-1])\n",
    "    y_sample = -angle_params[ii,0]/angle_params[ii,1]*x_sample - angle_params[ii,2]/angle_params[ii,1]\n",
    "    \n",
    "    plt.plot(x_sample*W/2+W/2,y_sample*W/2+W/2,'b')\n",
    "    plt.xlim([0,W])\n",
    "    plt.ylim(([0,W]))\n",
    "    \n",
    "    # Plot the estimated lines\n",
    "    y_est = -outputs[ii,0]/outputs[ii,1]*x_sample - outputs[ii,2]/outputs[ii,1]\n",
    "    plt.plot(x_sample*W/2+W/2,y_est*W/2+W/2,'r')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96478202",
   "metadata": {},
   "source": [
    "## test trained model on noiseless, multicolor data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "9f6940d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "[tensor(0.2804), tensor(0.2585), tensor(0.2758)]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1080 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA2QAAANSCAYAAAAKyw14AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4xLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvDW2N/gAAIABJREFUeJzs3Xd4lFX6xvHvmfROCKTQLQgqoK5YKKuAUqQoTVfdxXXVxd/adUVUVGBpKip21l27q64gSBGlKGADdQEVxEJVKSmUQHqbOb8/EiNRMhNIeWcm9+e6uAzvyWRuJzOHeeY973OMtRYRERERERFpeC6nA4iIiIiIiDRWKshEREREREQcooJMRERERETEISrIREREREREHKKCTERERERExCEqyERERERERByigkxERERERMQhKshEREREREQcooJMRERERETEIaENeWfNmjWz7dq1a8i7lMbup5/w7N3PF/ZUTj/d6TCBbe3atXuttc2dzlEfNDeJBK5gnpvAf+envXuh8MdMWrMTTjgB4uKcjiTid2o6PzVoQdauXTvWrFnTkHcpjd3Ikex+byNnxq5BT73aMcb86HSG+qK5SSRwBfPcBP47P5WVweknFfL29vakJDbFrF4FxjgdS8Sv1HR+0pJFCW7p6WS50mjZ0ukgIiIiwSM0FO6ZEsW9ZeMxn30KCxc6HUkkYDXoGbLNmzczcODAhrxLCVDWWq/jZWVl1Y6tXr268uv1BQVstANZu3YhsbGX1Vm+xiIvL8/pCA0iIyOD6dOnOx1DgpyveU1+4euxGjt2bAMlcV5mZiaPPPJInfwsb4+rx+PxetuDBw8e5ucZFqdczbZ97Wk99k5yunUD128/6w8PD6/255panFVzHea+Gkptcktwi4qKOuLb6AyZBC9rSbWWDNpizG6n04iIiAQVYyy/77OSu8v+Qdh33xI+Z47TkUQCkgoyCVrxQDSQzjEYk+50HBERkaBzzDFb2NV9GBtCTyVy2gNQUuJ0JJGAo4JMglZqxdKMdNJ0hkxERKQeGAP33FfE2LIphP30AxGvvup0JJGAo4JMglbKIQWZy6WCTEREpD507VqG7X8eq0J6Ejn9ISgocDqSSEBRQSZB6+czZBmkYkyGw2lERESC17h7CrnTPYXQrEwin33W6TgiAUUFmQStFC1ZFBERaRAnnugm7ZKzWOy6gIhHH8fk5DgdSSRgqCCToJViLUWEcoAwQP8wiIiI1KexYwu4zzWZ0JwDRD71lNNxRAJGg+5DJlJXarKfT6rHQzpNMSYdbRciIg1Be43VnLfHSo9jw/O1p1dcXFy1Yz/vUdakCXS87Dje+M8fGPHUTPZccgnuZs1ISkqq9rYhISFHFxjfe6c5uU+ZyJHw+Uw1xkQaYz43xnxljNlojJlYcfwYY8xnxpgtxpg3jDHV7/on4oDyPciSdf1YENP8JNLI7dzpdILDasxz0/XXH2BK+ARMcTFNnn7a6TgiAaEmHx0UA32stacApwIDjDFnAw8AM6y1xwPZwNX1F1PkyKVaSzotdf1YcNP8JNJYeTxw1VVOp6hOo52bmjd30/OqFJ63fyH21dcJ3bXL6Ugifs9nQWbL5VX8NazijwX6AG9WHH8JGFovCUWOUrK1pHOMWt4HMc1PIo3Y00/DsmVOpzisxj43jR59kEfjxuF2GxIff9zpOCJ+r0aLa40xIcaYL4EsYBmwFThgrS2r+JadQMtqbjvaGLPGGLOmRLu3SwMJt5YkIIOWGJPudBypR0c7Px06N+Xn5zdcYBGpve+/hzvugAEDnE5Srbp67xSI81N8vIfBf4vjSXsdMXPm4vr+e6cjifi1GhVk1lq3tfZUoBVwJtCxpndgrf2XtbartbZreHjQLZUWP1W15b0KsmB2tPPToXNTTExMvWYUkbpj3G644gqIioLnnnM6TrXq6r1ToM5PV1yRw7PNxlBooomYMsXpOCJ+7Yjaz1hrDwArgG5AE2PMz10aWwFaJCx+QwVZ46P5SaRx6LZyJXz+OcycCS1aOB3Hp8Y6N0VFWS6/OZTpnr8TvmABIV984XQkEb/ls+29MaY5UGqtPWCMiQL6Un5R6gpgJPBf4M/A/PoMKsGnNi2PfbW6TdWm0I2C5idpaGrHXnO1eayqm+NTd+2ix/LlcPnlcMklR/3z65u/zk3Gyx4wvn5f3trTv/TSS4c97na7eKXJldyc+yTREydSNHv2EWUC/21d7+3x8vX/JPJrNXmWpwErjDHrgf8By6y1bwNjgduMMVuAJMB/1w1Io/NzQZZBqtreBzfNTyKNRGhpKRfOnk1+bCw8+aTTcXzR3ASEhHg4vfcaJrvvImLlSsI++cTpSCJ+yecZMmvteuC0wxzfRvmaaBG/k2otHgxZuIg0aiYTrDQ/iTQevZYupdmePbz2l79weWKi03G80tz0i06dvmbRd38nfdMMkiZNofTdRaAzSCJV+Od5YJFaSrGWLBKwriyno4iISC213bqVM1etYs3ZZ/PD8cc7HUeOgDGWv9/jYbz7PsLX/o/wpUudjiTid1SQSVBKsZZ0UtTQQ0QkwEUUFjJ4zhz2NWvG8v79nY4jR6Fv31K+7vontoUcT+TkqeWbeotIJRVkEpRSrSWDFmroISIS4PouWkRcbi4LRo6k7Ffb56xZ41AoOSLGwF33lXC3exLh331DxNy5TkcS8SsqyCQopVpLOm3V0ENEJIB12LiRLl98wSfnnkt669ZVxgoK4E9/ciiYHLFu3crYf95QNrhOIXLqA1Ba6nQkEb+hgkyCjrGWZGtJ1xkyEZGAFZObywXz5pHeogWf9O79m/ExY+D77x0IJkftrnGF3OmZQtiOH4h89VWn44j4DZ9dFkX8kbd9yJpR/sQu34NM/1qLyJHRXmM1Vx97jQHkHDzIsDlzCCsu5rULLuBAfn6V8Xfegaefhttug0ceOeoIcgS87a0VExPj9bb79u0DKvbxvqAnq5b0oOv909l9/vkkt2t31Pfra78vX3uW+useZ9L46JkoQSelYgIu34NMZ8hERALNGevXc+LWrSw+91z2NGtWZaygIIarroLOnWHKFIcCylG76eZ93M1Uwvdl0eS115yOI+IXVJBJ0Emp+MQ2nTRcLnVZFBEJJE3272fw8uVsaduWVV27VhmzFhYvHk52NvznPxAZ6VBIOWrt2pWSenEXFpsBJP7z33DwoNORRByngkyCTmplQZYE7HU2jIiI1JjxeBg8ezYWmD1wIPZXS9LWr+/K5s0nM3UqdOniTEapveuu28f40MmE5R4g8sknnY4j4jgVZBJ0fi7IMjEYo2tBREQCxZkff0zrH39kQd++HIyPrzKWnd2U998fQps2W7n1VocCSp1ISSmj8xXH8AaXEPbUTExWltORRBylgkyCTqq1HCSGItcBp6OIiEgNNU9P55xly/ju5JNZd/LJVcY8Hhdvv/0HXC4PgwbNQr0YAt811+zjgejxUFRE5IwZTscRcZSmNAk6KdaSTjLG6PoxEZFAEFJWxpDZsymKimLxRReV7yR8iNWre7F7d1v69ZtHfLyuOQoGiYkezvlrc16wVxL23POYn35yOpKIY9T2XgJScXFxtWPlm0K3VEEmIuIgXy3xS0pKKr8+b9kyUjIyeP2yyzgYHs7No0dXjn35ZRgPPZTEsGGFPPVUL6BX/QRu5Hy1kPf2+/TVPv6NN9447PGYmDCeSLyXUQf+Q/i0+8l7/LEj+tm+MjvF13PfX3OLc3SGTIJOijVk0Eot70VEAkDrH3+kxyefsO6009jUoUOVsYICww03NCElxcPUqTozFmwiIkq5dExTnrLXEfHGG4Rs2uR0JBFHqCCToFO+ZDENl0sFmYiIPwsvLmbovHkcaNKEJQMG/Gb8H/+IY/v2EB577AAJCWrSFIxGjSri5RZ3UGiiiX7gAafjiDhCBZkElWi3m1g8pJOGMRlOxxERES/6LVlCYnY284YOpSQiosrYe+9F8PLLMVx7bT49epRU8xMk0EVEwNV3RvOQ5zYiFy4k9KuvnI4k0uBUkElQSaq4JqG8INMZMhERf9X+++85fd06VnXvzk/t2lUZ27vXxW23JXDSSaWMHZvrTEBpMBdfXMyC429mvyuJ6MlTnI4j0uBUkElQaVZaCkAGqWrqISLip6Ly87lwwQIyk5NZ0adPlTFr4fbbE8jJcfHEEwf41YkzCUIhIXDTPSFM8dxFxAcrCfvkE6cjiTQoFWQSVJpWniGLw5g8h9OIiMhvWEv/efOIKizkreHDcYdWbfi8bt1pLF0ayd1353LiiWUOhZSGdsEFJXx62l9Jd7UkavKU8spcpJFQQSZB5ZczZGopKyLij07+8ks6fv01K3r3JjM1tcrYvn2JLF48gJ49i7nmmnyHEooTjIG/3+NhvOc+ItauIXzpUqcjiTQY7UMmASk39/DXFMTl5VFMGAdMPlENnElEAoOvPYLkF74eK2/jZWW/PbsVf/AgfRcsYEebNrR54gnahIQc8v1w+eWtiYoKYebMXKKjI48+uDQoX/tqRUZW/7vMyPilAVf79vDImSPZumY6qRP+wU+dO9O6bdujvl9f4x6Pp9oxX3uridQlPdskqDQvKyODZFwhun5MRMSveDwMmTsXl8fDghEjyi8cOsQ//9mUr76KYuLETFq2VNHcWF1/y37GeSYRs3UzCe++63QckQahgkyCSlJZGem0VEMPERE/c8Znn3HMtm0sGzCA7KZNq4x99VUkTz+dxJAhOQwcqOt/G7NOnQrZf15/1ptTaP7E01BxKYJIMFNBJkGleaklnRbag0xExI8k7dlDn6VL2XzCCXzRtWuVsfx8w5gxqaSklHHffVkOJRR/cv2NexjHZKJ27yD8lVecjiNS71SQSVBpVlamPchERPyIy+3mojlzKA0P5+2hQ8u7NxzigQea89NPYTzwQAbx8dVf0yONx7HHFhN6YTc+MT0Iu386FBQ4HUmkXqkgk6AR6vHQ1FNSsQeZCjIREX/Q84MPaLFrF+8MGUJ+XFyVseXLY3jjjSZcdVU2Z55Z6FBC8Ud/u24P97omE7Yng4hnn3U6jki9UkEmQaOZ2w1QcYZM15CJiDgtbedOen7wARtOOYXvOnWqMrZ3bwjjxqXQsWMRt9yyz6GE4q/S0kppeVknFjOAsIcfhYMHnY4kUm/U9l78kq9Wy7t3//YMWGpFi+V0UnQNmUgjp9b2NVebx8rbbZtFRzP8rbfIj49n9eWX0yQ6+pDbwcSJrcnPD+HZZ/NIS6va5CPkVx0YxXneWsj7eg55ayE/f/78asdatYpmUuQkBuScQdhjj5F/551Vxr210wffbe+d4u3x8tfMUr98niEzxrQ2xqwwxnxjjNlojLm54vgEY8wuY8yXFX8G1n9ckeqlVOwnkkEkxvx2/xsJLpqbRPxbtwULSMzK4v0//YmSQ4oxgFWrTmbp0nDuvbeAjh3dDiWsP5qf6kZMTAHdrj+RWVxMxMx/YfbscTqSSL2oyZLFMuDv1tqTgLOB640xJ1WMzbDWnlrx5516SylSAykVnzhl6sOlxkJzk4ifardlC6d88AFfnXsuOzt0qDKWlZXA3Lk9OffcEkaPLnIoYb3T/FRH/va3Ah5OmIgpKiLmscecjiNSL3wWZNbadGvtuoqvc4FvgZb1HUzkSKV4PHgwZJlip6NIA9DcJOKfIgoLGTRnDvtTUlh14YVVxtxuFy+/3JfQUDdPPpmPl5VsAU3zU92Ji7MMuq0VL3AlES+8hGvHDqcjidS5I5oKjTHtgNOAzyoO3WCMWW+Med4Yk1jH2USOSIrHwx6S8Li0pKGx0dwk4j/6LVxIbG4u740ahTs8vMrYkiVd+fHHVC69dAVpaY2jxb3mp9q78spCnkm5B7cbYh5+2Ok4InWuxgWZMSYWmAPcYq3NAWYCxwGnAunAYV8hxpjRxpg1xpg1JSUldRBZ5PBSPJBOS7W8b2TqYm7Kz89vsLwiwazjhg10+vJLPundm6y2bauMbd+ewpIlXTnjjO847bStDiVsWJqf6kZkJFx2R1OestcR8d83CNm82elIInWqRgWZMSaM8gnlVWvtXABrbaa11m2t9QD/Bs483G2ttf+y1na11nYN/9UnZSJ1KcUToj3IGpm6mptiYmIaLrRIkIrJyWHAvHmkt2zJql69qowVF4fx8st9adIkj4sv/tCZgA1M81PduvTSIl5vdweFRBN9/wNOxxGpUzXpsmiA54BvrbWPHHI87ZBvGwZ8XffxRGou2VrtQdaIaG4S8SPWMmjuXEJLS1lw8cV4ftW2fu7cnuzbl8CoUe8RFRX8q2U0P9W90FAYPS6ah+xtRL29kNCvvnI6kkidqck+ZD2AUcAGY8yXFcfuBi4zxpwKWOAH4Np6SShyGL9e/mqsJcUWk04aLtc3DqWSBqa5SaSe+dpfqrCwEICua9dy3KZNLOrfn11xcVBYyFVXXQXAkiURrFrVhBtuyOeuu3pU3jY0tPq3IEGwF5Pmp0N4+336Wj31ww8/VH7dqRP88/hruXHrk5h77sOz5N2jvl9f4x6P92scve2tJnKkfBZk1tqPgcM9Y9WqVfxGEhDGz2fItCl0Y6C5ScQ/NN2/nwHLlrH1mGP4/Iwzqozt2ePittvi6dSplDvuyHMoYcPT/FQ/XC644sZcpt58Fw99PobcTz7B3aOH7xuK+DmV9xIUft6DLIMkYJ+zYUREGgnj8TB8/nzcLhdvDRmCPeSMg7Vw663x5OcbnnrqILqMXOrCWWcdZNWpo9htWhI+fmL5E00kwKkgk6CQUrG0IIMwAn+li4hIYOi5ahVtdu5k0QUXkJOQUGXs5ZejeO+9CO65J5cOHdwOJZRgYwxcfcNeJtj7iFj7P0KXLHE6kkitqSCToJD68xkyo0/KREQaQvLu3fT+4AO+PvFE1nfqVGVs794kJkyIo1evYq66qtChhBKsOnfOZ3OPoWx1HU/YxMng43ovEX+ngkyCws8FWaYpdTiJiEjwCyktZfCsWRRGR7Nw4EAOXZrgdruYN28kkZGWRx/NQb0PpD6Mvj6Tez0TifhuI2Fz5jgdR6RWNE1KUEi1lhziKHRlOx1FRCTo/f6990jOzGTe4MEURkdXGfvoo16kp7fkwQdzSE3VmQupH8cdV4jn4uGsN10ImzQNSvWBrASumrS9F/F7yTa0ouW9NoUWaQx8tWOXX/h6rLyNl5WV/eZYmx9+4KyPPmJd1678fto0fn/I2Lp1EUyZksqIEXmMHAkQUe3P9tY2PAja3jcqvn5f3p5jvtrHL126tNqx224/lvvmTmbejgspevFFCq+4osp4VFSU15/tj88zX69Xf8wstaczZBIUUisKMm0KLSJSf8KLirhwzhyyExNZNmBAlbG8PMOttzajRYsyxo9Xt1upf23bumk6qg+r6E7kg49Aoa5XlMCkgkyCQqr1qCATEalnfRcvJv7gQRYMH05pRNWzX5MmNWXHjlAefngvcXE6gykN49bbChgfPpXwvRlEP/+803FEjooKMgkKqbaEDFIxRksWRUTqQ/tvv+W0tWtZ3bMnO9u2rTK2dGk0s2bF8be/HeTMM4sdSiiNUXKyh5P+ryvvMoDIR5/E5OQ4HUnkiKkgk4AXYy2xlOkMmYhIPYnOz2fQ/PlkpKbyQZ8+Vcb27AnhrruS6NSpmJtvPuBQQmnMrr8+n/tjJxGWm030zJlOxxE5YirIJOD93PI+nXiM0fpxEZE6ZS0D588nsqiI+SNH4gkNPXSIO+5IIj/fMGPGXsLDHcwpjVZCguX3N3dgFhcTOfNfmD17nI4kckRUkEnAq9yDjDCHk4iIBJ8uX35Jx2+/ZeX557MnJaXK2H/+E8fKldHcdVc2xx+vtuPinKuvLuCxpAlQVETMY487HUfkiKggk4D3c0GWYXQRuYhIXUo4cIB+ixbxU9u2fNa9e5WxPXuaMnVqIuecU8gVV+Q6lFCkXHQ0XDimFS9yJZEvvoRrxw6nI4nUmPYhE790JHsMpfx8hsylT2dFgon2Gqu52jxWHk81mzd7PPzx/fcJdbnYMXkyZ6elVQ6VlRluuqkr0dHw9NNFJCTE/+bmvvaXEgHf+2pFRFS/l92GDRuq/L1LF8N9yWMYlfUKxffcS+jrrx31ffvKVe3rhvp97nt7rWuPssCl2VICXooHSggj2+gTWhGRunLG6tU0/fJLNl13HUWHFGMAL798DJs2xfPII/mkpalwFv8QFmbpe3UJT3MdLZYuxbVpk9ORRGpEBZkEvBQbXt7y3qUOiyIidaFZVha9ly5lT7dupP9qA+iNGxP473/b0b//boYM0coE8S+9emXyWtubKCCaiClTnY4jUiMqyCTgpdpQtbwXEakjrrIyhsyeTUl4ON/ddhscsgyqoCCEadNOJjm5iOuu09kH8T8uF1x0zUEesbcSuXABIV9+6XQkEZ9UkEnAS7G2oiDTptAiIrXVc+VK0nbv5p2hQylJTKwy9tRTJ5CVFcmdd24kJsbtUEIR7846ay+LOlzNftOU8ImTnY4j4pMKMgl4qbZYZ8hEROpAix076P7BB6w/7TQ2nXxylbGPPmrOkiUtuPTSH+jU6aBDCUV8MwYuvXYPU+1dRH6wnNBPPnE6kohXKsgkoIVZS3OKyCAZY7KcjiMiErDCSkoYMns2ufHxLBs8uMrYvn3hzJjRkRNOyOGKK7Y7lFCk5jp3PsC3vUez27QgbMKk8l3MRfyU2t6LX6ppC+fkn/cgIwZjtHxGROTXvLXnBsjLywNgyJIlJO3bx7OXX86+sjLIy6NLly5YC5ddlkBpaRgvvJBH+/adK28bEhJS7c/11YJbLbobD2+/a1//3nu77eeff+71trfcdSoTV9zHM2v/j8JFiyju27fKeG2evyJ1SWfIJKClVG4KHeZwEhGRwHX8tm10W7eOj884g21t21YZe/75SJYvD+e++/Jo314ffEng6Ny5jL1DLmOLOZ7IyfeDjw8nRJyigkwCWmplQaalCCIiRyOysJARixaRlZTE0nPPrTK2aVMIEyfGct55xVx1VZFDCUWO3t/vLGY8E4na9A2R8+Y5HUfksFSQSUD7uSDLNGUOJxERCUwXLV1KbEEBs4YMoSzsl9UGbncI110XR0yM5dFHc9EKLglExx7rJuTyC1lPFyKnTYdS7Z0n/kcFmQS0FE8IHgxZJs/pKCIiAefE9es55ZtvWN6jB7vT0qqMffxxH9avD+Phh3NJSdEqBAlct/69gAlhk4nc+QNRr7/udByR31BBJgEtxUayl2a4XeqwKCJyJGJzcug/fz470tL4oHv3KmM7drRl9epzufzyQgYOLHEooUjdSEvzkHZNLz6hO5HTZ0BhodORRKpQQSYBLcWGalNoEZEjZS2D5swhtKyMWUOG4HH98naguDiChQsvJiEhm8mT8x0MKVJ3rr+hgMlRk4nYm0H0Cy84HUekChVkEtBSrYcMUnG5tCm0iEhNnfbZZxy7eTPLBwxgX1JSlbFlywaTk9OEIUNmERurpYoSHJo2tXS5sSuL6U/ko09icnKcjiRSSfuQiV+q6T5kqbaEjaRhzMZ6TiQida2mr3Px/Vh5Gy8rq9r0qOm+ffR59122Hnccn3ftynVXXVU59s47UWzYkMRNN+UwZswQwsK8byniclX/ua72cZKaqM3zxNfz87333qvy9/btQ5kacx8DcnuQecdYWr/w/FHn8jbua+8/b6+b2qjNnm7iLJ/PCGNMa2PMCmPMN8aYjcaYmyuONzXGLDPGbK74b2L9xxX5hbGWFApIpxlwwOk40sA0N4kcOeN2c9GcObhDQlg4bBiHtk7MyHAxdmwTunQp4ZZbdPagNjQ/+afIyDLaDQ9jFhfT4Z3FmD17nI4kAtRsyWIZ8Hdr7UnA2cD1xpiTgDuB96217YH3K/4u0mCaAuG4ySBa7ZgbJ81NIkeox8cf02rnTt4dPJjc+PjK4x4P/P3vTSkqMjz++H58nHgQ3zQ/+anevTczo8lYQktLiJwxw+k4IkANCjJrbbq1dl3F17nAt0BL4CLgpYpvewkYWl8hRQ7nlz3ItPK2MdLcJHJkUtPTOWfFCjZ26sTGLl2qjL30UgwffhjJvfce5LjjtK9jbWl+8l9hYR66XFLMi1xJ2LPPY3budDqSyJE19TDGtANOAz4DUqy1P3dSyABSqrnNaGPMGmPMmpIStc6VupNcUZBlGF2H0tjVdm7Kz1cnOQluIaWlDH3zTQpiYnhn8OAqY5s2hTJlShP69Clk1Ci9Fuqa5if/06PHdp5JuQW3GyLuf8DpOCI1L8iMMbHAHOAWa22VxeW2/CrCw74rttb+y1rb1VrbNTw8vFZhRQ6VWnHRbIYpdTiJOKku5qaYmJgGSCrinN7vv0/zPXtYOHQoRdHRlcfLylzcdFNTYmI8TJ+ereXfdUzzk39yuSzdL93PU/Y6Il5/HdfmzU5HkkauRgWZMSaM8gnlVWvt3IrDmcaYtIrxNEA780qDSrWRAGS59OlhY6W5ScS3Ntu3c/bq1aw54wy2tm9fZWzFil5s3BjOgw9mk5zsvTOcHBnNT/7t9NN3sKjzGAqJInzyVKfjSCPn8+IbU94j8zngW2vtI4cMLQD+DNxf8d/59ZJQAlZt2jT7ahkLkOKJIhcPBa792r+hEdLcFBjU2r7mavNYVTdnhhcVcdnixZS0akXE449zYVRU5djatTF8/PFxjBpVxLBhLiD6N7f31Z5bbbQPT/NTw/D1/NuxY4fX8dH3hPPwH27jvoWTyPv8c0o7d64c83VmMiQkpOZBRXyoyRmyHsAooI8x5suKPwMpn0z6GmM2A+dX/F2kwSTbENJJw5jdTkcRZ2huEvGh76JFhGVm8tOUKXgOKcZyc13cc08bWrUqYfLkAgcTBi3NTwGgZ88SVne7gf2mKdGT9asQ5/g8sWCt/Rio7iOI8+o2jkjNpVpbUZCl+/5mCTqam0S8a//NN5yybh2Z11xDwa+6Kj7wQEuyssJ44YUtxMYmOZQweGl+Chw33mOYNuhOpn98B4WrV1PSrZvTkaQRqp+twkUaQJotUUEmInIY0Xl5DJw3j4y0NDKvvbbK2NKlCbz9dlOuvjqTLl10dkwTQ/pNAAAgAElEQVQat1NPLWVL/6vZbVoQNfkB0DJrcYAKMglYqeSRQROMKXY6ioiI/7CWC+bNI6K4mAUXX4w9ZJfnzMxQJk9uRadO+fz1r5kOhhTxH7fcVcYk7iXmy/8R8d57TseRRkgFmQSkGGuJo5gMonx/s4hII9Jl3To6fPstK/v2ZW/KL9tceTwwfnwbSkoMU6b8xCF1mkij1r59GQdHXMZWjiNq8oPlLxaRBqSCTAJSSuWm0OqvKCLys4TsbPouWsSPxxzD5927Vxl7/fVmfPppHLffvpu2bUscSijin24ZU8TEkIlEb/mGqPlqfikNSwWZBKTUyoLM4SAiIv7C42HwnDkALBwxAg5pWb9lSwSPPZbGOeccZMSI/U4lFPFbrVq5ifjzEL6iC5HTHoLSUqcjSSOi0wvil0p9TIQtPeWVWJZLE6aIk7TPWM3Vxz5jP8vJyeH3n39O2+3bmT1wIDtDQiAnB4BmzVrypz81IT4eZs4sIzm5ZZXbettPSfuM+YdDfw+N7TVXm+dgaKj3t7mvvPJKlb+ntohmQugE3to1HM/LL1N85ZXV3tbbHn2+Mnt7Pfva+682vD139Fp3ls6QSUBKtuUbNmaYfIeTiIg4L3nPHvp/+CEb27dnbadOVcYeeCCar78OZcaMPJKTG9ebeZEjERtbQM7vm/MJ3Qmd+hAUFjodSRoJFWQSkFI9UZQQxn6T7XQUERFHucrKuPTttymKiGBu//5wyCfdP/10DE8+GcUVVxQyYICuGxPx5Zxz/8c/IsYTsS+dyOeeczqONBIqyCQgpdoQMkjFuLQHmYg0bj2XL6dFVhZzBwwgPyam8nhxcQSLFl1Cu3YeJk7UagKRmoiMLCH0vFAW05/Qhx7FVCz9FalPKsgkIKVaW16QaVNoEWnEWv70E90++IA1nTvzTfv2VcaWLbuI3Nx4Zs7MJTbWoYAiAahbty+Y0WwS4bnZRDz5lNNxpBFQQSYBKcWWkE4KxuxxOoqIiCPCSkoYPHs2OU2asPC886qMffttFzZu/B3duy/n9NPLHEooEpjCwsq4YNxJzGYkYU/OxOzRew2pXyrIJCClkkcGCRijC9RFpHHq8847JO7fz9sjRlAcEVF5PCcnniVLhpGW9hPdu69wMKFI4Lr88mL+3XoCruJCImY86nQcCXJqey9+qaioqNqxEI+HZHJJN9ENmEhEpH55a0ldUlK1Icfxmzfzu88/Z1W3bmxt1YqbR48GwOOBSy9tSkhIGLNnR3LssTf6bP1dm/bdIv7M1/PX+2uugKF3pvLi9Vfy52ef5+BfrsTd8pctI+Li4qq9rbetJEQOR2fIJOAklZUvv8nU5wki0ghFFRRw4fz5ZCYns7xPnypjzz4bw8cfRzBxYg7HHut2KKFIcBg8uJD/nnAXbjfEPKKzZFJ/VJBJwEmq2DQ6Q8sVRaSxsZaBixYRXVDAW8OG4Q4Lqxz67rtQpk2Lo1+/Ii6/XPsnidSWywVX3JPATP5G7OxZhG7d6nQkCVIqyCTgNC0u/2+GKXU2iIhIA+u0YQOdNm5kZa9eZKalVR4vLoYbbmhCXJyHhx46iFYaitSNXr2KWfK7v1Noo4i5/yGn40iQUkEmASexqPzi9UxXgcNJREQaTtzBgwx85x12tGrFJz16VBl74IE4vvkmjEceOUizZh6HEooEH2Pg2nsjeJjbiFv8NmEbNjgdSYKQCjIJOInF5RfL7nUdcDiJiEgDsZaL5s8nxO3mrWHDsIc0Ddi+vR3PPBPDqFH5nH9+sYMhRYJT164lrO11HftNU6KnPOh0HAlCKsgk4CSVWPbQjDJXhtNRREQaxBmff85x27axtF8/spOSKo8XFkbw1ltDOeYYN+PH5zqYUCS43XC34X47lrhPVhL+6adOx5Ego4JMAk6z0hLSScOYdKejiIjUu6Z79tB32TI2H388a7t2rTL2zjsDyc2N44knDhAdrUZHIvXlxBNL+enCq9hFC6InPQBeWuaLHCn1DRe/tHfv3mrHkkoMGbTDmG0NmEikcfK2T4/8lrfHy9djWVaxpcehjNvNoFmzcMXGEvLii1yenFw59vbbsWzYkMbNN++jW7cQ4PB7H3nbZwz8c68xX5kbM2+/r8b2eq3tc9fbfmFPP/30b44ltkhkihnH0+uvJ3fxYkr79TvsbWvzmvN4vF8DWl+vDV/PHX+cJ4KJZjwJOCk2j3QSnI4hIlLvenz4IS137iRrwgTchxRj6emhjB+fzKmnFnLttfsdTCjSeCQmZrPmlC5s4ThCxk8p34ldpA6oIJPAYi0pNpsMopxOIiJSr1J37eL3K1fydZcu5A0cWHnc44GxY1Nwuw0PPZRJqNa6iDSYs3//ERNd9xG96WvC33rL6TgSJFSQSUBp4vEQThkZJsz3N4uIBKjQ0lKGvvkm+bGxLB48uMrYiy824dNPoxk3bg9t2mg/RpGGFBuby7YzW7GezoRMnAaleg1K7akgk4DSvMwNQKarca2TF5HGpfeyZTTbu5eFw4ZRFPXLioDvvgvn4YeTOP/8PEaOzHEwoUjjdebZHzM1ehJRu7YT8dprTseRIKCCTAJK87LyNyaZpsThJCIi9aPdtm2ctXo1/zvrLLYff3zl8eJiw5gxqSQkeJg8OQtdYy/ijKioItrfej6r6EbIlOlQWOh0JAlwKsgkoCSVxgCQYQocTiIiUvciiooYMncu+5KSeP9XHdxmzEji++8jmDYtk6ZN3Q4lFBGA0dcWMz1xCpH70ol49jmn40iA06XA4hhvLVb37dt32ONxhbEAZLoO1EsmkcaosbXKro3aPFa+btu8eXN6vfgicbm5zBszhsSWLSvHvv46meefT+Cqq4oYNiwSiKxyW2/tu/21XbVa29c9X79rvdar8vZ4JSR47+ZsbR6n33YKi+/tT6/pj5I/cgQ2Lq5Gt/X2evXFW1t8vaYCl8/fnDHmeWNMljHm60OOTTDG7DLGfFnxZ6C3nyFSV1JsCHnEUODa43QU8QOanySYHPPFF3T49FO+GDCAPcccU3k8Pz+cG26I5fjj3UyYkO9gQqkpzU2Nw6WX5vFEykQi87OJ+9e/nY4jAawmpfSLwIDDHJ9hrT214s87dRtL5PBSrYd00jAmw+ko4h9eRPOTBIGY3Fx+/+qr7GnThnWDBlUZe/3135OV5WLmzFyiox0KKEfqRTQ3Bb3wcOh753HMZiTRzzyLq5rVPSK++CzIrLUfAtp1UvxCii0hnWYYozazovlJgoS1XPDWW4QVFbH8yivxHLKc6fPPj2fNmuO5445CTjtN140FCs1NjcdFFxXwwjH3ElJcSOzjTzkdRwJUbRab3mCMWV9xWj6xzhKJeJFq88gg3ukY4v80P0nAOGXNGtp/9x2fDxvGgRYtKo/v3x/L66/35NhjM7jpJnVxCxKam4JMSAiMvCeNl/gzsa+8QsiuXU5HkgB0tAXZTOA44FQgHXi4um80xow2xqwxxqwpKVGrcqmdNA6QYaJ8f6M0ZjWanw6dm/LzdV2OOKPJ/v2ct2gRPxx7LBt696487vHAiy/2wuMx/OUvywlVC65gcFTvnTQ/+b/zzitkTqe7cLsh9pHHnY4jAeioCjJrbaa11m2t9QD/Bs708r3/stZ2tdZ2DQ8PP9qcIkRbSzz5ZBq9M5Hq1XR+OnRuiomJadiQIoDxeBg8ezbWGBaNHAmHdEh7770ubNrUkj/8YRXNm+c6mFLqytG+d9L85P+MgSvvi2cmfyNuzixcmzc7HUkCzFEVZMaYtEP+Ogz4urrvFakryZ7y6yoy/LODs/gJzU8SKM78+GNa//gjy4YMIadJk8rjO3c2Zf78Mzn11O106/a9gwmlLmluCm5nnVXMym63UmCjcE2Y4nQcCTA+TzUYY14HegHNjDE7gfFAL2PMqYAFfgCurceM0ggdbp+N5mVNgINkGC19lXKan8TfeNvnqbDwl+vAUjIzOWfZMjZ27Mj/OnaEwkKGDh1KURH0759EUhK8+moMSUlDAQj1sWbR235K/roPWTDT3OQfavPc97Wn1z//+c/fHGvaMY0Zq2/l3kWTObB2Le5TTjnin+2vr1dvc5u/Zg4kPgsya+1lhzmsLcmlwaXa8mYemUbr6aWc5icJRCFlZYyYN4/CyEgWDhxYvt6pwrRpsXz/fSivvZZNUpI28Q1Umpsap9TUdBaeMIjrNj1NxPipuOe94XQkCRDa0lsCRrKNBCDTdcDhJCIiR6/3Bx+QmpXF/MGDKTjk+qAPPwznmWdi+MtfCujTRysBRALRab0+5UEzltiP3yd01Sqn40iAUEEmASPVE0opoWS79jodRUTkqLTZsYOeq1ez5rTT2HTCCZXHCwujuPnmeNq3L+Pee9XEQyRQJSXtY9+l17CbNELumwJelvqJ/EwFmQSMVOsmg1Ss2ed0FBGRIxZeXMzw+fM5kJDA4r59K49bC++8M5g9e1w8+eRBoqMdDCkitXbzXYapofcS++VnhC1b5nQcCQAqyCRgpNoSMmiKrh0VkUDU/733aJKdzVsXXURJRETl8Q0buvDNN50ZMyaPU04pczChiNSFFi08mKv/yBaOw3Xf1PKNBUW8UEEmASOFfDKIdzqGiMgRO+677zhj3To+6daNH9u0qTx+4EACixcPpnXrH7nhhgIHE4pIXbrxtjKmRkwgdsvXhM+b53Qc8XPaYVcc462F6uGkcYDPzbH1lEYkeB3pa62x8/Z4+Xosy8p+e4YrKj+fC+bMoaRDB1q/8AJXVZwdc7vh8stTCQsL59VXQ4iOjvjNbX/mqwW3P7ad9pVZGp6354nmiap8vaYSEhKqHcvJySEsDJr83wWsf6wzx46fSs6550JYGABNmzat9rYhISFHF5jDbxl0KL0m/Zd+MxIQQqylOfvJ0GcIIhJIrGXgggVEFRay55FH4JCliv/+dzyffx7JhAn7aN1aSxVFgs1frs7lgbh/EJv+A3Fvvul0HPFjKsgkIDT3ROPCkmn0CZ6IBI5OX33Fid98w8o+fSg96aTK4998E84jjyQyYEA+w4drb0WRYBQbaznu5p6sohvRDz2BKSpyOpL4KRVkEhBSbBIAmS7tzSMigSH+4EEGLFrEjjZt+LRnz8rjRUWGW25pRmKim6lT96lRkUgQu/yPuTySNIno7AziXvmP03HET6kgk4CQ4okFINOli95FJAB4PAyZOxeXx8OCESOwh1y78eCDiWzeHM706XtJTFT3NZFgFhEBZ97RhSX0I/rxf2Jytc+g/JYKMgkIKZ5IADLNQYeTiIj4dsZnn3HMtm0su+ACsg+5gP+jjyJ54YV4/vznHM45R8uXRBqDYcPyeLrVRKLy9xP3r2edjiN+SAWZBIRUW97MI8u11+EkIiLeJe3ZQ5+lS9l8wgl8cfrplccPHHAxZkwzjj++hDvvzHYwoYg0pNBQGHD3MbzJCGL//Txmr97LSFUqyCQgpFgPe2lKmZYsiogfc7ndXDRnDqXh4bw9dCg/XyBmLYwbl8T+/SE8+uheIiPVoEikMenfv4D/nHAvoSWFhEx/xOk44mfUQ1wCQqotIZ0kYLfTUUT8kvYQqrnaPFa+9vm5bPt2Wuzaxdfjx3PquedWHl+6NIV33onh3nsL6NYtEoj8zW0DcY+gQMws8rPa7N/nbb+wF1544bDHY884lpc2/ZkrnnuO4r+NxtOy5RFn8sfXnK851R/3SfQ3/vdbFTmMVPLIJM7pGCIi1UrbuZO2r7xCxvnns+eQYiwjI5LHHz+Bbt1KufFGXTcm0lgde+w2nm/1F9xllrCp052OI35EBZkEhFQOkmGinY4hInJYoSUlXDh7NiVJSWy+6abK4243TJt2IgBPP52Plw/VRaQR6NDvG/7J/xE9+7+EbNnidBzxEyrIxO9ZD6SRRYbRClsR8U+9ly4lae9evhs7lrLY2Mrjb7zRhg0bmnDTTZto00Yt7kUau5Ytd/H5+bdTaCMJ+cf9TscRP6GCTPxeIklEUEKGliCLiB9qt2ULZ6xezf+6dSP7d7+rPL5pUywvvngM556bRd++mQ4mFBF/ct2EWB7lFuLfnU/IV185HUf8gAoy8XvJ7vI9fDJNscNJRESqiigsZPDcuext3pwV/ftXHi8udjFt2kkkJJRy663fo2vaReRnHTq42Tb8RvaTSMj4aU7HET+ggkz8Xootb+aRoZb3IuJn+i9cSGxuLgtHjqQsLKzy+L/+dRw//hjD2LHfEh9f5mBCEfFHN94TxkMhY4n/5H1CV61yOo44TBfliGNq2no6xVPeHjrTHKjPOCIigPfW9nl5eZVfd/r2Wzp99RXv9ezJ5iZNIC+PTp06sXx5GG+91YTRowu48sqWQHlra29tssF7a2in2kb7Y4ttqR++nmPaWqMqb49X7CHXkR5OdnY2sbGw5w9/YvdrjxF11ySy33oVjKF58+ZHfb++fofe5ja91p2lR1/8XqotfxOT6drvcBIRkXJxeXkMXbyYHWlprOzevfL4vn2Gm26Ko0OHMsaNy3cwoYj4u6tvLOb+sHtI/GYN0StXOh1HHKSCTPxeqvWQTxT5xu10FBERsJbhixYRVlbG7CFD8FSc+bIWbr89juxsF08/nUNUlMM5RcSvJSW54erhbOVYYqc9Bj42npfgpYJM/F4KJaSThK6KFxF/cMaXX9Jh2zYW9+7N3qSkyuMbNvyORYsiuPPOfDp31gdIIuLblX/N54HoCST88A2x77zjdBxxiAoy8XupNp8M4p2OISJC0+xsBr7/PpvbtePT00+vPJ6dnciyZUPo1q2E664rdDChiASSuDgPSTf0Yz2diXngcSgtdTqSOEAFmfi9NLLJMFr7IyLOMh4PFy9ciMflYs6gQdiKs/Yej+Htty/GGMuTT+bio3eHiEgVl/8pl+lNJhKf+QNh/3nV6TjiABVk4tesDSeNLDKMGoKKiLPO+ugj2u7axYJ+/ciJ/+Ws/aefnsPOne3o128BrVvrGhAROTKRkZYOt3VjFd0wk6ZDoc6yNzYqyMSvRXpSSCCHDKN2uyLinOTduznnvffY0LEjX518cuXx9PQWfPTR+Zx44npOPvlLBxOKSCAbMTKXx1MmEp29m7B/P+d0HGlgOu0gjnG7fV/0nuxpCkCmKanvOCJ+TXsAHRlvj5evx7KsrOpGziGlpQyZNYuCqCiSZs3iusREAAoLDRdckExysuWNN5JITLyOsEM2h/41X/v8OLXXmIj8Vm32ZfP1Wn/ttdcOe9z9+5NZ8mY/znlwBu5Rf8TGxR3Rz/bXOcTbY+WvmRuazzNkxpjnjTFZxpivDznW1BizzBizueK/ifUbUxqrVFs+GWW5ChxOIv5I85M0hF7Ll5OclcXCoUPxJP7ydJoyJYGtW8OYMSObxEQVzPILzU1yNE46aSPPH/8PovL3E/7kTKfjSAOqyZLFF4EBvzp2J/C+tbY98H7F30XqXLKNACDTdcDhJOKnXkTzk9SjNj/8QLdVq1jbtStbTzih8viKFZG89FIs11yTS8+exQ4mFD/1Ipqb5Ai5XDB8ckfeZAThT87E7N3rdCRpID4LMmvth8D+Xx2+CHip4uuXgKF1nEsEgFRP+araDJPncBLxR5qfpD6FFxVx4dy5ZCcmsqx//8rj+/e7uP32RDp0KGXs2IMOJhR/pblJjlafPqXMOeU+QksKCHvoMafjSAM52qYeKdba9IqvM4CU6r7RGDPaGLPGGLOmpETXAcmRSbWWMkLYpyXGUnM1mp8OnZvy8/MbLp0EjH6LF5Nw8CDzhw2jNKL8bL21MHZsIgcOuHj88f1ERjocUgLJUb130vzUuBgDo6a24SX+TNSLL+DatcvpSNIAat1l0ZZfqVft4nlr7b+stV2ttV3Dw8Nre3fSyKTaYjJJrNzvR+RIeJufDp2bYmJiGjiZ+LsTvvuO09atY3XPnuxs27by+KxZ0SxeHMWYMQc56SRt4CpH50jeO2l+anzOPLOMlefcicdtCZn6kNNxpAEcbUGWaYxJA6j4b1bdRRL5RQr5pBPv+xtFfqH5SWolOj+fQfPnk5GaysrevSuP79/fhPHjm9C9exGjR2sZtRwxzU1SY9dMas4zXEvs7Ndxbd3qdBypZ0dbkC0A/lzx9Z+B+XUTR+QX1kIa2WSYKKejSGDR/CRHz1oGLVhAZFER80eMwBNafh2r222YM2coISHwyCPZ+OhqLXI4mpukxk46yc36wX+n0EYSMn6a03Gknvnch8wY8zrQC2hmjNkJjAfuB2YZY64GfgQuqc+Q4r9qs9eP732VEkgjk3Um9SiSSWMQbPOT9hqrudo8Vh6Pp9qxzuvW0fHbb9l9yy2cfeWVlcf//e9kduxI45ln8mjfPqLa2wfiHkG+9kySIxdscxN4f/5q7qrK12s9Kqr6D5ozMjIqvx5xXTiPL7qZu5dMZcuKP1J04om0atXqqO/X27i3eRE0T9Q3nwWZtfayaobOq+MsIlW4PKkk8wWZptrrnqWR0/wkdSk+O5u+b79N3u9+x55RoyqPb9wYxTPPpDJgQDYjR+qNp/imuUnqQuvWJcweejX735pJ/INPUvTCU05Hknqiclf8VjPbFBeWDKML50Wknnk8DJ47F2MtOyZNgpAQAAoLDePGtSEpqZS771a3MxFpWKNuLOHh0LEkr/mQ6LVrnY4j9UQFmfitZHd5M49Ml1r+ikj9OmP1atpt28Z7gwZR0rJl5fEZM1rwww+RTJq0g/h4t4MJRaQxat68jOw/Xspu0oi///HyC+wl6KggE7+Vasuv08gwBxxOIiLBrFlWFr2XLmVTx458dfrplcc/+iiOWbOaMWpUFmeeqa6KIuKMP/41n+kR42j23TpCly1zOo7UAxVk4rdSbfkljlkuLVkUkfrhKitjyOzZlISH8+6wYeW7sgL794cwYUJr2rcv5IYbMnz8FBGR+pOQ4MH11yFs5Vg8d00GHw04JPCoIBO/lWLLJ5xMP+1MJiKBr+fKlaTt3s07Q4eSHxsLlK8ImjSpNTk5IUyd+hMREVoiJCLOuvSKXKbH3kf8tg2Ezn3L6ThSx3x2WRSpL6Wl3s98pdpi9hFHidEnQRIc1Br6yNRXa/vc3FwAWu/eTbeVK1nbqRNr27SBiuMrVx7LihVxTJyYT69eSVVuG1LR7KM6/tjaXu2qRepebbYB8PaafOut6out9HNPZcOiTrS7dyqlAy+AsLAa/1zwz/nJ12Plj5nrg2Zp8Vup5JFBnNMxRCQIhZWUcMnCheTExbHw/PMrj2dnN2XcuFh69izh//6v0MGEIiJVnXr6eh5tNom4jG1EvP5fp+NIHVJBJn7JWhdpZJNhop2OIiJB6IKVK2mWnc2bgwZRHBkJgMfj4u23LyEszPLkk3noxJKI+JPQUA+nT+jNKrrhmvwwFOpDo2Chf27EL1mbTCqZZBitqhWRutV++3a6rVvHx2ecwba2bSuPr17di1272vLgg3m0bKml0iLif4aPKOGZNpOIPbCb8GdfcDqO1BEVZOKXrCeVNNLJMLrmRkTqTmRBASMWLSIzKYkl55xTeXz37lZ8/HEfTjrpS4YPL3EwoYhI9UJCoO+UriylL+EPP46puPZVApsKMvFLCbY5kRSTZfTGSETqTr8FC4gtKGDWkCGUVVwQX1ISxsKFfyAuLpd+/eY7nFBExLt+/Ur4z4n/IKpgP2FPzHQ6jtQBFWTil1JseTOPDJPvcBIRCRYnrl/PyevXs7xHD3anplYeX7FiINnZTRk0aDaRkUUOJhQR8c0YGDGtI28ygsin/4nZu9fpSFJLKsjEL6V4yi+yz3TpVLyI1F5sTg79589nV+vWrOzWrfL4li0d+OKLsznzzI9p23abgwlFRGque/dSFp11L6ElBYROf9zpOFJL6pggjsnPr/7s17G2/LOCTH1kICKH4WvvmpKSQ5Y7W8sFs2cTWlrK3Isu4oZbbgFg714Xffo046STSnnjjfZERLQHIDS0+n8aA3GfH5H65ut5rz0Yq/L2eEVERHi97U8//VT59fk3RvHyZ1fwp5df4NsRg2nTo8dR36+v36G3vR2112Ht6REUv5RaMXln6s2NiNRS1zVrOH7rVpb268f+Zs0AsBZuvz2BnBwXTzxxAB/vgURE/E7HjoW83/MWPG5L06eeczqO1IIKMvFLKbaEAsLJcTqIiAS0pvv20XfpUrYcdxxrzjij8vhrr0WxdGkkd9+dy4knljmYUETk6A2/NYRnzLWkLV6Aa8sWp+PIUVJBJn4plTzSiS+/clVE5CgYt5uhb72FOySEBRddVDmfbN8ewvjx8fTsWcw116hxkIgErrZti1nX/1oKbSSecVOdjiNHSQWZ+B2PJ4I09pFhopyOIiIBrOcnn9B6504WDRpEbnw8AG634cYbmxAWBo8+egBd+iAige6SG9084bqZJkvfImT9eqfjyFHQP0Xid0pLm5NGOpnqOSMiRyk1PZ1zV67k65NPZmPnzpXHP/roHNatC+f++w/SokX1F6mLiASKlJRSfhh5BftJpOzOyU7HkaOggkz8TmlpMqlkkOlSVyYROXIhpaUMmzuXguhoFg0aVHl8586WfPDBOQwfXshFF2m/MREJHpeMLmRG+FgSVy8jZNUqp+PIEdIpCHFMenr64QcKIZEDZJjohg0kUgfU3rnmfD1W3sbLyqpvxHHukiUk79nDrmefZfg55wCQn28YOrQNaWluHn64mMjIyGpv762Fs7+2tVfbaRH/UZttAHy9lt99993qf+71o9k94zEi75hE2fvzfnMdvrd5z1/nNm+Plb9mPhqawcXvNCuLBSDLVeBwEhEJNG22b+fsVas4cPnlFFQUYwD339+cn34K48EHM0lIUNEsIsHnqhsMM2LG0XTjp4S//77TceQIqCATv5PsDgcgwxQ6nEREAkl4UREXzp1LdmIie++4o/L48uUxvPFGAldfnc2ZZ2peEWen/UMAACAASURBVJHgFBtrSbz9UrZyLNw9Dbxs5iz+RQWZ+J3m7vKnZUYQnYoWkfrX7913iT94kPkjR2Kjy5c8790bwt13J9OxYzG33LLf4YQiIvVr1NVuHkscT5MfvyZ8/gKn40gNqSATv5PicQOQqWsiRKSGTvj2W05dt45V55zDrtatAbAWxo1LJi/PxcMPZxAerqWKIhLcIiLg+HuHsIFOmPEPQmmp05GkBvSOV/xOqi3CjWGv00FEJCBE5+UxaP580tPS+LBXr8rjb7wRz4oVsYwZs4/27UucCygi0oBG/qGUp9L+QULmVsJf/6/TcaQGVJCJX7EWkm0+mcTh0ZJFEfHFWgbNn09EcTHzR4zAE1rePHj79jCmTWtO9+4FjBp1wOGQIiINJzQUzprcm9WcTejkR6BI23z4OxVk4lesbUIaWWSYKKejiEgAOOWLL+jw3XesOP989qakAOB2uxgzJpXwcMv992eg1c8i0tgMHFTC88f9g9iDuwl79kWn44gPtdqHzBjzA5ALuIEya23XugglwcHXHkP5+fm/OeZ2tyWNdDKMtsiT2qmv+Un7jB2Z2jxe3m6bmppK7N699H/3XXZ36MCPw4aRWlF5LVjwO9avj+S553I56aSE39w2JCTE6/3649422mcseDTG907eXlOaU6vyNf+Eh4dXO/btt99W+XvHvyWz9Pa+dJ/+KBvP7srJ3bod9f16G/f46OZYX/OXr+eOP87l1amLR6i3tfbUxjChSP2ztgVppJNpNEFLndD8FKSMx8O5L7wAwId/+Qs/nwbburU5ixadyiWXFHPRRbpuTPyW5iapd127HuDlDncSW5RNyqtvOh1HvNBHbuJXjCeFZLLINMVORxERP9bpvfdI27SJ1ZdeSl5SEgBFRaE891wvEhPzuf/+356BFxFpbHrc3IQ5DKf1rFmYffucjiPVqG1BZoGlxpi1xpjRdRFIGrdmNp4QPPw/e/cdHlWd/XH8/Z2Z9ITQk0hHURYLHaXqigV7AbtiQ1xFV9HVtezaC6tYVlfdtWNZRQTshSKIDSQJIEgXASkJIhDCpM7M9/dHRn7okpmQdm8yn9fz5HFyZ+7M4Zo5c8/ce8/JM0VOhyINn/JTI9UyL48+U6eytkcPVg0YsHv5W28dwdatTbjsstk0aaKj7OJayk1Sb7p1K+Sd3jcQFyjGPvi40+FIJWpakA2y1vYCTgDGGGOG/P4BxpjRxphsY0x2WZlOH5HIMkKJAOR7NF1eaixiftozN+3tekZxJ08gwCmTJlGWlMSXI0dC+BqBhQvb88UXXTn++O848MB8h6MUiWif9p2Un6Smjrk2nlcZSeqE5zEbNjgdjuxFjQoya+3G8H+3AFOBfnt5zLPW2j7W2j6RLkQUAci0FRfb5zegCzHFnaLlpz1zU0pKihMhSjUM+uwzMjdv5ouRIylJSwOgoCCJCRMG067dVk47LcfhCEUi29d9J+UnqamOHYuYNeRqbDBE6O5HnA5H9qLaBZkxJsUYk/brbeA4YEltBSaxKcNWHBnLU0EmNaD81Di1WbeO/p9/zqLevVnfowdQMbtwwoTBlJbGMWrUbHw+HV0X91JuEqeccFWQZz1Xkj7lNTyrVzsdjvxOTXqLZwBTwy0lfcB/rbWf1EpUEhP21q4001Y089ARMqkh5acGIFrL4uLi4t2348vKOOmttyhIT+eDoUMZdcopAEyYkMTixU24776djBo1ePfjfb7KP95q0t5ZpIaUm6RGYwAitZD/6quvIq679dyxFP/3JcpufYDga8/85r6GOA6kMal2QWatXQN0r8VYJMZZ6yOTQraRRKne+FIDyk+Nz3EzZtBs+3ZeGjmS0oQEAFav9nLXXWkcdVQpl11WHOUZRJyn3CROuuzWVJ566zr+OvMBti4ZQ+CQQ5wOScLU9l5cw9rWZJFHPolOhyIiLtJl9Wr65eTwdf/+rOvQAYDychgzJp3ERMvjj+9Ec5NFRCJr2TLEjlFXsY1m2Nv/4XQ4sgd9hIlrWLsfmeSRZ2pyJq2INCZJRUWc9v775LdqxWdHHbV7+aOPprBoURwPPbSTzExdNyYiUhWXjo3jiaSbafXtDOLmzXM6HAlTQSauYe1+ZLGZPKP5QSICWMvJH39MclERk08/nUD4urCffmrHP/+ZwtlnF3PKKRoiLyJSVU2aWHzXX8ImsrC3jqvojCSOU0EmrmFDmWSxmXxPudOhiIgLHLpkCYcuXcqsI48kLzMTgNLSeN59dzht2oS4//5ChyMUEWl4LrgCnmhyOy2XzSX+s8+cDkdQQSYu0sQ2I4kS8o0uzheJdWkFBZz8ySesb9uWrwYM2L182rQT2LGjKU8+WUBamr7ZFRHZV0lJ0OqWs1lDJ7jtHxDSad9OU0EmrpFhK5p55HnUYVEkpoVCnPj223iDQaacdhqhcMeO5cu7snBhbwYM+JIjjtCRdBGR6jr7wiBPtrqT5usXE//eB06HE/PUPUHqTLRZGr+XEaqYgaEZZOK0ff3bjWXRtlWk+wOBwF6X95k7l06rV/PLffdxxoUXArBli4enntqPQw4p5aWXOpAQbn1fmUizetw6TydSzCKNVbT3Y6zl45rkp7i4uIj3f/3117/53XtBFxY/fggZt96PGX4GVHN+Y7SYQxGOwNVl3ov0t+O2zwFlf3GNTFvxhs1z2ZtEROpP859/Zui0aazu0oVdF1wAVFxzfvPNLfH7DY8/vpX4eIeDFBFpBI4YmMcTrW+l9Y71eF/9r9PhxDQVZOIamZQAOkImEqtMMMhpU6ZQ7vPxwRlnQDgXvPZaKrNnJ3HbbTs44IC9H1UTEZF94/FAxqj2fMMRcM/DUFLidEgxSwWZuIK1KWRSQDE+CpwORkQcMXDOHNps2MDHp5zCrrQ0AFav9nH//c048shiRo5UV0URkdrUs9cWnu1wM00KNmL+/aLT4cQsFWTiCtZmVcwgI3H3t+IiEjsyN25k8OzZLDnsMJYdeigAZWUwdmxLkpIsDz/8i1KDiEgtMwa6jG7GNI4lbvzjUKgvvpyggkxc4f+HQke+IFVEGh9feTmnv/02/tRUPjn55N3Ln3iiKYsXJ/Dgg7/QunXQwQhFRBqvrl238cERd5FStBUefcbpcGKSCjJxBWszySSPfKNZGCKx5o/Tp9Ny61beP+MMSpKSAFi3ri1PP92Es87axbBhmk0oIlKXzn74ECZzJknPPIX55Renw4k5ansvdWZfWtWGQhVHyL7wlKHvCcQJsdZauapqul0itTsePHgwTXNz6f7NN2w84wzaXnopbQG/38vTT/emffsQDz9cRlr4erI9RWuV7LaWxqC29iJSt6LlvRUrVlR6X//+/Zk49G+cPvMddt7zCMF/3PGb+5OTkytd1+v17lug8j/06SCuEB9qRXO2k2/UQU0kVngLCzlo3DiK2rVjzZVX7l7+r3/tT35+Is8842cvtZiIiNSB8+9tw2tmJM1efwnPpk1OhxNTVJCJK2TYREAzyERiyQH/+hcJW7ey/LbbCCVW5IA5c1ry8cdZnH/+evr10xc0IiL1pWPHIIvPvAkbCsG9jzsdTkxRQSaukGErDndrBplIbDjo++/J/PRT1l10EYV/+AMAv/wSz/jxB3LQQTu55JJ1DkcoIhJ7LvxbC573XknL997Au2aN0+HEDBVk4gqZtqKDmo6QiTR+KYWFnPDOOxQeeCDrL7oIAGth3LiDKC31cPvty/H5dE2fiEh9y8gI8dPIsZTYBOzfH3E6nJihgkwcZ60hk1JABZlIo2ctJ06dSlxZGctvvx3rq+gtNXXqfsyf35yrrlpD+/bqqigi4pSRNyXzTPx1ZMyaim/JEqfDiQkqyMQFWpDFzwQxbFVBJtKodc/OpsuKFcw+/niKOnQAYN26ZP79784cfvgvnHaaLiQXEXFS06aWojF/YhvNCN76kNPhxAQVZOK4UCiLTPLYQgIhFWQijVbTbds45qOPWNu5M/OPOAKA8nLD/fd3JSkpyM03r0ApQETEeReMieeplJvIzJlB3Lx5TofT6GkOmdSZqs4vsrZiBlme8QG6bkSkIYk0Zwxg165dAJhQiPMnTsQaw8Rhw9hVVES3bt24//4UVq5M5uWXCxg8uMtv1o0028aNc8ZAs8ZEaluk93oszo+sSe7z+Srf7X/77bf/Z9nyY3uy+Z1Mdl19Oy0Wz6Gyb8xqMhcy2mdIXeXUaH879f0Zo08OcZy1WWSxmXwTe4lVJFYM+vZbOm7YwHvHHktBejoAc+f6ePLJJC64oJgTTyxzOEIREdlTnyE/8GjKX+iyeSne6TOdDqdRU0Emjvv/I2TaIRNpjDK3bOHYOXNYctBBLDzkEABKSxO45pomtGsX4t57/Q5HKCIiv+fzhfj51K6soROBm++HKEezpPpUkInjTCiD1mxhi/4aRRodbyDAWe+/T3FiIu8OG7b7lJfp009mwwYPTz+9k9RUHR0XEXGjnof/yKPpN9Hip+/wTHnP6XAaLe0Ci+Na2GR8BNXyXqQRGvrll2Rt2cKUE07An5wMwPLlB7N4cW+uv76Ivn0DDkcoIiKV8Xgs5SP2YwkHE/rbOAgoZ9cFFWTiuExbceG+CjKRxqXNunUMmTuX+d27s6JLRcOOwsI0Pv74DDIzN3DjjUUORygiItEcfNh6Xj7gbpr/vAoz4Q2nw2mUVJCJ4zJsxTnJKshEGo/40lJOmTSJHenpfDh0KFAxBP6DD0YQCPg49dS3iItzOEgREYnKGBgy/hi+4Qg89z0MJSVOh9ToqO29RBStLWik+6O1Mq1YP55MigHIV0Em4ohI7+NoOSBQyekrx334IU23b+fnSZMYdfjhALz4Yipr1zblgQe2c9FFZxMXpSKL1O7YrW3vRUTcKlLe9PsjN1fq1buQ8YfdxePfDSPvn88SuHbU7vvS0tIirhtphIlUqNERMmPMMGPMCmPMamPMLbUVlMQOazPIYjOgI2RSu5SfnHPAihX0zs7mm4EDKQsXYytW+HjggXSGDi3mwgvVVVFil3KTNFTHj+vBdI4h9cl/YcIzJqV2VLsgM8Z4gaeAE4BuwHnGmG61FZjEhl9b3m8njlIVZFJLlJ+ck+T3c8q775KfkcHso48GoKwMrruuOampIR5+eHtls0VFGj3lJmnIDj20nI8H3UFq8S94/vm80+E0KjU5QtYPWG2tXWOtLQPeBE6rnbAkVlibRSZ55BkdzpZapfzkBGs56f33SSou5t3hwwn6Ks6Kf+SRJnz/fTwPPbSdVq00x0ZimnKTNGin3deFKZxJ0xeexbNtm9PhNBom2vUBla5ozAhgmLV2VPj3i4DDrbXX/O5xo4HR4V8PAZZUP9w60RLY6nQQe+HGuNwYE7gzLjfGBDWLq4O1tlVtBlNXqpKfGkBuAnf+HbkxJnBnXG6MCdwZl3LTbx/n9vzkxr8hcGdcbowJ3BmXG2OCeshPdd7Uw1r7LPAsgDEm21rbp65fc1+4MSZwZ1xujAncGZcbYwL3xuUEt+cmcGdcbowJ3BmXG2MCd8blxpic5Pb85MaYwJ1xuTEmcGdcbowJ6ieumpyyuBFot8fvbcPLREScpvwkIm6k3CQi/6MmBdl8oIsxppMxJh44F3ivdsISEakR5ScRcSPlJhH5H9U+ZdFaGzDGXAN8CniBF62130dZ7dnqvl4dcmNM4M643BgTuDMuN8YE7o2rVlUjP7l1u7gxLjfGBO6My40xgTvjcmNMtU77TnXOjXG5MSZwZ1xujAnqIa5qN/UQERERERGRmqnRYGgRERERERGpPhVkIiIiIiIiDqmXgswYM8wYs8IYs9oYc0t9vGZVGGPWGmMWG2MWGmOyHYzjRWPMFmPMkj2WNTfGTDfGrAr/t5kLYrrLGLMxvL0WGmNOrOeY2hljZhljlhpjvjfGXBde7vS2qiwux7aXMSbRGPOtMWZROKa7w8s7GWPmhd+LE8MXlcc0N+Yn5aZqxaX8VPWYnN5Wyk9V4MbcBMpP1YjJ6feb63JTlLhic9/JWlunP1RctPoD0BmIBxYB3er6dasY21qgpQviGAL0Apbssewh4Jbw7VuAf7ggpruAvzi4nbKAXuHbacBKoJsLtlVlcTm2vQADpIZvxwHzgCOAt4Bzw8v/DVzl1P9PN/y4NT8pN1UrLuWnqsfk9LZSfoq+jVyZm8KxKT/tW0xOv99cl5uixBWT+071cYSsH7DaWrvGWlsGvAmcVg+v22BYa+cA2363+DRgQvj2BOB0F8TkKGvtZmttbvh2IbAMaIPz26qyuBxjK+wK/xoX/rHA0cDb4eX1vq1cSPkpAjfmJlB+qoWYHKX8VCXKTVG4MT8pN9VKXI5xMjfVR0HWBvhpj9834IIPhDALTDPG5BhjRjsdzO9kWGs3h2/nARlOBrOHa4wx34UPy9f7qUq/MsZ0BHpS8e2Fa7bV7+ICB7eXMcZrjFkIbAGmU/Ft6w5rbSD8EDe9F53i1vyk3FQ9yk9Viwkc3lbKT1G5NTeB8lN1KDdF4Kb85FRuivWmHoOstb2AE4AxxpghTge0N7biGKkb5hM8A+wP9AA2A484EYQxJhWYDFxvrd25531Obqu9xOXo9rLWBq21PYC2VHzb2rU+X19qRLlp3yk/VT0mx7eV8lODpvy0bxx/v4E7c1MlccXkvlN9FGQbgXZ7/N42vMxx1tqN4f9uAaZSseHdIt8YkwUQ/u8Wh+PBWpsf/kMNAc/hwPYyxsRR8cZ93Vo7JbzY8W21t7jcsL3CcewAZgH9gabGmF8HwrvmveggV+Yn5aZ954b3mxvzk5tzUzgW5ae9c2VuAuWnfeWG95sbc1Nlcblhe4XjqNfcVB8F2XygS7hDSTxwLvBePbxuRMaYFGNM2q+3geOAJZHXqlfvAReHb18MvOtgLMDuN+yvzqCet5cxxgAvAMustY/ucZej26qyuJzcXsaYVsaYpuHbScCxVJyfPQsYEX6YK/6uHOa6/KTcVD3KT1WPyQXbSvkpOtflJlB+qg4XvN9cl5sixRWz+07Run7Uxg9wIhXdU34Abq+P16xCTJ2p6Fq0CPjeybiAN6g4LFtOxbmplwMtgJnAKmAG0NwFMb0KLAa+o+KNnFXPMQ2i4pD6d8DC8M+JLthWlcXl2PYCDgMWhF97CXBHeHln4FtgNTAJSKjPbeXGH7flJ+Wmasel/FT1mJzeVspPVdtOrspNe/w/Un7at5icfr+5LjdFiSsm951M+IVERERERESknsV6Uw8RERERERHHqCATERERERFxiAoyERERERERh6ggExERERERcYgKMhEREREREYeoIBMREREREXGICjIRERERERGHqCATERERERFxiAoyERERERERh6ggExERERERcYgKMhEREREREYeoIBMREREREXGICjIRERERERGHqCATERERERFxiAoyERERERERh6ggExERERERcYgKMhEREREREYeoIBMREREREXGICjIRERERERGHqCATERERERFxiAoyERERERERh6ggExERERERcYgKMhEREREREYeoIBMREREREXGICjIRERERERGHqCATERERERFxiAoyERERERERh6ggExERERERcYgKMhEREREREYeoIBMREREREXGICjIRERERERGH+OrzxVq2bGk7duxYny8pIrUkJydnq7W2ldNx1AXlJpGGqzHnJlB+EmnIqpqf6rUg69ixI9nZ2fX5kiJSS4wx65yOoa4oN4k0XI05N4Hyk0hDVtX8pFMWRUREREREHGKstfX2Yl6v16amptbb64lIzRQUFOy+bYzJsdb2cTCcOtOsWTM7dOjQWnkuY0ytPI+IVG7SpEm7bzfm3ATg8XhsQkKC02GISBUVFxfvvl3V/KQjZCIiIiIiIg5RQSYiIiIiIuIQFWQiIiIiIiIOUUEmIiIiIiLiEBVkIiIiIiIiDlFBJiIiIiIi4hAVZCIiIiIiIg6JWpAZYxKNMd8aYxYZY743xtwdXt7JGDPPGLPaGDPRGBNf9+GKiPw/N+Yna221f0SkcXBjbhIR96rKEbJS4GhrbXegBzDMGHME8A/gMWvtAcB24PK6C1NEZK+Un0TEjZSbRKTKohZktsKu8K9x4R8LHA28HV4+ATi9TiIUEamE8pOIuJFyk4jsiypdQ2aM8RpjFgJbgOnAD8AOa20g/JANQJu6CVFEpHLKTyLiRspNIlJVVSrIrLVBa20PoC3QD+ha1Rcwxow2xmQbY7J1jYSI1Lbq5qc9c1NpaWmdxigisUf7TiJSVfvUZdFauwOYBfQHmhpjfOG72gIbK1nnWWttH2ttH2NMjYIVEanMvuanPXNTQkJCPUYqIrFE+04iEk1Vuiy2MsY0Dd9OAo4FllGRXEaEH3Yx8G5dBSkisjfKTyLiRspNIrIvfNEfQhYwwRjjpaKAe8ta+4ExZinwpjHmPmAB8EIdxikisjeNKj9FOjVJ35KLNCiNKjeJSN2KWpBZa78Deu5l+RoqzokWEXGE8pOIuJFyk4jsi326hkxERERERERqjwoyERERERERh6ggExERERERcYgKMhEREREREYeoIBMREREREXGICjIRERERERGHVGUOmYiIOCzSjLJoNMNMRETEvXSETERERERExCEqyERERERERByigkxERERERMQhKshEREREREQcooJMRERERETEISrIREREREREHKK29yIijVy0lvlqiy8iIuIcHSETERERERFxiAoyERERERERh6ggExERERERcYgKMhEREREREYeoIBMREREREXGICjIRERERERGHqCATERERERFxiOaQiYjEuEhzyjSjTEREpG7pCJmIiIiIiIhDVJCJiIiIiIg4RAWZiIiIiIiIQ1SQiYiIiIiIOEQFmYiIiIiIiENUkImIiIiIiDhEbe9FRKRSkVriV4Xa5ouIiEQW9QiZMaadMWaWMWapMeZ7Y8x14eV3GWM2GmMWhn9OrPtwRUQqKDeJiFspP4nIvqjKEbIAcKO1NtcYkwbkGGOmh+97zFo7vu7CExGplHKTiLiV8pOIVFnUgsxauxnYHL5daIxZBrSp68BERCJRbhIRt1J+EpF9sU9NPYwxHYGewLzwomuMMd8ZY140xjSr5dhERKpEuUlE3Er5SUSiqXJBZoxJBSYD11trdwLPAPsDPaj4FuiRStYbbYzJNsZk1/TicBGR36uN3FRaWlpv8YpI7NC+k4hURZUKMmNMHBUJ5XVr7RQAa22+tTZorQ0BzwH99rautfZZa20fa20fddsSkdpUW7kpISGh/oIWkZigfScRqaqqdFk0wAvAMmvto3ssz9rjYWcAS2o/PBGRvVNuEhG3Un4SkX1RlS6LA4GLgMXGmIXhZbcB5xljegAWWAtcWScRiojsnXJTAxDpdCt98y+NWK3mp9o6bVHvORF3qkqXxS+Bvb2DP6r9cEREqka5SUTcSvlJRPbFPnVZFBERERERkdqjgkxERERERMQhKshEREREREQcooJMRERERETEISrIREREREREHFKVtvciIiK1riatvNW+W2Tf1Vb7/Nqk97KIjpCJiIiIiIg4RgWZiIiIiIiIQ1SQiYiIiIiIOEQFmYiIiIiIiENUkImIiIiIiDhEBZmIiIiIiIhDVJCJiIiIiIg4pF7nkKUB7puAISICoVCoSo/zePQ9lhtEm6ek2UYiDYOTs9GUJ8Qt6nXPYv9QiLPKy+vzJUVERERERFyrXguyXSTxfHEx15aWggunxYuIiIiIiNSnei3IVtGVtziW+0pLeaC0FKOiTEREREREYlj9Xgxh1nIuU/gnlzCmrIwXiouJV1EmIiIiIiIxql6behhTQGLSqYwteouNtOehwD20KiriguRkdurCShERERERiTH13i7M58shOeU4xptLuZDn6R8M8ZHfT2YVO5yJiIiIiIg0FvV6hCwzM5Mrr7wSgMLCyTz66FC2hD5kcug0pvn9DE9OZpXXW58hiYgQCnkIBAK7f/f5Kk+N0drjqy2+O9SklbZaYYvEBidb7ldG+Sc2ObbnkJbmJyXlJD7zxnEkc0mwKUzzF9F3j50iEZH64N3ZhJ/WH6XmryIiIlLvHP0q15hdJCefw5K45QxgEb/QiveKijhBs8pEpB51Zi13LprDj3P/RElJU6fDERERkRji+Lk1xgRITLyKjfFTGcASvqcLrxcXc3FZmdOhiUiM2JqYyAnmQ2ZvHUmLz4ayYcMAp0MSERGRGOF4QQZgDCQm3sOuxHEcRQ7T6M8TJSXcUlKiAdIiUud2JCRww5GD2Jrm4Y3gJYydn8PKb0ZRWprmdGgiIiLSyLmiIPtVfPzz2KQ/cSqf8jJncmtZGU+UlOBVUSYideyntDRuGdKPVw/syggmMT3vchKmDWPz5r5OhyYiIiKNmKsKMoC4uA+ITx7BpTzH/VzHxeXlvF5cTJKKMhGpYyGPh0kHdeGvfxxCUWqAKYHzGT13JSu+vZSysmSnwxMREZFGyHUFGYDPN5eUlGH83dzI1TzC8YEA7xUV0VyzykSkHqxt2pRbjx7ApC5dGckEPtl4NUw7nfz8Hk6HJiIiIo1M1Dlkxph2wCtABmCBZ621/zTGNAcmAh2BtcDZ1trtkZ7L4/GQmpq6+/ebbrqp0sc+/PDDpKQcy3+KJpEXmsh/g+czraiIM5OTWa85PyIxrzZzU4sWLbjwwgt3/z5jxgwApmdksKrbQYyc+TUf7DqLZ77+E/9qP5JOh04kLq5kr88VbU5ZJJph5g6RZhNpRpBURW3mJ4ktbpyNBsp9da0qn/4B4EZrbTfgCGCMMaYbcAsw01rbBZgZ/r12g/NsJiXlRN7zZnIss2gZime638+hwWBtv5SINDz1kpvWtm7Ng2edzCcHd+dK/sP762+gfMbZbN16cI3/ASLSaDm27yQiDU/Ugsxau9lamxu+XQgsA9oApwETwg+bAJxeFwEas5PkEImXIwAAIABJREFU5OHM9eUziGzKbVM+8vs5UgOkRWJafeamcp+PKQP6Mf6Uk4lP3M7HpcM580s/KxZeQCAQX9OnF5FGxul9JxFpWPbp/BhjTEegJzAPyLDWbg7flUfFYfk6YUwZSUmjWB3/Gf35jvW05+2iIoZrgLSIUH+5aXVmJn85ZhAfddifsTzO1LW34595Adu2HVhbLyEijYxT+04i0nBUuSAzxqQCk4HrrbU797zPVpzwuteTXo0xo40x2caYbL/fX+1AjbEkJv6NrQlPMYhFzKUHLxYXc01pabWfU0QavtrITTt37tzbQ/aq1OfjhZ6HcMfAgaQn5DO9+AyGzYGVi88lGIx6Wa6IxJDayE9uvaZIRGpPlQoyY0wcFQnldWvtlPDifGNMVvj+LGDL3ta11j5rre1jre2TkpJS44ATEp6mLGksxzGbtzmO+0tLua+kBKOEJRJzais3NWnSZJ9fe3GrVtxwzCBmtOvIrTzEmz/cx47PLmHHjs7V/NeISGNSW/lJzRREGr+oBZmpyAQvAMustY/ucdd7wMXh2xcD79Z+eHsXFzcFb/L5nMN/eZJLubasjOeLi4lXUSYSM9yQm4rj4vh378O474gjyIxbx0z/6QyZlcKqpWcSCnnr6mVFxOXckJ9EpOGoyvk1A4GLgMXGmIXhZbcB44C3jDGXA+uAs6vygnu2dU5OrnzQ6i23RG489NBDD+H1nsp1hRPZQAf+EbiLVsXFXJSSQoEKM5FYUGu5yRhDQkLC7t+PP/74Sh9bWFi41+XTd+2i94Q3uSv7Hk5Z0YtrNt5LYp+PaNLkp92P8XojF2mRWuarJb471OT0MR3piCm1uu8k4jSnTp2NlbwZtSCz1n4JVLY1htZuOPvG611KWpNhjN81iU2hdrwYGMWHhYUMT04mXzsvIo2a23JTWWoq34wZxZSnSrly4TJm7zqDOz+/kw8O6k3nLu9hjAbbi8QKt+UnEXG3Bl+1eDwbSU09gTe8XTmZj+kU8jLd7+cAzSoTEQfM3W8/rh86iPmtMxlnb+e55c+y+fPR7Nq1n9OhiYiIiAs1+IIMwOMpIDX1TGbFlXAUX5NoU5lWVEQfzSoTEQcUJCTw8OHdGd+zF928i/h853AOm3UAP6w6AWtj4/QLERERqZpGUZABGFNKcvJlLI7PZQAL2G5b835REcdrVpmIOMEYvmjXluuHDmZxyxY8Zv/C40v+y/rPR+H3t3Y6OhEREXGJRlOQARgTIinpr2xMmMAAvuN7DuKN4mJGlpU5HZqIxKhtiYk80L8nT3TvQV/PXGZvP5vOMw7hxzXHoP5DIiIi0qgKMgBjICHhnxQm3s4f+YbpDOTJkhJuLi1Fez8i4ghjmNmhPTceeySrm6fzTOhaHlz0Hj9+MZri4hZORyciIiIOanQF2a/i49/CJl/KKbzHy4zg9tJSHi8pwauiTEQc8nNyMvcN6ct/DuvOkZ5ZzP7lXLKm92P9uiP1fZGIiEiMqsocslpjjPnNLJ1IswUSExMjPlekOWWPPfZY+NZcyhPP5vLtr7HJtue28kfJ8ni4JD6e4hiZayAiVbNnPvL5Kk+N6enpEZ/nggsuqPS+qVOnAjC72x9Y1q4tV3y9gBe3j+ad3NO4a9NVZPV4k8TEHXtdN9KMMtCcsoYg2hyfWJm3IyJSVU7NP4ukLnJ1o/8Ej4tbQvMWp3KH9yrG8BjHlZbyblERzaLs3IiI1KX8tDTuP3YQr3TvyQnmI2bkXUCz6UeyceMAp0MTERGRetToCzIAr3c9zZufynNxgziLt+gehE+LiminokxEHGQ9Hj7+w0HcNuwYfkn38d/gpdw4P5vVcy+ntDTN6fBERESkHsREQQbg8WyjWbOz+DAhjWOZRetQAtP9fg7RAGkRcdim9HTuOf5IXu3ajTOZzPS8USRNH8bmzX2dDk1ERETqWMwUZADGFJOefjnz4lYziPkEbDM+8hcxWAOkRcRhIY+HKV0P5OY/DmFXapDJgQu4at4KVs2/jLKyZKfDExERkToSUwUZgDFBEhOv54eEqQxgIT/RgclFRZypAdIi4gJr09O59egBTDywKxfwGp9svArP9NPIz+/hdGgiIiJSB2KuIINfZ5U9zNbEcQzmW+bRk5eKi7mqtNTp0ERECHg8vNmtK7ceOZhAcjHvl5/DyK83sjJnJOXlkTvQioiISMNSr23vfy9S28hoLZzj4+Mrve+GG26IuO6vrachl+3bH2DYypm8Zi5kXOlH7GctdyQkYNV+WCRmGGN+k48i5aZo7W4j3T9ixIiI6xYUFPzPss/PK6dg8jtcMf05jls/javyH2Fb7xxatlwS8bn2hVrmu0NN2jurZb6ISP2oi1b8Mf8p3KzZXPY/+EbOMy/ztBnFn8vK+E9JCXEunHsgIrEnGBdHzrlncevAAfgSC/ikdDhnfe1n9XcXEghU/sWUiIiINAwxX5ABpKYuo9uhV3ND3B3cyl2cU17OpKIiUlWUiYhLLG/RghuP7s/7HQ7gev7J1LW3U/zZRWzbdqDToYmIiEgNqCALS0zcwCGHXslDnlO4hBcYHAzxkd9Pa80qExGXKPX5eL57N/7Wvz9N4vOZXnIGJ31pWP39eQSDjp6BLiIiItWkgmwPcXHbSUk5mdd9bTmFDzkg5GWa38/+mlUmIi6yuFUrrh86kOltO3ILDzPxh/vYMXMkO3Z0djo0ERER2UcqyH7HGD9JSecxM24rR/EVKTaVaUVF9NasMhFxkeK4OJ7pdQh3H344rePWM9N/OkfOSmbV0jMJhbxOhyciIiJVpIJsL4wJkJh4Dd/Ff8ZAciiwGbxfVMxxmlUmIi6Tm5HB9UMHMqdNB+7kXiaseJSfP7uUnTvbOx2aiIiIVIEKskoYA4mJD7Ah8SkGkMNyDuKN4mIuLCtzOjQRkd/wx8fzr37dGXf44XT0reKzwjPo+1krVi8/lVBIaV5ERMTNXHsVeLSZKpHm5sTFxUVc98wzz6z0vq5du/5uSQHr17/N0NlfMtmM4KmS2WRay/j4+IqqTUQahT1zTqQZIzXJTdHWbdasWaX3nX/++RHXfeONN5ibmcnSY5oxesFSHsz/G6cuO4LrNt5Ber8PSE3dVOm6oQjNizSjrGGoyd+siIg4S5+0VdC+/QIGDnuG072TeYWz+HtpKY+WlOBRW3wRcZmdCQmMP7wH43v3ppt3EZ/vPJNDZ3ZizeoTsVY75iIiIm6jgqyKWrf+gWNPephLeIhxjOXy8nJeKS4mUUWZiLiNMXzZti3XHzOERS1b8qi9iSeWvMaGOVfg97d2OjoRERHZgwqyfZCenkdK6nHc7rmEP/MoJwUCvFNURDMVZSLiQtsTExk3oBdP9OhJL8+3zN5+Fl1mHszaH49BaUtERMQdVJDtI48nn5SUE3na24NzmUivIHzi99NWA6RFxI2MYVbHDtxwzBBWNk/nqdB1jFv0Huu+vILi4hZORyciIhLzVJBVgzGFJCefxTtxIY5nBlmhBKb7/XTTAGkRcamtycncO7gv/z6sO4M9nzPrl/NpM70v69cdqaNlIiIiDlJBVk3GlJOY+Ce+iV/AYOZibTM+9hcxUAOkRcStjOHTzp24YegQfmqazAuhP3Hngs/44asrKClp6nR0IiIiMane295Xtf1upBa+0Z4nWpvmSG3xDz744Ijr/m9b6p9YsGA1/Wfn8Al/ZGrRWkYnJfFOlNb7IuJekfJLTXJTtPwX6f6EhISI61500UWV3rd9+/b/WTZvxAh2zZjJsMnvMPDnr/jztPGs6PEzbdp8FfF19pXa5jsv2t9sJGqZLyJS96J+UhpjXjTGbDHGLNlj2V3GmI3GmIXhnxPrNkx369nzS7qfPJtBfEU2PXmpuJjRGiAtUueUn2rA4+H7447l3bv+xpY0H68HL+PmnGx+mHcFpaVpTkcn0qApN4nIvqjKV5cvA8P2svwxa22P8M9HtRtWw9Oly3eUJl/GMXzIuwzj4ZIS7iopQRdniNSpl1F+qpGCrCxuO7IfE7p243SmMDP/ctJmDiMvr5/ToYk0ZC+j3CQiVRS1ILPWzgG21UMsDZ7P9w3elNM5i3/zDJcxtqyMf5eU4FNRJlInlJ9qR8jjYcqBB/CXIwexMzXEpMBFjPl2BT9kX0ZZWbLT4Yk0OMpNIrIvanJy/zXGmO/Ch+V/f2FVzPJ6l5OUOoxrzFj+xl2cV17OW0VFpKooE6lPyk/VsC49nVuOOoI3unTlfF7n001X45l2Kvn5PZwOTaSxUG4Skf9R3YLsGWB/oAewGXiksgcaY0YbY7KNMdm7du2q5ss1LB7PJlJST2Sc949cxgscGQzxvt9PK80qE6kPVcpPe+amgoKC+ozP1QIeD2/+4UD+OmQQZcmlvFd+Dhd/vYGVOSMpL090OjyRhqxa+041acoiIg1DtQoya22+tTZorQ0BzwGVXmxgrX3WWtvHWtsnNTW1unE2OMYUkJw8nFd9TTmN9+ka8jLdX0RnFWUidaqq+WnP3JSenl6/QTYAq5s25aY/HsHkAw5iFM/z/vqxBKYPZ+vWbk6HJtIgVXffSZ0uRRq/ahVkxpisPX49A1hS2WNjmTFlJCVdxoz4H/kjX5BmU5jm99NLA6RF6ozyU+0p93p5/dBu3D5kMHGJBXxcOoIRX+xk5cLzCQTinQ5PpEFRbhKRykSdQ2aMeQM4CmhpjNkA3AkcZYzpAVhgLXBlbQcW7RuhSIfwa/Jtks8XeZO0adOm0vuuvfbaSu7JY968XxgwI5tP7VF84M9jZFIiMzSrTKRGnMhPNckvdTlfMdK6LVq0iLjueeedV+l9r732GovT0rjuqMO5aOkq/rz+SYb9+AlXbX6Ikl5fkJHxY8TnDkU4K0AzytyvJn+zscypfScRaZiiFmTW2r19Ur9QB7E0aocf/jVfffU2/Yvn8hHDmFi8jGut5b/x+pZZpLqUn+pPqdfL84d2Zd5+rbh2wTKmlQznka/H8sr+Z7P/wVPwegNOhyjiGspNIrIv9PVkPYqLm0xh8hiO4lNmMZhnSkq4sbRUs8pEpMFY3KIF1x11BJ+07cDNPMLEH+5lx8yR7NjR2enQREREGiQVZPXM55tDKOVcTuZVXmcEd5SWMr6kBI+KMhFpIIp9Pp7p3o07+valVfwGZvpP56hZSaxeeiahkNfp8ERERBoUFWQO8HqXEJ96Ehebu3mYsVxRXs6E4mISVJSJSAOS27o1Nx47mDltOnAH9zFhxSP8/Nml7NzZ3unQREREGgwVZA7xeH4iOfVEbvWexfU8yqmBAFOLimiqokxEGhB/fDz/6tedBw8/nA6+1cwqPJ1+n7Vk9fJTCYX0ESMiIhKNPi0dZMx2kpNP5ynf/pzDm/QJwsd+P200q0xEGpj5++3H2OOG8G3mfjxg/86zy/7N5lmXU1iYFX1lERGRGBa1y6JbRWq1W5dter3eyq+PaNasWcR1b7jhhr0uD4UW8uCDmQwrn847oZOY7i9ieHISyyK8log0PHU5ziPS/dHWTUxMrPS+Sy+9NOK6W7du/c3v359yCsXzs+n/+lvM3nkmt8+8hxndutNp/48xpvbOAFDLfHeI9nkbiVrmi4hU0CeaC3g8lsTEm/gm4XOG8A3GNuNjfxEDAmojLSINjDGs6deXqff8jY1du/KovZl/ff8aG+eMxu9v7XR0IiIirqOCzCWMgYSEx1iZ+DT9mUs+HZhaVMyp5eVOhyYiss+K0tOZed2V/LNHT3p65jN7x1kcOPNg1v54rCZ9iIiI7EEFmcvEx7/J1uSbGchscunJhOJiRpWVOR2WiMi+M4ZZHdoz9pghrGiezlP2eh7+7h3Wfzma4uIWTkcnIiLiCirIXMjnm0lpykiOZTLvcwKPlJRwR0mJBkiLSIO0NSmJewf14enDujPQ8wWzt51Huxl9Wb/uSKU1ERGJeSrIXMrrXYgn9TTOMo/yHy7jxrIyni4pwae9FxFpiIxhWqeOjD16MOuapvB86CruzJ3Bmq9GUVLS1OnoRFyruc3ioLLbIXAJodAhWKtdN5HGpsF2WYwFHs9aElJO5Gr/RDbadtxTfjetQyEuTk7Gr+5UItIA5aekcOeQvpz0w49cuPRTBv78FddNG8+Kntto2+5rp8MTcZ2ObCLb3oE/mMyCYE/mcynZNCfXU8oPZg3Gm40xeU6HKSI1oILM5TyeX0hJPZUHi19kU+A5/hMczQd+P2clJ7NVbZ9FpAGyxvDBAZ1ZmJXB1fMX82rB5UzKHsG9Gy6jXa9JJCQUOh2iiGt8bwyXeLz0tgn0Dq3iSr5lLOUQgh2kkxPszXxOJNckkW38bPAsx3gWYkyJ06GLSBU1yoKsLmf9RBJpRhlAWlpapffddNNNEdd96KELeKXkUfLL32ViaATT/UWcmZLMjyrKRBqNmuSfmuS1SDO9oq3bunXkVvbnnntupfe98sor3HxED85cs5YLV7/DkXmfM2baI6w57EcyMuZGnI8WCoUivq7mlLlfXX0WNzat2ralz803A5ALzPrlF1r9/DMZ6zfTdNU22m/6iSGFc4izAbCwJdSKbPqzyNeRJUlNWNmklF1pa0lIWM/KlcsrfZ1oM+VqMnNORCJrlAVZY2RMkMTE65juuZmhpbP5wB7PdL+fs5KTWKAB0iLSQIU8Ht4+oDPzM1px/YLlTPKP5NXcCxmXdQWdek0mPr7I6RBFXMV6vWzJzGRLZib0q1jmDQRonZfHpvdm0bXQx8Elizk+MA1vYQgKYQNtyKYn2aY7OQYWevPZ4f0OY7Y5+48REUAFWYNSMavsIRaazQws+ZpP7HF84M9jZHISM336XykiDde6tDT+Mqg356z+kXN/eIOjN3/G1dMeJb/vCjIyFjodnoirBX0+Nrdty5SMZMgAaEVisDkHFZVy4M5Euvoth5XkcnpoE1ggBD+Ud2Y+R5Nr0snxlLPQsx6/ZynGaP6pSH3TXnwDFB//KutNPv2Lv+BjTmFi0TLGJCYyMT7e6dBERKot6PHw3wP3Z15GS8YuWM67xefy3NejeKL9RXQ8bBJxcbomRqSqSrxeFqUls2j31RKtyVu+je7BBHqFWtM75OUIO59z7RYIQihoWM5BzKcTuSaZHM8ulnh/oMRsQGeQitQtFWQNVFzcNAo9WznK/wGTuYRnS74gy1oej49HmVNEGrIf0tO5fnAfLl6znstWv8ix66dzVf4j7Oi7kFatvnc6PJEGq8AY5vjKmMOG3ctahhLpEWxO71ALeodCHM88LrbbIAjlQR9L6EoO+5FtfOR6t/O9WUHQ43fwXyHS+Kgga8C83lwCKcM5yf8GL/F37i59myxruTUhgZCKMhFpwAJeL68f+gfm79eaMfMX83HxCJ748lqe63Q+nQ55G5+vzOkQRRqFrR7DDM92ptvw9WTWsp9NpleoLb2CTehtSzmTeYyyBRCAEhJYxIFk04pcjyXHk8cK8yPWo6YfItWlgqyB83rXYFJP5iL/RDbZttxY9jiZoRCjk5IoVVEmIg3cyhYtuOmYQZy/ZAV//vFJTvjxY/60eTzBw7+hefOVTocn0vgYwyYTYpNnPR/8updoLR1CLekdakevUDK97U5GMo8xIT+EYBcp5LI/OSadHFNKrncDa8xWnbEjUkUxWZBFaqcbra1rTVrxRmrDnJycHHHdW265JeL948adyi1FE9gUaMsjgb/QoqiIC1NSKDBGrWpFYoBTeS3auI9Iresvu+yyiOtu2bJl9+0Nw4bxzsqVDH7pDabvPIPxn9/AhM5n0bnbZLzewL4FHYVa5jtPn1v/z+v1kpqauvv3lJSUSh97zTXXRHyuSOMigsFgxHVLSv7/Gs6FwIJgCLOyhITF22m6+ke67PiRP5XPJ8mWQAi2k87S5K6sbdmOj7asZmHcRjZ5yv6nSNvzefeV/k6ksYjJgqwxMsZPcvK5PFn8BJvLX+fl4Eg+2uXnrJRkNuobKhFpBDYdeCBT7vwr/Sa9w81zH+GkNd24Om8cpu8smjZd43R4IjHFeD3wh2RK/5BM7kbIpRPBkqEkrPbQfM0u2ufn0bVwFWevf4cLKs51JI8W5Jr9yPXFs8hXwALfFjY6/Q8RcQEVZI2IMQGSkq5miudv5Jd+ytTQKXy6y8/w5CRWaFaZiDQC5YmJfHXRuUw1Aa7O+Z6ZRWfw4Oe38NaBw+l00Dt4PJG/5ReRuuNNtAQOCbLlkCS20IlsOlFacCrfvTqP7oFUegeL6G3XMax8CZ7yiqNb62kVvh4tRK53Cws8fnboi2SJMSrIGhljIDHxPr42lzOk5Es+tsfxiX875yUnMlezykSkkVjYujVjj2nGJYuW8/eN93Pyyh5cs+k+Evp+SpMm650OT0TCEtJLWJQ4n0XAK4C1HpKDfTm4rA29gvH0CBbQl1WcGfoBwmdUriKDHJNOrqeMHE8+izwh/CrSpBHTHnojlZDwAqs8+Qwo+oJPOIl3itYyKimRD+LinA5NRKRW+OPieKrPoXzbpiV/yl3KrF1ncPfsv/N+1x7sf9BHGFP59TIi4gxjQhT7VpLtW0k2FdeQWZtKevCP9Axl0dt66GO3MtAu4dzgBghCEA/LaF0xH827ixyzgyUegyYTSmOhgqwRi4v7gJ9TfmagfxofcA6vFOdyk7W8oAHSItKIzM/KYvkxzRm1cBn3593Bqcv6cd2mO0nr+yFpaZudDk9EojBmFzt93/A58DlQ0aujHa2CZ9Ir1IJeoSB92Mgwm8vIwM8AlOFjMS3J9fjIMdvJ8ZSxzBgCOpImDZAKskbO55tHScp5HON/nTcYy6Mln5AVCnFfQoLa0YpIo1GYkMBjh/fg2w2tuGLhEmYVDOfvM+9mxsE96HTAJxijbmwiDUXF7slPbPX9xDRgGmCtDxs6hP1Cp9A7lEYfW0xv1jAilM0V+CEIxcSxkGZke0Lkmh3kemClMVjt74jLqSCLAV7vSkKppzHc/wZP2yxuKnuJTGu5PjFR3ySJSKPyVds2fN+yBVcuWMb4LX/liyWDuGHjbTTv+y4pKVuiP4GIuJIxAYx3IXnehXwIfAiEQk2xoYF0DnWhVyiBPuykL4u5NLSAaymHIOwkgQWkkeMpJddTTI7Hw48VT+jsP0hkD1ELMmPMi8DJwBZr7SHhZc2BiUBHYC1wtrV2e92FWX+izeOJNPMi2rqR7o+2bqRZPgC33nprpfeNHz8e2EZ8/Aiu3vkiGwPtuLP8HjKBUU2asKO8POJzi7hVrOWn6qrJnLGaijTTKy7KNa1ZWVmV3nfOOedEXPde8wpHb2zK6O+zmb19BH+dfj+f/+EPtG3/KUlJkfNppFlNmlEmVVHbuamqf3c1+fuMNtMrISGh0vuaNGkScd2K/ZC9izb/rKysrNL7ioqKfvN7uW3Oe1t78vS6v+BdWUr6qrUcXPQjvcllTGghCaGKmYU7vCmsapLBZ4WbyPWEyPF42Py7bRcpD4BmoEntqso792Vg2O+W3QLMtNZ2AWaGfxeX83gKaZJ+Pg8mHMqV/JujywNMKSigRZSkI+JiL6P8JHtjDJ+1bcOYIUewtFk6/7JjeWzp+2yeN4aiohZORyeN38soN9U7Y6BVq+307LOCw85fy5YT5zPjjJ3cctQxDDjkKU5s/QJ/jnuIt4PnErc9jRsD5UwsK2N1SQmrimBiiZe/lpVzXDBICxVcUo+iHiGz1s4xxnT83eLTgKPCtycAs4G/1mJcUkeMKSc19Wpe9fydvOKpvBk4m2n+YoanJLFW3/xKA6P8JNH8kpTEnYd3Z9hPzbl82ZfM2f4tN874B7mHldG+w+c6a0nqhHKTe3i9ZbRsuZKWLVdCV9gM/FjSlJe2ncfieQEODTWlt/XThyX0Dc3nxNAKPIGKYmwtSeR4LLmeADnGsMDjYaeShtSB6l5DlmGt/bV1VR6QUUvxSD0wxpKScg8zPVcw1D+T9+1JTPPv4qzkJBZpgLQ0fMpP8lvG8En79ixo2ZI/L1zBcwVX8+GCE7l9w9Xs12cyiYk7nI5QYoNyk0skJu5gv/2yWZjwEQuBBdbDc7YrodBRJAeupUcoid5spS/Z9AllMzy0Zve6K0kkxxMg21hyPR4WGkOxijSpoRo39bDWWhOhfZUxZjQwGqBZs2Y1fTmpRUlJz7HEs4VBhXP4xJ7Ah/58LkpOZJYGSEsjESk/7ZmbWrVqVa9xiTPyk5P5W/8enLFxMxcsmcFnP3/D9dMeZnnPbbRt943T4UkM2Zd9pxYtdIptXTMmhDFL8XiWUuaDb4FvgsmEQr2w9nyaBrvSy3rowxr6Mp/BofmcxyYIBglgWGriyDEBcjweco1hsTGUq0iTfVDdPe98Y0yWtXazMSYLqLR1lbX2WeBZgPbt2+uEXJdJSHiX9cFN9C+ayccMZ1LRcq5OTOAtzSqThqtK+WnP3NSlSxflphhhjeGjAzqzIKMVY+Yv5pWCUbydPZx7NlxGu16TSEgodDpEabyqte/UqVMn5ScHGLMLr3cOMIddPvjcwue0JxTqSyh0MxnBTvSmlD4spq+dzyl2HpeGKnq0lGJYbDzkhI+iZRvDcmMIqkiTSlS3IHsPuBgYF/7vu7UWkdQ7n+8rdqZcypH+yUzhSp4r+YJMa3kiPl5tYaUhUn6SqDanpXHHH/tzysrVnLfsXYbkzeHaaeNZ32cjWVnznQ5PGiflpgasYndoPV7verzeyfzis3xqfXxiD8XafoSCF9DB7kdvfqEP2fS133KuzebK0C4A/HhYaCDXY8gxhmxj+EEz0iSsKm3v36DiItSWxpgNwJ1UJJO3jDGXA+uAs+sySKl7Xu8ygqnDOcn/X16yD3Bv6SSyrOW2hAQlC3Et5SepiZAxvHtQFxZkZXD1t4uZWHgxr829gH+0uYQOPd4iPr4o+pOI7IVyU2wwJoAxC4AFeL3/YROw0TbjXduHUGgoNngzB9CcPqwOF2lzuTy4gGuzq9lBAAAgAElEQVQpBWAHhgUGcjwecowhx+NhfcUTO/ivEieY+pyj0L59e3vTTTfV2+vVt7rcltGeO9K8jPIoc8Zef/313bcDgTTWr32Uu4ve5AYeY4rPx5VJSZQpOcSkgoKC3beNMTnW2j4OhlNnunTpYh977DGnw2iQapL3arJutBlBgUCg0vs2bdr0P8s8wSC9PplOv+nTyLcZXB33CD/3WU7r1gt/+7gadKPVDLPa8/bbb+++3ZhzE1ScsnjPPffUynM5NTurrvJEtOetyb5TtPlopaWlld63bdu2PWKAbduas2FDWzZubEvehgzSN/9CXxbSl/n04Wu6s5R4KnLWFgy5HkNuuEDL8XjIr+I+mGajuUNJScnu21XNT+reIL/h8xXSsfMY7vnpPjYWtOGRwF9oWVTEBcnJavUqIo1WyOsl+6RhrDvsYA5/+iXeLTqP57+5nMfbjaTDoW8RF1cS/UlERH7HGGjRYhstWmyje/fvAHjppTf5P/buOzyO8trj+PfdplVzwb1iYwO2DK6SKbZEMCWUm1ATQidASCgXQkguJCGB9FBCEm5yScilJuESegmY2FjuuMkVN9x7xdhWl3Z33vuH1sRga1dtNSPt7/M8eiztaHaPR97jOZp5z5lYO4w3akZRU/MLbHUeec4nFLCAAuaR78zmHNbjjxeF24BF8eLsUPv9T3RO1q6oIJMj+Hy19O9/L8/t+B679v2NZ2I3MLGiksuzMo+YZC8i0p7s7deP/5pwGlesWsvX1z/DOVsnc9ue3/Bx/hK6dl3udngi0g74fDWEw4sIhxd9+tjuaDderRnJXz4ZhrU3EHaGMpJ18SJtFvnOXL7sbP/0+zeYw66ixYs0tSRqu1SQyVEZY+nd+2FeLf8yu2sm8rrz5boB0llh1mhWmYi0Y1G/n7+fNIQFvbtzR8kK3qn6Cn+YfTt/GnA1x538KoFArdshikg7EwjsJRCYTFnZXwGIWR8ldijznQKsvRDHeZAOtjejD93qaKdSYBdyufMxAA6wxtQ1DDm0Hm2pMVTrSlqboIJM6mUMZGQ8zge+nRRVTWOivYB/Vezniqww8zWrTETauTXHHMN3J5zGVSvXcNvG/+G8Te/xrV2/ITJ2Dl26rHE7PBFpx+pmo63A51sBPAtAtc1lljOambYAx7kdxymgK/66hiF8QL6dygS7jKspi89IgxXxAu1Q+/3lxhBVkeY5OquWpILBl1lj9nJ65RTe4xLeqtzEjZlh3g0G3Q5NRCSlagMBnh2ex/ze3bm9ZAWTqi/hsRnf5tlBX2XQsNfw++tvHiIi0pKMKcPvnw5MB+oahpTRnylOAZOdsTjOI1g7kt58Em8YMo2xdjoX2Y+40akCoBpYdthVtIXG8JExOCrSXKWCTBokEJjGnuzbGV/xFm9zA3+rWsg91vKMBkiLSBpY2bUr95w9juuWf8R3N/+WC9YP5badD2HGTqdz5w1uhyciaejzs9GstVgbZK89mXdsAW87p2Dt7Vg7mOPYQD7zKeBf5Nu5XGM3cKtT14W7HFhiDCU+H4vif2749wtIK1BB1oJMkn+4zWlHmuy5E7VTDia5knXNNdfUu23x4sWf+bq8/EkumvoiT5Xfye+qJ9LLcfhlRobetCJpqjl5L9m+iSRrIZ8o7/Xr1y/hvl/9av3jof7nhReY0+MY7li8mvcrL+Ghaf/FC4Mv5tjjX8XnixFK8EuqZK361RZfjsYY85n3SirPJVIl0esm+/s0J+Zkz+1PsCY+kGRpRkZGRr3bcnNzE+57//3317utOSM9qqqqPvfILuBtKirCbNnSk6VLOzJ393+xe/ex1NZkciIfcZp/NuMzp5NXMYNvxraTGW+/vx9Y7Pez2O9nkc/HAmvZCk0631M7/uRUkEmj5OR8zLhzH+am6Y/wi309ubf2GXpZy7fDYWIqykQkDSzu1o07z+zETcvX8MMdv+LCdSO4fefPCIx5jy5ddrodnojIZ2RnVzN06CbC4Y0AWGs4cKAbu3cPoGT3Cfxz17nsLe9FABjGCgp4j7GmmDHOMu6M7SFIXUG1m3j7/fjtjot8Pvbo3K9FqCCTRsvIKKdowsM8MPsOduzow48iP6e7Y/l6ViaVemOKSBqoCAZ5fNQw5vbuym1LVjO14jJ+OvN+3h5awHEn/BNjEv+WW0TELcZYOnfeQ+fOexgyZD4Azz77D2KxEax28lkRK+Cp2FVY258MqhnOQsbyFvlmJgXOKr7IAXzxGWlb4dMB1ofa7x/QuWCjqSCTJgkEIowv/B0/e20C2yNP8MfYbbxVUcVXs8J8ottuRCRNzO/Rg1VnduaWZR/x890P8OWVBdy57UFyx75Dbq6ulolI22BMNYHAPGDep485Tg9isXyWOvksjF6A4/wIyCGbckYxjbHmLfKZS76zgYudik/3W3dYZ8eFPh+LgQoVaQmpIJMm8/ks4fB3eNb3XXbVvMb/OVfUzSrLzmSzijIRSRNloRC/yT+ZuTu6cuuHK5hWein3T/kJ7w8bycDB72GM1k+ISNvj8+3G53sHeAefL4K1PqwdSo0zljm2gNnOXVj7J8BHJ/aTz5sUmHcpYBGnOVu5wqmb2RgDVscHWR9qHLLMGGpUpH1KBZk0S92sskf5l7mKs6sn8bb9MpMqKvhKVphlGiAtImlkdu9erOnZg28sXMGje+5j1vJxfGf7D+hc8BbZ2XvcDk9EpFk+OxvtGQCszcVxxlBuCyh2Cnjf+W+gBwDd2UQBrzDWTCaf5XzR2cW1Tl3TkAiw/HMz0lam8Yw0FWTSIkKhF1hs9jC+agrv2Yt4p2IX12aFmaYB0iKSRg6Gwzx6+miKtnTjpqWLmLr/K9w3+efMHn4yxw6cooa0ItKu1M1GmwZMA+pmo1nbH2vHss8Zy7vOeN6xdwBhwNKPEsaaVylgBvl8xOXOfm6OF2lVwNJDDUOMocQY1hiDTYPEqbNlaTHB4Pts8e3j9Ip3eZereLlyFbdmhnlFA6RFJJ0Yw4xj+7O8eze+WbKc//74O0xZOoH/2vYduhe8QWbmPrcjFBFJCWPAmC3UzUd7BQDHCWDtcKwtYLszltfszbxqf133/UQYzHsUmLcpYC5j2MD1sQpujz9fGbD4sFsdF/p8bDz0Qu1IqxdkLTVLoy1K5SyNRM/dnHk9o0ePTrhv9+7dj3jswIG3+NLrb/Jc6Y08VTWTno7DHxLM6xCR9itVea85z5to9hBAVlZWvdtuuOGGhPtu3rz5M1/POOssPpk3j6I33mHqviv57qRfUzK8hn79p7fo+YRmmKUPt2aJJeLV2WipPO9qjua8XxOds4XD4YT7durUqd5tI0aMSLhvovlotbW1CfctKys77KvNwGYqKzPZurUX06dXs690KC+VPsoL0Q4ABH2ljMn+F6cH32fwgSnk263cHqvl0JnkPv7dfv9Q45AdR/lZt6U6Q1fIpMV16rSPL17xLBf876951v6WX9S8Qi9ruT8jIy0uO4uIfMoYlp96KltOOIH8J57lyf23886SC/jh9lvpOfoVwuEDbkcoItLqsrKqOPHEDWzZMhmom41WVdWX0tIhlJYOZfnBEczbfwnW1pUqIdYy3PcaBUxhDB+Sb/fwXSdGIN5+fyd8OhvtUKG2162/XBOoIJOUyMoqJ5BzGddUPs3OWG/uqn2cno7DrZmZ1KooE5E0U3rMMfy0MJ/zNm7iuuXvU7x3Dne//zArR35Cn74fuB2eiIirjLFkZW0lK2srPXvWFWmxWIi5c2txnLHEbAELnSspsffG96glkwWM9r1JPjPIZzX5tpQLolEOXX/cDJ/ORztUqJV69BxUBZmkjDGVhLOu5ntVv2N79CEejt5L18oqrsnKpMyjbwgRkVSxxjDxuIEs6d6NOxYs57nSb/Dawkt4cNtN9Bn1EpmZFcmfREQkTfj9tfj9c/H75376mLU9cZwCHKeAGqeA2c6PmU1OfOvHdDTTGWP+SQHzGMMG8p0aLgWIX0lbc6j9fnw92lJjqPTAOakKMkkpY2KEM/+T39d8n521z/N07Ou8W1HF5VlhdmvNg4ikoZ05OfzoC6fwpbXruXr12xTunsl/vv8om/N30KvXArfDExHxLGN24fe/jd//NtZarPVj7VAcpwBrx1LqFFDsXEJx/DqZMR/RhWIKzETyWUy+3cl4J8bXAGIxYsDKw2akLTSG5ca0+t1cKsgk5YyBcPhXvOK7nt3Vb/OacxmTK6q5NCuDdZpVJiJpyDGGN08YzKKe3bljwQpeLL+Bv8+9il/3vp5jR71MKFTpdogiIp5nTAxjluPzLefzs9EOFWkfO5cy0d7KRAAqMWYxvc375FNMAR8yxh7kAsfh+njjkhrgw3iRtjA+I221McRSWKSpIJNWEwo9xyyzmzOqJvOuvYjJFQf4alYGCzSrTETS1NYOHfjBmadw6Zr1fPWjf3Dmjqncvvc37C5YS48eS9wOT0SkzTk0G83nmwrUzUaDYz8t0ByngO3OvWznAd4EYAc+M59jzfuMNTPJt2sYY2u4wnG4JV6kVfDvGWkL47c8rm/BGWmungl7tR2pFyU7VqlqDx1IUiz169ev3m233377UR/fvn0ZE/4xlTdqLuKtys18PTOD9zSrTEQ+J1Huas4okGQStaRO1HIaYODAgfVu69GjR73bLHDPn//MnYtW83rlVTz1wY38tu9V9B32DwKBKkKhUMLXTdSSWi3xJdXcasWfynNBt9rxpzK3JdKcY5ksP2VnZ9e77Zprrkm471VXXVXvtmg0mnDfmpqaozxqgfns2PEuu3f3ZMeOfvGP8WzcfzEbgZeMg9+/iqC/hCGBYgqYx2hnKyOjEW6KRPjP+DMdABYfNh9toTFsaeLPR5cmpNX16bOV8PWTGf/ky7zNN3mhaiHftpbnk7yhRUTasw0dO/Ldony+tmYDN2x4lnO2TebWPY+yb/RievX6yO3wRETaDb8/Ru/e2+ndeztQ1zSksjKLHTv6smNHPxYs8FFdexGLa65nMXVX3QKBxYQzF3B8ZCL5LGKMLWWM4/CfjkMo3jRkL8D550NBAeTnNzgeFWTiii5dPqYy52ucXfE8L9qf8t/V79HLWh4Khdrd9HURkYaK+v38bejxzO/ZlbsWread6iv449zb+PPAKxlw0qsEAokHsIqISNNkZVUyePAaBg9ew9q1T2GtIRY7jkhkDNHoaCKR0ZRV3cUi7mERYMwmjJlP2DeHEWY6Y1hFvo1w/fbtMGkSJLhz4fNUkIlrfL492JzLubTiaZ5wevKDmmfp5TjcEw6ndOGkiIjXrencmbu/MJZrVq3j1s1PcN7G97ht1yMcLJhPly5r3A5PRKTdM8YSCKwnEFgPvASAtZkcPDgo3np/LI5zGpV8lTnAHGoxZhklZ+Rz+p0VFOYshisLG/RaKsjEVcaUE8q+mm9WPc72aB/uj/yC7hZuygxTpaJMRNJYrd/P0yedyLxeXblr8WomVl3O72bcyTODvsJxw17H70+8fkJERFqWMVX4fB/g833w6WPW9vp0Npq1BTzzDPyhIhsY3+Dn1UpfcZ0xEcKZt/KzUGdu44+cH43yZkU1nRtxqVdEpL1a0aUL3z23kPeOHcx3+D0vr/8JZe9fzf79x7kdmohI2jNmJ37/WwSDPyIUOo+DB2HpUnjyyYY/hwoy8YS6WWU/5ZnwBi7nJUY4hkkV1fRXUSYiQnUgwP+OPomfjBtH59BOJldeyrnTAqxbcSmOo3mOIiJe4ffD8OHwjW80fB8VZOIpodBfeC/zDc7hHbrZLCZVVHNSvHONiEi6W9q9O/ecW0Rx34F8n4f425qH2Tfleg4e7O92aCIi0kTNWkNmjNkElAExIGqtbXh/x2ZqzgyH9sitmRZ+f/2/me3SpUvCfe++++56tz3yyCOMr5zIe/YrvFuxm2uyMpihAdLSCG7mJ0m9VM6xTNXsxpycnIT7Xn/99fVuW7t27We+XnDaaexfvZpzXn6b4vJL+NnUH/LmkBEMOP6f+HyfvbMg0YyyZDTDrOUpN7Uct+afJdOc81C3/k5uzbtNdqwSnWcmm5UbDofr3dahQ4eE+/7yl7+sd1tzcmp9WiLTnmmtHamEIi0pEJjL5uxvczqvs5UTeLWyissiEbfDkrZH+UnarXVDhvDsPbezMm84P7U/4alVf2TPtBspL+/tdmiSnHKTiHxKv/oSz/L7P+JAznWcYf7CXMbxdFUVtx116rqISHqqysrinasv46GCAgYFVjO19DJGTenLxnUXYK03rx6IiMhnNbcgs8AkY8xCY8wtLRGQyOF8vp1Ecr7G+b4f8wqX8auaGn5WVY1Jw9tSpdGUnyRtzO3Th7vPKWJhjx48bH/AH5c/y47pN1FR0d3t0ORIyk0i8hnNLcjGW2tHA+cDtxtjij7/DcaYW4wxJcaYkvLy8ma+nKQjY0rxZ1/F1f6v8Adu585ILU9WVRNUUSaJJcxPh+emgwcPuhOhSAs6mJHBo6eO4rHRYzjZv5hpB77CkPdPZNOGs1G69JRGnTuVlpa2foQi0qqaVZBZa7fH/9wDvA6MPcr3PGmtzbfW5idb0CxSH2Nqycj6JvcET+D7/JKvRiO8VFlNrs4ypB7J8tPhualjx45uhCjS8oxhZv9+3H12ESu6dOFxew+PLn2FrTNvorIycaMlaR2NPXdK1nxARNq+JhdkxphsY0zuoc+Bc4HlLRWYyOcZYwln/ojfZpRyPc9SFHN4p6Ka7ppVJp+j/CTp7pPMTH45fgx/GDmSU3wfMHXf1zj2/ZFs3nSGrpa5SLlJRI6mOX3EewCvx1tdBoAXrLXvtUhUzdSc1p3tkVutTBO1KoXELUe/973vJdz3l7+cxu6q13nFuYLJFTVcmhVifZLXk7Ti2fwk7nMrJyZrIR8KherdNmTIkIT79u9f/xyyO595hjsWreLPB+7g3cXn84Ott9Jt5EuEwwcACAaD9e6brL2z2uI3mnJTGlA7/tZ53lSez7d2bmtyQWat3QCMaMFYRBosGHyNmWYvZ1a+wzv2K0yuOMhXskIs1KwyQflJ5HB7srJ4YNxoLti4metXTWHqx3O4e+rDfDh8H737zHY7vLSi3CQiR6NfbUmbFQjMZFX2DxjHmxygL/+srOaLmlUmInIEawzvHDeAu844ne0dMng2dgv3L57H5vk3U1OT63Z4IiJpTQWZtGl+/0p25dzCePM8KxnJC1XVXFtb63ZYIiKetDMnhx8W5vPUkDwuMO8wZc/NdJg0gR07CtwOTUQkbakgkzbP59tGRc61nOX7Ne9zLn+oruZ7NTVo5bqIyJEcY3hj8HHcXXQ6+3J8/F/0Bu6at4x1866jtjbL7fBERNKOCjJpF4zZj82+mkv83+A5ruP+mhoeq67Bp6JMROSotubmcl9RPn8fMozLeZl/7biV0KQL2L17pNuhiYikFRVk0m4YU0Mw62a+ETiNX3EfN0Vq+WtVDWEVZSIiRxXz+Xh16Ance2YRldkxXotczc0fbGTdwmuJRMJuhycikhZUkEm7YoxDOPNefpIR5A7+mwuiEd6sqKGzijIRkXpt6tSJ7591Gi8fP5TreJ5/brkLJl/M3r3D3A5NRKTdS8se4YlmHqTbjDJo3vFI1UyerKzE6xjuu+++erc99NBDhMOP87TvCnZVvcDfnet4r6KGy7Mz2ObzpeXPWEQaLlVzcVI51zEnJ6febdddd13CfZctW/bvz4cPZ9/27Xz5tYm8ffAKnpj1Lf5nwJUMOOkVAoEjGyYlm1OWiGaYibQut+ajpeq8K5V/n9auFZQNpd0Khf7BxKwXOZc36emEmVReTV4s5nZYIiKetr1PH/7yreuZkX8a3+TPvLnpXiLvf5VPPjnR7dBERNolFWTSrgWD01iU8yuKeBPHdmVieTXjo1G3wxIR8bRoMMjk887i/vHjyAgf4N3qr3DxjCrWffhVYrG0vLlGRCRlVJBJu+f3L2NT7l2MMy+yjeN5rbKaSzRAWkQkqVVdu3LP2eN499jB3M3jvLz+J5RPuYYDB45zOzQRkXZDBZmkBZ9vM/tzbuALvt8zn9N5uqqKb9bUuB2WiIjn1QQCPDVqGA+cfjqdQruYXHkp504Lsm7FpThO4rVtIiKSnAoySRs+3yfU5lzHBf7v8AaX8HBNDQ9WV2PU5ENEJKll3btzzznjmdJ3IN/nIf6+9hE+mXItpaX93Q5NRKRNU0EmacWYKkzWTVwV+A/+yG3cXVvLn6pqCKooExFJqjIY5In8k/n5qafSO7iJKeWXMa64Ixs++hLW6pRCRKQptDL3c5K10Ey3lunNOR6pbPEcDtc/sDRRS3yARx55hEDge3yv6jvsqP45v4jeT/cqH1/PzeSAujCKSDOkaoxIc3JxKBRKuO+oUaPq3XbCCSfUu21KeTndfvowP9n1U760cgx3bnuA8Jh3yMnZAUAgkPgUI1HLfLXEF2k/3Gq3n0hzzudT8fdRxpO0ZAxkZj3G77N383X+QlE0wpullXRrxkwdEZF0UpuTw+8KTuZXY8YwKLCaqaWXUzCtP5vWX4i13jsBExHxKhVkktYyMv7OKzmT+TIvcXzMx6SKWo7TVTIRkQab07s3d04Yx/zuPXnI/pA/rXyOPbNupqKiu9uhiYi0CSrIJO2FQu8zu8MTTOANcm0ukypqGa2iTESkwQ5mZPDI2OE8OnIUJ/mXMPXAFQydfDybNpxNmt3pLyLSaCrIRIBAYBEfdfwB43iJMvrwz4pqztasMhGRhjOGGf36cueE8XzYpQu/s9/lN0tfZuvMm6ms7OJ2dCIinqWCTCTO79/IzpxvMM48yWpG8I+qaq6qrXU7LBGRNuWTcJhfnDaSP4wcRYFvLlP3XcHAycPZvOkMXS0TETkKFWQih/H5PqYi53rO8v2YYs7miepq7qmuQWcRIiKNYAzFAwdwzzlnsO6Yjjzh3MkvFk9k8+wbqa7u5HZ0IiKeooJM5HOMqcDJvpFLAlfxN67mx7U1PFpdi09FmYhIo+zNyuLnRQU8OXwkRWYqxXuvoeekU9i29XS3QxMR8QzNIWuk5syYaY9SNXMnmUQzajIyMhLue++999a77S9/+cunn1v7C+7adyc7DvTmvyKP0D+YwXV+S7UH52mIiPc1J+elMp8mmvuYm5ubcN9rr7223m1z5sz59PPVAwfyuzGjuPydYp7e8y3eKLmIB7fdSO9Rr5CRUXbEvolmlImINJfXZqPpCplIPYyBY7o+zqPdwtzFY5xTWcYbFbV0TsPCW0SkuT7u1Ik/X3kxbxSewfnmXd7fdSOdJk9g584Ct0MTEXGVCjKRJDp2/D9e6vkRV/I8ox2H98pr6avf3oqINJr1+ZiRP5rfXnslH+cGeCH6db49bxnr519PbW2W2+GJiLhCBZlIA+TkTGF2n7c4n5fpZUNMqqglT7PKRESaZE+XLvzwzFP425BhXMorTNrxLTInn8/u3SPdDk1EpNWpIBNpoMzMxczP/hlFvISxxzCxopZx0ajbYYmItEmOz8erQ47n3jOLKM92eCVyLbfM2cj6hdcQiYTdDk9EpNWoIBNpBL9/LRty7mSceYadHMfrldVcrAHSIiJNtqljR75/1mn84/ihXMNfeWfrtzGTL2Lv3mFuhyYi0ipUkIk0ks+3m305N3OG79eUcCrPVFVzS40GSIuINFXU5+PFYSfy/TMKiWVW8VbN17h61l7WL/ka0WjI7fBERFKqWW3vjTHnAb8H/MD/Wmt/3SJRtVHJWmimW1v8VB6PRM+dqCU+QDAYrHfbLbfcknDfw9s4O84L3FDyAI9s/x8eqXmTXtbyk4xQXXtGcZ3yk7QnzcmnyfZtzviSUKj+Ymn8+PEJ9x058ujrxWZdU0vJLx/hlo1Pcu7GSdy282E+GTOfY45ZnfD52grlJhH5vCZfITPG+IE/AucDecCVxpi8lgpMxOt8vignFfyZ7w++hj/xTb5TW8OfqiIE0qzw9iLlJ5G2ywmFeP6kE/n+6acRyjjAe9Vf4fLZNWxccQWxWNsen6rcJCJH05xbFscC66y1G6y1tcCLwEUtE5ZI22CMZejJL/DEyWP4ET/hymg1L1VGyFFR5jblJ5E2blWXLtw94VTe6j+Yb/M4r2z4KdXTruXAgUFuh9Ycyk0icoTmFGR9gK2Hfb0t/phI2hk0eCK/yVzHTTzBGbEIb1dE6KZZZW5SfhJpB2oCAf53xFDuP/VUOoR2M6nyci6cGeRn99fQRvspKTeJyBFMU9fxGGMuB86z1t4c//pa4BRr7R2f+75bgEMLc04Cljc93JToCnzsdhBH4cW4vBgTeDMuL8YEzYvrWGttt5YMJlUakp/aQG4Cb/478mJM4M24vBgTeDMu5abPfp/X85MX/w2BN+PyYkzgzbi8GBO0Qn5qzs3Y24F+h33dN/7YZ1hrnwSeBDDGlFhr85vxmi3OizGBN+PyYkzgzbi8GBN4N64USJqfvJ6bwJtxeTEm8GZcXowJvBmXF2NKEZ07pZAX4/JiTODNuLwYE7ROXM25ZXEBcLwxZqAxJgR8DXirZcISEWkW5ScR8SLlJhE5QpOvkFlro8aYO4B/Ude69Wlr7YoWi0xEpImUn0TEi5SbRORomtU/1lr7LvBuI3Z5sjmvlyJejAm8GZcXYwJvxuXFmMC7cbW4RuYnrx4XL8blxZjAm3F5MSbwZlxejCkldO6UUl6My4sxgTfj8mJM0ApxNbmph4iIiIiIiDRPc9aQiYiIiIiISDO0SkFmjDnPGPORMWadMea+1njNhjDGbDLGfGiMWWKMKXExjqeNMXuMMcsPe+wYY8xkY8za+J+dPRDTg8aY7fHjtcQYc0Erx9TPGDPVGLPSGLPCGHNX/HG3j1V9cbl2vIwxYWPMfGPM0nhMP4k/PtAYMy/+XvxHfFF5WvNiflJualJcyk8Nj8ntY6X81ABezE2g/NSEmNx+vyLjk2sAACAASURBVHkuNyWJKz3Pnay1Kf2gbtHqeuA4IAQsBfJS/boNjG0T0NUDcRQBo4Hlhz32MHBf/PP7gIc8ENODwHddPE69gNHxz3OBNUCeB45VfXG5drwAA+TEPw8C84BTgZeAr8Uf/xNwq1s/Ty98eDU/KTc1KS7lp4bH5PaxUn5Kfow8mZvisSk/NS4mt99vnstNSeJKy3On1rhCNhZYZ63dYK2tBV4ELmqF120zrLUzgE8+9/BFwHPxz58DLvZATK6y1u601i6Kf14GrAL64P6xqi8u19g65fEvg/EPC0wAXok/3urHyoOUnxLwYm4C5acWiMlVyk8NotyUhBfzk3JTi8TlGjdzU2sUZH2ArYd9vQ0P/IcQZ4FJxpiFxphb3A7mc3pYa3fGP98F9HAzmMPcYYxZFr8s3+q3Kh1ijBkAjKLutxeeOVafiwtcPF7GGL8xZgmwB5hM3W9bD1hro/Fv8dJ70S1ezU/KTU2j/NSwmMDlY6X8lJRXcxMoPzWFclMCXspPbuWmdG/qMd5aOxo4H7jdGFPkdkBHY+uukXqhHeYTwCBgJLAT+I0bQRhjcoBXgW9ba0sP3+bmsTpKXK4eL2ttzFo7EuhL3W9bh7Tm60uzKDc1nvJTw2Ny/VgpP7Vpyk+N4/r7DbyZm+qJKy3PnVqjINsO9Dvs677xx1xnrd0e/3MP8Dp1B94rdhtjegHE/9zjcjxYa3fH/6E6wF9w4XgZY4LUvXH/bq19Lf6w68fqaHF54XjF4zgATAVOAzoZYw7NH/TMe9FFnsxPyk2N54X3mxfzk5dzUzwW5aej82RuAuWnxvLC+82Luam+uLxwvOJxtGpuao2CbAFwfLxDSQj4GvBWK7xuQsaYbGNM7qHPgXOB5Yn3alVvAdfHP78eeNPFWIBP37CHXEIrHy9jjAGeAlZZax87bJOrx6q+uNw8XsaYbsaYTvHPM4FzqLs/eypwefzbPPHvymWey0/KTU2j/NTwmDxwrJSfkvNcbgLlp6bwwPvNc7kpUVxpe+6UrOtHS3wAF1DXPWU98MPWeM0GxHQcdV2LlgIr3IwL+D/qLstGqLs39SagCzAFWAu8DxzjgZj+CnwILKPujdyrlWMaT90l9WXAkvjHBR44VvXF5drxAoYDi+OvvRz4cfzx44D5wDrgZSCjNY+VFz+8lp+Um5ocl/JTw2Ny+1gpPzXsOHkqNx32M1J+alxMbr/fPJebksSVludOJv5CIiIiIiIi0srSvamHiIiIiIiIa1SQiYiIiIiIuEQFmYiIiIiIiEtUkImIiIiIiLhEBZmIiIiIiIhLVJCJiIiIiIi4RAWZiIiIiIiIS1SQiYiIiIiIuEQFmYiIiIiIiEtUkImIiIiIiLhEBZmIiIiIiIhLVJCJiIiIiIi4RAWZiIiIiIiIS1SQiYiIiIiIuEQFmYiIiIiIiEtUkImIiIiIiLhEBZmIiIiIiIhLVJCJiIiIiIi4RAWZiIiIiIiIS1SQiYiIiIiIuEQFmYiIiIiIiEtUkImIiIiIiLhEBZmIiIiIiIhLVJCJiIiIiIi4RAWZiIiIiIiIS1SQiYiIiIiIuEQFmYiIiIiIiEtUkImIiIiIiLhEBZmIiIiIiIhLVJCJiIiIiIi4RAWZiIiIiIiIS1SQiYiIiIiIuCTQmi/WtWtXO2DAgNZ8SWmktWuhe/lGOvpKYcQIt8MRD1m4cOHH1tpubseRCspNIm1Xe85NoPwkaWzTJjh4kOX+EYTDMHiw2wE1XkPzU6sWZAMGDKCkpKQ1X1Ia6bHHYMU9T/GUczM8/zzk5bkdkniEMWaz2zGkinKTSNvVnnMTKD9JGhs2jNoxp5Ix6Z888AB8//tuB9R4Dc1PumVRPuPss6GYCXVfTJnibjAiIiIikn5KS2HVKjb3OAWAU05xOZ4Ua9UrZJWVlSxcuLA1X7LFWWtded5k2x3HqXdbdXV1wn0vu+yyw17HcMCsYqPtzsp77uG6Bx9MuK+0b/v27XM7hFaxdetW7rzzTrfDEJEGevzxx90OodUcPHiQiRMnuh1GyqTqvEqOlOhcsTmS/QxjsVi925YtW3bUxwds2MB11vLge/sBhx/+8DwCgarPfI/P583rStOnT2/0Pt78m4hrjLEEgzMo5mzGRaP4lChFREREpBX12bYNgA9qzyMra+MRxVh7o4JMjhAIzGAKF9LJWoYn+K2GiIiIiEhL67N9Ox936cK2ilPJzV3pdjgpp4JMjhAMTv90HVlhJOJyNCIiIiKSNqylz7ZtbOh6HNFoBxVkkp78/q3s9VWxkv4URqNuhyMiIiIiaaJDaSm55eUszRgJQG7uCpcjSj0VZHJUweB0pnAep0YiBLWOTERERERawaH1Y7Mi4/D7K8nKateTLQAVZFKPunVk55MNjNFVMhERERFpBX22byfq9zNt/xnk5KzCmNR0h/QSFWRyVMHgTKZzBg5Gty2KiIiISKvos20bO3v0ZtuefmmxfgwaMIfMGBMGZgAZ8e9/xVr7gDFmIPAi0AVYCFxrra1NZbBeYIypd1sqZ2kket1k2wOBxD/mbt26HfXxTVU7WVxzAoWR9TySmZk8SJFWpvwkIl6k3PRZmjWW3hL9/D8/Y89vLd/bupVXOuXhOP60WD8GDbtCVgNMsNaOAEYC5xljTgUeAn5rrR0M7AduSl2Y4oasrDm8z39QEI2SpWQq3qT8JCJepNwk0gQDKivJdBwWmFEAaXOFLGlBZuuUx78Mxj8sMAF4Jf74c8DFKYlQXJOdPYdiziEEjNVti+JByk8i4kXKTSJNM6y87m3zQfQcMjJ2EArtdzmi1tGgNWTGGL8xZgmwB5gMrAcOWGsPnaVvA/qkJkRxS2bmQmYxllr8FGkemXiU8pOIeJFyk0jjDSsv50AgwIeVZ5OTkx63K0IDCzJrbcxaOxLoC4wFhjT0BYwxtxhjSowxJfv3p0eV2174fFXUBlYyj+EqyMSzmpqfDs9NVVVVKY1RRNJPS507lZaWpixGEa/Jq6hgeVZnaiO9VJDVx1p7AJgKnAZ0MsYc6hbRF9hezz5PWmvzrbX5nTt3blaw0vrq5pF9ieGxGB2d9t92VNquxuanw3NTpprWiEiKNPfcqUOHDq0UqYi7MmMxBlZWsjhwAgA5Octdjqj1JC3IjDHdjDGd4p9nAucAq6hLLpfHv+164M1UBSnuCQRmUMxZ+IHTtY5MPEb5SUS8SLlJpPGGlJfjB+baUzEmQnb2WrdDajVJ294DvYDnjDF+6gq4l6y1/zTGrAReNMb8HFgMPJXCONu9ZG3tm9My1udLXHf/+Mc/rnfbHXfczVyGUUmIwkiEiaFQk+MQSQHlJxHxIuUmSRvJzlFjsVi92/x+/6efn1RZCcDsyIVkZ68lGIzh8/nr27VdSVqQWWuXAaOO8vgG6u6JlnbMmCgEFzArMpai6By3wxH5DOUnEfEi5SaRxssrL2dbOMzWylPp0eOfbofTqhq1hkzSU906sv9gaCxGN60jExEREZEWlldWxrLMXjhOZtrMHztEBZkkFQjMYApnATBe3RZFREREpAV1ramhe20tJb6TAdKqwyKoIJMG8PtXs4TeHCCLIjX2EBEREZEWlBcfCD3XKSIQ2E84vMPliFqXCjJJyhjwh2YzjSIKdYVMRERERFpQXlkZEWOYU3UhubkrSdLrrt1RQSYNEgzOYAoXMNBx6JegW46IiIiISGMMLS9nTVYuB6qHpN36MVBBJg0UCEynmAkAFOq2RRERERFpAT5rGVpWxtKMAQDk5qbX+jFo2BwyaQMSzTFLNuOsa9euSZ/f79/OahNil+1MUaSCFzIyGh2jiIiIiKSXSILlLsYYBlRWkuU4zDdjAIfc3NVJz13bG10hkwYLhmZRzNmMj0ShGYOqRUREREQAhpaVATA7ci6ZmVsIBCpcjqj1qSCTBgsGp1PMufSyDsdrHpmIiIiINFNeeTllfj9LK85Ny9sVQQWZNEIgMItivgBAkbotioiIiEgz5ZWVsTy7K5HYMWnZ0ANUkEkj+Hz72eIvZyO91P5eRERERJolHIsxsKKCRYETgfRs6AEqyKSRgsEZFPNFxkejGK0jExEREZEmOqG8nAAwz56Oz1dFdvYmt0NyhQoyaZS6dWRn09laTtY8MhERERFporx4Q4+ZNReQk7MaY9Lz3FJt79NAstahGQla2H9+32BwPsX8BoCiaJRlAf0TEhEREXGb41LDNZvkjqny8vJ6tw0tL2d7RpjNVafSu/dLLR1aSqSiJb+ukEmjGFPFx4FtrOQ4rSMTERERkSbLKyvjw3BvrA2m7foxUEEmTVB32+L5nBqJEtA6MhERERFppMyDB+lZU0OJfzhA2nZYBBVk0gTB4AymcBY5WEZHo26HIyIiIiJtTLeNGwGYEzuDjIzdZGTsczki96ggk0YLBJYwg1E4GApVkImIiIhII3XfuJGoMcyu+hI5Oel7dQxUkEkTGBOjLLiKxQzTOjIRERERabTuGzeyLrMDB2sHpfX6MVBBJk1Ut47sPMZGY2RqHZmIiIiINJTj0G3TJpaEBgLpvX4MVJBJEx1aR5aBZaxuWxQRERGRBuq0ezeh6mrmm3yMiZKT85HbIblKQ6RaULK5BMnmNKTqtZPF5ff76902duzYoz5uLcwvHkqk1k9hJML0YLBhgYqIiCSRyv8vRaTxEr0nk71fp0+ffsRjhevXAzAr8kWys9fh99c2L8A2TlfIpEmMgXDX9cxjDEURXSETERERkYYZtG8flcEgiyu/mPa3K4IKMmmGLl0WM4XzGBmLkuvSdHgRERERaVsG7dvHmg69iTq5KshQQSbN0KXLEoqZgB84XevIRERERCSJYDRKv/37WZKRB6ihB6ggk2bIzNzHfNOVKkIUqf29iIiIiCQxYP9+AtYy1zmdQKCUcHir2yG5TgWZNIsNzWUW4yiMxtwORUREREQ8btDHHwMwtfI8cnNXkqT3XFpQQSbNUtf+/lyGxaJ01ToyEREREUlg0L597M3KZk3p6LQfCH2I2t63Ec1pqZ9sX5+v/rr8pptuSrjvnDnfo5hbARgfifBGRkbC7xcREQG1tm9P9LNMb06SX8hv3LjxM1/337WLRRl9AZ/Wj8UlvUJmjOlnjJlqjFlpjFlhjLkr/viDxpjtxpgl8Y8LUh+ueI3Pd5ClPj8HyaZQjT2kFSk3iYhXKT+JHF2nSIQ+NTWU+EYAkJOzyuWIvKEhV8iiwD3W2kXGmFxgoTFmcnzbb621j6YuPGkLfKHZTKs+k8LIe26HIulFuUlEvEr5SeQo8srKAJgdPZNweAvBYJnLEXlD0itk1tqd1tpF8c/LgFVAn1QHJm1HMDiDYs5mkBOlT0zNPaR1KDeJiFcpP4kc3bDycqLAB9Vf1vqxwzSqqYcxZgAwCpgXf+gOY8wyY8zTxpjO9exzizGmxBhTsn///mYFK94UCMyjmHEAFOm2RXFBc3NTVVVVK0UqIummufmptLS0lSIVSb2h5eWsz+zIwWh/cnJUkB3S4ILMGJMDvAp821pbCjwBDAJGAjuB3xxtP2vtk9bafGttfufOR8070sYZU81qfwV7OIZCzSOTVtYSuSkzM7PV4hWR9NES+alDhw6tFq9IKhlrGVpWxuLQIABdITtMgwoyY0yQuoTyd2vtawDW2t3W2pi11gH+AoxNXZjidcHQDIo5h8JIDNRtSVqJcpOIeJXyk8hn9auupkMsxgLy8flqyMpa73ZIntGQLosGeApYZa197LDHex32bZcAy1s+PGkr6taRTaC3jTFY88ikFSg3iYhXKT+JHGlovKHHrMgXyc5ejc+nvgOHNKTL4jjgWuBDY8yS+GM/AK40xowELLAJ+GZKIpSUSzSHrGPHjg16Dr9/CVN5GIDCSIR1fn+LxCaSgHKTiMs0f6peyk/SriR6r0eT9A84dJ45rKKCSp+fhZXn0bPPm/h8voTnoOkkaUFmrZ0FHG2y8LstH460VcY4bA5sZ3O0D0WRPTwTDrsdkrRzyk0i4lXKTyJHyisrY0Vmd2IVWRoI/TkqS6XFBEMzKeYcxkcdjH5rKiIiIiJAyHEYXFHBwsBQABVkn6OCTFpMMDidYiZwjI0xTPPIRERERAQYXF5O0Frm2XGEQnsJhfa4HZKnqCCTFuPzrWUqwwAoUvt7EREREaHudkWAGTVfIjd3JeZoN/SmMRVk0mKMgb2hNaxmMIURDYgWERERkbqB0HuCYTbUFOh2xaNQQSYtqq79/TmcFnUIaB2ZiIiISNrLKytjabgfoPVjR6OCTBIKhUIJP4wxn/k4NI8slxijkrRBFRERb7PWJvwQkfSQKA/U1tYm/OgYidC3upoS3wggRk7Oarf/Op6jgkxalN+/ixm+fjgYilSQiYiIiKS1IfH1Y7OjE8jO3oDfX+1yRN6jgkxaXFloGUs5mfFaRyYiIiKS1vLKynCAWVUXkZu7wu1wPEkFmbS4utsWz2ZsNEZYt7SIiIiIpK288nI2hDty0OlNbu4qt8PxJBVk0uICgdlM4QuEcRir2xZFRERE0pO1DC0rY3FoMICukNVDBZm0OJ+vlDn+jkTxU6h5ZCIiIiJpKWfPHjpGo8xnLH5/GZmZW9wOyZNUkElK1IRKmE8BhRHH7VBERERExAVd160DYGbteeTmrsIYLWU5GhVkkhLB4EymcDajYhFytY5MREREJO103bCBKp+Pkuovav5YAgG3A0gnxph6t6Vynkui10223edLXLPfcMMNR308Gg1Q/Ptx/AjLaZEIk0KhpHGKiEjL07wwkfbDcVJz51GyPJFo+969e+vd1nH1alaGexCrzGhTBVmyc+eWpitkkhKBQJQFfh/VhLSOTERERCTN+KNRum3fzsLAMAB1WExABZmkjBOaw2zGU6R6TERERCStdN2xg0AsxhxnPOHwNoLBA26H5FkqyCRlgsEZTOEsTnJq6JKiS+wiIiIi4j09N28GYGbNRW3qdkU3qCCTlPH7lzGVfADGaR6ZiIiISNrotWULZTkdWB8ZoYIsCRVkkjLGOCwJVFJKDoW1um9RREREJF302LKFtZ2HAkYFWRIqyCSlfKFZTOcLFOkCmYiIiEhayKis5Ji9e1kUGIMxNWRnr3U7JE9T2/t2ojkt9RPt6/f7E+5bVFRU77ZnnnmGYHAGxVzJl5x/0jsWZkeS5xMRkSOpdb2IuClRDnrttdeOeGzs/v0AvLV7BDk5a/H59Jv5RHSFTFLK51vPNHMSAIVaRyYiIiLS7g0tK8MBZlZdrNsVG0AFmaSUMbAqsJu9dKEwooJMREREpL3LKytjU0YnDtjuKsgaQAWZpFwgNIupTKAwAui2GxEREZH2y1ryyspYFBoMQG7uCpcD8j4VZJJydevIJtDX1nCc5pGJiIiItFu9amroFI0yj1MIBj8hI2OX2yF5ngoySTmfbzfTfccCUBhR+3sRERGR9iqvrAyAWbUXkJu7ggS94yROBZm0io2BzWylD0URXSETERERaa/yysqoNj5Kas4hN3eV2+G0CSrIpFUEQzMp5izGRx2M1pGJiIiItEtDy8pYmdmTKEGtH2ugpAWZMaafMWaqMWalMWaFMeau+OPHGGMmG2PWxv/snPpwpbUZYxJ+5OTk1PtxuEBgNsWcQVdby9BYzKW/jbQnyk3S3lhr6/1IN4mORVs4Hu0xP7Xln4c0n+M49X4c/m/BF4txQkUFJb5hgEN29ip8Pl+9H1KnIUciCtxjrc0DTgVuN8bkAfcBU6y1xwNT4l+LHJXPV8Z0X3cAijSPTFqGcpOIeJXyk6SlQZWVZDgOc50isrI2EghUuh1Sm5C0ILPW7rTWLop/XgasAvoAFwHPxb/tOeDiVAUp7cPu0GrWcDyFtfptmjSfcpOIeJXyk6SrQw09ZtRcRE6O5o81VKOuFRpjBgCjgHlAD2vtzvimXUCPFo1M2p1D7e9Pj0bw6xYHaUHKTSLiVcpPkk7yysvZF8hgfewkrR9rhAYXZMaYHOBV4NvW2tLDt9m6G4iPeoZtjLnFGFNijCnZv39/s4KVti0QWEAx4+hAlFFaRyYtpCVyU1VVVStEKiLppiXyU2lp6dG+RcSThpaVsTTjWMCQm6srZA3VoILMGBOkLqH83Vr7Wvzh3caYXvHtvYA9R9vXWvuktTbfWpvfuXObWbsqKWBMLTP92YDmkUnLaKnclJmZ2ToBi0jaaKn81KFDh9YJWKSZsqNRjq2qYoEZg89XSVbWJrdDajMa0mXRAE8Bq6y1jx226S3g+vjn1wNvtnx40t4cDC1lKcMZH9GUQGke5SYR8SrlJ0lHQ8vL8QGzomeRm7sKYzR7tqECDfieccC1wIfGmCXxx34A/Bp4yRhzE7AZ+GpqQhQ3mSTj1YPBYL3b/H7/EY9lZMyiuGoC34quIMNmUKPx7dJ0yk3iOWoB/m/NORaO0+ZP5JSfpE1J9n6NJuiQfehcMa+8HIBZ1ReR23Vi0nNI+bekBZm1dhZQ3xE9q2XDkfYuEFhOMTdzNzEKolFmJSjoRBJRbhIRr1J+knQ0tKyMjRmdOFDTlV5q6NEomsgmrcoYy5ygIYpf68hERERE2gNrySsrY1HgBAA19GgkFWTS6moySighn/GRhtwxKyIiIiJe1r2mhi6RCPM5hYyMHYRC6qzeGCrIpNWFQjOZwlmMiVWSo/UWIiIiIm3aofVjM2svJDd3lcvRtD0qyKTV+XwbmWaGEcThVN22KCIiItKm5ZWVUWN8lETO1EDoJlBBJq3OGCgJ1VBDiMKIBkSLiIiItGVDy8pYldGTCCGtH2sCFWTiilhoLh9wOkWRI1vji4iIiEjb4LeWE8vLKQmcjDERcnLWuh1Sm6OuCh6RbFZDc+a5NGcORLLXTfTc9913X73bysqymPJgP37uTKOz04n9Pv1uQES8QbPEGi5Vs8b0M5B05dYMvmTvucrKynq3DayoINNx+CB2BtnZa/H5als6vBbntRlpOgsWV+TmVjLdNwCA8QmGDYqIiIiIdw2NN/SYUf1l3a7YRCrIxDWLAwcoI4fCiDu/DRIRERGR5skrK2O/P4P1Nk8FWROpIBPXmNBsZlBEYUT/DEVEpAlqvX9rlEh7l1dWxtKMgYBRh8Um0pmwuCYY/IBivsAJTjm9XLpnWkRE2qgpU2D4cLejEElrgaoqBlRWMs+MIRA4QDi8w+2Q2iQVZOIaY8qZ4e8BQKHmkYmISAN0rKiAK6+Es88G/d8h4qqumzbhA+ZEzyY3dyUe65XRZqggE1etCOxgH8cwPqJ3sIiI1M/nOExYtowHXnwRXn8dHngAli93OyyRtNZtwwYAZtT8h9aPNYPa3ktCydqC+v31zxE74YQTkj5/IDSLqTVnUhiZCNaiX62ISKqppfpnpap1fTKxWKzebXv37v3M10P27eOWJUsYUFrKoh49GD1rFgwejH6UIg2X6L2eLA+sXHn0Yit/2TI2hzqyv7YrvbV+rMl0hUxcFQiUUMw4+ttKBmodmYiIHKZDTQ23LVrEL2fMICcS4aGxY/n5aafB4MGsWAFf+ILbEYqkt/47d7IoMASA3NzVLkfTdukKmbjKmAgzAp0gWreObGOCK24iIpIejLWcs2kTV69YQWY0yuvHH8/LQ4ZQHQgQjWZw773w2GOQm+t2pCLpq2NZGR3Ly5mbeRqZmZsIBMrdDqnNUkEmrtsQWM/2aG8KI+U8H3Y7GhERcVP/vXu5Z/p0Tti/n+Vdu/KXESPY2qED1sLOHWNZtuwm3n4bbrwRfv1r6N7d7YhF0lO/nTsBmFV7IbldtH6sOVSQieuCoZkUV0/gvMgrGOvHah2ZiEjayayp4aIFCzhj1SoOhkL8Lj+fGX37gjFUVHRn2bKb2LWrgA4dNjNpEowf73bEIumt/86dRHx+SmKF9Mt93O1w2jQVZOI6v38FxVzOtfyNIbEQqwL6Zykikjas5ZS1a7l83jxyqquZnpfHUwMGUBkK4TgB1q65iI8+uhxwOOmkZxk06B3Gj3/Z7ahF0l7/nTvZ0GEAtQcy1GGxmXTmK64zxjIrGIIIFEaiKshERNJEr08+4crZszlx5042duvG4+efz9auXancu5e9e09iyZJbKC/vS+/eczj55KfJytrndsgiAhjHoe/u3bze6Uv4fFVkZ290O6Q2TWe+4gk7gqtZFxlEUWQfT2a6HY2IiKRSRiTC+fPnc9aHH1IVCvHXwkJmDxmCNYbKyg6UlFzF1q1nkJ29i9NO+zk9ey5yO2QROUyPffvIiESYVVtITs5HGFP/GAtJTgWZNEuiOWXZ2dkNfp5gcDpTOIuvRZ/Fb7OJaR2ZiCSgWWKflarjkWzOWKLt1dXVRz5oLflbtnDl/Pl0qazk+WCQB0MhPlm2DLt0ObW1N1FdfT8QJhR6CJ/vMVasqGaFxhulnN5T6S3Ze33WrFmf+fpLe/YAMOngOeT2WZKyuNKFCjLxBL9/M9PMjXzT1jIiFmaRblsUEWlXepSWcs28eZy8YwdbOnfmSmOYH8/10egoqqp+i+OMxO+fRjj8Hfz+9S5HLCL1ySsv56A/xNpYHkNyX3A7nDZPZ73iGbOCQC0U1kZVkImItBPBaJQLly/nwg8/JOr387exYyk+8UTmv/UW1nakuvpH1NbeiDF7yMy8kWDwNUBXa0S8bFh5OUuCAyFmyM3VJezm0lmveMb+4BKW1Z5MYWQ7v3c7GBERabbh27Zxzbx5dC8vZ87AgbyYn8/BrCyshdraK6iu/hnWdiEUepJw+JcYUwqA7p4T8a7MWIzjKit5IzOfUGg3GRlqttNcKsjEM4LBmRRzPt+M/ZGQzaVW68hERNqkzmVlXD5zJmO2bmVHx448dO65rOrVC4ADB3ozd+51VFUNwe9fQGbm5fj9y1yOWEQa6sSKCvzA7Mi55HTQ1bGWoIJMPMPn+5hpvkF824lSEI0yOxh0OyQREWkEfyzGWR9+GeASCwAAIABJREFUyIULFwLw8ujRvJeXR8zvJxIJsWzZl1mx4jyCwWoyM+8iGHweY3Q5TKQtGVZeDsDs6Pnk5LzocjTtgwoy8ZQ5wRpiNT4KI5bZqsdERNqME7Zv58pZs+h14ABLBgzgr2PGsC8nB4AtW0Yyf/41VFR0ZdCg/2/vvsPjOsv0j3/fM300Ize523GL41hO7DhxS1zTK4QkkLKEDQtsgP2xDVjKUheWXVgI7LK7lACBUEINkEoKJHGR5RLXuHfZcpNcJM1Imv7+/vDE6wSr2CpnNHN/rkuXx3M0mjsnnkfnmTnneZdyxRW/4vnnf+JyYhE5H5XxOPt9/TiWHkxlZJPbcYqCGjJpV3tj7Tva7u1gMEcwGPyz+xJs4NXkDOald3UuoIgULY3h/j9d2RcdjbNu72dnMpl2H7ts2TIqMhk+VlfHW5qaOODz8YFRo1gcDHLoxRfJ5S4gkfgKmcwtOM4WwuH7qa+v5rnn2s/c0e8eETl37b3Ws9n21xHzeDynb0+Jx1nhnQ7pDOXlu3Acp9sylqoO96Ax5hFjTJ0xZtMZ933eGHPQGLM+/3VLz8aUUuH3r+AlFjIj20BEB2PSAdUnEfc4uRz3nzjBs3v2cGMsxv8OGsRbxo1jcSSCtT6SyX8kHl9JJrOQQOAzlJXNx+utdjt2r1BtkmI1KJlkaCrFCnsVZWW78XiSbkcqCp1paX8E3HSW+79hrb0s//Vs98aSUuU4LSzxjsZHjtnptNtxpPD9CNUnkV43vq6OTz3xBJ+qq2N9KMRbx43jfwYPJuk4NDfPYu/e35FMfh6v909EIrMIBL6JMe1/2lZkfoRqkxShyvz1Y0tTtxGNbnE5TfHo8JRFa+0SY8zYno8icsqaQJxkxs/8tIc/+d1OI4VM9Umkd0USCe5ctYr5O3ZwMhzm70eM4IVoFIwhkxlEXd3HaGp6Kz7fAUKhd+DzveB2ZFeoNkmxqozFSGNYk7uS0dGH3I5TNLpy0ueHjDEb8x/LD2jrm4wxDxpjXjXGvHry5MkuPJ2UilxwJdVcyby0p+NvFjm7DuvTmbWptbW1t/OJ9CnGWuZt28YXf/1rrty5k+cvvZTPvP3tvFBejsXDyZP3sWfPszQ13cSgQd9h3Li3lmwz1oFzPnZqamrqzXwi7Zocj7MtMIIEISIRjbzvLufbkH0bmABcBhwG2myRrbUPW2tnWGtnDBjQZu0ROc3vX8+fmM+03En6d3AxushZdKo+nVmbQqFQb+YT6VNGHzvGx596igeWLePQgAF88Y47+M3s2ST9flpbp1BT8wuOHv0sweBmxo27ncGD/wvHSbgduxCd17FTeXl5b+UTaZdjLZPjcdY4U/F6mwiFat2OVDTOa8qitfbo67eNMd8Dnu62RFLyjEmzxDMQJ2uZl8nwtF/nLUrnqT6JdI9gMsltK1dy9datxAMBfrBwISsuvBCMIZkM8eqrd1BTsxCP5zjDh3+U8vJn0HDEtqk2SV83prWVsmyW5dlFRCJbtYZgNzqvhswYM9xaezj/1zsALUIg3Wq9r454tox5KT9Pqx+Tc6D6JNJF1jJz507uqq4m2trKK5WV/P6KK2gNBLAWdu2czcqVd5NMRhgw4GdUVHwTjyfuduqCp9okfd3kWAyAJanbiA5d4XKa4tJhQ2aM+TmwCKgwxtQCnwMWGWMuAyywD3h/D2YUOl6TpStr1LT3s7vyc89cs+JsvvCFL7S57cMf/hFLE/NZkF5B1y51lGKm+lT4tJbY/+nJtcTa09H6Qo2Njadvj2xs5D1r1zKlro5dAwfyVsdhfW0t1NaSzV5EIvEQ2ewCHGcN4fCHyWbXc/RoOz+8HcW81phqk/Q16Q4mWxtjqIzHaXL87MhdzOToI0X9Gu5tnZmyeN9Z7v5BD2QROc3j2cpLfIib7XMMy/XniBYdlLNQfRLpHoFMhjs3b+bW7dtJ+Hx8b8YMXho/nvXPPYe1IZLJfyKV+lughWDwH/H5foQxusa3LapNUowqYzE2+MdjEw7R6Fa34xSV8zplUaSnGWNZ4i2DDMxNpXk8GHA7kohI8bGWmbW1PLBuHRUtLbw8bhyPTZ1KLBgEIJ2+kUTiq1g7Bp/vMQKBz+A4x1wOLSK9LZDNMr65maeCMwkGD+Dzafpnd1JDJgVri28/JzIDmJ/28niw/VNuRETk3FQ0NXFvVRWXHjhATb9+fPOaa9gxeDAAzc0VrFv3AK2tM3GcrYRCt+D1VrmcWETcclE8jheoSt9AdKDG3Xc3NWRSsDz+pbzcejULMn8E60Hju0REus6byXDThg3ctH49Wcfh0csu4/mJE8k5Dtmshx07bmXz5jsBCAQ+i9//LYxp//oSESlulfmBHlXZ64lGf+ZymuKjhkwKlsdzgJfNHdxlf8uYXD9qOhgSIiIi7Zuyfz/3Ll/OkKYmVk2YwG/mzGF/JgNAXd1k1qx5D01Noxk5cjXTpz/KkiU/cTmxiBSCyfE4B739qMsMZUS5PiHrbmrIpKAt9fogDfPTWTVkIiLnaUA8zt3Ll3P5vn0c6dePb9x6K9tGjgQgcdSyYcM72bdvIWVldcyb9x+MHLnW5cQiUkgqYzFe9U7HySUJh3e7HafoqCGTLmlv5GlH41BH5g8G2rPbt5ND6eHMT1l+Gkydcz4R6RqNrX+jntwf7Y227+h5k8nkWe/35HIM++Uv+XgigQN8IRDgf6wltWwZ1jqkUu8mkfgsEMbvfwjH+SobN7aycWPnMmvstci568oyFl3RXh1paGhoc1uoqYnhySTVgblEIttxnL5xXX9fqk9qyKSg+fzLeKnlGq7P/B6sX9eRiYh00kVHjvCu6mpGJhI86/XyiVCI/fklRLLZabS2fp1s9go8niUEgx/B49nhcmIRKURDamoAWJq8hcigLS6nKU5qyKSgOc4JXjETud82MynrYbtX/2RFRNpT3tLC3a++ylW7d1MfiXBvOMxzPh8A1paTSHyaVOq9GHOMUOiv8Xp/pfe6RKRNQ/ftI4NhDXMYU/7vbscpSjq6lYK31GchBfPThu36FysiclYml+Pqbdu4c906fJkMT02bxjNTp/Lck09iLaTTbyeR+BLWDsbv/z7B4JcwphGdlSoi7Rm6bx/b/SNoTYWJRPQJWU/Q4a0UvEP+zexOjWd+upXvh85+nYSISCkbX1/P/dXVjD1+nE0jRvCzOXM42q8fANnshbS2fo1sdhEez1pCobvxeDa4nFhE+oRcjiE1NbzkXI3ff4xAoM7tREVJDZkUPJ9vBS9xA+/I/BzHBsnp3BoREQDKEgluX7mSuVu30hgO861Fi3h17FgwhkzGz4YNtxKPfwdoJRj8CH7/DzHGnYECItL39K+rI9DaynLv1UTKt+j05h6ihkwKnjEtLHZG89e5VqZmfazXdWQiUuKMtVy5bRt3rFxJKJnkxSlTeGL6dBL5a8UOHJjKihXvJB4fjM/3C4LBz+A49S6nFpG+Zui+fQAsy9xMefkSd8MUMR3ZSp+wzJ+CBMxPeVmvf7UiUsJGHTvGvUuXMuHoUXYNG8bP589nbyQCQDw+kJUr/4L9+y+nX79D3HTTV6iu1kX4InJ+htTU0OoLsS19MZWR77gdp2jp0FZ6TEfrPwSDwU7/rBO+tWxKTGFe+iT/TaKr0UTkDFpr7I26sj+6sr5QJpNpc9vWrVsJZzK8d/9+7jp0iCafjy9NnMhzQ4bA4cNs2LCFVOpvSCY/ARgCgc+Ty/0Py5enO3zevrRWj4i0raPa1V59evrpp896//Xr17PeM45cGqLR7V3KJ21TQyZ9gte7jpe4g/dlf4jPlpHWAYSIlApruba+ng/t3cvAVIonhg3j4bFjiedP325snEZz83fJ5Srxep8lGPw4jrPf5dAi0tf5s1nGxWI8E5hFOLwXj6fV7UhFSw2Z9AnGZFjiGcLfZVPMyASozl8nISJSzIadPMlfVFVx8eHDbItE+OTkyWyLRgFIp/uzd+/fUFd3M8bsJxS6D5/vWZcTi0ixGN/UhNdalqZuoHzIZrfjFDU1ZNJnLPfHyLY6zEuFqPa1fWqPiEhf50+nuWX9em7YuJGk18tDEybw5LBh5IzBWsORI2+hpub9ZLNhRo36KY2N/4QxLW7HFpEiMqmhAYDq3EIikUddTlPc1JBJn9HsW8Xa1suZnz7EV1FDJiJFyFouq6nhnupqBsXjLJ84kcdnz2ZVftJZPD6RXbs+SjxeSb9+a5kw4RuEw/vYuFHNmIh0r0mNjRzx9eNwegSXl2tB6J6khkz6DI9nGy9zH/+Q+w5hW06LriMTkSJS0dTEvcuXM/XAAQ4OGMB/3HYbu4YPByCTCVNT8z4OH74Tn6+Riy76IoMHv6A1gUSkx0xqaGCt93K8tplQqMbtOEVNDZn0GcbAYm9/PpbJMjud5mW/3+1IIiJd5s1muX7dOm5cu5ac4/Cr2bN5+ZJLyDoO1sKePTNZu/bfSKUGMmzYE4wd+zBeb9zt2CJSxMqTSYa3tvIt/1z69duBMZrG25PUkBWJ9sYW9+RI6/aet6NRyt52FngeNmzYWe/f7k+SOuJjfqqcl/0afy/yOo2ufyO3Rte399h4/M+bqEsOH+aB1asZHovxW6+Xfw4EOLx1K2zdSjY7gUTiIbLZq3GcdZSVvYOWlrVsOcczhzTWXl6nOlHa2qtPjY2Nb/h75cmTACxJ3UgotAHHcXo0W6nT3pU+xYmuYwVzmJc5/wMmERG3DWxp4W+XLuUTL70EwJevuYa/Coc57DhYGySR+BTNzdVks5cTDH6EsrJr8HjWupxaREpFZSxGFsMaZhGJaMJiT9MnZNKn+HyHWexcz6dyy+iX60ej3rERkT7Ek8tx47Zt3PnaazjW8uupU3mmspKMxwNAOn0dicTXsHYcPt8vCQQ+jePUuZxaREpNZTzODt9wmtMRolEN9Ohpasikz6kO98eJW65KW/4QcDuNiEjnTKqr492rVjG6sZG1I0fykxkzqI9EAGhuHkhLy0/IZN6K4+wgFHoLXu8SlxOLSEmylsp4nN975hIIHMTna0AtQ8/S3pU+Z1u/47TEQ8xL9eMPAV3YLiKFLdrSwp0rV3Lljh0cC4f5+sKFrB01CoBczsO2bTfy2mt3kslYAoEv4vd/E2NSLqcWkVI1KpGgPJNhub2G6ACdrtgb1JBJn+OPrGEp81iQ2eB2FBGRNplcjgVbt3L7qlX4MxmemDKFJy65hFR+oFFd3UWsWvVXNDaOZuTItTQ2vhvH0WhpEXFXZX4A0fLsdUSjf3I5TWlQQyZ9jsfTyMtmFl+2LzIk1586XUcmIgVmTF0df7F0KWOOHWPryJH8Yu5cdvt8ACQSUdatu5c9exYSDh9jwYKvM2rUWp5+Ws2YiLivMhaj2fjYbKcwJfJNt+OUBDVk0ict9XkhBXPTDr/TdWQiUiDCiQS3r17N/C1baAqH+f611/LqhAlgDDbWzO7dC1m37h7S6RCVlU9x6aW/x+tNuh1bROS0ynicDb4LseksZWW73I5TEjpsyIwxjwC3AXXW2kvy9w0EfgmMBfYBd1trT/ZcTHFLR+vXdGVNk/bWtPj0pz/d7mM/+OCvOZnqz/xkOb8LNJ13Bunbiq0+aY2gzuvJdcba+9nJ5NmbJ2MtV+3axe1VVfS3lu8GAnwlECC2bh2sW0cmcwnNzV8lm52Fx7OMcPgj1NZuo7a2c5m1lljfUmy1SfqGjupiNpttc9vrx2S+XI6Jzc18yzebSGQHXm8WrZLV8zqzh38E3PSm+z4B/MlaOxH4U/7vIr3G8a3iFRawIBtzO4q460eoPonLRp04wSeefZb3LlvGbo+Ha8rL+XRZGTFjsDZKc/OXaGp6iVxuHMHg+wmHb8Xj2eZ2bOlZP0K1SfqgC5ub8VtLVfoGjbvvRR02ZNbaJcCJN919O/Bo/vajwNu6OZdIu4xpZbEzjnH2OBe0846PFDfVJ3FTMJ3mnlWr+NyTTzKssZFH5s3j1miUzV4v1kIyeTsNDdUkkw8SCPyYSGQGfv8v0IddxU+1SfqqytipN7qr7Xw1ZL3ofK8hG2qtPZy/fQQY2k15RDptqS8HSZiXCvBYKON2HCkcqk/Ss6xl5r593LtqFf1aWlg8aRK/veIKmgMB7JYtZLPjaW7+CpnMNXg8GygrewCvdw2ZjOpUiVNtkoJXGYtxxFPOwewoZqgh6zVdHuphrbXGmDZPWjXGPAg8CDBs2LCuPp3Iabv82ziSHMq8dBmPhRrcjiMFqL36dGZtikajvZpL+q5hjY28c8UKphw6xL5Bg/ifa65h7+DBAGQyXlpaPkYi8fcYkyIc/jiBwCMY0/41a1J6zuXYaciQIb2WS2RyLMZaz3R8zgkCgcMdP0C6xfk2ZEeNMcOttYeNMcOBura+0Vr7MPAwQGVlpa5Yl27j8a7nJRZydeZFsA46D0jyOlWfzqxNQ4cOVW2SdvnSaW5et47r1q8n7fXy0zlzeHnSJGz+Qvja2ktYseKdJBJD8ft/Qzj8WRznqMuppcCc17HTxIkTVZ+kV0TTaUYnEjzsnU+0fIsOq3rR+TZkTwIPAF/O//lEtyUS6SRjsiz2jOAvso1MyvVju8fjdiQpDKpP0q0u3bePu6uqqIjFWD5hAr+aOZOmUAiA5ub+rFp1H/v2zaS8/AjR6B34fEtcTiwFSrVJCtrk/ILQyzI36fqxXtaZsfc/BxYBFcaYWuBznComvzLGvBeoAe7uyZAibVnqS0EW5iYjbA+3uh1Hepnqk/SkgU1N3FNVxdSaGg4NGMDX3/pWNg0aBEAu57Bly3WsW/c2rHW4/PLfcsklz/H002rGRLVJ+qbKWIwcsIYrGBPV+wW9qcOGzFp7Xxubru3mLFJkOlo3p73tFRUVnXqOQ4EN7E2MZX7a4RHUkJWavlaftM7YG/XkWmLt6Wi4xpGaGu7au5d7du/GGsP3J03iibFjyabTVD3+OJnMbBKJh8jlLsXrfZ5Q6GPs2rWPXR2sn6q1xEpHX6tNUhw6qqmJRKLd7ZWxGDt9I4ilI0QiW7szmnSgy0M9RNzkONt5mRu5I/skjvWT0wGPiHTB5IMH+WxVFaOam1k2dCgPT57MsfzpialUOa2t/006/ZcYU0so9E683qd1nYWI9H3WMjkW42lnLuHwPrzeFrcTlRQ1ZNKnGQOveCp4T7aZSzJeNvp0HZmInLv+zc28Y8UKZu7Zw6FwmM/MmMGa/PREaw21tdezfft7SKdD+P3/RSDwFYxpdjm1iEj3GJ5M0j+TYblzLdEBun6st6khkz6vyh+DVpiXGsBGX5PbcUSkD3FyOa7ZvJm3rlmDJ5fjiSuu4JFBg0jnhwQ1NY1l8+YP0dBQyYABm0il3ofHo1N5RKS4vL4g9PLcIqLR511OU3rUkEmfd9z/KltaJ7MgneRbbocRkT7jwiNH+IuqKkadOMFro0fzi6uuor68nHRtLZlMiJ0776em5q14vXEuvfTrjBz5R5YvVzMmIsWnMhaj1fjYZC9havQbbscpOWrIpM/zeA7xErfyV7lf4bNh0rqgQ0TaEWlt5a5Vq5i7Ywcnysr41nXXsX7sWDAGa+Hw4bls3fp+ksmBjB79HBdd9CP8/rjbsUVEeszkWIyN3gmQSxEO73M7TslRQyZFYYk3yocySaZnQqzyqSETkT9ncjnmbt3K7StXEkyl+MO0aTwzfTopnw+AxsbBLF9+H7W1lxCN7mb69C8xYMB2l1OLiPQsJ5Phonic73rnEIlsxZjzn2Ir50cNmbimvRHQfr//nB67InCcXMYwP1XBKt+JbskncjYaXf9Gbo2u7+ixra1vXAZj7PHjPLBiBeOPH2eJx8NHw2G2790Le/dibYBU6h9IJj8MpAgEPg58jy1bsuecS6PtRaQrta0j7dXcjupxbW3tWe8fdvAgAWupSt/QpxaELqZ667gdQKQ7xP2rWcvlzE+f+wGUiBSvcDLJu1au5HPPPMPAlha+PW8ebwmH2Z4f2pHJXE1zczXJ5D/j9T5NJDKTQOA7GKNaIiKlYcSBAwCs4Ko+1ZAVE31CJkXBcRp5xczj73KPEbJRWovoXRMROQ/WMnfPHu5ds4ZIMskfL76Y3152Ga1+P2zcSC43jETi38lk7sRxdhEOvw2v92W3U4uI9LoRtbXUe6Lsz17ALDVkrlBDJkVjiTfER9MZZqe9vOLXu9sipWrEiRPcs3gxk+rq2FVRwVevu479AwcCkMs5JJMfJJn8Z8BPIPCv+P3fxJiku6FFRFwyoraW1Z5LCHiP4Pfrsg83qCGTorEqcIh02svc5EBe8de7HUdEelkgleK2NWu45rXXaPH7+cGVV7L0wgux+U/M6+snsGLFAySTY/B6XyAY/BiOs9fl1CIi7gm0tlJRX88Kz3u0ILSL1JBJ0Uj717KCWSzIHORLbocRkd5jLZfv2cM7qqsZ0NzMsosv5rGpU2kOBgFIJstYu/Zudu5cRDh8nFDoXXi9T6Izm0Wk1A0/eBCAqux1un7MRWrIpGgYk+AVM5F/tisoz5XT5GhmjUixG9LYyD3LljGltpb9FRU8fP317B06lNbWVqw17N49jzVr7iaVKqOy8g9Mm/Y7nnnmSbdji4gUhJH5gR6rmcnY6OMupyldasikqCzxeflMKsdVqTDPBRNuxxGRHuLLZLhp3TpuWL+ejNfLL+bOZUllJbn8GzEnT45k5coHqKubxODBO5gz51EGDDj7yGcRkVI1vLaWmtAYYokwkcgOt+OULDVkJaCjdRp6al2ljp63ve2e/EjqtsyfP/+s98ePl9OyNMTcVH+eCx7pOKQIp14DWl/s7Lq6X9pbj6ejn51Op896/6X79/O2l15iTDbL46EQXywvpz6/plguFyYW+zDNzX+NMY0Eg39DIvEYixd3/r+jmNa2EZHS0VFNfeaZZ978AD6wezd/4EbKynbiOKkeTCftUUMmRaVsYA3LmMOC7E63o4hINxsYi3HfihVM37+fHV4v7xg0iOWBAADWQiJxM42NXyCXG4HP9yMCgc/jOCfdDS0iUqCGJZMMTKdZbq4jWrHV7TglTQ2ZFBVjcrzijOHfci8zONefel1HJtLnebJZbti0idvWrQNj+M2MGXz04EHS+U+yMpkLaGz8V5LJa/F6NzNw4AdIpRa7nFpEpLBVxuMArLDziEaf6eC7pSepIZOis9SXhSRclezPE6Emt+OISBdcfOgQ71y+nOGNjawZO5Zfzp7NiUiE9KFDWOsnHv8gsdjfYkyW8vLPUVb2Q4zJktKZNyIi7aqMxUgYLxvtVKZFv+p2nJKmhkyKzpbAdhqS/ZiXiqghE+mjypububOqitl79lAXjfKfN9zAptGjT29PJufT0PAlstkJBINP0q/fv+Dx6LpREZHOqozH2ei9EGwzweBBt+OUNDVkUnSsZxeLmc2i7Aa3o4jIOXJyORZu2sRbVq/Gm8vx5PTp/GHqVNLeU7+uWlr6sXLl3Rw/PhuPZy8DB95HMLjE5dQiIn2LJ5djUnMz3zNXEolu0bqMLlNDJkXHGFjsGc7t2RcYlelPrVfXkYn0BeOPHOHepUsZffw4m0eP5mdz5lBXXg5ALuewdevVrFnzNnI5L9Ho14hEvoUxSZdTi4j0PeNbWgjmclRxHdHoZrfjlDw1ZNIl7Y2H7mj8anuPdToYxvGud72rzW1Llixhmb8VWmFuajC/9B5v92eJFLuujK5vb2x9Z2Sz2Ta31dfXAxBNJnnX5s1cV1PDsVCIr8yaxcoRI/jT888DkMlcQSLxDXK5aXg8fyQU+ieM2UNzc9vPq9H1Uoq0fEfxa+//cXv1Ft5YF6fkB3qs5Eqi0W92eNwlPUsNmRSlnf5NHG0dwrx0gF+6HUZEzspYy3X79nH/5s2EMhl+N3Eiv774YhL50xOt7U8i8TnS6XdjzGFCob/E631Cp9aIiHRRZTzOcSfCvtxYZkc18t5tasikKDmeI7zMlSzKVp9aoEhHcCIFZfSxY3xk8WIuOnmSTRUVfG/aNA7kT0+0FvbvX0Q8/l2sHYDf/78EAl/GmLi7oUVEikRlLMarnumEAjV4vXHA43akkqaGTIrWEu9A7s2c4MLsIHZ5dRqHSCEIJZPc/uqrLNyyhUa/n/+84gqWjB59+k2TpqbRrF//IMePT8HjWUkw+GE8nk0upxYRKR7hTIYxra086iwkOkDXjxUCNWRStJb5myADc5PD2OU97HYckdJmLbN37eKuFSuIJhIsnjyZH4wbR4vfD0AmE2DbtrvZtesteL2tTJ/+v+za9SmM0ZspIiLd6eJ4HAeozi0kEtnodhxBDZkUsQO+9dRwAQvShkfdDiNSwoafOMF9VVVMOnyYvYMH898338yBigpa6uuxFg4fnsXGje+ltXUwY8b8kSlTfkIgEGP3bjVjIiLdrTI/0GM1M7kg+nOX0wioIZMi5nhivGTmcnvuFYz1YnUdmUivCqTT3LRqFde99hoJv5+fzJ9P1cUXn34tNjcPYcOG93H06AzKy/cxc+Y3GDRom8upRUSKW2Usxm7PcBptiLKyvW7HEdSQSZFb4o3yV+kYUzLD2ORLuR1HpDRYy2V79vCOqioGNDezbNIkfjdrFvFQCIBs1suGDdezdu3NOE6OSy75IRMmPIPjdG3EvoiIdMBaKmMxXjRXESnbhjHtj8qX3tGlhswYsw+IAVkgY62d0R2hRDpaD6M8P42tI1X+Y5CGecmhbPId6I5o0kcUW33qyfWF2ltrrKN1yJLJNy7MPKSpiXeuXMnUgwfZP2AA9wCrjhyBJ58EIJNZQGvr18jlLsLr/T3B4CfZv/8Q+/efW2atMyZ9VbHVJikc6XS63e3GGIakUlSk0yznWqLRraqlBaI7PiG72lp7rBt+jki3O+Z/ja3Nk5ifyfAdt8OIG1Sfeokvk+GW117j1tdeI+Px8NjMmfxp8mRWPfEEALncEBKJfyVAoeyvAAAViklEQVSdvhvH2Us4fBde7x9dTi3iGtUmcUVlLAbASq4iGn3C5TTyOp2yKEXNmCSvmIt5V+4FvDZIRu8EiXS7S2truX/lSobEYqwYN45fzpxJQzgMgLUOqdR7SSQ+DQQJBL5CIPANjEnQgx/6iYjIWVTGYiTxsIFpTIv+u9txJK+rDZkFXjCn5hJ/11r78Ju/wRjzIPAgwLBhw7r4dCLnbokvwAdTrVyWHsyrfi0sW0LarU9n1qZIJOJCvL5vQCzG25ct44r9+zlcXs5/3HgjW4cPP7392LFxxOMvkctdhtf7EsHgR/F49riYWKQgnNOx05AhQ3o5nhSzybEYr3kngtNAIKAPaQtFVxuyedbag8aYIcCLxpht1tolZ35DvtA8DFBZWan3Q6XXVfsPk0sZ5iXVkJWYduvTmbVpyJAhqk3nwJPNcu1rr3HrmjVgLb+5/HKemzKFrMcDQDIZZu3au9i+fRHGHCUUejc+3+/RB9QiwDkeO02cOFH1SbqFx1omxeM8Yq4iGt3qdhw5Q5caMmvtwfyfdcaY3wGzgCXtP0qkdzX5trKeS5mfaeE/3Q4jvUb1qWdcdOgQ9y1dyvCGBtaPHctPZ8zgeP4TRmthz54rWb36HpLJKJWVL1Jb+z6MibmcWqRwqDaJW8Y2NxPK5VjONUSjm92OI2c474bMGFMGONbaWP72DcAXui2ZSDcxJscrznj+X+5ZArkyko7epi92qk/dr7ylhbuqq5m9axf10Sj/c9NNbBoz5vSUxYaGEVRXv4ujRy9m8OBdXH/9QwwadICDB9WMibxOtUnc9PqC0CuZTTT6DZfTyJm68gnZUOB3+XGZXuAxa+1z3ZJKpAN+v7/NbWcb4brM5/DhZIpZ6bEs1TnTpaBP1qeujLZvbzx9Rz83k8m0uW3V8uXcc+IEf1tXR8Bavj14MN+vqCB54AAcOMD+/cdJJj9GKvUhIE4w+HckEj9m8eKO/1s0bllKUJ+sTfLnOloSpKe0V8+bm5vbfWxlLMZJp4zduTFcGdne3dF6RKn8njjvhsxauweY1o1ZRHrM6mAN6aSXuan+ashKgOpT9xhfV8eH9+xhciJBVVkZXxo+nP2BwOntTU1XE4//E9ZegM/3EwKBz+E4x11MLFLYVJvETZNjMV51plEW2ovHk+z4AdJrNPZeSkKLZx+ruIwFmQa+7HYYkQJXlkhw5+rVLNi+nSNeLx8eNYoXyst5fSpHKjWCI0c+SSx2NY6zmVDoRrzeFS6nFhGRtvgSCca1tPAzs0jXjxUgNWRSEoyBJZ5RfCz7JJFcP+K6jkzkzxhrmbt9O3euXk04leL5Sy/lM+k0Lfnpibmcl+PH3019/fsxxjJ06Ndoafl3jGn7lEcREXFfRU0NDrDCziMaXed2HHkTNWRSMpb4snwym2NOciR/DB1yO45IQRl9/DjvrKpiQl0dO4YN47GrruLgwIG0VFcD0Nw8k0OHPkMqNZ5o9EWGD/8KPt8RDhxQMyYiUugG7zm1BuQqZjEm+lOX08ibqSGTkrE+uJPWRJB5qTL+GHI7jUhhCCaT3LpqFdds2UI8EOCRhQupvvDC06cnZjKDOHLkn2hsvA2f7wAXXPBBotGlLqcWEZFzMXjfPvZ6htFAgItDtW7HkTdRQyYlI+2pZzmXsTBb53YUEfdZy8xdu7iruppoSwuLJ0/m9zNm0JIf2pHLGbZtW8jOnQ9hbZDBg79NRcX3cRxdCC4i0tcM2bOHZ5hPNLoFY7TWeKFRQyYlZbF3KF/IrGBQdjDHPVm344i4YtjJk9y7dCmTDh1i3+DB/Pf111MzePDp7fX1Y6iqup9jx8ZSVlbN8OH/SiBQ42JiERE5X+GTJylraKCKq4lGt7gdR85CDZm0u8ZDV9ZF6srzdrTuhOM4bW573/ve1+a21Eo/vPIEVyYv4Onw3o5DipyjnlpLrCPZbNtvMDQ1NQEQyGS4Y/Nmbt22jYTPxw9mzOBP48fzzHOnlkGyth+JxGdIp9+LMXWEQu/BcR6nrgsfKpfKGjIiIt2ho98h7W1fvnz5We+/vObUG2oruZJo9DfnH056jBoyKSnpqZamV6LMS/t42u0wIr3FWmYcPMhfrl3L4JYWXhk3jsemTSMWDL6+mXT6bpLJL2HtIPz+7xII/BvGNLkcXEREump8fT1p42G9vYzLol90O46chRoyKSm+UJolTGNRVqdfSWmoaGriA0uWMP3wYfb368fnr72W7WecntjYOIKWlqfIZhfg8awmGLwLj2eji4lFRKQ7jauvZ4tvEsapx+fTG22FSA2ZlJzF3oHcllnGiMxIDnlb3Y4j0iO8mQw3btjAzevXkzGGH0+fzvMTJ5LLn+6byfjZvPkOtm+/jVwuRjD49/h8j+pibxGRImJyOcYeO8aj9jai/XT9WKFSQyYlZ5m/ETJwVXI0v/HucDuOSLebcuAA91ZVMaSpidXjx/PDSy7hZDh8evvBg5ezZs27aWkZzNixizl27D04zjEXE4uISE8Y0dhIKJNheX7CohQmNWRScnb4t1HfUsH8NOjSVikmA+Jx3lFdzRV793KkXz/+85Zb2Dpq1OmhHs3NFaxd+wAHD86gX78DXHPNvzBkyDaefVbNmIhIMRpfXw/ASmYTjX7V5TTSFjVkUnqcNC+bqSzKbT01zUBT4KSPc7JZrt2wgVvXrMGxlt/PnMmLU6eS8XgAyGY9bN9+K5s33wlYpk37GZMm/QHH0dIPIiLFbFx9PY1OhD2MYVbZbrfjSBvUkEmP6WjcdXujWzt6rCd/oHk2V111VbuP/d73vsdSbxl3p48yLjOevb6Gdr9fSk9PLffQ0Vj79p43mTz7gswXHTnC/dXVjGpo4A9eL58Ih9m/cyfs3AlAJnMVLS1fI5ebjNf7FMHgJ9i7t5a9nVz1QWPrRQpLTy5HI4Wvvd8j27dv/7P7RtbWssZMJRTegeNkejKadIEaMilJy/z1kIa5yRFqyKRPKm9t5e7Vq7lq927qIxHuKyvjOZ/v9PZcroLW1i+STt+LMTWEQu/A53vBxcQiItKbgtks41ta+CWLiEQ2ux1H2qGGTEpSjW8X+xnJgnSKn7odRuQcmFyOq7dv5861a/FnMjw9dSpPT5vGc089BYC1DqnUu0kkPoO1YQKBr+H3fw1jNFFURKSUTGpuxgOs5Cqi0VVux5F2qCGTkmQceMVcxC12PeQAR6dlSeEbX1/P/dXVjD1+nM0jRvCzOXM40q/f6e2ZzDRaWx8im70Cr3cxodBH8Xh2dXiqpIiIFJ/KWAw4NdDjgugPXU4j7VFDJiVrqS/AX6ZOMjkzha3+w27HEWlTOJHgnuXLWbBjB43hMN9euJDV48adHkiTTIZoafkKqdR7MaaecPh9+HyPa16NiEgJmxyPU+MMpcHjcKH/KOC4HUnaoIZMSlZV4CCkYF6yQg2ZFCRjLXO2b+eOFSsIJ5O8OGUKT0yfTiJ/rZi1sGfPbFavvpdUKoLf/31CoX/DmCaXk4uIiNumxGIs4wai0c16g67AqSGTknXEe5DtjGd+ppnvuR1G5E1GHjvGfUuXMuHoUXYNG8aPZ8+mduDA09sbGoaxYsX9HD5cSUXFHjye2/F6N7iYWERECsXAVIphqRTLuZpIRAtCFzo1ZFKyjIHFzljuy63CkwuQdTRKWNwXTKW4bfVqFm3aREsgwI8XLWLFpEkkUikAMhk/GzbcxqZNN+H1Jrnyyh9z0UWLeeIJNWMiInJKZTwOvL4g9M9dTiMdUUMmfVJ7ayNFIpFO/5wlPsODyTiXpiaxPtjJhZmkKHV2bZ+uDMjIZNpZA8ZaRlVV8Te7dzMwleKp4cP5/rhxxKyFbdtYt24d6fSNJBJfxdox+HyP4fd/ls2b69ncwTRjrSUmItI3dPS7KJvNtrntzFo/JR4ng8M6pjIt+nmMMTiOriErVGrIpKRVB2ogCfNT/VgfdDuNlKphDQ3cV1XF5EOH2B6J8KkpU9heXn56eyIxhJaWn5LJvAXH2UoodAteb5WLiUVEpJBVxmJs9lyICRzF49GyJ4VODZmUtAbvCdYziQXZk/y322Gk5PgzGW5Zt44bNm4k6fXy9YkTeXr4cHL5dzlzOQ+1te+gpuYBcrkcgcDn8Pv/F2PSLicXEZFCZazl4nicn+beTjSq68f6AjVkUvJe8YziA9ll+HMDSDkpt+NIiZhWU8M9y5dTEY+zfOJEHp89mzUHDpze3tAwlZ07/5GWlnEMGrSMZPIDOM6Bdn6iiIgIXNDaSiSbZSVziUY7OKddCoIaMil5y3xp/iGb5IrkOKpD292OI0VuUFMT91ZXM23/fg4OGMBXb7uNncOHn96eSvVnz54PcPToTQSDh5ky5ZNUVFSzbp2aMRER6diZC0JHo//uchrpDDVkUvJWB/eSSXiYlyqjOuR2GilW3myWG9au5Zb168k5Dr+ePZuXLrmEbP4ia2sNhw69hb17/5psNsQFF/yECy74KR5P0uXkIiLSl1TG48RMiJ1mFLNC+9yOI52ghkxKXtxpZjWVLMwe5atuh5GiNPnAAe5eupShjY28Om4cv5ozh4YzpoEeOzaaZcvup75+HP37r+XCC/+TsrL9LiYWEZG+qjIWY42ZRll0B8ZoSZ++oEsNmTHmJuC/AA/wfWvtl7sllUgH2hvj7fP52n2sx+P5s/uWeIfwkcwrlGVH0uyJdzmfuO9c61Nnx9l39H3x+P/9+xnQ0sL9a9Ywe/9+Dkej3BEO89Lx4/DMMwBYW04y+c+kUg9izDFCofeRzf6aHTs6FeUNNNpepG/QsZN0RTLZ9lkTxhj82SwTWlp43C6kvHyzfjf0Eee9IIExxgP8L3AzUAncZ4yp7K5gIr2pKtCClyyzkuPdjiLdwO365MnluHnrVv7jqaeYfvAgv546lU/eeisveU+9B2YtpNN3EY+vJpV6Pz7fD4hEZuLz/Rr97hQpXm7XJil+FzU347WWlVxJJKIJi31FVz4hmwXsstbuATDG/AK4HdD/felz1gb3kWgOMC/t42W3w0h3cK0+Taqr492rVjG6sZF1I0bw4xkzqI9GT2/PZi8kkXiIbHYRjrOWcPhePJ51PR1LRAqDjp2kR70+0GMVs7gg+n2X00hndaUhGwmcOfarFpjdtTgi7kg5GZabShZlD/BFt8NId+j1+hRtbeXOFSu4cscOjoXDfH3BAtaOGsXrH3llMj4SiU+RSv090Eow+BF8vkcwpnOnSopIUdCxk/SoybEYtc4QTvosF/ob3I4jndTjQz2MMQ8CD+b/mpwxY8amnn7Oc1QBHHM7xFkUYq5CzATdlOta6k/dONHVnwQUyb5607nnY7o9jYveXJu+/e1vd7k2fe31Gy0tsGRJG9/1cQASiVNfHSjEf0eFmAkKM1chZoLCzKXadIY316dbbrlFx06dU4i5ejXT9a/fSI5k2bJ2v7Xk99U56PH61JWG7CAw+oy/j8rf9wbW2oeBhwGMMa9aa2d04Tm7XSFmgsLMVYiZoDBzFWImKNxcPaDD+lTotQkKM1chZoLCzFWImaAwcxViph6iY6ceVIi5CjETFGauQswEvZPrvId6AKuBicaYccYYP3Av8GT3xBIR6RLVJxEpRKpNIvJnzvsTMmttxhjzIeB5To1ufcRau7nbkomInCfVJxEpRKpNInI2XbqGzFr7LPDsOTzk4a48Xw8pxExQmLkKMRMUZq5CzASFm6vbnWN9KtT9Uoi5CjETFGauQswEhZmrEDP1CB079ahCzFWImaAwcxViJuiFXMZareAtIiIiIiLihq5cQyYiIiIiIiJd0CsNmTHmJmPMdmPMLmPMJ3rjOTvDGLPPGPOaMWa9MeZVF3M8YoypM8ZsOuO+gcaYF40xO/N/DiiATJ83xhzM76/1xphbejnTaGPMy8aYLcaYzcaYv8/f7/a+aiuXa/vLGBM0xqwyxmzIZ/qX/P3jjDEr86/FX+YvKi9phVifVJvOK5fqU+czub2vVJ86oRBrE6g+nUcmt19vBVebOshVmsdO1toe/eLURau7gfGAH9gAVPb083Yy2z6gogByLAAuBzadcd9/AJ/I3/4E8JUCyPR54KMu7qfhwOX521FgB1BZAPuqrVyu7S/AAJH8bR+wEpgD/Aq4N3//d4APuvX/sxC+CrU+qTadVy7Vp85ncntfqT51vI8Ksjbls6k+nVsmt19vBVebOshVksdOvfEJ2Sxgl7V2j7U2BfwCuL0XnrfPsNYu4c+XI74deDR/+1HgbQWQyVXW2sPW2rX52zFgKzAS9/dVW7lcY0+J5//qy39Z4BrgN/n7e31fFSDVp3YUYm0C1aduyOQq1adOUW3qQCHWJ9WmbsnlGjdrU280ZCOBA2f8vZYC+IWQZ4EXjDFrjDEPuh3mTYZaaw/nbx8BhroZ5gwfMsZszH8s3+unKr3OGDMWmM6pdy8KZl+9KRe4uL+MMR5jzHqgDniRU++2NlhrM/lvKaTXolsKtT6pNp0f1afOZQKX95XqU4cKtTaB6tP5UG1qRyHVJ7dqU6kP9Zhnrb0cuBn4f8aYBW4HOht76jPSQhiH+W1gAnAZcBh4yI0QxpgI8DjwD9bapjO3ubmvzpLL1f1lrc1aay8DRnHq3daLe/P5pUtUm86d6lPnM7m+r1Sf+jTVp3Pj+usNCrM2tZGrJI+deqMhOwiMPuPvo/L3uc5aezD/Zx3wO07t+EJx1BgzHCD/Z53LebDWHs3/Q80B38OF/WWM8XHqhfsza+1v83e7vq/OlqsQ9lc+RwPwMnAl0N8Y8/r6gwXzWnRRQdYn1aZzVwivt0KsT4Vcm/JZVJ/OriBrE6g+natCeL0VYm1qK1ch7K98jl6tTb3RkK0GJuYnlPiBe4Ene+F522WMKTPGRF+/DdwAbGr/Ub3qSeCB/O0HgCdczAKcfsG+7g56eX8ZYwzwA2CrtfbrZ2xydV+1lcvN/WWMGWyM6Z+/HQKu59T52S8Db89/W0H8u3JZwdUn1abzo/rU+UwFsK9UnzpWcLUJVJ/ORwG83gquNrWXq2SPnTqa+tEdX8AtnJqeshv4VG88ZycyjefU1KINwGY3cwE/59THsmlOnZv6XmAQ8CdgJ/BHYGABZPoJ8BqwkVMv5OG9nGkepz5S3wisz3/dUgD7qq1cru0vYCqwLv/cm4DP5u8fD6wCdgG/BgK9ua8K8avQ6pNq03nnUn3qfCa395XqU+f2U0HVpjP+H6k+nVsmt19vBVebOshVksdOJv9EIiIiIiIi0stKfaiHiIiIiIiIa9SQiYiIiIiIuEQNmYiIiIiIiEvUkImIiIiIiLhEDZmIiIiIiIhL1JCJiIiIiIi4RA2ZiIiIiIiIS9SQiYiIiIiIuOT/AwCcEDloDGUYAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1080x1080 with 9 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the Results\n",
    "\n",
    "# line_data_32_10000_grey_multicolor_centered.pkl\n",
    "\n",
    "# Load dataset \n",
    "\n",
    "data_folder = 'foj_data/grayscale_lines/'\n",
    "\n",
    "with open(data_folder + 'line_data_32_10000_grey_multicolor_uncentered.pkl','rb') as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "# wedges = data['wedges']\n",
    "wedges_grey = data['wedges_grey']\n",
    "params = data['params']\n",
    "boundaries = data['boundaries']\n",
    "wedges = data['wedges']\n",
    "\n",
    "\n",
    "line_data = LineDataset(wedges_grey, params, boundaries, wedges)#, transform=trainTransform)\n",
    "data_size = len(line_data)\n",
    "\n",
    "print(data_size)\n",
    "\n",
    "train_proportion = .85\n",
    "# Split dataset into training and testing\n",
    "train_dataset_TEST, test_dataset_TEST = torch.utils.data.random_split(line_data, [int(data_size*train_proportion), int(data_size*(1-train_proportion))], generator=torch.Generator().manual_seed(42))\n",
    "\n",
    "# Create loaders for the training and testing data\n",
    "train_loader_TEST = torch.utils.data.DataLoader(train_dataset_TEST, batch_size=500, shuffle=True)\n",
    "test_loader_TEST = torch.utils.data.DataLoader(test_dataset_TEST, batch_size=500, shuffle=False) #len(test_dataset)\n",
    "\n",
    "\n",
    "W,H = 32,32\n",
    "\n",
    "img_show = 0\n",
    "plt.figure(figsize=[15, 15])\n",
    "plt.subplot(131)\n",
    "plt.imshow(wedges[img_show,:,:].squeeze().permute(1,2,0).cpu())\n",
    "plt.title('RGB Image')\n",
    "plt.axis('off');\n",
    "plt.subplot(132)\n",
    "plt.imshow(wedges_grey[img_show,:,:].squeeze().cpu(),cmap='gray', vmin=0, vmax=1)\n",
    "plt.title('Grayscale Image')\n",
    "plt.axis('off');\n",
    "plt.subplot(133)\n",
    "plt.imshow(boundaries[img_show,:,:].squeeze().cpu(),cmap='gray', vmin=0, vmax=1)\n",
    "plt.title('Boundaries')\n",
    "plt.axis('off');\n",
    "\n",
    "\n",
    "\n",
    "W,H = 32,32\n",
    "\n",
    "model.eval();\n",
    "\n",
    "ang_loss_all = []\n",
    "\n",
    "for batch_i, data in enumerate(test_loader_TEST):\n",
    "    # get the input images and their corresponding labels\n",
    "    \n",
    "    inputs, output_gt, _, _ = data\n",
    "    inputs, output_gt = inputs.to(dev), output_gt.to(dev)\n",
    "    \n",
    "\n",
    "    # forward pass to get outputs\n",
    "    outputs = model(inputs).squeeze().detach().cpu()\n",
    "    \n",
    "    gt = output_gt.cpu().squeeze()\n",
    "    \n",
    "    c = -output_gt[:,2]*torch.cos(output_gt[:,0]) + output_gt[:,1]*torch.sin(output_gt[:,0])\n",
    "    angle_params = torch.stack((-torch.sin(output_gt[:,0]),torch.cos(output_gt[:,0]),c),axis=1).detach().cpu()\n",
    "  \n",
    "    # Calculate angular loss\n",
    "    ang_loss = torch.mean(torch.abs(torch.rad2deg(torch.atan2(-angle_params[:,0]*outputs[:,1] + angle_params[:,1]*outputs[:,0]\n",
    "                                         ,angle_params[:,1]*outputs[:,1]+angle_params[:,0]*outputs[:,0]).cpu())))\n",
    "\n",
    "    ang_loss_all.append(ang_loss)\n",
    "\n",
    "    \n",
    "print(ang_loss_all)\n",
    "\n",
    "plt.figure(figsize=[15, 15])\n",
    "\n",
    "for ii in range(9):\n",
    "    \n",
    "    plt.subplot(3,3,ii+1)\n",
    "    plt.imshow(inputs[ii].cpu().squeeze(),cmap='gray', vmin=0, vmax=1)\n",
    "    \n",
    "    # Plot the ground truth lines\n",
    "    x_sample = torch.linspace(-1,1,inputs.shape[-1])\n",
    "    y_sample = -angle_params[ii,0]/angle_params[ii,1]*x_sample - angle_params[ii,2]/angle_params[ii,1]\n",
    "    \n",
    "    plt.plot(x_sample*W/2+W/2,y_sample*W/2+W/2,'b')\n",
    "    plt.xlim([0,W])\n",
    "    plt.ylim(([0,W]))\n",
    "    \n",
    "    # Plot the estimated lines\n",
    "    y_est = -outputs[ii,0]/outputs[ii,1]*x_sample - outputs[ii,2]/outputs[ii,1]\n",
    "    plt.plot(x_sample*W/2+W/2,y_est*W/2+W/2,'r')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f18128aa",
   "metadata": {},
   "source": [
    "# 16x16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c56e2544",
   "metadata": {},
   "source": [
    "# train on noiseless, multicolor data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5f3e6b5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA2cAAAElCAYAAABgRJorAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4xLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvDW2N/gAAFsFJREFUeJzt3X24ZVddH/Dv787NnQQyeZHwIiQkxQQJWBJrOwG0QIUoKKnY9mkRXxr6WMDYWis0CFrACGgRREXBmj4EU6QVoTS8iBoTYoskigjFKhULCEGSkIS8TEIGkntX/9h7mDPTmcmds+/MWXPz+TzPeXLOPfu319pn7l7Z373XPrdaawEAAGCxlhbdAQAAAIQzAACALghnAAAAHRDOAAAAOiCcAQAAdEA4AwAA6IBwBsB9RlW9uapeseh+AOxLVf11VT11Qv0dVfWIjewTh5dwtgmNO/Zd4w56/Xgwcuxey/zdqnpPVd1SVbdW1V9U1Sur6sTx/fOranVcxx1V9amq+qEDtPnkqvrcod42YLGq6llV9UdVdWdVfWF8fkFV1aL7dqhVVauq0xfdD2Dj7XXsdEtVvbeqTll0vw5Wa+3Y1tqnFt0P5iecbV7ntdaOTXJ2km9M8uJdb1TVE5JcleQPkzyqtXZCkqcluSfJWTPruHrcyY9N8o+TvLqqvvEw9R/oTFW9IMkvJvm5JA9J8uAkz0/yzUlW9lOz5bB1EGCaXcdOX5vkhiSvX3B/1q2qlhfdBzaGcLbJtdauT/K7GULaLq9Ocklr7WdaazeMy322tfay1tpV+1nPR5J8PMmZ62m3qq6qqldU1QfHs1DvrqoHVNVvVNXtVfWhqjptZvlfrKprx/c+XFV/f+a9Y6rq18czWR+vqgtnr9JV1UOr6h1VdWNVfbqqfmTdHxCwLlV1fJKLklzQWnt7a21HG3yktfa9rbUvj8u9uareWFW/XVV3JvkHVfWdVfWRcf++tqpePrPe91bVv96rrY9V1XfX4HXjFbrbq+rPquobxmWOqarXVtVnquq2qvpAVR0zvvdb46yB26rqf1TVYw6wXc+oqo+OMwg+WFWPXefn8fKxnbdU1Y6xb4+sqheP/b22qr5tZvnnjOPXjnEmwvP2Wt+FVXVdVX2+qn5w9ipdVW2tqtdU1Wer6oaq+tVd2wpsvNbaziRvT/LoZBj/qurS8TjjM1X1k1W1NL738qp6y67aqjpt3H+Xx9dXVdVPV9Ufjvv/71XVSTPLf/+4zpur6idm+1FV26vq6nF8uq6qfrmqVmbeb1X1w1X1V0n+auZn9zp2VNVJNcygurWqvlhV/3PXNrFY/hE2uao6OcnTk/zf8fX9kzw+yTsOcj1/L8kjk/zJQZQ9K8n3J3lYkq9LcnWSS5J8TYag97KZZT+UIUB+TZK3Jvmtqjp6fO9lSU5L8ogk5yb5vpl+LSV5d5L/NbbzlCQ/WlXffjDbB9yrxyfZmuSydSz77CSvTLItyQeS3JnkB5KckOQ7k/xQVT1zXPbXs+c+fVaGffm9Sb4tyRMzjD3HJ/mnSW4eF31Nkm9K8oQM48aFSdbG996X5IwkD0ryp0l+Y1+drGEmwJuSPC/JA5L8xyTvqqqt69jGJDkvyX9OcmKSj2Q4EbY09v+icX27fCHJM5Icl+Q5SV5XVX9n7MfTkvxYkqcmOT3Jk/dq52fHz+Ds8f2HJXnpOvsIHKSqul+Sf5bkmvFHr88wBj0iyZMyjGfPOYhVPntc/kEZZhm8cGzn0UnemOFY6aEZxqGTZ+pWk/zbJCdlGIOfkuSCvdb9zCTnZAySeznQ2PGCJJ9L8sAMsyBekqQdxDZxqLTWPDbZI8lfJ7kjyY4MO9oVSU4Y3zt5/NmjZpZ/dZJbMxxA/eT4s/MzTHO8dWY9r09S+2nzyUk+N/P6qiQ/MfP6tUneN/P6vCQfPcA23JLkrPH5p5J8+8x7P7irrQwD0mf3qn1xhiuDC/+38PDYLI8MAer6vX72wXGMuCvJE8efvTnJpfeyrl9I8rrx+dHj/n7G+Po1Sd4wPv/WJJ9I8rgkSzP1S2ObZ62j3yeM49fxM/17xfj8jUl+eq/l/zLJk/azrpbk9PH5y5NcPvPeeeO4u2V8vW1c/oT9rOu/J/k34/M3JfmZmfdO39VWkhrH5q+bef/xST696N8JD4/N9MjuY6dbk9yd5PNJ/naSLUm+kuTRM8s+L8lV4/OXJ3nLzHunjfvv8vj6qozHVuPrC5L8zvj8pUn+68x79x/beup++vijSd4587ol+da9llnX2JHhBNJlu8Y0j34erpxtXs9srW3LEJoeleGsSzIcBK1lmE+dJGmtXdiG+87emWR2zvI1rbUTxvU8JMljkrzqIPpww8zzu/bx+qtfUlJVLxyn/NxWVbdmOEO1q88PTXLtTO3s81OTPHS8LH/rWPuSDGeBgI1zc5KTaua+htbaE8ax4+bsORNjdh9NVZ1TVe8fpwTdluE+tZPGdexM8ptJvm+8Ev49Ga5GpbV2ZZJfTvIrSb5QVb9WVceNtUcn+eTenayqLVX1s1X1yaq6PcMBV7J7PJl1apIX7DV+nJJhzFmPvce0m1prqzOvk3Gcq6qnV9U14/ShW5N8R9Y3xj0wyf2SfHimj78z/hzYWM8cx7Sjk/yrJH+Q4aT2UUk+M7PcZzJchVqv62eefym7j3/22Pdba3dm9+yAjFOl3zNO0749wzHY3mPZtdm3exs7fi7DrKrfG6da//hBbA+HkHC2ybXW/iDDmeLXjK/vTPJHSf7RQa7nhgxTIc/b4C6mhvvLLswwZenEcWC8LcNZnyS5Lnte5p/99qRrM5wFOmHmsa219h0b3U+4j7s6yZeTfNc6lt17asxbk7wrySmtteOT/Gp279/JMLXxezNM2flSa+3qr66otV9qrX1Thik7j0zy75LclGRnhunSe3v22MenZjjJc9r48319m+S1SV651/hxv9baf1nHNq7bOE3yHRnG4QePY9xvZ31j3E0Zgt5jZvp4fBu+tAA4BFprq621/5ZhWuHjMlxJO3VmkYcn+Zvx+Z0ZQtAuDzmIpq7LzP4+Tqd8wMz7b0zyfzLMLDguw8nnvcey/U1FPODY0Yb7hl/QWntEkn+Y5Meq6ikH0XcOEeHsvuEXkpw73suRDEHoX1TVj1fVg5Kv3pv2t/a3gqp6QJLvTvLnh6B/2zJMobwxyXJVvTTDfRm7vC3Ji6vqxKp6WIazWbv8cZIdVfWiGr4gYEtVfcN4jxywQVprtyb5qSRvqKp/UlXbqmqpqs7OMBXnQLYl+WJrbWdVbc8QoGbXfXWGK/qvzXjVLBnudR2vuh2V4QBoZ5K11tpahqmAP1/DFwJtqarHjyFoW4YQeXOGA6YDXe2/OMnzxzaqqu5fw5eXbFv3B7M+Kxnu17sxyT1V9fQM99Pt8rYkz6mqM8eDs3+/641xWy/OcI/arvH6Ye6rhUNnHA++K8P9pP87wz76ynHcOzXDPaK7vgTko0meWFUPr+GLk168z5Xu29uTPKOqvmX8oo+Lsuex+bYktye5o6oelWS/f9Job/c2dtTwZUinV1VlOCG+mt337bJAwtl9QGvtxiSXZrwJtLX2gQz3cjwxySdmLnVflT2/NvbxNf6dswxf4HFjkj2+VW2D/O7Y/icyTBXYmT0v01+U4abVTyf5/QyD2ZfHbVnNcJP92eP7NyX5TxnOmAMbqLX26gwHJRdmmNJ3Q4YvvXhRhvvP9ueCJBdV1Y4M49Db9rHMpRnu73jLzM+Oy3BwcUuGseHmDFNxkuGG+j/L8GVCX0zyHzL8P+3Scdm/SfIX2X1D/76250+S/MsMUydvyTDF5/wDbMdcWms7kvxIhu2+JUM4fdfM++9L8ktJ3j/2YVefvzz+90W7fj5Obfr9JF+/0f0E8u7xmOf2DF9q9M9ba3+e4djnzgz3wH8gw2yANyVJa+3yDFOzP5bkw0nes97GxnX/8Li+6zKMD7N/M/aFGcaLHRnGwt88yO050Nhxxvj6jgwzI97QWnv/Qa6fQ6Ba88UsHFlq+GPYz2qtPWnRfQE2RlX9QJLntta+ZdF9WbSqOjPD2fqtrbV7Ft0fAA4fV87oXlV9bVV98ziF6uszfP3rOxfdL2BjjFP5Lkjya4vuy6LU8HfdtlbViRmuAr5bMAO47xHOOBKsZJg6tSPJlRm++vUNC+0RsCHG+x9uzDBF8q0L7s4iPS/D30L7ZIZ7P9Z9bwkAm4dpjQAAAB1w5QwAAKADwhkAAEAHlg9nY63KHMqD1Pb5d1MPj7UJ2f20P37gvS90ANed9YW5a9uWxf2atSP5V3zCr1qrtrhf1A2wsrJyBP/DcTAuvvjiSfVnnHHG3LVLS9POhw5/jmgxFtn2FNu3bz8yO74n49N9xMc//vFJ9WeeeeYG9YTDZJ/jkytnAAAAHRDOAAAAOiCcAQAAdEA4AwAA6IBwBgAA0AHhDAAAoAPCGQAAQAeEMwAAgA4IZwAAAB0QzgAAADognAEAAHRAOAMAAOiAcAYAANCB5UV3gHvTJtbXhMr52/7Q49bmrk2SU+6cv99taeJnNn/TQOee+9znTqq/4oor5q5dWjpyz4e2Nv+4WmVQhfXYunXrortAB47c/1MAAABsIsIZAABAB4QzAACADghnAAAAHRDOAAAAOiCcAQAAdEA4AwAA6IBwBgAA0AHhDAAAoAPCGQAAQAeEMwAAgA4IZwAAAB0QzgAAADognAEAAHRAOAMAAOjA8qI7wIHVxPq2Ib04eCes3T6pvtambjnA/6+1aaPi1HqA/Xn4wx8+qX7K+FTluKsXrpwBAAB0QDgDAADogHAGAADQAeEMAACgA8IZAABAB4QzAACADghnAAAAHRDOAAAAOiCcAQAAdEA4AwAA6IBwBgAA0AHhDAAAoAPCGQAAQAeEMwAAgA4sL7oD9KvS5q7dktVJbW+5e8vctWtHrU1qu9X82w1sbvfcc8/ctcvLi/tfblUtrG1gfbZsmf/YJ0nW1uY//pnaNhvHlTMAAIAOCGcAAAAdEM4AAAA6IJwBAAB0QDgDAADogHAGAADQAeEMAACgA8IZAABAB4QzAACADghnAAAAHRDOAAAAOiCcAQAAdEA4AwAA6IBwBgAA0AHhDAAAoAPLi+4Am9NS1ibVH33rMXPX3n3M3ZPavs9qE2prw3oBXduxY8fctVu3bp3UdpUdDTazqfv4HXfcMXft8ccfP6ltNo4rZwAAAB0QzgAAADognAEAAHRAOAMAAOiAcAYAANAB4QwAAKADwhkAAEAHhDMAAIAOCGcAAAAdEM4AAAA6IJwBAAB0QDgDAADogHAGAADQAeEMAACgA9VaO2yNtarD1xhJkpZaSLtrE9u96sSz5q592nUfm9T22pa1+YsnftztCN1F2lJbzC/aBllZWTkyP3gOu23bts1de9lll01qe3l5ee7aqiN3F53S9+3btx+5G76b8Yl1eclLXjJ37ate9aoN7AnrtM/xyZUzAACADghnAAAAHRDOAAAAOiCcAQAAdEA4AwAA6IBwBgAA0AHhDAAAoAPCGQAAQAeEMwAAgA4IZwAAAB0QzgAAADognAEAAHRAOAMAAOiAcAYAANAB4QwAAKAD1Vo7bI21qsPXGJO11EJqk+SuHDN37Ylf+vKktlePWp2/eNpmpx2hu0hbahO3fLFWVlaOzA+eI8qVV145qX55eXnu2qojdxed0vft27cfuRu+m/GJddm5c+fctVu3bp3U9pE8xizQPj80V84AAAA6IJwBAAB0QDgDAADogHAGAADQAeEMAACgA8IZAABAB4QzAACADghnAAAAHRDOAAAAOiCcAQAAdEA4AwAA6IBwBgAA0AHhDAAAoAPCGQAAQAeWF90B2JejcvfctUv31KS215bnr2/VJrUNbF6rq6uT6rds2TJ3bdW0cRHo38rKyty1rU07fjHGbBxXzgAAADognAEAAHRAOAMAAOiAcAYAANAB4QwAAKADwhkAAEAHhDMAAIAOCGcAAAAdEM4AAAA6IJwBAAB0QDgDAADogHAGAADQAeEMAACgA8IZAABAB5YX3QE2p0qbVL+Utblrj7prZVLb9xy9OqkeYF927tw5qX5lZf6xrbVpY3JVTaoHDr0p++lXvvKVSW1v3bp1Uj27uXIGAADQAeEMAACgA8IZAABAB4QzAACADghnAAAAHRDOAAAAOiCcAQAAdEA4AwAA6IBwBgAA0AHhDAAAoAPCGQAAQAeEMwAAgA4IZwAAAB0QzgAAADognAEAAHRgedEdgH2ptLlrz3zfqZPa/tPv+cv5i+fvdpKkUvM3XRMbBw6pa665ZlL9ueeeO3dt1fxjC3BkmLKfX3LJJZPafv7znz+pnt1cOQMAAOiAcAYAANAB4QwAAKADwhkAAEAHhDMAAIAOCGcAAAAdEM4AAAA6IJwBAAB0QDgDAADogHAGAADQAeEMAACgA8IZAABAB4QzAACADghnAAAAHajW2mFrrFUdvsZYqJZaWP1tddykth/0pR1z164tr01qe8rH1ha4e7WlNu0ffMFWVlaMTRxyVdN2kyuuuGLu2uXl5UltT+37opxzzjlHZsf3ZHzikLvlllsm1Z944okb1JP7lH2OT66cAQAAdEA4AwAA6IBwBgAA0AHhDAAAoAPCGQAAQAeEMwAAgA4IZwAAAB0QzgAAADognAEAAHRAOAMAAOiAcAYAANAB4QwAAKADwhkAAEAHhDMAAIAOCGcAAAAdWF50B2Cj3a/dNal+aXX+cxZry2uT2gY2r9bapPq1tfnHl6ltV9WkeqBvxx133KT6KWOM8WVPrpwBAAB0QDgDAADogHAGAADQAeEMAACgA8IZAABAB4QzAACADghnAAAAHRDOAAAAOiCcAQAAdEA4AwAA6IBwBgAA0AHhDAAAoAPCGQAAQAeEMwAAgA4sL7oDsC+VNnftlqxOanvLV+bfLVZXprXdav7tBja3u+++e+7ao446alLbrc0/NlXVpLaBQ29padr1mtXV+Y9/lpfFkVmunAEAAHRAOAMAAOiAcAYAANAB4QwAAKADwhkAAEAHhDMAAIAOCGcAAAAdEM4AAAA6IJwBAAB0QDgDAADogHAGAADQAeEMAACgA8IZAABAB4QzAACADghnAAAAHVhedAdgo1XapPrjPn/s3LU3nfHFSW0D7M9NN900d+0pp5wyqe2qmlQP9G3qPn799dfPXXvyySdPanuzceUMAACgA8IZAABAB4QzAACADghnAAAAHRDOAAAAOiCcAQAAdEA4AwAA6IBwBgAA0AHhDAAAoAPCGQAAQAeEMwAAgA4IZwAAAB0QzgAAADognAEAAHRgedEdgI1WaZPqrzn76Llrz7ijJrXd2vx9r0xsu6Z9bsChdf75589de/nll09qe2nJuVxg/2644Ya5a08++eQN7MmRz2gLAADQAeEMAACgA8IZAABAB4QzAACADghnAAAAHRDOAAAAOiCcAQAAdEA4AwAA6IBwBgAA0AHhDAAAoAPCGQAAQAeEMwAAgA4IZwAAAB0QzgAAADognAEAAHRgedEdYHOqtEn1LbVBPTl4D77n5rlra3Viv7dMKwc2r9XV1blrW5s2JgMcyGMf+9i5a6eOT1WLO2Y8FFw5AwAA6IBwBgAA0AHhDAAAoAPCGQAAQAeEMwAAgA4IZwAAAB0QzgAAADognAEAAHRAOAMAAOiAcAYAANAB4QwAAKADwhkAAEAHhDMAAIAOCGcAAAAdqNbaovsAAABwn+fKGQAAQAeEMwAAgA4IZwAAAB0QzgAAADognAEAAHRAOAMAAOiAcAYAANAB4QwAAKADwhkAAEAHhDMAAIAOCGcAAAAdEM4AAAA6IJwBAAB0QDgDAADogHAGAADQAeEMAACgA8IZAABAB4QzAACADghnAAAAHRDOAAAAOiCcAQAAdEA4AwAA6IBwBgAA0IH/B2bD1/UTfgd4AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1080x1080 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load dataset \n",
    "\n",
    "data_folder = 'foj_data/grayscale_lines/'\n",
    "\n",
    "with open(data_folder + 'line_data_16_50000_grey_multicolor_noiseless_uncentered.pkl','rb') as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "# wedges = data['wedges']\n",
    "wedges_grey = data['wedges_grey']\n",
    "params = data['params']\n",
    "boundaries = data['boundaries']\n",
    "wedges = data['wedges']\n",
    "\n",
    "\n",
    "line_data = LineDataset(wedges_grey, params, boundaries, wedges)#, transform=trainTransform)\n",
    "data_size = len(line_data)\n",
    "\n",
    "print(data_size)\n",
    "\n",
    "train_proportion = .85\n",
    "# Split dataset into training and testing\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(line_data, [int(data_size*train_proportion), int(data_size*(1-train_proportion))], generator=torch.Generator().manual_seed(42))\n",
    "\n",
    "# Create loaders for the training and testing data\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=1000, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=500, shuffle=False) #len(test_dataset)\n",
    "\n",
    "\n",
    "W,H = 16,16\n",
    "\n",
    "img_show = 0\n",
    "plt.figure(figsize=[15, 15])\n",
    "plt.subplot(131)\n",
    "plt.imshow(wedges[img_show,:,:].squeeze().permute(1,2,0).cpu())\n",
    "plt.title('RGB Image')\n",
    "plt.axis('off');\n",
    "plt.subplot(132)\n",
    "plt.imshow(wedges_grey[img_show,:,:].squeeze().cpu(),cmap='gray', vmin=0, vmax=1)\n",
    "plt.title('Grayscale Image')\n",
    "plt.axis('off');\n",
    "plt.subplot(133)\n",
    "plt.imshow(boundaries[img_show,:,:].squeeze().cpu(),cmap='gray', vmin=0, vmax=1)\n",
    "plt.title('Boundaries')\n",
    "plt.axis('off');\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e4444ccb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1            [-1, 2, 14, 14]              20\n",
      "              ReLU-2            [-1, 2, 14, 14]               0\n",
      "            Conv2d-3            [-1, 2, 12, 12]              38\n",
      "         MaxPool2d-4              [-1, 2, 6, 6]               0\n",
      "         AvgPool2d-5              [-1, 2, 3, 3]               0\n",
      "            Linear-6                    [-1, 3]              57\n",
      "================================================================\n",
      "Total params: 115\n",
      "Trainable params: 115\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.01\n",
      "Params size (MB): 0.00\n",
      "Estimated Total Size (MB): 0.01\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "class offCenterLineNet(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "                \n",
    "        self.conv1 = nn.Conv2d(1, 2, kernel_size=3) #64 is good\n",
    "        self.conv2 = nn.Conv2d(2, 2, kernel_size=3)\n",
    "#         self.conv3 = nn.Conv2d(1, 1, kernel_size=3)\n",
    "#         self.conv3 = nn.Conv2d(4, 1, kernel_size=3)\n",
    "#         self.conv3 = nn.Conv2d(128, 1, kernel_size=3)\n",
    "        self.fc = nn.LazyLinear(3)\n",
    "        self.maxpool = nn.MaxPool2d(2)\n",
    "        self.avgpool = nn.AvgPool2d(2)#,stride=1)\n",
    "        self.activate = nn.ReLU()\n",
    "#         self.batchnorm = nn.BatchNorm2d(16)\n",
    "    \n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.conv1(x)\n",
    "        x = self.activate(x)\n",
    "        x = self.conv2(x)\n",
    "#         x = self.activate(x)\n",
    "#         x = self.conv3(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.shape[0],-1)\n",
    "        \n",
    "        x = self.fc(x)\n",
    "         \n",
    "        # We're defining\n",
    "        # a = - sin(theta)\n",
    "        # b = cos(theta)\n",
    "        # c = -cy*cos(theta)+cx*sin(theta)\n",
    "        # Hence, we want to normalize the vector by 1/sqrt(a^2 + b^2)\n",
    "        norm_factor = (torch.norm(x[:,:2],p=2,dim=1)).unsqueeze(1)       \n",
    "        out = x/(norm_factor)#+eps)\n",
    "#         print('Output shape=',x.shape)\n",
    "\n",
    "#         out = x\n",
    "        \n",
    "        return out\n",
    "    \n",
    "model = offCenterLineNet()\n",
    "model = model.to(dev)\n",
    "summary(model, input_size=(1, H, W))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "36b4ada3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Avg. Train Loss: 0.6603625804878944, Avg. Test Loss: 0.6266629695892334\n",
      "Epoch: 2, Avg. Train Loss: 0.5894265521404355, Avg. Test Loss: 0.5715212821960449\n",
      "Epoch: 3, Avg. Train Loss: 0.5286536438520565, Avg. Test Loss: 0.49993446469306946\n",
      "Epoch: 4, Avg. Train Loss: 0.4427446508130362, Avg. Test Loss: 0.3917577266693115\n",
      "Epoch: 5, Avg. Train Loss: 0.3566987743211347, Avg. Test Loss: 0.3351559638977051\n",
      "Epoch: 6, Avg. Train Loss: 0.3053384028201879, Avg. Test Loss: 0.27737799286842346\n",
      "Epoch: 7, Avg. Train Loss: 0.2557509520719218, Avg. Test Loss: 0.3898288905620575\n",
      "Epoch: 8, Avg. Train Loss: 0.5054217667080635, Avg. Test Loss: 0.529272735118866\n",
      "Epoch: 9, Avg. Train Loss: 0.5073338816332262, Avg. Test Loss: 0.5047097206115723\n",
      "Epoch: 10, Avg. Train Loss: 0.48274005152458366, Avg. Test Loss: 0.4785251319408417\n",
      "Epoch: 11, Avg. Train Loss: 0.38404107925503755, Avg. Test Loss: 0.2602853775024414\n",
      "Epoch: 12, Avg. Train Loss: 0.1635086401257404, Avg. Test Loss: 0.11181928217411041\n",
      "Epoch: 13, Avg. Train Loss: 0.08634750770274983, Avg. Test Loss: 0.06320759654045105\n",
      "Epoch: 14, Avg. Train Loss: 0.05187071599932604, Avg. Test Loss: 0.04094311594963074\n",
      "Epoch: 15, Avg. Train Loss: 0.036197991781803066, Avg. Test Loss: 0.030613631010055542\n",
      "Epoch: 16, Avg. Train Loss: 0.02840029218688954, Avg. Test Loss: 0.025030585005879402\n",
      "Epoch: 17, Avg. Train Loss: 0.023845163498853527, Avg. Test Loss: 0.021474048495292664\n",
      "Epoch: 18, Avg. Train Loss: 0.020827737788474836, Avg. Test Loss: 0.01895056664943695\n",
      "Epoch: 19, Avg. Train Loss: 0.01851259013854487, Avg. Test Loss: 0.01699567586183548\n",
      "Epoch: 20, Avg. Train Loss: 0.016750072020777437, Avg. Test Loss: 0.01542993076145649\n",
      "Epoch: 21, Avg. Train Loss: 0.015221625609799873, Avg. Test Loss: 0.014063512906432152\n",
      "Epoch: 22, Avg. Train Loss: 0.01394625608051239, Avg. Test Loss: 0.012909765355288982\n",
      "Epoch: 23, Avg. Train Loss: 0.012805684556274913, Avg. Test Loss: 0.01187896728515625\n",
      "Epoch: 24, Avg. Train Loss: 0.011793459743954415, Avg. Test Loss: 0.01096861157566309\n",
      "Epoch: 25, Avg. Train Loss: 0.010918252624917862, Avg. Test Loss: 0.010178019292652607\n",
      "Epoch: 26, Avg. Train Loss: 0.01010941859161438, Avg. Test Loss: 0.00941359531134367\n",
      "Epoch: 27, Avg. Train Loss: 0.00937017415065405, Avg. Test Loss: 0.008758867159485817\n",
      "Epoch: 28, Avg. Train Loss: 0.008723518551262311, Avg. Test Loss: 0.008159246295690536\n",
      "Epoch: 29, Avg. Train Loss: 0.008130771746902271, Avg. Test Loss: 0.007650103885680437\n",
      "Epoch: 30, Avg. Train Loss: 0.007607230364323356, Avg. Test Loss: 0.007146480027586222\n",
      "Epoch: 31, Avg. Train Loss: 0.007123199984604536, Avg. Test Loss: 0.0067110126838088036\n",
      "Epoch: 32, Avg. Train Loss: 0.006698271183860164, Avg. Test Loss: 0.006310873199254274\n",
      "Epoch: 33, Avg. Train Loss: 0.006306072924459396, Avg. Test Loss: 0.005959250032901764\n",
      "Epoch: 34, Avg. Train Loss: 0.005950661636022634, Avg. Test Loss: 0.005621488206088543\n",
      "Epoch: 35, Avg. Train Loss: 0.005617754479740248, Avg. Test Loss: 0.005320982076227665\n",
      "Epoch: 36, Avg. Train Loss: 0.005318637352523415, Avg. Test Loss: 0.00504594761878252\n",
      "Epoch: 37, Avg. Train Loss: 0.005043731211836255, Avg. Test Loss: 0.0047937058843672276\n",
      "Epoch: 38, Avg. Train Loss: 0.004790611402673083, Avg. Test Loss: 0.004551491234451532\n",
      "Epoch: 39, Avg. Train Loss: 0.0045513689712902835, Avg. Test Loss: 0.0043485029600560665\n",
      "Epoch: 40, Avg. Train Loss: 0.004336054935011753, Avg. Test Loss: 0.004133145324885845\n",
      "Epoch: 41, Avg. Train Loss: 0.004139710905376908, Avg. Test Loss: 0.003941847011446953\n",
      "Epoch: 42, Avg. Train Loss: 0.00393719807657045, Avg. Test Loss: 0.00376537605188787\n",
      "Epoch: 43, Avg. Train Loss: 0.003763467912713802, Avg. Test Loss: 0.0036072968505322933\n",
      "Epoch: 44, Avg. Train Loss: 0.0035993075864606127, Avg. Test Loss: 0.0034458707086741924\n",
      "Epoch: 45, Avg. Train Loss: 0.003443687006311361, Avg. Test Loss: 0.003319533308967948\n",
      "Epoch: 46, Avg. Train Loss: 0.0032996500593198592, Avg. Test Loss: 0.00316656194627285\n",
      "Epoch: 47, Avg. Train Loss: 0.0031641633899579216, Avg. Test Loss: 0.003043601755052805\n",
      "Epoch: 48, Avg. Train Loss: 0.003037869849047342, Avg. Test Loss: 0.002919628983363509\n",
      "Epoch: 49, Avg. Train Loss: 0.002912907693318503, Avg. Test Loss: 0.0028065238147974014\n",
      "Epoch: 50, Avg. Train Loss: 0.002803879546348092, Avg. Test Loss: 0.0027010298799723387\n",
      "Epoch: 51, Avg. Train Loss: 0.0026989221183020013, Avg. Test Loss: 0.002606102963909507\n",
      "Epoch: 52, Avg. Train Loss: 0.0025989168680944415, Avg. Test Loss: 0.00250571733340621\n",
      "Epoch: 53, Avg. Train Loss: 0.0024993958731376847, Avg. Test Loss: 0.002414620714262128\n",
      "Epoch: 54, Avg. Train Loss: 0.0024085407481030667, Avg. Test Loss: 0.0023310675751417875\n",
      "Epoch: 55, Avg. Train Loss: 0.0023280905375560354, Avg. Test Loss: 0.0022551214788109064\n",
      "Epoch: 56, Avg. Train Loss: 0.002243781305286427, Avg. Test Loss: 0.0021763609256595373\n",
      "Epoch: 57, Avg. Train Loss: 0.0021663313179255224, Avg. Test Loss: 0.002104592276737094\n",
      "Epoch: 58, Avg. Train Loss: 0.0021016045208197345, Avg. Test Loss: 0.002077973447740078\n",
      "Epoch: 59, Avg. Train Loss: 0.0020305401439843483, Avg. Test Loss: 0.001977067207917571\n",
      "Epoch: 60, Avg. Train Loss: 0.0019638446230051477, Avg. Test Loss: 0.0019069623667746782\n",
      "Epoch: 61, Avg. Train Loss: 0.0018979411539729945, Avg. Test Loss: 0.0018482067389413714\n",
      "Epoch: 62, Avg. Train Loss: 0.001837971739384324, Avg. Test Loss: 0.0017909068847075105\n",
      "Epoch: 63, Avg. Train Loss: 0.001782266160494886, Avg. Test Loss: 0.0017351278802379966\n",
      "Epoch: 64, Avg. Train Loss: 0.0017269807272092548, Avg. Test Loss: 0.001684212009422481\n",
      "Epoch: 65, Avg. Train Loss: 0.0016716180834919214, Avg. Test Loss: 0.0016334212850779295\n",
      "Epoch: 66, Avg. Train Loss: 0.0016206034789468314, Avg. Test Loss: 0.0015895541291683912\n",
      "Epoch: 67, Avg. Train Loss: 0.0015739210458948862, Avg. Test Loss: 0.001536649651825428\n",
      "Epoch: 68, Avg. Train Loss: 0.0015275913106580807, Avg. Test Loss: 0.0015153157291933894\n",
      "Epoch: 69, Avg. Train Loss: 0.0014790225432925793, Avg. Test Loss: 0.0014449416194111109\n",
      "Epoch: 70, Avg. Train Loss: 0.0014417161948459094, Avg. Test Loss: 0.0014348814729601145\n",
      "Epoch: 71, Avg. Train Loss: 0.0013938247995061237, Avg. Test Loss: 0.001360638882033527\n",
      "Epoch: 72, Avg. Train Loss: 0.0013497684118446223, Avg. Test Loss: 0.001322264433838427\n",
      "Epoch: 73, Avg. Train Loss: 0.0013093744989397915, Avg. Test Loss: 0.001291160937398672\n",
      "Epoch: 74, Avg. Train Loss: 0.0012695681449935534, Avg. Test Loss: 0.0012427057372406125\n",
      "Epoch: 75, Avg. Train Loss: 0.001231532265042323, Avg. Test Loss: 0.0012050342047587037\n",
      "Epoch: 76, Avg. Train Loss: 0.0011937600062337033, Avg. Test Loss: 0.0011709877289831638\n",
      "Epoch: 77, Avg. Train Loss: 0.0011558561818674207, Avg. Test Loss: 0.0011402680538594723\n",
      "Epoch: 78, Avg. Train Loss: 0.0011259430727033422, Avg. Test Loss: 0.0011133668012917042\n",
      "Epoch: 79, Avg. Train Loss: 0.0010913652124229906, Avg. Test Loss: 0.001080938265658915\n",
      "Epoch: 80, Avg. Train Loss: 0.0010691377087929394, Avg. Test Loss: 0.0010514280293136835\n",
      "Epoch: 81, Avg. Train Loss: 0.0010445456624269313, Avg. Test Loss: 0.0010336021659895778\n",
      "Epoch: 82, Avg. Train Loss: 0.0010144347907043993, Avg. Test Loss: 0.0010015693260356784\n",
      "Epoch: 83, Avg. Train Loss: 0.0009900751242110895, Avg. Test Loss: 0.0010033242870122194\n",
      "Epoch: 84, Avg. Train Loss: 0.0009718527570691739, Avg. Test Loss: 0.0009599648765288293\n",
      "Epoch: 85, Avg. Train Loss: 0.0009458153711653553, Avg. Test Loss: 0.0009398051188327372\n",
      "Epoch: 86, Avg. Train Loss: 0.0009246991099898031, Avg. Test Loss: 0.0009280752274207771\n",
      "Epoch: 87, Avg. Train Loss: 0.000905023388250536, Avg. Test Loss: 0.0009001047001220286\n",
      "Epoch: 88, Avg. Train Loss: 0.0008878472713255432, Avg. Test Loss: 0.00089363002916798\n",
      "Epoch: 89, Avg. Train Loss: 0.0008702107521077228, Avg. Test Loss: 0.0008812730084173381\n",
      "Epoch: 90, Avg. Train Loss: 0.0008571524914830576, Avg. Test Loss: 0.0008914830978028476\n",
      "Epoch: 91, Avg. Train Loss: 0.000853517502925337, Avg. Test Loss: 0.0008377396734431386\n",
      "Epoch: 92, Avg. Train Loss: 0.0008218962899517527, Avg. Test Loss: 0.0008214603876695037\n",
      "Epoch: 93, Avg. Train Loss: 0.0008146891757564316, Avg. Test Loss: 0.0008082701824605465\n",
      "Epoch: 94, Avg. Train Loss: 0.0008025771659409064, Avg. Test Loss: 0.000800925015937537\n",
      "Epoch: 95, Avg. Train Loss: 0.0007809380876160291, Avg. Test Loss: 0.0007832428091205657\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 96, Avg. Train Loss: 0.0007672843125345575, Avg. Test Loss: 0.0007822668994776905\n",
      "Epoch: 97, Avg. Train Loss: 0.0007606591977893786, Avg. Test Loss: 0.0007644547149538994\n",
      "Epoch: 98, Avg. Train Loss: 0.0007482694264306406, Avg. Test Loss: 0.0007511418662033975\n",
      "Epoch: 99, Avg. Train Loss: 0.0007340044682022444, Avg. Test Loss: 0.0007406917284242809\n",
      "Epoch: 100, Avg. Train Loss: 0.000725801782357658, Avg. Test Loss: 0.000736924062948674\n",
      "Epoch: 101, Avg. Train Loss: 0.0007159413490985888, Avg. Test Loss: 0.000727673526853323\n",
      "Epoch: 102, Avg. Train Loss: 0.0007057063265292104, Avg. Test Loss: 0.0007204331923276186\n",
      "Epoch: 103, Avg. Train Loss: 0.0006951638876438834, Avg. Test Loss: 0.0006996665615588427\n",
      "Epoch: 104, Avg. Train Loss: 0.0006816309557274677, Avg. Test Loss: 0.0006846036412753165\n",
      "Epoch: 105, Avg. Train Loss: 0.0006657987386313115, Avg. Test Loss: 0.0006738916854374111\n",
      "Epoch: 106, Avg. Train Loss: 0.000643436695438225, Avg. Test Loss: 0.0006559969042427838\n",
      "Epoch: 107, Avg. Train Loss: 0.0006277107574088975, Avg. Test Loss: 0.0006320741958916187\n",
      "Epoch: 108, Avg. Train Loss: 0.000610886684478109, Avg. Test Loss: 0.0006205566460266709\n",
      "Epoch: 109, Avg. Train Loss: 0.0005969867031739722, Avg. Test Loss: 0.0006033451645635068\n",
      "Epoch: 110, Avg. Train Loss: 0.0005799133119411594, Avg. Test Loss: 0.0005908762686885893\n",
      "Epoch: 111, Avg. Train Loss: 0.0005686195042027637, Avg. Test Loss: 0.000581020605750382\n",
      "Epoch: 112, Avg. Train Loss: 0.0005583462960541595, Avg. Test Loss: 0.0005689876852557063\n",
      "Epoch: 113, Avg. Train Loss: 0.0005492881829796229, Avg. Test Loss: 0.0005595676484517753\n",
      "Epoch: 114, Avg. Train Loss: 0.0005407983661889163, Avg. Test Loss: 0.0005530760972760618\n",
      "Epoch: 115, Avg. Train Loss: 0.0005329422210072448, Avg. Test Loss: 0.0005410476005636156\n",
      "Epoch: 116, Avg. Train Loss: 0.0005243844636932535, Avg. Test Loss: 0.0005313450237736106\n",
      "Epoch: 117, Avg. Train Loss: 0.0005106483890707496, Avg. Test Loss: 0.000522452755831182\n",
      "Epoch: 118, Avg. Train Loss: 0.0005026019786127171, Avg. Test Loss: 0.0005142115405760705\n",
      "Epoch: 119, Avg. Train Loss: 0.0004933121658829149, Avg. Test Loss: 0.0005018074298277497\n",
      "Epoch: 120, Avg. Train Loss: 0.0004844147120439989, Avg. Test Loss: 0.0004946089466102421\n",
      "Epoch: 121, Avg. Train Loss: 0.0004785622769241156, Avg. Test Loss: 0.0004847388481721282\n",
      "Epoch: 122, Avg. Train Loss: 0.00046721393875994306, Avg. Test Loss: 0.0004752263776026666\n",
      "Epoch: 123, Avg. Train Loss: 0.00045956130177432367, Avg. Test Loss: 0.00047453976003453135\n",
      "Epoch: 124, Avg. Train Loss: 0.0004538268150036158, Avg. Test Loss: 0.00046149324043653905\n",
      "Epoch: 125, Avg. Train Loss: 0.0004435093446667198, Avg. Test Loss: 0.00045192314428277314\n",
      "Epoch: 126, Avg. Train Loss: 0.0004383068955449258, Avg. Test Loss: 0.00044789127423428\n",
      "Epoch: 127, Avg. Train Loss: 0.0004330664781073845, Avg. Test Loss: 0.0004435053269844502\n",
      "Epoch: 128, Avg. Train Loss: 0.00042839889579755796, Avg. Test Loss: 0.0004370498936623335\n",
      "Epoch: 129, Avg. Train Loss: 0.00042373816913188715, Avg. Test Loss: 0.00043194752652198076\n",
      "Epoch: 130, Avg. Train Loss: 0.0004191768259557267, Avg. Test Loss: 0.00042841798858717084\n",
      "Epoch: 131, Avg. Train Loss: 0.0004180840827080659, Avg. Test Loss: 0.0004265304596628994\n",
      "Epoch: 132, Avg. Train Loss: 0.0004141403593631938, Avg. Test Loss: 0.00042479741387069225\n",
      "Epoch: 133, Avg. Train Loss: 0.00041296535447716366, Avg. Test Loss: 0.00042235676664859056\n",
      "Epoch: 134, Avg. Train Loss: 0.00040928931327450065, Avg. Test Loss: 0.0004334251570980996\n",
      "Epoch: 135, Avg. Train Loss: 0.00040758981066214486, Avg. Test Loss: 0.000417647126596421\n",
      "Epoch: 136, Avg. Train Loss: 0.0004053962109664585, Avg. Test Loss: 0.00041423121001571417\n",
      "Epoch: 137, Avg. Train Loss: 0.0004040648806082128, Avg. Test Loss: 0.0004111724847462028\n",
      "Epoch: 138, Avg. Train Loss: 0.0004047045164719917, Avg. Test Loss: 0.0004194007196929306\n",
      "Epoch: 139, Avg. Train Loss: 0.0004000326376245899, Avg. Test Loss: 0.0004082716768607497\n",
      "Epoch: 140, Avg. Train Loss: 0.0003974295064243813, Avg. Test Loss: 0.0004192001069895923\n",
      "Epoch: 141, Avg. Train Loss: 0.0003972056384068416, Avg. Test Loss: 0.0004122578538954258\n",
      "Epoch: 142, Avg. Train Loss: 0.00039644417796977035, Avg. Test Loss: 0.0004155000497121364\n",
      "Epoch: 143, Avg. Train Loss: 0.00039547164504806146, Avg. Test Loss: 0.0004021096683572978\n",
      "Epoch: 144, Avg. Train Loss: 0.00039141617246990116, Avg. Test Loss: 0.00040430238004773855\n",
      "Epoch: 145, Avg. Train Loss: 0.0003938265117751651, Avg. Test Loss: 0.0003988737880717963\n",
      "Epoch: 146, Avg. Train Loss: 0.00039243216620931445, Avg. Test Loss: 0.0003992470446974039\n",
      "Epoch: 147, Avg. Train Loss: 0.00039082527536963825, Avg. Test Loss: 0.00039816086064092815\n",
      "Epoch: 148, Avg. Train Loss: 0.00038994566556391154, Avg. Test Loss: 0.0004033491713926196\n",
      "Epoch: 149, Avg. Train Loss: 0.00038741389018765024, Avg. Test Loss: 0.00039459532126784325\n",
      "Epoch: 150, Avg. Train Loss: 0.00038524402974195085, Avg. Test Loss: 0.0003996464656665921\n",
      "Epoch: 151, Avg. Train Loss: 0.00038695186417181653, Avg. Test Loss: 0.0003973781713284552\n",
      "Epoch: 152, Avg. Train Loss: 0.00038439082320194777, Avg. Test Loss: 0.00039679481415078044\n",
      "Epoch: 153, Avg. Train Loss: 0.0003811056694546498, Avg. Test Loss: 0.00038951385067775846\n",
      "Epoch: 154, Avg. Train Loss: 0.0003800744868999044, Avg. Test Loss: 0.0003905509365722537\n",
      "Epoch: 155, Avg. Train Loss: 0.00038025280539227954, Avg. Test Loss: 0.00039384167757816613\n",
      "Epoch: 156, Avg. Train Loss: 0.00037886629011048826, Avg. Test Loss: 0.00038817120366729796\n",
      "Epoch: 157, Avg. Train Loss: 0.0003797291510002038, Avg. Test Loss: 0.00038868843694217503\n",
      "Epoch: 158, Avg. Train Loss: 0.0003773105475607566, Avg. Test Loss: 0.0003865246835630387\n",
      "Epoch: 159, Avg. Train Loss: 0.00037836638241356543, Avg. Test Loss: 0.0004099478537682444\n",
      "Epoch: 160, Avg. Train Loss: 0.00037790019251947657, Avg. Test Loss: 0.000386556115699932\n",
      "Epoch: 161, Avg. Train Loss: 0.0003747194646695239, Avg. Test Loss: 0.0003856167895719409\n",
      "Epoch: 162, Avg. Train Loss: 0.0003764275359910328, Avg. Test Loss: 0.0003817774122580886\n",
      "Epoch: 163, Avg. Train Loss: 0.00037405456803457507, Avg. Test Loss: 0.0003850941429845989\n",
      "Epoch: 164, Avg. Train Loss: 0.0003713713119586193, Avg. Test Loss: 0.00038250163197517395\n",
      "Epoch: 165, Avg. Train Loss: 0.0003734684480235067, Avg. Test Loss: 0.0003792140632867813\n",
      "Epoch: 166, Avg. Train Loss: 0.000372141110981533, Avg. Test Loss: 0.0003777186793740839\n",
      "Epoch: 167, Avg. Train Loss: 0.0003700280970850483, Avg. Test Loss: 0.00037925070500932634\n",
      "Epoch: 168, Avg. Train Loss: 0.0003685072297230363, Avg. Test Loss: 0.00038482510717585683\n",
      "Epoch: 169, Avg. Train Loss: 0.00037157356124479585, Avg. Test Loss: 0.00037747781607322395\n",
      "Epoch: 170, Avg. Train Loss: 0.0003687710031531318, Avg. Test Loss: 0.00037478195736184716\n",
      "Epoch: 171, Avg. Train Loss: 0.0003694476550282521, Avg. Test Loss: 0.00037596301990561187\n",
      "Epoch: 172, Avg. Train Loss: 0.0003648911485026136, Avg. Test Loss: 0.0003735825011972338\n",
      "Epoch: 173, Avg. Train Loss: 0.00036427561670195226, Avg. Test Loss: 0.00037549776607193053\n",
      "Epoch: 174, Avg. Train Loss: 0.00036401111499926203, Avg. Test Loss: 0.0003730549942702055\n",
      "Epoch: 175, Avg. Train Loss: 0.0003696855876410683, Avg. Test Loss: 0.00038712879177182913\n",
      "Epoch: 176, Avg. Train Loss: 0.00036228274544809275, Avg. Test Loss: 0.0003733959747478366\n",
      "Epoch: 177, Avg. Train Loss: 0.00036242497248336844, Avg. Test Loss: 0.00037281206459738314\n",
      "Epoch: 178, Avg. Train Loss: 0.00036386095006343756, Avg. Test Loss: 0.00037400491419248283\n",
      "Epoch: 179, Avg. Train Loss: 0.0003618531417762211, Avg. Test Loss: 0.00037125099333934486\n",
      "Epoch: 180, Avg. Train Loss: 0.00036061206374988824, Avg. Test Loss: 0.00036844328860752285\n",
      "Epoch: 181, Avg. Train Loss: 0.0003622950252340457, Avg. Test Loss: 0.00040259171510115266\n",
      "Epoch: 182, Avg. Train Loss: 0.0003645738037194797, Avg. Test Loss: 0.0003812798240687698\n",
      "Epoch: 183, Avg. Train Loss: 0.00036104507527725643, Avg. Test Loss: 0.0003654944302979857\n",
      "Epoch: 184, Avg. Train Loss: 0.00035734868508243805, Avg. Test Loss: 0.00036769182770513\n",
      "Epoch: 185, Avg. Train Loss: 0.00035994946970171186, Avg. Test Loss: 0.00037311227060854435\n",
      "Epoch: 186, Avg. Train Loss: 0.0003577756768547345, Avg. Test Loss: 0.0003689173317980021\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 187, Avg. Train Loss: 0.00035816753082800395, Avg. Test Loss: 0.00037736320518888533\n",
      "Epoch: 188, Avg. Train Loss: 0.0003598135047278172, Avg. Test Loss: 0.00036342773819342256\n",
      "Epoch: 189, Avg. Train Loss: 0.0003549871386873514, Avg. Test Loss: 0.00036466625169850886\n",
      "Epoch: 190, Avg. Train Loss: 0.0003570846706996997, Avg. Test Loss: 0.0003648290876299143\n",
      "Epoch: 191, Avg. Train Loss: 0.000361161385689927, Avg. Test Loss: 0.00036418551462702453\n",
      "Epoch: 192, Avg. Train Loss: 0.0003546036090864258, Avg. Test Loss: 0.00036787064163945615\n",
      "Epoch: 193, Avg. Train Loss: 0.00035468355730869047, Avg. Test Loss: 0.0003629263665061444\n",
      "Epoch: 194, Avg. Train Loss: 0.0003538310553521178, Avg. Test Loss: 0.00036169920349493623\n",
      "Epoch: 195, Avg. Train Loss: 0.0003521746162563389, Avg. Test Loss: 0.00036071843351237476\n",
      "Epoch: 196, Avg. Train Loss: 0.00035154161606590416, Avg. Test Loss: 0.0003611047868616879\n",
      "Epoch: 197, Avg. Train Loss: 0.0003512677612043051, Avg. Test Loss: 0.0003622269141487777\n",
      "Epoch: 198, Avg. Train Loss: 0.00035203702349843847, Avg. Test Loss: 0.0003618462069425732\n",
      "Epoch: 199, Avg. Train Loss: 0.00035405417208473174, Avg. Test Loss: 0.0003669705183710903\n",
      "Epoch: 200, Avg. Train Loss: 0.00035052379013883857, Avg. Test Loss: 0.00035993920755572617\n",
      "Epoch: 201, Avg. Train Loss: 0.0003493517660265139, Avg. Test Loss: 0.00036055053351446986\n",
      "Epoch: 202, Avg. Train Loss: 0.0003511319999572236, Avg. Test Loss: 0.00035804990329779685\n",
      "Epoch: 203, Avg. Train Loss: 0.00034897550290753675, Avg. Test Loss: 0.0003633147571235895\n",
      "Epoch: 204, Avg. Train Loss: 0.00034966748979397465, Avg. Test Loss: 0.0003575375012587756\n",
      "Epoch: 205, Avg. Train Loss: 0.0003490369959171255, Avg. Test Loss: 0.000394659407902509\n",
      "Epoch: 206, Avg. Train Loss: 0.0003535778222464805, Avg. Test Loss: 0.00036055638338439167\n",
      "Epoch: 207, Avg. Train Loss: 0.00034746875699479565, Avg. Test Loss: 0.0003580570628400892\n",
      "Epoch: 208, Avg. Train Loss: 0.0003497512120385329, Avg. Test Loss: 0.0003617163747549057\n",
      "Epoch: 209, Avg. Train Loss: 0.00035120178755849253, Avg. Test Loss: 0.00036404989077709615\n",
      "Epoch: 210, Avg. Train Loss: 0.0003494560376058744, Avg. Test Loss: 0.00035678385756909847\n",
      "Epoch: 211, Avg. Train Loss: 0.00035036533399550025, Avg. Test Loss: 0.0003521709004417062\n",
      "Epoch: 212, Avg. Train Loss: 0.0003460989743850172, Avg. Test Loss: 0.00035344346542842686\n",
      "Epoch: 273, Avg. Train Loss: 0.0003083361946262939, Avg. Test Loss: 0.00032065881532616913\n",
      "Epoch: 274, Avg. Train Loss: 0.0003096299268965891, Avg. Test Loss: 0.0003161757776979357\n",
      "Epoch: 275, Avg. Train Loss: 0.00030495658608933174, Avg. Test Loss: 0.0003134283178951591\n",
      "Epoch: 276, Avg. Train Loss: 0.00030464780798485113, Avg. Test Loss: 0.0003145877562928945\n",
      "Epoch: 277, Avg. Train Loss: 0.00031449983226741816, Avg. Test Loss: 0.00030910022906027734\n",
      "Epoch: 278, Avg. Train Loss: 0.0003087509939241288, Avg. Test Loss: 0.0003243254031985998\n",
      "Epoch: 279, Avg. Train Loss: 0.0003041075386897509, Avg. Test Loss: 0.00030756500200368464\n",
      "Epoch: 280, Avg. Train Loss: 0.00030154490513120626, Avg. Test Loss: 0.0003124307550024241\n",
      "Epoch: 281, Avg. Train Loss: 0.0003025120538442807, Avg. Test Loss: 0.00030636609881184995\n",
      "Epoch: 282, Avg. Train Loss: 0.0003007175400853157, Avg. Test Loss: 0.00030604389030486345\n",
      "Epoch: 283, Avg. Train Loss: 0.0003044317316718746, Avg. Test Loss: 0.00030556609272025526\n",
      "Epoch: 284, Avg. Train Loss: 0.0003025352516276545, Avg. Test Loss: 0.0003284291015006602\n",
      "Epoch: 285, Avg. Train Loss: 0.0003053334793400799, Avg. Test Loss: 0.000316790712531656\n",
      "Epoch: 286, Avg. Train Loss: 0.0002984062431455958, Avg. Test Loss: 0.0003064660122618079\n",
      "Epoch: 287, Avg. Train Loss: 0.0002972069419758005, Avg. Test Loss: 0.00030255227466113865\n",
      "Epoch: 288, Avg. Train Loss: 0.00029722316973019653, Avg. Test Loss: 0.00030488247284665704\n",
      "Epoch: 289, Avg. Train Loss: 0.00029788956216666415, Avg. Test Loss: 0.0002982691512443125\n",
      "Epoch: 290, Avg. Train Loss: 0.00029269863274706485, Avg. Test Loss: 0.00030181187321431935\n",
      "Epoch: 291, Avg. Train Loss: 0.00029863060322092024, Avg. Test Loss: 0.00029736722353845835\n",
      "Epoch: 292, Avg. Train Loss: 0.00029180106114011343, Avg. Test Loss: 0.0003006573533639312\n",
      "Epoch: 293, Avg. Train Loss: 0.00029087758915455537, Avg. Test Loss: 0.00029772441484965384\n",
      "Epoch: 294, Avg. Train Loss: 0.0002897988123613475, Avg. Test Loss: 0.0002952960494440049\n",
      "Epoch: 295, Avg. Train Loss: 0.00028986976343900136, Avg. Test Loss: 0.0003042549651581794\n",
      "Epoch: 296, Avg. Train Loss: 0.00029968037973916115, Avg. Test Loss: 0.0002931134367827326\n",
      "Epoch: 297, Avg. Train Loss: 0.00028924267335664913, Avg. Test Loss: 0.0003025422047358006\n",
      "Epoch: 298, Avg. Train Loss: 0.0002886837498598927, Avg. Test Loss: 0.0002956278040073812\n",
      "Epoch: 299, Avg. Train Loss: 0.0002875386055039112, Avg. Test Loss: 0.00029285813798196614\n",
      "Epoch: 300, Avg. Train Loss: 0.0002888460152208545, Avg. Test Loss: 0.0002920673578046262\n",
      "Epoch: 301, Avg. Train Loss: 0.0002899921646742367, Avg. Test Loss: 0.0002943629224319011\n",
      "Epoch: 302, Avg. Train Loss: 0.00028560093947859524, Avg. Test Loss: 0.0002892168704420328\n",
      "Epoch: 303, Avg. Train Loss: 0.0002888513452828277, Avg. Test Loss: 0.0002919224789366126\n",
      "Epoch: 304, Avg. Train Loss: 0.000284970287899595, Avg. Test Loss: 0.0002897939120884985\n",
      "Epoch: 305, Avg. Train Loss: 0.000286414754999325, Avg. Test Loss: 0.0002939189434982836\n",
      "Epoch: 306, Avg. Train Loss: 0.00028818773530791836, Avg. Test Loss: 0.0003088101220782846\n",
      "Epoch: 307, Avg. Train Loss: 0.0002839987512764543, Avg. Test Loss: 0.00028748411568813026\n",
      "Epoch: 308, Avg. Train Loss: 0.0002837978698703092, Avg. Test Loss: 0.0002864615526050329\n",
      "Epoch: 309, Avg. Train Loss: 0.00028486102027547826, Avg. Test Loss: 0.00028652625042013824\n",
      "Epoch: 310, Avg. Train Loss: 0.00028230406636328893, Avg. Test Loss: 0.000289013929432258\n",
      "Epoch: 311, Avg. Train Loss: 0.00028117132633058135, Avg. Test Loss: 0.00028473729616962373\n",
      "Epoch: 312, Avg. Train Loss: 0.0002794831762426035, Avg. Test Loss: 0.0002932756033260375\n",
      "Epoch: 313, Avg. Train Loss: 0.0002849647182386455, Avg. Test Loss: 0.0002821723173838109\n",
      "Epoch: 314, Avg. Train Loss: 0.0002847373895726145, Avg. Test Loss: 0.0002848708245437592\n",
      "Epoch: 315, Avg. Train Loss: 0.00027987444069409786, Avg. Test Loss: 0.00028187286807224154\n",
      "Epoch: 316, Avg. Train Loss: 0.00027943353864450963, Avg. Test Loss: 0.0002850407618097961\n",
      "Epoch: 317, Avg. Train Loss: 0.00027783738677985534, Avg. Test Loss: 0.0002887433802243322\n",
      "Epoch: 318, Avg. Train Loss: 0.00027983484053334525, Avg. Test Loss: 0.00028097713948227465\n",
      "Epoch: 319, Avg. Train Loss: 0.00028150539227956255, Avg. Test Loss: 0.0002819274668581784\n",
      "Epoch: 320, Avg. Train Loss: 0.00027807631941382274, Avg. Test Loss: 0.00028326240135356784\n",
      "Epoch: 321, Avg. Train Loss: 0.00027651014754028863, Avg. Test Loss: 0.0002842234680429101\n",
      "Epoch: 322, Avg. Train Loss: 0.0002755653299255903, Avg. Test Loss: 0.0002826784329954535\n",
      "Epoch: 323, Avg. Train Loss: 0.00028114736237195, Avg. Test Loss: 0.00029112177435308695\n",
      "Epoch: 324, Avg. Train Loss: 0.0002788365365081835, Avg. Test Loss: 0.00028433112311176956\n",
      "Epoch: 325, Avg. Train Loss: 0.0002750633281065411, Avg. Test Loss: 0.0002753158041741699\n",
      "Epoch: 326, Avg. Train Loss: 0.00027271974046692946, Avg. Test Loss: 0.00027470162604004145\n",
      "Epoch: 327, Avg. Train Loss: 0.00027156110885444767, Avg. Test Loss: 0.0002743730728980154\n",
      "Epoch: 328, Avg. Train Loss: 0.00027277696671960657, Avg. Test Loss: 0.00027442851569503546\n",
      "Epoch: 329, Avg. Train Loss: 0.00027067663735536816, Avg. Test Loss: 0.0002750868152361363\n",
      "Epoch: 330, Avg. Train Loss: 0.0002710653481149483, Avg. Test Loss: 0.00027852613129653037\n",
      "Epoch: 331, Avg. Train Loss: 0.00027115283016830165, Avg. Test Loss: 0.00027689547277987003\n",
      "Epoch: 332, Avg. Train Loss: 0.0002705999399632822, Avg. Test Loss: 0.00027185317594558\n",
      "Epoch: 333, Avg. Train Loss: 0.0002708425691221343, Avg. Test Loss: 0.0002872584154829383\n",
      "Epoch: 334, Avg. Train Loss: 0.0002696934003155505, Avg. Test Loss: 0.0002753640874288976\n",
      "Epoch: 335, Avg. Train Loss: 0.00027043613988288873, Avg. Test Loss: 0.00027239826158620417\n",
      "Epoch: 336, Avg. Train Loss: 0.00027131698118674374, Avg. Test Loss: 0.0002765943354461342\n",
      "Epoch: 337, Avg. Train Loss: 0.00026868490115089646, Avg. Test Loss: 0.00027464237064123154\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 338, Avg. Train Loss: 0.00026654930166672744, Avg. Test Loss: 0.0002693083952181041\n",
      "Epoch: 339, Avg. Train Loss: 0.0002670641846380868, Avg. Test Loss: 0.00027037758263759315\n",
      "Epoch: 340, Avg. Train Loss: 0.00026731640384749096, Avg. Test Loss: 0.00027674721786752343\n",
      "Epoch: 341, Avg. Train Loss: 0.00026937138978229446, Avg. Test Loss: 0.0002747678372543305\n",
      "Epoch: 342, Avg. Train Loss: 0.00027055949240728, Avg. Test Loss: 0.00026930065359920263\n",
      "Epoch: 343, Avg. Train Loss: 0.00026860079480345945, Avg. Test Loss: 0.00026946570142172277\n",
      "Epoch: 344, Avg. Train Loss: 0.00026594228713589093, Avg. Test Loss: 0.0002877934603020549\n",
      "Epoch: 345, Avg. Train Loss: 0.0002667776831469044, Avg. Test Loss: 0.00027741966187022626\n",
      "Epoch: 346, Avg. Train Loss: 0.0002679253717191344, Avg. Test Loss: 0.0002687986707314849\n",
      "Epoch: 347, Avg. Train Loss: 0.0002656001499502075, Avg. Test Loss: 0.0002727799292188138\n",
      "Epoch: 348, Avg. Train Loss: 0.0002653292846611463, Avg. Test Loss: 0.0002665119245648384\n",
      "Epoch: 349, Avg. Train Loss: 0.00026372969989816463, Avg. Test Loss: 0.00026852553128264844\n",
      "Epoch: 350, Avg. Train Loss: 0.0002624799878482685, Avg. Test Loss: 0.00027644573128782213\n",
      "Epoch: 351, Avg. Train Loss: 0.00026428770053276226, Avg. Test Loss: 0.0002734670997597277\n",
      "Epoch: 352, Avg. Train Loss: 0.00026387436691736584, Avg. Test Loss: 0.000287411967292428\n",
      "Epoch: 353, Avg. Train Loss: 0.0002669848716238427, Avg. Test Loss: 0.0002702796773519367\n",
      "Epoch: 354, Avg. Train Loss: 0.0002649034560268182, Avg. Test Loss: 0.0002699756878428161\n",
      "Epoch: 355, Avg. Train Loss: 0.0002620764175527404, Avg. Test Loss: 0.0002701533667277545\n",
      "Epoch: 356, Avg. Train Loss: 0.00026256781711708754, Avg. Test Loss: 0.0002653957053553313\n",
      "Epoch: 357, Avg. Train Loss: 0.0002617511676954712, Avg. Test Loss: 0.00026590973720885813\n",
      "Epoch: 358, Avg. Train Loss: 0.0002632946470416649, Avg. Test Loss: 0.0002732718421611935\n",
      "Epoch: 359, Avg. Train Loss: 0.0002646978929649692, Avg. Test Loss: 0.00026824817177839577\n",
      "Epoch: 360, Avg. Train Loss: 0.00026215239580948077, Avg. Test Loss: 0.00026461444213055074\n",
      "Epoch: 361, Avg. Train Loss: 0.00026364157756054123, Avg. Test Loss: 0.0002646664797794074\n",
      "Epoch: 362, Avg. Train Loss: 0.0002602473172754439, Avg. Test Loss: 0.00026271515525877476\n",
      "Epoch: 363, Avg. Train Loss: 0.00026034657216663363, Avg. Test Loss: 0.0002656459400895983\n",
      "Epoch: 364, Avg. Train Loss: 0.0002625705775815647, Avg. Test Loss: 0.0002618207654450089\n",
      "Epoch: 365, Avg. Train Loss: 0.00025870835376080387, Avg. Test Loss: 0.0002625569759402424\n",
      "Epoch: 366, Avg. Train Loss: 0.0002582006594355673, Avg. Test Loss: 0.00026319213793613017\n",
      "Epoch: 367, Avg. Train Loss: 0.0002588384502518619, Avg. Test Loss: 0.00026682380121201277\n",
      "Epoch: 368, Avg. Train Loss: 0.000256583807640709, Avg. Test Loss: 0.0002611572854220867\n",
      "Epoch: 369, Avg. Train Loss: 0.00025895173149724856, Avg. Test Loss: 0.00026239181170240045\n",
      "Epoch: 370, Avg. Train Loss: 0.0002563780973676246, Avg. Test Loss: 0.00026133397477678955\n",
      "Epoch: 371, Avg. Train Loss: 0.0002576148578745508, Avg. Test Loss: 0.0002635243290569633\n",
      "Epoch: 372, Avg. Train Loss: 0.000257742046013063, Avg. Test Loss: 0.0002617614227347076\n",
      "Epoch: 373, Avg. Train Loss: 0.00025796705483307325, Avg. Test Loss: 0.00026868682471103966\n",
      "Epoch: 374, Avg. Train Loss: 0.00025858883651211687, Avg. Test Loss: 0.00026355250156484544\n",
      "Epoch: 375, Avg. Train Loss: 0.00026191636712864303, Avg. Test Loss: 0.0002613875549286604\n",
      "Epoch: 376, Avg. Train Loss: 0.0002584425711511569, Avg. Test Loss: 0.0002597977581899613\n",
      "Epoch: 377, Avg. Train Loss: 0.0002591281738078092, Avg. Test Loss: 0.0002641838800627738\n",
      "Epoch: 378, Avg. Train Loss: 0.0002600345560918064, Avg. Test Loss: 0.000265086127910763\n",
      "Epoch: 379, Avg. Train Loss: 0.0002552790883359997, Avg. Test Loss: 0.0002599171129986644\n",
      "Epoch: 380, Avg. Train Loss: 0.000260866777077967, Avg. Test Loss: 0.0002613909309729934\n",
      "Epoch: 381, Avg. Train Loss: 0.0002587567761047678, Avg. Test Loss: 0.0002606242196634412\n",
      "Epoch: 382, Avg. Train Loss: 0.00025849328762147746, Avg. Test Loss: 0.0002629118680488318\n",
      "Epoch: 383, Avg. Train Loss: 0.00025693005151223653, Avg. Test Loss: 0.00025841096066869795\n",
      "Epoch: 384, Avg. Train Loss: 0.00025432776601519436, Avg. Test Loss: 0.00025978346820920706\n",
      "Epoch: 385, Avg. Train Loss: 0.00025622837169659, Avg. Test Loss: 0.0002600617881398648\n",
      "Epoch: 386, Avg. Train Loss: 0.00025646109201642143, Avg. Test Loss: 0.00026036688359454274\n",
      "Epoch: 387, Avg. Train Loss: 0.0002581390517027399, Avg. Test Loss: 0.0002877173537854105\n",
      "Epoch: 388, Avg. Train Loss: 0.00026111765040442086, Avg. Test Loss: 0.000282095221336931\n",
      "Epoch: 389, Avg. Train Loss: 0.0002567266989878357, Avg. Test Loss: 0.0002620855811983347\n",
      "Epoch: 390, Avg. Train Loss: 0.00025892408150464814, Avg. Test Loss: 0.0002586302871350199\n",
      "Epoch: 391, Avg. Train Loss: 0.00025550319561409916, Avg. Test Loss: 0.0002591630909591913\n",
      "Epoch: 392, Avg. Train Loss: 0.00025468123677392423, Avg. Test Loss: 0.00026190761127509177\n",
      "Epoch: 393, Avg. Train Loss: 0.000253003511271916, Avg. Test Loss: 0.00025710463523864746\n",
      "Epoch: 394, Avg. Train Loss: 0.00025207398568962287, Avg. Test Loss: 0.0002576327824499458\n",
      "Epoch: 395, Avg. Train Loss: 0.0002510454072508701, Avg. Test Loss: 0.000258220883551985\n",
      "Epoch: 396, Avg. Train Loss: 0.0002533379911044396, Avg. Test Loss: 0.0002569375210441649\n",
      "Epoch: 397, Avg. Train Loss: 0.0002540758811614238, Avg. Test Loss: 0.0002594565157778561\n",
      "Epoch: 398, Avg. Train Loss: 0.00025313126490462224, Avg. Test Loss: 0.0002633504045661539\n",
      "Epoch: 399, Avg. Train Loss: 0.0002530493470975523, Avg. Test Loss: 0.00026820608763955534\n",
      "Epoch: 400, Avg. Train Loss: 0.0002592307174318405, Avg. Test Loss: 0.00025768723571673036\n",
      "Epoch: 401, Avg. Train Loss: 0.00025319055109934577, Avg. Test Loss: 0.00026442305534146726\n",
      "Epoch: 402, Avg. Train Loss: 0.0002502339508324905, Avg. Test Loss: 0.00025698624085634947\n",
      "Epoch: 403, Avg. Train Loss: 0.00024973523402369995, Avg. Test Loss: 0.0002589030482340604\n",
      "Epoch: 404, Avg. Train Loss: 0.0002514590258130717, Avg. Test Loss: 0.0002593010722193867\n",
      "Epoch: 405, Avg. Train Loss: 0.0002508629187887405, Avg. Test Loss: 0.0002570399083197117\n",
      "Epoch: 406, Avg. Train Loss: 0.0002494703387424653, Avg. Test Loss: 0.0002586774353403598\n",
      "Epoch: 407, Avg. Train Loss: 0.0002566444793131289, Avg. Test Loss: 0.0002617856953293085\n",
      "Epoch: 408, Avg. Train Loss: 0.0002503697902538142, Avg. Test Loss: 0.00026209832867607474\n",
      "Epoch: 409, Avg. Train Loss: 0.00025090147222684654, Avg. Test Loss: 0.0002672912087291479\n",
      "Epoch: 410, Avg. Train Loss: 0.00025188981326632634, Avg. Test Loss: 0.0002552010118961334\n",
      "Epoch: 411, Avg. Train Loss: 0.00025140849276456635, Avg. Test Loss: 0.00025623265537433326\n",
      "Epoch: 412, Avg. Train Loss: 0.0002493486898074056, Avg. Test Loss: 0.0002578666899353266\n",
      "Epoch: 413, Avg. Train Loss: 0.00025013662423927684, Avg. Test Loss: 0.00025551917497068644\n",
      "Epoch: 414, Avg. Train Loss: 0.0002500159127182912, Avg. Test Loss: 0.0002644137421157211\n",
      "Epoch: 415, Avg. Train Loss: 0.00025180052474498487, Avg. Test Loss: 0.00027808413142338395\n",
      "Epoch: 416, Avg. Train Loss: 0.00025096456933127673, Avg. Test Loss: 0.0002536335668992251\n",
      "Epoch: 417, Avg. Train Loss: 0.000249152677878196, Avg. Test Loss: 0.00025560628273524344\n",
      "Epoch: 418, Avg. Train Loss: 0.0002496368062227618, Avg. Test Loss: 0.0002592014498077333\n",
      "Epoch: 419, Avg. Train Loss: 0.00025131799880317735, Avg. Test Loss: 0.0002581320295576006\n",
      "Epoch: 420, Avg. Train Loss: 0.0002473751594025512, Avg. Test Loss: 0.00025267942692153156\n",
      "Epoch: 421, Avg. Train Loss: 0.00024681222397660794, Avg. Test Loss: 0.000252792815444991\n",
      "Epoch: 422, Avg. Train Loss: 0.00024938423810580873, Avg. Test Loss: 0.00026919704396277666\n",
      "Epoch: 423, Avg. Train Loss: 0.0002479784686096706, Avg. Test Loss: 0.0002524351584725082\n",
      "Epoch: 424, Avg. Train Loss: 0.0002465910788592991, Avg. Test Loss: 0.00025473220739513636\n",
      "Epoch: 425, Avg. Train Loss: 0.0002455437030686542, Avg. Test Loss: 0.0002550149511080235\n",
      "Epoch: 426, Avg. Train Loss: 0.0002461782166582727, Avg. Test Loss: 0.00025258815730921924\n",
      "Epoch: 427, Avg. Train Loss: 0.00024819675004542915, Avg. Test Loss: 0.0002575982070993632\n",
      "Epoch: 428, Avg. Train Loss: 0.00024605169655419454, Avg. Test Loss: 0.0002551742654759437\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 429, Avg. Train Loss: 0.00024325378390765466, Avg. Test Loss: 0.00024942305753938854\n",
      "Epoch: 430, Avg. Train Loss: 0.00024368379164898637, Avg. Test Loss: 0.0002522219147067517\n",
      "Epoch: 431, Avg. Train Loss: 0.0002433232720102032, Avg. Test Loss: 0.0002484485739842057\n",
      "Epoch: 432, Avg. Train Loss: 0.00024646006864333136, Avg. Test Loss: 0.0002524235169403255\n",
      "Epoch: 433, Avg. Train Loss: 0.00024443779169137827, Avg. Test Loss: 0.00026392508880235255\n",
      "Epoch: 434, Avg. Train Loss: 0.00024394067931584582, Avg. Test Loss: 0.0002516502281650901\n",
      "Epoch: 435, Avg. Train Loss: 0.00024302166901518006, Avg. Test Loss: 0.0002479002869222313\n",
      "Epoch: 436, Avg. Train Loss: 0.00024158026627806384, Avg. Test Loss: 0.0002570901997387409\n",
      "Epoch: 437, Avg. Train Loss: 0.00024258639009636936, Avg. Test Loss: 0.00024985597701743245\n",
      "Epoch: 438, Avg. Train Loss: 0.00024242673392764965, Avg. Test Loss: 0.00025244776043109596\n",
      "Epoch: 439, Avg. Train Loss: 0.00024359107293665062, Avg. Test Loss: 0.00025872664991766214\n",
      "Epoch: 440, Avg. Train Loss: 0.00024008079124668744, Avg. Test Loss: 0.00024519136059097946\n",
      "Epoch: 441, Avg. Train Loss: 0.0002395314097453212, Avg. Test Loss: 0.0002460064715705812\n",
      "Epoch: 442, Avg. Train Loss: 0.00024073821428870825, Avg. Test Loss: 0.0002473888744134456\n",
      "Epoch: 443, Avg. Train Loss: 0.00023816774503143808, Avg. Test Loss: 0.0002474302891641855\n",
      "Epoch: 444, Avg. Train Loss: 0.00024130506384143128, Avg. Test Loss: 0.00025569662102498114\n",
      "Epoch: 445, Avg. Train Loss: 0.00023983911574590778, Avg. Test Loss: 0.00024351968022529036\n",
      "Epoch: 446, Avg. Train Loss: 0.0002376617448198674, Avg. Test Loss: 0.00025097921025007963\n",
      "Epoch: 447, Avg. Train Loss: 0.0002378673336013805, Avg. Test Loss: 0.00024842977290973067\n",
      "Epoch: 448, Avg. Train Loss: 0.0002411286499578679, Avg. Test Loss: 0.0002432293549645692\n",
      "Epoch: 449, Avg. Train Loss: 0.00023821210772946997, Avg. Test Loss: 0.00024362653493881226\n",
      "Epoch: 450, Avg. Train Loss: 0.00024063165264399074, Avg. Test Loss: 0.00025172746973112226\n",
      "Epoch: 451, Avg. Train Loss: 0.0002389749478911548, Avg. Test Loss: 0.00024383854179177433\n",
      "Epoch: 452, Avg. Train Loss: 0.0002376676180405369, Avg. Test Loss: 0.0002529607154428959\n",
      "Epoch: 453, Avg. Train Loss: 0.0002424651076665235, Avg. Test Loss: 0.00024754280457273126\n",
      "Epoch: 454, Avg. Train Loss: 0.00023901219334897348, Avg. Test Loss: 0.0002558875421527773\n",
      "Epoch: 455, Avg. Train Loss: 0.0002372596107645307, Avg. Test Loss: 0.00024173970450647175\n",
      "Epoch: 456, Avg. Train Loss: 0.00023603300004926793, Avg. Test Loss: 0.00024523696629330516\n",
      "Epoch: 457, Avg. Train Loss: 0.00023633238844584327, Avg. Test Loss: 0.00024525608750991523\n",
      "Epoch: 458, Avg. Train Loss: 0.00023711137852609851, Avg. Test Loss: 0.0002497429377399385\n",
      "Epoch: 459, Avg. Train Loss: 0.00023577008450533762, Avg. Test Loss: 0.0002412868634564802\n",
      "Epoch: 460, Avg. Train Loss: 0.00023944716735439765, Avg. Test Loss: 0.00027708549168892205\n",
      "Epoch: 461, Avg. Train Loss: 0.000237881206314426, Avg. Test Loss: 0.000245197385083884\n",
      "Epoch: 462, Avg. Train Loss: 0.0002357546642130284, Avg. Test Loss: 0.0002428652223898098\n",
      "Epoch: 463, Avg. Train Loss: 0.00023478743360312872, Avg. Test Loss: 0.00024745482369326055\n",
      "Epoch: 464, Avg. Train Loss: 0.00023593315292897007, Avg. Test Loss: 0.00024354920606128871\n",
      "Epoch: 465, Avg. Train Loss: 0.00023616597172804177, Avg. Test Loss: 0.00025192444445565343\n",
      "Epoch: 466, Avg. Train Loss: 0.00023762675253999267, Avg. Test Loss: 0.00024494013632647693\n",
      "Epoch: 467, Avg. Train Loss: 0.00023414801974066122, Avg. Test Loss: 0.0002450000320095569\n",
      "Epoch: 468, Avg. Train Loss: 0.0002342089530091386, Avg. Test Loss: 0.00024118153669405729\n",
      "Epoch: 469, Avg. Train Loss: 0.0002331238339498076, Avg. Test Loss: 0.0002564876922406256\n",
      "Epoch: 470, Avg. Train Loss: 0.00023439961829396007, Avg. Test Loss: 0.000265930691966787\n",
      "Epoch: 471, Avg. Train Loss: 0.00023519799389421593, Avg. Test Loss: 0.0002520383568480611\n",
      "Epoch: 472, Avg. Train Loss: 0.0002348694779780195, Avg. Test Loss: 0.0002413485781289637\n",
      "Epoch: 473, Avg. Train Loss: 0.00023336305491474652, Avg. Test Loss: 0.00024231984571088105\n",
      "Epoch: 474, Avg. Train Loss: 0.00023307502310354868, Avg. Test Loss: 0.0002528276527300477\n",
      "Epoch: 475, Avg. Train Loss: 0.00024031290072449592, Avg. Test Loss: 0.0002450244501233101\n",
      "Epoch: 476, Avg. Train Loss: 0.00023317879044212574, Avg. Test Loss: 0.00023843429517000914\n",
      "Epoch: 477, Avg. Train Loss: 0.0002340178359381118, Avg. Test Loss: 0.00023798414622433484\n",
      "Epoch: 478, Avg. Train Loss: 0.00023588897636008644, Avg. Test Loss: 0.0002388149732723832\n",
      "Epoch: 479, Avg. Train Loss: 0.00023149015641836233, Avg. Test Loss: 0.00024173615383915603\n",
      "Epoch: 480, Avg. Train Loss: 0.0002315429094799816, Avg. Test Loss: 0.0002393869508523494\n",
      "Epoch: 481, Avg. Train Loss: 0.0002310804110345279, Avg. Test Loss: 0.00024365507124457508\n",
      "Epoch: 482, Avg. Train Loss: 0.00023264400924956642, Avg. Test Loss: 0.00024083346943370998\n",
      "Epoch: 483, Avg. Train Loss: 0.0002342726917515054, Avg. Test Loss: 0.00025142476079054177\n",
      "Epoch: 484, Avg. Train Loss: 0.00023245153986567327, Avg. Test Loss: 0.00024465395836159587\n",
      "Epoch: 485, Avg. Train Loss: 0.0002316018264621583, Avg. Test Loss: 0.00023939338279888034\n",
      "Epoch: 486, Avg. Train Loss: 0.00023141698600442776, Avg. Test Loss: 0.00024060079886112362\n",
      "Epoch: 487, Avg. Train Loss: 0.00023108873912945475, Avg. Test Loss: 0.0002528392360545695\n",
      "Epoch: 488, Avg. Train Loss: 0.00023580588864671544, Avg. Test Loss: 0.00024127901997417212\n",
      "Epoch: 489, Avg. Train Loss: 0.00023152785873863587, Avg. Test Loss: 0.00024189920804928988\n",
      "Epoch: 490, Avg. Train Loss: 0.000232130833251705, Avg. Test Loss: 0.00024152305559255183\n",
      "Epoch: 491, Avg. Train Loss: 0.00023615999258296607, Avg. Test Loss: 0.000259661755990237\n",
      "Epoch: 492, Avg. Train Loss: 0.00023557138690172673, Avg. Test Loss: 0.00023707954096607864\n",
      "Epoch: 493, Avg. Train Loss: 0.00023080651251718317, Avg. Test Loss: 0.00024909613421186805\n",
      "Epoch: 494, Avg. Train Loss: 0.00022973867808739372, Avg. Test Loss: 0.00024156419385690242\n",
      "Epoch: 495, Avg. Train Loss: 0.00023079432917997068, Avg. Test Loss: 0.0002397986245341599\n",
      "Epoch: 496, Avg. Train Loss: 0.00023159412816058585, Avg. Test Loss: 0.00023898424115031958\n",
      "Epoch: 497, Avg. Train Loss: 0.00023358372015726947, Avg. Test Loss: 0.00023633072851225734\n",
      "Epoch: 498, Avg. Train Loss: 0.0002335766787223821, Avg. Test Loss: 0.00024157164443749934\n",
      "Epoch: 499, Avg. Train Loss: 0.00023299173910853042, Avg. Test Loss: 0.00023733153648208827\n",
      "Epoch: 500, Avg. Train Loss: 0.00023197646247396288, Avg. Test Loss: 0.00024475809186697006\n",
      "Epoch: 501, Avg. Train Loss: 0.00023360009275398455, Avg. Test Loss: 0.00024081158335320652\n",
      "Epoch: 502, Avg. Train Loss: 0.00023175584596343512, Avg. Test Loss: 0.0002386118285357952\n",
      "Epoch: 503, Avg. Train Loss: 0.0002311631071998543, Avg. Test Loss: 0.00023519480600953102\n",
      "Epoch: 504, Avg. Train Loss: 0.00023306496536120946, Avg. Test Loss: 0.00024628991377539933\n",
      "Epoch: 505, Avg. Train Loss: 0.00023332488557951914, Avg. Test Loss: 0.0002499295223969966\n",
      "Epoch: 506, Avg. Train Loss: 0.00023091983606464902, Avg. Test Loss: 0.0002399342629360035\n",
      "Epoch: 507, Avg. Train Loss: 0.0002297165121363346, Avg. Test Loss: 0.0002372182789258659\n",
      "Epoch: 508, Avg. Train Loss: 0.00022888067990628092, Avg. Test Loss: 0.00023826831602491438\n",
      "Epoch: 509, Avg. Train Loss: 0.00022817944240117403, Avg. Test Loss: 0.00023451802553609014\n",
      "Epoch: 510, Avg. Train Loss: 0.00022939576694287013, Avg. Test Loss: 0.0002372339804423973\n",
      "Epoch: 511, Avg. Train Loss: 0.00023043117970553075, Avg. Test Loss: 0.00023589684860780835\n",
      "Epoch: 512, Avg. Train Loss: 0.00022898694746694418, Avg. Test Loss: 0.00023907949798740447\n",
      "Epoch: 513, Avg. Train Loss: 0.00022856166909806172, Avg. Test Loss: 0.00023576927196700126\n",
      "Epoch: 514, Avg. Train Loss: 0.00022830979270470697, Avg. Test Loss: 0.00023721075558569282\n",
      "Epoch: 515, Avg. Train Loss: 0.00022739500279787407, Avg. Test Loss: 0.0002349395799683407\n",
      "Epoch: 516, Avg. Train Loss: 0.0002279344368807235, Avg. Test Loss: 0.00023509094899054617\n",
      "Epoch: 517, Avg. Train Loss: 0.0002278277919855142, Avg. Test Loss: 0.0002378640929237008\n",
      "Epoch: 518, Avg. Train Loss: 0.00022727959426553098, Avg. Test Loss: 0.00023923190019559115\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 519, Avg. Train Loss: 0.0002296033266628551, Avg. Test Loss: 0.00023692796821705997\n",
      "Epoch: 520, Avg. Train Loss: 0.0002288014369442799, Avg. Test Loss: 0.00023563497234135866\n",
      "Epoch: 521, Avg. Train Loss: 0.00022690641716783218, Avg. Test Loss: 0.0002423696278128773\n",
      "Epoch: 522, Avg. Train Loss: 0.00023065695673129847, Avg. Test Loss: 0.00023450535081792623\n",
      "Epoch: 523, Avg. Train Loss: 0.00023044476950227088, Avg. Test Loss: 0.0002561045694164932\n",
      "Epoch: 524, Avg. Train Loss: 0.00022965686925047966, Avg. Test Loss: 0.00023785329540260136\n",
      "Epoch: 525, Avg. Train Loss: 0.00023011038645690438, Avg. Test Loss: 0.0002380034711677581\n",
      "Epoch: 526, Avg. Train Loss: 0.00022935733398108548, Avg. Test Loss: 0.00023756548762321472\n",
      "Epoch: 527, Avg. Train Loss: 0.0002275367722938617, Avg. Test Loss: 0.0002424259582767263\n",
      "Epoch: 528, Avg. Train Loss: 0.00022848413615530834, Avg. Test Loss: 0.00023791755666024983\n",
      "Epoch: 529, Avg. Train Loss: 0.0002296014653713724, Avg. Test Loss: 0.0002342164661968127\n",
      "Epoch: 530, Avg. Train Loss: 0.00022645195476375088, Avg. Test Loss: 0.00023340649204328656\n",
      "Epoch: 531, Avg. Train Loss: 0.00022648423125014403, Avg. Test Loss: 0.0002395328920101747\n",
      "Epoch: 532, Avg. Train Loss: 0.0002285994106746647, Avg. Test Loss: 0.00023775582667440176\n",
      "Epoch: 533, Avg. Train Loss: 0.00023023940475256897, Avg. Test Loss: 0.0002437774237478152\n",
      "Epoch: 534, Avg. Train Loss: 0.0002298520070495257, Avg. Test Loss: 0.00023804439115338027\n",
      "Epoch: 535, Avg. Train Loss: 0.00022669195476377946, Avg. Test Loss: 0.0002432830078760162\n",
      "Epoch: 536, Avg. Train Loss: 0.00022998943838269212, Avg. Test Loss: 0.00023530496400780976\n",
      "Epoch: 537, Avg. Train Loss: 0.00022593406563743864, Avg. Test Loss: 0.00023870858422014862\n",
      "Epoch: 538, Avg. Train Loss: 0.000227441142521647, Avg. Test Loss: 0.00023562413116451353\n",
      "Epoch: 539, Avg. Train Loss: 0.0002267025800308126, Avg. Test Loss: 0.00024376038345508277\n",
      "Epoch: 540, Avg. Train Loss: 0.00022677398187942197, Avg. Test Loss: 0.00023329912801273167\n",
      "Epoch: 541, Avg. Train Loss: 0.00022617608124693466, Avg. Test Loss: 0.00023308607342187315\n",
      "Epoch: 542, Avg. Train Loss: 0.0002251979448226129, Avg. Test Loss: 0.0002363803650951013\n",
      "Epoch: 543, Avg. Train Loss: 0.00022653909061688844, Avg. Test Loss: 0.00024089669750537723\n",
      "Epoch: 544, Avg. Train Loss: 0.0002277208005516725, Avg. Test Loss: 0.00023436552146449685\n",
      "Epoch: 545, Avg. Train Loss: 0.00022586181503991314, Avg. Test Loss: 0.0002497154928278178\n",
      "Epoch: 546, Avg. Train Loss: 0.00022602312200496969, Avg. Test Loss: 0.00023254237021319568\n",
      "Epoch: 547, Avg. Train Loss: 0.00022873010311741382, Avg. Test Loss: 0.00023612493532709777\n",
      "Epoch: 548, Avg. Train Loss: 0.00022543963893630737, Avg. Test Loss: 0.0002317478065378964\n",
      "Epoch: 549, Avg. Train Loss: 0.00022830103177490623, Avg. Test Loss: 0.0002346965338801965\n",
      "Epoch: 550, Avg. Train Loss: 0.0002277152126162248, Avg. Test Loss: 0.00023977700038813055\n",
      "Epoch: 551, Avg. Train Loss: 0.00022779937852498923, Avg. Test Loss: 0.0002328156988369301\n",
      "Epoch: 552, Avg. Train Loss: 0.00022580117179449042, Avg. Test Loss: 0.00023728114319965243\n",
      "Epoch: 553, Avg. Train Loss: 0.00022747977616449514, Avg. Test Loss: 0.00023112834605854005\n",
      "Epoch: 554, Avg. Train Loss: 0.00022496540893984654, Avg. Test Loss: 0.00023440865334123373\n",
      "Epoch: 555, Avg. Train Loss: 0.00022695536710332732, Avg. Test Loss: 0.00023369633709080517\n",
      "Epoch: 556, Avg. Train Loss: 0.0002226594254796848, Avg. Test Loss: 0.00023561465786769986\n",
      "Epoch: 557, Avg. Train Loss: 0.00022607314742852523, Avg. Test Loss: 0.0002319406485185027\n",
      "Epoch: 558, Avg. Train Loss: 0.0002292982735102563, Avg. Test Loss: 0.00023286518990062177\n",
      "Epoch: 559, Avg. Train Loss: 0.000224430818952685, Avg. Test Loss: 0.00023615827376488596\n",
      "Epoch: 560, Avg. Train Loss: 0.00022688520724376186, Avg. Test Loss: 0.000243074944592081\n",
      "Epoch: 561, Avg. Train Loss: 0.00022670943669021823, Avg. Test Loss: 0.00023891072487458587\n",
      "Epoch: 562, Avg. Train Loss: 0.0002263143241031875, Avg. Test Loss: 0.0002367732668062672\n",
      "Epoch: 563, Avg. Train Loss: 0.0002247962672913144, Avg. Test Loss: 0.00023549955221824348\n",
      "Epoch: 564, Avg. Train Loss: 0.00022343992016029133, Avg. Test Loss: 0.00023277345462702215\n",
      "Epoch: 565, Avg. Train Loss: 0.0002253863153042445, Avg. Test Loss: 0.00024484185269102454\n",
      "Epoch: 566, Avg. Train Loss: 0.00022946003259993484, Avg. Test Loss: 0.0002336853794986382\n",
      "Epoch: 567, Avg. Train Loss: 0.0002255398177049058, Avg. Test Loss: 0.00023455054906662554\n",
      "Epoch: 568, Avg. Train Loss: 0.00022485617515739312, Avg. Test Loss: 0.00023213797248899937\n",
      "Epoch: 569, Avg. Train Loss: 0.0002255701164844944, Avg. Test Loss: 0.0002293544530402869\n",
      "Epoch: 570, Avg. Train Loss: 0.0002243267128590581, Avg. Test Loss: 0.00023480354866478592\n",
      "Epoch: 571, Avg. Train Loss: 0.00022084199042373532, Avg. Test Loss: 0.00023069215239956975\n",
      "Epoch: 572, Avg. Train Loss: 0.00022223947751119212, Avg. Test Loss: 0.00023743006750009954\n",
      "Epoch: 573, Avg. Train Loss: 0.00022267403830990716, Avg. Test Loss: 0.000230805337196216\n",
      "Epoch: 574, Avg. Train Loss: 0.0002204721274401256, Avg. Test Loss: 0.00022904641809873283\n",
      "Epoch: 575, Avg. Train Loss: 0.00022092591910243987, Avg. Test Loss: 0.00023301057808566839\n",
      "Epoch: 576, Avg. Train Loss: 0.00022385373737305662, Avg. Test Loss: 0.00023221064475364983\n",
      "Epoch: 577, Avg. Train Loss: 0.00022292928939392833, Avg. Test Loss: 0.00023062633408699185\n",
      "Epoch: 578, Avg. Train Loss: 0.000223379107706552, Avg. Test Loss: 0.00023266520292963833\n",
      "Epoch: 579, Avg. Train Loss: 0.00022266937154453507, Avg. Test Loss: 0.00023142895952332765\n",
      "Epoch: 580, Avg. Train Loss: 0.00022694691887049567, Avg. Test Loss: 0.00023151017376221716\n",
      "Epoch: 581, Avg. Train Loss: 0.0002206243983426586, Avg. Test Loss: 0.00022962834918871522\n",
      "Epoch: 582, Avg. Train Loss: 0.00022351405472321393, Avg. Test Loss: 0.00022752546647097915\n",
      "Epoch: 583, Avg. Train Loss: 0.00022309717450150137, Avg. Test Loss: 0.00023151675122790039\n",
      "Epoch: 584, Avg. Train Loss: 0.0002217752406194936, Avg. Test Loss: 0.00023299254826270044\n",
      "Epoch: 585, Avg. Train Loss: 0.000221771756281838, Avg. Test Loss: 0.00023413082817569375\n",
      "Epoch: 586, Avg. Train Loss: 0.00022350877136273614, Avg. Test Loss: 0.00023123635037336498\n",
      "Epoch: 587, Avg. Train Loss: 0.0002204547477155101, Avg. Test Loss: 0.00023027595307212323\n",
      "Epoch: 588, Avg. Train Loss: 0.00022248495783017906, Avg. Test Loss: 0.000229774130275473\n",
      "Epoch: 589, Avg. Train Loss: 0.00022348037651512598, Avg. Test Loss: 0.00024419205146841705\n",
      "Epoch: 590, Avg. Train Loss: 0.00022371840523826607, Avg. Test Loss: 0.0002299461921211332\n",
      "Epoch: 591, Avg. Train Loss: 0.0002214927940364104, Avg. Test Loss: 0.0002276160812471062\n",
      "Epoch: 592, Avg. Train Loss: 0.00021912019563091615, Avg. Test Loss: 0.00022701469424646348\n",
      "Epoch: 593, Avg. Train Loss: 0.00022081635231801936, Avg. Test Loss: 0.00022898035240359604\n",
      "Epoch: 594, Avg. Train Loss: 0.0002216577569163556, Avg. Test Loss: 0.00023024850816000253\n",
      "Epoch: 595, Avg. Train Loss: 0.00021947269513390873, Avg. Test Loss: 0.00022984022507444024\n",
      "Epoch: 596, Avg. Train Loss: 0.00022015824702806597, Avg. Test Loss: 0.0002283794165123254\n",
      "Epoch: 597, Avg. Train Loss: 0.00022063401783545784, Avg. Test Loss: 0.00022684744908474386\n",
      "Epoch: 598, Avg. Train Loss: 0.00021850146410098777, Avg. Test Loss: 0.00023166873143054545\n",
      "Epoch: 599, Avg. Train Loss: 0.0002202838148277383, Avg. Test Loss: 0.00022601019009016454\n",
      "Epoch: 600, Avg. Train Loss: 0.00022183881522979328, Avg. Test Loss: 0.00022947901743464172\n",
      "Epoch: 601, Avg. Train Loss: 0.00022083089814174835, Avg. Test Loss: 0.00022897518647368997\n",
      "Epoch: 602, Avg. Train Loss: 0.0002216404692410643, Avg. Test Loss: 0.000226963558816351\n",
      "Epoch: 603, Avg. Train Loss: 0.00021972435934003443, Avg. Test Loss: 0.000231162688578479\n",
      "Epoch: 604, Avg. Train Loss: 0.0002221717183792227, Avg. Test Loss: 0.00023537954257335514\n",
      "Epoch: 605, Avg. Train Loss: 0.00022044457389626567, Avg. Test Loss: 0.00022850357345305383\n",
      "Epoch: 606, Avg. Train Loss: 0.00022262028251980367, Avg. Test Loss: 0.0002359914651606232\n",
      "Epoch: 607, Avg. Train Loss: 0.00021939803433312146, Avg. Test Loss: 0.0002315374294994399\n",
      "Epoch: 608, Avg. Train Loss: 0.00022313262398224756, Avg. Test Loss: 0.00022577967320103198\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 609, Avg. Train Loss: 0.00021819355301992146, Avg. Test Loss: 0.0002327883121324703\n",
      "Epoch: 610, Avg. Train Loss: 0.00021803544443046543, Avg. Test Loss: 0.0002274561848025769\n",
      "Epoch: 611, Avg. Train Loss: 0.0002182124386985548, Avg. Test Loss: 0.00023014315229374915\n",
      "Epoch: 612, Avg. Train Loss: 0.00022145283718452637, Avg. Test Loss: 0.00023466604761779308\n",
      "Epoch: 613, Avg. Train Loss: 0.00021898806254855942, Avg. Test Loss: 0.0002388337888987735\n",
      "Epoch: 614, Avg. Train Loss: 0.00022010323672750316, Avg. Test Loss: 0.00023749507090542465\n",
      "Epoch: 615, Avg. Train Loss: 0.00022048195201340457, Avg. Test Loss: 0.0002274354628752917\n",
      "Epoch: 616, Avg. Train Loss: 0.00022044391263016436, Avg. Test Loss: 0.00022550398716703057\n",
      "Epoch: 617, Avg. Train Loss: 0.000218498750338006, Avg. Test Loss: 0.00023855007020756602\n",
      "Epoch: 618, Avg. Train Loss: 0.00021829931363246815, Avg. Test Loss: 0.00022598124633077532\n",
      "Epoch: 619, Avg. Train Loss: 0.00021949010734652105, Avg. Test Loss: 0.0002265210059704259\n",
      "Epoch: 620, Avg. Train Loss: 0.0002177161970690196, Avg. Test Loss: 0.00022755758254788816\n",
      "Epoch: 621, Avg. Train Loss: 0.00022420055959861032, Avg. Test Loss: 0.000248790456680581\n",
      "Epoch: 622, Avg. Train Loss: 0.00021864860663786098, Avg. Test Loss: 0.0002282501955050975\n",
      "Epoch: 623, Avg. Train Loss: 0.00021660948229065643, Avg. Test Loss: 0.0002232024125987664\n",
      "Epoch: 624, Avg. Train Loss: 0.00021925446886006137, Avg. Test Loss: 0.00023196052643470466\n",
      "Epoch: 625, Avg. Train Loss: 0.00021659188733306214, Avg. Test Loss: 0.00022300441924016923\n",
      "Epoch: 626, Avg. Train Loss: 0.00021532416610361272, Avg. Test Loss: 0.0002234804560430348\n",
      "Epoch: 627, Avg. Train Loss: 0.00021538306210395816, Avg. Test Loss: 0.00022574390459340066\n",
      "Epoch: 628, Avg. Train Loss: 0.00021839522496732168, Avg. Test Loss: 0.0002257514133816585\n",
      "Epoch: 629, Avg. Train Loss: 0.0002165299509976839, Avg. Test Loss: 0.0002312366705155\n",
      "Epoch: 630, Avg. Train Loss: 0.00021800943338961968, Avg. Test Loss: 0.00023345115187112242\n",
      "Epoch: 631, Avg. Train Loss: 0.00021618186783175483, Avg. Test Loss: 0.0002234006387880072\n",
      "Epoch: 632, Avg. Train Loss: 0.00021627250934279588, Avg. Test Loss: 0.0002340584760531783\n",
      "Epoch: 633, Avg. Train Loss: 0.0002189505730923482, Avg. Test Loss: 0.00022274674847722054\n",
      "Epoch: 634, Avg. Train Loss: 0.00021508419148483162, Avg. Test Loss: 0.0002339957281947136\n",
      "Epoch: 635, Avg. Train Loss: 0.00021913956050750215, Avg. Test Loss: 0.0002304993395227939\n",
      "Epoch: 636, Avg. Train Loss: 0.0002193761350543693, Avg. Test Loss: 0.00023363891523331404\n",
      "Epoch: 637, Avg. Train Loss: 0.00021687721824111027, Avg. Test Loss: 0.00022315591922961175\n",
      "Epoch: 638, Avg. Train Loss: 0.00021843804177817304, Avg. Test Loss: 0.0002241412439616397\n",
      "Epoch: 639, Avg. Train Loss: 0.00021584052490990956, Avg. Test Loss: 0.0002254308492410928\n",
      "Epoch: 640, Avg. Train Loss: 0.00021566509514191556, Avg. Test Loss: 0.00022305204765871167\n",
      "Epoch: 641, Avg. Train Loss: 0.00021507538148461905, Avg. Test Loss: 0.00022359128342941403\n",
      "Epoch: 642, Avg. Train Loss: 0.0002176863571823856, Avg. Test Loss: 0.0002274194994242862\n",
      "Epoch: 643, Avg. Train Loss: 0.00021534523761528002, Avg. Test Loss: 0.00022356114641297609\n",
      "Epoch: 644, Avg. Train Loss: 0.0002147582664863791, Avg. Test Loss: 0.00022180337691679597\n",
      "Epoch: 645, Avg. Train Loss: 0.00021303334743120209, Avg. Test Loss: 0.00022379875008482486\n",
      "Epoch: 646, Avg. Train Loss: 0.00021471521955221718, Avg. Test Loss: 0.00022257670934777707\n",
      "Epoch: 647, Avg. Train Loss: 0.00021772158669232023, Avg. Test Loss: 0.00022285319573711604\n",
      "Epoch: 648, Avg. Train Loss: 0.00021612835434796072, Avg. Test Loss: 0.00023298276937566698\n",
      "Epoch: 649, Avg. Train Loss: 0.00021736782455686912, Avg. Test Loss: 0.0002272993588121608\n",
      "Epoch: 650, Avg. Train Loss: 0.00021514846966331176, Avg. Test Loss: 0.0002231926773674786\n",
      "Epoch: 651, Avg. Train Loss: 0.00021485224309334054, Avg. Test Loss: 0.00022342335432767868\n",
      "Epoch: 652, Avg. Train Loss: 0.0002143180575140557, Avg. Test Loss: 0.00022365414770320058\n",
      "Epoch: 653, Avg. Train Loss: 0.0002140590083801599, Avg. Test Loss: 0.00022374780382961035\n",
      "Epoch: 654, Avg. Train Loss: 0.0002142198930012582, Avg. Test Loss: 0.0002233862178400159\n",
      "Epoch: 655, Avg. Train Loss: 0.00021328344713723244, Avg. Test Loss: 0.0002216380089521408\n",
      "Epoch: 656, Avg. Train Loss: 0.00021396901899797105, Avg. Test Loss: 0.00022253072529565543\n",
      "Epoch: 657, Avg. Train Loss: 0.00021281313363646784, Avg. Test Loss: 0.00023152738867793232\n",
      "Epoch: 658, Avg. Train Loss: 0.00021586221707768218, Avg. Test Loss: 0.00022048325627110898\n",
      "Epoch: 659, Avg. Train Loss: 0.00021264200243654898, Avg. Test Loss: 0.00022325629834085703\n",
      "Epoch: 660, Avg. Train Loss: 0.00021548477254623851, Avg. Test Loss: 0.00022500884369947016\n",
      "Epoch: 661, Avg. Train Loss: 0.00021394948998931795, Avg. Test Loss: 0.00022673072817269713\n",
      "Epoch: 662, Avg. Train Loss: 0.00021348730796341632, Avg. Test Loss: 0.0002227199584012851\n",
      "Epoch: 663, Avg. Train Loss: 0.0002161400997740498, Avg. Test Loss: 0.00022975429601501673\n",
      "Epoch: 664, Avg. Train Loss: 0.0002147380555682101, Avg. Test Loss: 0.00022233005438465625\n",
      "Epoch: 665, Avg. Train Loss: 0.00021300562163327583, Avg. Test Loss: 0.0002247325173811987\n",
      "Epoch: 666, Avg. Train Loss: 0.00021342207849578022, Avg. Test Loss: 0.00022285136219579726\n",
      "Epoch: 667, Avg. Train Loss: 0.00021328060714484646, Avg. Test Loss: 0.00022420556342694908\n",
      "Epoch: 668, Avg. Train Loss: 0.0002124401555277494, Avg. Test Loss: 0.00022169756994117051\n",
      "Epoch: 669, Avg. Train Loss: 0.00021376207993409143, Avg. Test Loss: 0.00022090999118518084\n",
      "Epoch: 670, Avg. Train Loss: 0.0002142738944818374, Avg. Test Loss: 0.00022067248937673867\n",
      "Epoch: 671, Avg. Train Loss: 0.00021463119645527196, Avg. Test Loss: 0.00021906037000007927\n",
      "Epoch: 672, Avg. Train Loss: 0.00021124435189385834, Avg. Test Loss: 0.0002206895442213863\n",
      "Epoch: 673, Avg. Train Loss: 0.0002124593474734358, Avg. Test Loss: 0.0002216259017586708\n",
      "Epoch: 674, Avg. Train Loss: 0.00021336878599804762, Avg. Test Loss: 0.00024102028692141175\n",
      "Epoch: 675, Avg. Train Loss: 0.00021677056793123484, Avg. Test Loss: 0.00023269187659025192\n",
      "Epoch: 676, Avg. Train Loss: 0.00021426973398774862, Avg. Test Loss: 0.0002279542968608439\n",
      "Epoch: 677, Avg. Train Loss: 0.00021235214216028188, Avg. Test Loss: 0.00021988821390550584\n",
      "Epoch: 678, Avg. Train Loss: 0.0002118693414241682, Avg. Test Loss: 0.00022014281421434134\n",
      "Epoch: 679, Avg. Train Loss: 0.00021179474356887472, Avg. Test Loss: 0.00022198102669790387\n",
      "Epoch: 680, Avg. Train Loss: 0.00021717662491218382, Avg. Test Loss: 0.00021941632439848036\n",
      "Epoch: 681, Avg. Train Loss: 0.00021086227579237245, Avg. Test Loss: 0.00021983959595672786\n",
      "Epoch: 682, Avg. Train Loss: 0.0002116063507517453, Avg. Test Loss: 0.00022177986102178693\n",
      "Epoch: 683, Avg. Train Loss: 0.00020992904590161213, Avg. Test Loss: 0.00022144247486721724\n",
      "Epoch: 684, Avg. Train Loss: 0.00021186310372878472, Avg. Test Loss: 0.00021921352890785784\n",
      "Epoch: 685, Avg. Train Loss: 0.00021061954544694705, Avg. Test Loss: 0.00021889391064178199\n",
      "Epoch: 686, Avg. Train Loss: 0.00021184895791351622, Avg. Test Loss: 0.00022647895093541592\n",
      "Epoch: 687, Avg. Train Loss: 0.00021409803932413544, Avg. Test Loss: 0.00021910340001340955\n",
      "Epoch: 688, Avg. Train Loss: 0.00021037914273112492, Avg. Test Loss: 0.0002184559270972386\n",
      "Epoch: 689, Avg. Train Loss: 0.00021086396347612228, Avg. Test Loss: 0.00022023629571776837\n",
      "Epoch: 690, Avg. Train Loss: 0.0002137819744327084, Avg. Test Loss: 0.00022311529028229415\n",
      "Epoch: 691, Avg. Train Loss: 0.0002118230940839059, Avg. Test Loss: 0.00021812260092701763\n",
      "Epoch: 692, Avg. Train Loss: 0.00020972393225705208, Avg. Test Loss: 0.0002223715273430571\n",
      "Epoch: 693, Avg. Train Loss: 0.00020990507077523182, Avg. Test Loss: 0.0002192487590946257\n",
      "Epoch: 694, Avg. Train Loss: 0.00021127874923729186, Avg. Test Loss: 0.00022306246683001518\n",
      "Epoch: 695, Avg. Train Loss: 0.00021213102682363674, Avg. Test Loss: 0.00021795439533889294\n",
      "Epoch: 696, Avg. Train Loss: 0.0002107203367496516, Avg. Test Loss: 0.00021969513909425586\n",
      "Epoch: 697, Avg. Train Loss: 0.00020970532577214114, Avg. Test Loss: 0.00022285401064436883\n",
      "Epoch: 698, Avg. Train Loss: 0.00021014469276388112, Avg. Test Loss: 0.00021950030350126326\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 699, Avg. Train Loss: 0.00020880619812551019, Avg. Test Loss: 0.00022571157023776323\n",
      "Epoch: 700, Avg. Train Loss: 0.00021180454919082222, Avg. Test Loss: 0.00022357866691891104\n",
      "Epoch: 701, Avg. Train Loss: 0.0002114507829943715, Avg. Test Loss: 0.00022710546909365803\n",
      "Epoch: 702, Avg. Train Loss: 0.00021077730242152114, Avg. Test Loss: 0.00022186418937053531\n",
      "Epoch: 703, Avg. Train Loss: 0.0002104488159475718, Avg. Test Loss: 0.00022648471349384636\n",
      "Epoch: 704, Avg. Train Loss: 0.00020938403132848095, Avg. Test Loss: 0.00022852564870845526\n",
      "Epoch: 705, Avg. Train Loss: 0.00020977426902391016, Avg. Test Loss: 0.00021940076840110123\n",
      "Epoch: 706, Avg. Train Loss: 0.00020910283282594107, Avg. Test Loss: 0.00022100111527834088\n",
      "Epoch: 707, Avg. Train Loss: 0.00021243830100459935, Avg. Test Loss: 0.00022829898807685822\n",
      "Epoch: 708, Avg. Train Loss: 0.00020807140796488629, Avg. Test Loss: 0.00022646882280241698\n",
      "Epoch: 709, Avg. Train Loss: 0.0002100718580592467, Avg. Test Loss: 0.00021994145936332643\n",
      "Epoch: 710, Avg. Train Loss: 0.00021013719717387195, Avg. Test Loss: 0.0002174055262003094\n",
      "Epoch: 711, Avg. Train Loss: 0.00020681333465523324, Avg. Test Loss: 0.00021652807481586933\n",
      "Epoch: 712, Avg. Train Loss: 0.00020755165619342478, Avg. Test Loss: 0.00022099293710198253\n",
      "Epoch: 713, Avg. Train Loss: 0.00020797879686903988, Avg. Test Loss: 0.0002140615979442373\n",
      "Epoch: 714, Avg. Train Loss: 0.00020853433044638138, Avg. Test Loss: 0.00021529487275984138\n",
      "Epoch: 715, Avg. Train Loss: 0.0002081653876175974, Avg. Test Loss: 0.0002137837145710364\n",
      "Epoch: 716, Avg. Train Loss: 0.00020574402303683982, Avg. Test Loss: 0.00021772418403998017\n",
      "Epoch: 717, Avg. Train Loss: 0.00020805419947908714, Avg. Test Loss: 0.00022036726295482367\n",
      "Epoch: 718, Avg. Train Loss: 0.0002091002801492767, Avg. Test Loss: 0.00021755350462626666\n",
      "Epoch: 719, Avg. Train Loss: 0.00021400864521680442, Avg. Test Loss: 0.00022012829140294343\n",
      "Epoch: 720, Avg. Train Loss: 0.00020871772924925438, Avg. Test Loss: 0.00021633668802678585\n",
      "Epoch: 721, Avg. Train Loss: 0.00021244591097943052, Avg. Test Loss: 0.00022923678625375032\n",
      "Epoch: 722, Avg. Train Loss: 0.00020938707234034704, Avg. Test Loss: 0.00021874252706766129\n",
      "Epoch: 723, Avg. Train Loss: 0.00020674539616244824, Avg. Test Loss: 0.00021685600222554058\n",
      "Epoch: 724, Avg. Train Loss: 0.00020632651556001672, Avg. Test Loss: 0.00021566513169091195\n",
      "Epoch: 725, Avg. Train Loss: 0.00020565457207551442, Avg. Test Loss: 0.00021672423463314772\n",
      "Epoch: 726, Avg. Train Loss: 0.0002083517164316808, Avg. Test Loss: 0.00022171885939314961\n",
      "Epoch: 727, Avg. Train Loss: 0.00020763518892466848, Avg. Test Loss: 0.0002252101548947394\n",
      "Epoch: 728, Avg. Train Loss: 0.00020525622659438658, Avg. Test Loss: 0.0002205384662374854\n",
      "Epoch: 729, Avg. Train Loss: 0.00020621287830033187, Avg. Test Loss: 0.00021454819943755865\n",
      "Epoch: 730, Avg. Train Loss: 0.00020628445037250775, Avg. Test Loss: 0.00021920791186857969\n",
      "Epoch: 731, Avg. Train Loss: 0.0002088222285830091, Avg. Test Loss: 0.00021991530957166106\n",
      "Epoch: 732, Avg. Train Loss: 0.00020617996965166787, Avg. Test Loss: 0.00021178752649575472\n",
      "Epoch: 733, Avg. Train Loss: 0.00020666163093897752, Avg. Test Loss: 0.00021558103617280722\n",
      "Epoch: 734, Avg. Train Loss: 0.0002052614358416217, Avg. Test Loss: 0.00021509524958673865\n",
      "Epoch: 735, Avg. Train Loss: 0.00020519374946922843, Avg. Test Loss: 0.00021211066632531583\n",
      "Epoch: 736, Avg. Train Loss: 0.00020417561592144329, Avg. Test Loss: 0.00021331418247427791\n",
      "Epoch: 737, Avg. Train Loss: 0.00020669375615313564, Avg. Test Loss: 0.000219026580452919\n",
      "Epoch: 738, Avg. Train Loss: 0.0002052957932518925, Avg. Test Loss: 0.00021221634233370423\n",
      "Epoch: 739, Avg. Train Loss: 0.00020570434233292852, Avg. Test Loss: 0.00021354545606300235\n",
      "Epoch: 740, Avg. Train Loss: 0.00020349885879875009, Avg. Test Loss: 0.00021061628649476916\n",
      "Epoch: 741, Avg. Train Loss: 0.00020346798437246837, Avg. Test Loss: 0.00022283427824731916\n",
      "Epoch: 742, Avg. Train Loss: 0.00020565355784086468, Avg. Test Loss: 0.00021235851454548538\n",
      "Epoch: 743, Avg. Train Loss: 0.00020504066365944264, Avg. Test Loss: 0.00021817843662574887\n",
      "Epoch: 744, Avg. Train Loss: 0.00020493466784733585, Avg. Test Loss: 0.00021397616364993155\n",
      "Epoch: 745, Avg. Train Loss: 0.0002088288578264372, Avg. Test Loss: 0.00021699526405427605\n",
      "Epoch: 746, Avg. Train Loss: 0.0002044253464149268, Avg. Test Loss: 0.00021396488591562957\n",
      "Epoch: 747, Avg. Train Loss: 0.00020197453011141353, Avg. Test Loss: 0.0002155355759896338\n",
      "Epoch: 748, Avg. Train Loss: 0.00020298877559049965, Avg. Test Loss: 0.00021189152903389186\n",
      "Epoch: 749, Avg. Train Loss: 0.0002033562073890163, Avg. Test Loss: 0.00020951757323928177\n",
      "Epoch: 750, Avg. Train Loss: 0.00020350553677417338, Avg. Test Loss: 0.0002100347337545827\n",
      "Epoch: 751, Avg. Train Loss: 0.0002045591093117891, Avg. Test Loss: 0.00021382325212471187\n",
      "Epoch: 752, Avg. Train Loss: 0.00020524082322290904, Avg. Test Loss: 0.0002118685661116615\n",
      "Epoch: 753, Avg. Train Loss: 0.00020067687559233936, Avg. Test Loss: 0.00021348509471863508\n",
      "Epoch: 754, Avg. Train Loss: 0.00020199722500767038, Avg. Test Loss: 0.00021237788314465433\n",
      "Epoch: 755, Avg. Train Loss: 0.00020113251500947097, Avg. Test Loss: 0.0002132575900759548\n",
      "Epoch: 756, Avg. Train Loss: 0.00020267237634343896, Avg. Test Loss: 0.00021384688443504274\n",
      "Epoch: 757, Avg. Train Loss: 0.00020477230569921693, Avg. Test Loss: 0.00021260605717543513\n",
      "Epoch: 758, Avg. Train Loss: 0.0002049394584731957, Avg. Test Loss: 0.00021529197692871094\n",
      "Epoch: 759, Avg. Train Loss: 0.00020197119569232645, Avg. Test Loss: 0.00021049502538517118\n",
      "Epoch: 760, Avg. Train Loss: 0.00020207937293805097, Avg. Test Loss: 0.00021453697991091758\n",
      "Epoch: 761, Avg. Train Loss: 0.00020110640853513464, Avg. Test Loss: 0.00021433315123431385\n",
      "Epoch: 762, Avg. Train Loss: 0.000201963878447883, Avg. Test Loss: 0.00021109674707986414\n",
      "Epoch: 763, Avg. Train Loss: 0.00020097850802960958, Avg. Test Loss: 0.00020861522352788597\n",
      "Epoch: 764, Avg. Train Loss: 0.00020172267233097363, Avg. Test Loss: 0.00021016690880060196\n",
      "Epoch: 765, Avg. Train Loss: 0.00019952460350522902, Avg. Test Loss: 0.00020819126802962273\n",
      "Epoch: 766, Avg. Train Loss: 0.0001999831857934031, Avg. Test Loss: 0.0002122496662195772\n",
      "Epoch: 767, Avg. Train Loss: 0.00020136419977440477, Avg. Test Loss: 0.00021700745855923742\n",
      "Epoch: 768, Avg. Train Loss: 0.0001985869681067375, Avg. Test Loss: 0.00020875212794635445\n",
      "Epoch: 769, Avg. Train Loss: 0.00020043659030708895, Avg. Test Loss: 0.00020677193242590874\n",
      "Epoch: 770, Avg. Train Loss: 0.00019992033201053218, Avg. Test Loss: 0.00020771889830939472\n",
      "Epoch: 771, Avg. Train Loss: 0.00020007054398626868, Avg. Test Loss: 0.00020958305685780942\n",
      "Epoch: 772, Avg. Train Loss: 0.00019859843806168713, Avg. Test Loss: 0.00021074932010378689\n",
      "Epoch: 773, Avg. Train Loss: 0.0001985000417334959, Avg. Test Loss: 0.0002147795894416049\n",
      "Epoch: 774, Avg. Train Loss: 0.00020120997147006524, Avg. Test Loss: 0.00021277472842484713\n",
      "Epoch: 775, Avg. Train Loss: 0.000198120319319694, Avg. Test Loss: 0.00020787300309166312\n",
      "Epoch: 776, Avg. Train Loss: 0.0001981183639483873, Avg. Test Loss: 0.00020842916273977607\n",
      "Epoch: 777, Avg. Train Loss: 0.00020102172620258793, Avg. Test Loss: 0.00020738445164170116\n",
      "Epoch: 778, Avg. Train Loss: 0.00019985621221103641, Avg. Test Loss: 0.00022258823446463794\n",
      "Epoch: 779, Avg. Train Loss: 0.00019988232376162222, Avg. Test Loss: 0.00021115261188242584\n",
      "Epoch: 780, Avg. Train Loss: 0.00019844135318254662, Avg. Test Loss: 0.00020603778830263764\n",
      "Epoch: 781, Avg. Train Loss: 0.00019750483185161164, Avg. Test Loss: 0.00020787086396012455\n",
      "Epoch: 782, Avg. Train Loss: 0.00019988229838037474, Avg. Test Loss: 0.00020880898227915168\n",
      "Epoch: 783, Avg. Train Loss: 0.00019620358267105942, Avg. Test Loss: 0.00020811015565413982\n",
      "Epoch: 784, Avg. Train Loss: 0.00019940679898312273, Avg. Test Loss: 0.00020648736972361803\n",
      "Epoch: 785, Avg. Train Loss: 0.00019742016440939679, Avg. Test Loss: 0.00021486691548489034\n",
      "Epoch: 786, Avg. Train Loss: 0.0002002320655074707, Avg. Test Loss: 0.00021208327962085605\n",
      "Epoch: 787, Avg. Train Loss: 0.0001973831511053885, Avg. Test Loss: 0.0002069358597509563\n",
      "Epoch: 788, Avg. Train Loss: 0.00019848745060424038, Avg. Test Loss: 0.0002059981634374708\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 789, Avg. Train Loss: 0.0001977404334506583, Avg. Test Loss: 0.0002114221133524552\n",
      "Epoch: 790, Avg. Train Loss: 0.00019884812456100832, Avg. Test Loss: 0.00020627016783691943\n",
      "Epoch: 791, Avg. Train Loss: 0.00019621992954811039, Avg. Test Loss: 0.00020593139925040305\n",
      "Epoch: 792, Avg. Train Loss: 0.00019819122268060265, Avg. Test Loss: 0.00021030993957538158\n",
      "Epoch: 793, Avg. Train Loss: 0.00019542659906302253, Avg. Test Loss: 0.00020334777946118265\n",
      "Epoch: 794, Avg. Train Loss: 0.00019516636140991088, Avg. Test Loss: 0.00020535367366392165\n",
      "Epoch: 795, Avg. Train Loss: 0.00019787124535447897, Avg. Test Loss: 0.00021267362171784043\n",
      "Epoch: 796, Avg. Train Loss: 0.00019486566909404776, Avg. Test Loss: 0.00020455583580769598\n",
      "Epoch: 797, Avg. Train Loss: 0.00019493163698677753, Avg. Test Loss: 0.0002034475328400731\n",
      "Epoch: 798, Avg. Train Loss: 0.0001959355932465473, Avg. Test Loss: 0.0002064513391815126\n",
      "Epoch: 799, Avg. Train Loss: 0.0001947193289430119, Avg. Test Loss: 0.00020459346706047654\n",
      "Epoch: 800, Avg. Train Loss: 0.00019492895266604284, Avg. Test Loss: 0.0002045554865617305\n",
      "Epoch: 801, Avg. Train Loss: 0.00019445021360636104, Avg. Test Loss: 0.0002044687862507999\n",
      "Epoch: 802, Avg. Train Loss: 0.00019506267935232542, Avg. Test Loss: 0.0002028684102697298\n",
      "Epoch: 803, Avg. Train Loss: 0.0001940125383593705, Avg. Test Loss: 0.00020787665562238544\n",
      "Epoch: 804, Avg. Train Loss: 0.00019547060710042283, Avg. Test Loss: 0.00020588676852639765\n",
      "Epoch: 805, Avg. Train Loss: 0.00019498465638228713, Avg. Test Loss: 0.0002048748719971627\n",
      "Epoch: 806, Avg. Train Loss: 0.00019467420480755526, Avg. Test Loss: 0.0002088324836222455\n",
      "Epoch: 807, Avg. Train Loss: 0.00019355778322490148, Avg. Test Loss: 0.00020898327056784183\n",
      "Epoch: 808, Avg. Train Loss: 0.00019599785683080986, Avg. Test Loss: 0.00020366720855236053\n",
      "Epoch: 809, Avg. Train Loss: 0.00019462436111373178, Avg. Test Loss: 0.00020993036741856486\n",
      "Epoch: 810, Avg. Train Loss: 0.00019479321646179225, Avg. Test Loss: 0.00020147244504187256\n",
      "Epoch: 811, Avg. Train Loss: 0.00019696322073456073, Avg. Test Loss: 0.0002111183712258935\n",
      "Epoch: 812, Avg. Train Loss: 0.0001955194341906801, Avg. Test Loss: 0.0002044331340584904\n",
      "Epoch: 813, Avg. Train Loss: 0.0001932891179823728, Avg. Test Loss: 0.000202798648388125\n",
      "Epoch: 814, Avg. Train Loss: 0.0001926910603245677, Avg. Test Loss: 0.00020251637033652514\n",
      "Epoch: 815, Avg. Train Loss: 0.00019116665413982214, Avg. Test Loss: 0.00020693038823083043\n",
      "Epoch: 816, Avg. Train Loss: 0.0001940744831551646, Avg. Test Loss: 0.00019974053429905325\n",
      "Epoch: 817, Avg. Train Loss: 0.00019077489593845987, Avg. Test Loss: 0.00020319211762398481\n",
      "Epoch: 818, Avg. Train Loss: 0.00019149802866131935, Avg. Test Loss: 0.00020102520647924393\n",
      "Epoch: 819, Avg. Train Loss: 0.00019159681890647165, Avg. Test Loss: 0.00021626595116686076\n",
      "Epoch: 820, Avg. Train Loss: 0.00019484679119899696, Avg. Test Loss: 0.00020328507525846362\n",
      "Epoch: 821, Avg. Train Loss: 0.00019210201740903823, Avg. Test Loss: 0.00020294783462304622\n",
      "Epoch: 822, Avg. Train Loss: 0.00019073094373980406, Avg. Test Loss: 0.00019939165213145316\n",
      "Epoch: 823, Avg. Train Loss: 0.00019220324425394972, Avg. Test Loss: 0.00020440206571947783\n",
      "Epoch: 824, Avg. Train Loss: 0.00019216052118450577, Avg. Test Loss: 0.00019838132720906287\n",
      "Epoch: 825, Avg. Train Loss: 0.00018932045468529902, Avg. Test Loss: 0.00019913664436899126\n",
      "Epoch: 826, Avg. Train Loss: 0.00019147832333760032, Avg. Test Loss: 0.00020146783208474517\n",
      "Epoch: 827, Avg. Train Loss: 0.00019034751464861856, Avg. Test Loss: 0.00019948816043324769\n",
      "Epoch: 828, Avg. Train Loss: 0.00019052689746130517, Avg. Test Loss: 0.00019890359544660896\n",
      "Epoch: 829, Avg. Train Loss: 0.00018957393923449482, Avg. Test Loss: 0.0002056726807495579\n",
      "Epoch: 830, Avg. Train Loss: 0.0001918223742693446, Avg. Test Loss: 0.00019802831229753792\n",
      "Epoch: 831, Avg. Train Loss: 0.0001895892891361443, Avg. Test Loss: 0.00020182572188787162\n",
      "Epoch: 832, Avg. Train Loss: 0.0001904522424136007, Avg. Test Loss: 0.00019895196601282805\n",
      "Epoch: 833, Avg. Train Loss: 0.00018970050333273533, Avg. Test Loss: 0.00021060196741018444\n",
      "Epoch: 834, Avg. Train Loss: 0.00019018326244360314, Avg. Test Loss: 0.00020246066560503095\n",
      "Epoch: 835, Avg. Train Loss: 0.00019055294809689703, Avg. Test Loss: 0.0002079018158838153\n",
      "Epoch: 836, Avg. Train Loss: 0.00018954875934490024, Avg. Test Loss: 0.00019819739100057632\n",
      "Epoch: 837, Avg. Train Loss: 0.0001893022864499281, Avg. Test Loss: 0.0001964439288713038\n",
      "Epoch: 838, Avg. Train Loss: 0.00018909477173935537, Avg. Test Loss: 0.0001993294426938519\n",
      "Epoch: 839, Avg. Train Loss: 0.0001881564615380972, Avg. Test Loss: 0.00019619458180386573\n",
      "Epoch: 840, Avg. Train Loss: 0.00018673941735340672, Avg. Test Loss: 0.00019507390970829874\n",
      "Epoch: 841, Avg. Train Loss: 0.00018712716937866494, Avg. Test Loss: 0.00020294668502174318\n",
      "Epoch: 842, Avg. Train Loss: 0.0001887013928607366, Avg. Test Loss: 0.0002047409361694008\n",
      "Epoch: 843, Avg. Train Loss: 0.0001889002413981659, Avg. Test Loss: 0.0001968562719412148\n",
      "Epoch: 844, Avg. Train Loss: 0.00018742978356258813, Avg. Test Loss: 0.00019522653019521385\n",
      "Epoch: 845, Avg. Train Loss: 0.00018730226614469185, Avg. Test Loss: 0.000195017404621467\n",
      "Epoch: 846, Avg. Train Loss: 0.00018830552425094728, Avg. Test Loss: 0.00020134577061980963\n",
      "Epoch: 847, Avg. Train Loss: 0.0001863331989477237, Avg. Test Loss: 0.00020310049876570702\n",
      "Epoch: 848, Avg. Train Loss: 0.0001869194702310271, Avg. Test Loss: 0.0001990114396903664\n",
      "Epoch: 849, Avg. Train Loss: 0.00018696292867981503, Avg. Test Loss: 0.00019977979536633939\n",
      "Epoch: 850, Avg. Train Loss: 0.00018782283620757246, Avg. Test Loss: 0.0001996443752432242\n",
      "Epoch: 851, Avg. Train Loss: 0.00018631244080985875, Avg. Test Loss: 0.00019600201630964875\n",
      "Epoch: 852, Avg. Train Loss: 0.00018594699111756284, Avg. Test Loss: 0.00019368721405044198\n",
      "Epoch: 853, Avg. Train Loss: 0.00018568998398963189, Avg. Test Loss: 0.00019637391960714012\n",
      "Epoch: 854, Avg. Train Loss: 0.0001857201951193125, Avg. Test Loss: 0.0001942036469699815\n",
      "Epoch: 855, Avg. Train Loss: 0.0001845591485657361, Avg. Test Loss: 0.00019407850049901754\n",
      "Epoch: 856, Avg. Train Loss: 0.00018424024334350644, Avg. Test Loss: 0.0001933186431415379\n",
      "Epoch: 857, Avg. Train Loss: 0.0001838191170082969, Avg. Test Loss: 0.00019629482994787395\n",
      "Epoch: 858, Avg. Train Loss: 0.00018602450984681762, Avg. Test Loss: 0.00019330806389916688\n",
      "Epoch: 859, Avg. Train Loss: 0.00018557240519141994, Avg. Test Loss: 0.00020151086209807545\n",
      "Epoch: 860, Avg. Train Loss: 0.00018523263218433618, Avg. Test Loss: 0.00019379208970349282\n",
      "Epoch: 861, Avg. Train Loss: 0.00018304901544091313, Avg. Test Loss: 0.00020327960373833776\n",
      "Epoch: 862, Avg. Train Loss: 0.0001861262277342639, Avg. Test Loss: 0.00019917500321753323\n",
      "Epoch: 863, Avg. Train Loss: 0.00018396527373751756, Avg. Test Loss: 0.00020255356503184885\n",
      "Epoch: 864, Avg. Train Loss: 0.00018480550538380305, Avg. Test Loss: 0.0001911927538458258\n",
      "Epoch: 865, Avg. Train Loss: 0.00018457993614584813, Avg. Test Loss: 0.00019597128266468644\n",
      "Epoch: 866, Avg. Train Loss: 0.00018256678121424344, Avg. Test Loss: 0.00019122853700537235\n",
      "Epoch: 867, Avg. Train Loss: 0.0001853262419476672, Avg. Test Loss: 0.00019243288261350244\n",
      "Epoch: 868, Avg. Train Loss: 0.00018206268561148453, Avg. Test Loss: 0.00019151325977873057\n",
      "Epoch: 869, Avg. Train Loss: 0.00018187248598795037, Avg. Test Loss: 0.00019226595759391785\n",
      "Epoch: 870, Avg. Train Loss: 0.00018098159709425512, Avg. Test Loss: 0.0001944631221704185\n",
      "Epoch: 871, Avg. Train Loss: 0.0001854733191701302, Avg. Test Loss: 0.00019299835548736155\n",
      "Epoch: 872, Avg. Train Loss: 0.00018425066082272679, Avg. Test Loss: 0.00019291201897431165\n",
      "Epoch: 873, Avg. Train Loss: 0.00018159247532779308, Avg. Test Loss: 0.00020240845333319157\n",
      "Epoch: 874, Avg. Train Loss: 0.00018176139192926415, Avg. Test Loss: 0.00019509450066834688\n",
      "Epoch: 875, Avg. Train Loss: 0.00018135473933504072, Avg. Test Loss: 0.00020042789401486516\n",
      "Epoch: 876, Avg. Train Loss: 0.00018040254423773826, Avg. Test Loss: 0.00019058299949392676\n",
      "Epoch: 877, Avg. Train Loss: 0.00018016166367763005, Avg. Test Loss: 0.00019181473180651665\n",
      "Epoch: 878, Avg. Train Loss: 0.0001800231988200658, Avg. Test Loss: 0.00019259274995420128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 879, Avg. Train Loss: 0.0001790679305613171, Avg. Test Loss: 0.0001876262977020815\n",
      "Epoch: 880, Avg. Train Loss: 0.00018141880634154172, Avg. Test Loss: 0.00019414951384533197\n",
      "Epoch: 881, Avg. Train Loss: 0.0001826082193157311, Avg. Test Loss: 0.00018780403479468077\n",
      "Epoch: 882, Avg. Train Loss: 0.00018187105110142553, Avg. Test Loss: 0.0001912807929329574\n",
      "Epoch: 883, Avg. Train Loss: 0.00018160003217121282, Avg. Test Loss: 0.00018781273683998734\n",
      "Epoch: 884, Avg. Train Loss: 0.0001785124010449752, Avg. Test Loss: 0.00018644875672180206\n",
      "Epoch: 885, Avg. Train Loss: 0.0001803120360628507, Avg. Test Loss: 0.00019429167150519788\n",
      "Epoch: 886, Avg. Train Loss: 0.0001797234838514394, Avg. Test Loss: 0.00018697898485697806\n",
      "Epoch: 887, Avg. Train Loss: 0.00017694249948172635, Avg. Test Loss: 0.00018810280016623437\n",
      "Epoch: 888, Avg. Train Loss: 0.00017891080608743048, Avg. Test Loss: 0.0001906733523355797\n",
      "Epoch: 889, Avg. Train Loss: 0.00017927384929904757, Avg. Test Loss: 0.00018535865820012987\n",
      "Epoch: 890, Avg. Train Loss: 0.00017836143778431293, Avg. Test Loss: 0.00019585833069868386\n",
      "Epoch: 891, Avg. Train Loss: 0.00017851480989457044, Avg. Test Loss: 0.00018759578233584762\n",
      "Epoch: 892, Avg. Train Loss: 0.00017797821783460677, Avg. Test Loss: 0.0001862735953181982\n",
      "Epoch: 893, Avg. Train Loss: 0.00017876345440907793, Avg. Test Loss: 0.0001863195066107437\n",
      "Epoch: 894, Avg. Train Loss: 0.00017866085697680191, Avg. Test Loss: 0.00018601799092721194\n",
      "Epoch: 895, Avg. Train Loss: 0.00017869394397103164, Avg. Test Loss: 0.00018529751105234027\n",
      "Epoch: 896, Avg. Train Loss: 0.00017703667000141862, Avg. Test Loss: 0.00018433301011100411\n",
      "Epoch: 897, Avg. Train Loss: 0.00017644050916884268, Avg. Test Loss: 0.00018630511476658285\n",
      "Epoch: 898, Avg. Train Loss: 0.0001754507200445893, Avg. Test Loss: 0.00018656178144738078\n",
      "Epoch: 899, Avg. Train Loss: 0.00017627624884182803, Avg. Test Loss: 0.00018453596567269415\n",
      "Epoch: 900, Avg. Train Loss: 0.00017578774950802758, Avg. Test Loss: 0.00018782498955260962\n",
      "Epoch: 901, Avg. Train Loss: 0.0001750669525367706, Avg. Test Loss: 0.00018759362865239382\n",
      "Epoch: 902, Avg. Train Loss: 0.0001741570821925348, Avg. Test Loss: 0.00018351823382545263\n",
      "Epoch: 903, Avg. Train Loss: 0.00017480137839176975, Avg. Test Loss: 0.00018760876264423132\n",
      "Epoch: 904, Avg. Train Loss: 0.00017766674796422554, Avg. Test Loss: 0.0001922935771290213\n",
      "Epoch: 905, Avg. Train Loss: 0.00017912814029503267, Avg. Test Loss: 0.0001857549068517983\n",
      "Epoch: 906, Avg. Train Loss: 0.00017525976135254685, Avg. Test Loss: 0.00018280171207152307\n",
      "Epoch: 907, Avg. Train Loss: 0.00017295910524702522, Avg. Test Loss: 0.00018128972442355007\n",
      "Epoch: 908, Avg. Train Loss: 0.00017275010894843225, Avg. Test Loss: 0.00018204320804215968\n",
      "Epoch: 909, Avg. Train Loss: 0.00017589277372598042, Avg. Test Loss: 0.00018243567319586873\n",
      "Epoch: 910, Avg. Train Loss: 0.00017478151536589966, Avg. Test Loss: 0.00019225793948862702\n",
      "Epoch: 911, Avg. Train Loss: 0.00017441338507545202, Avg. Test Loss: 0.00018468017515260726\n",
      "Epoch: 912, Avg. Train Loss: 0.00017287831335209395, Avg. Test Loss: 0.00018011717475019395\n",
      "Epoch: 913, Avg. Train Loss: 0.00017227835886905965, Avg. Test Loss: 0.00018206474487669766\n",
      "Epoch: 914, Avg. Train Loss: 0.0001710672581265139, Avg. Test Loss: 0.0001861379569163546\n",
      "Epoch: 915, Avg. Train Loss: 0.0001716539206194453, Avg. Test Loss: 0.00018013293447438627\n",
      "Epoch: 916, Avg. Train Loss: 0.00017155520550278557, Avg. Test Loss: 0.00018079810251947492\n",
      "Epoch: 917, Avg. Train Loss: 0.00017274840129810103, Avg. Test Loss: 0.00018488233035895973\n",
      "Epoch: 918, Avg. Train Loss: 0.00017023673193085245, Avg. Test Loss: 0.0001794805721146986\n",
      "Epoch: 919, Avg. Train Loss: 0.00017144471247203995, Avg. Test Loss: 0.0001821827027015388\n",
      "Epoch: 920, Avg. Train Loss: 0.00016995193876683453, Avg. Test Loss: 0.00017979255062527955\n",
      "Epoch: 921, Avg. Train Loss: 0.00017208606140081619, Avg. Test Loss: 0.00017999662668444216\n",
      "Epoch: 922, Avg. Train Loss: 0.00017226686150236271, Avg. Test Loss: 0.0001810927496990189\n",
      "Epoch: 923, Avg. Train Loss: 0.0001701700570857759, Avg. Test Loss: 0.00017905252752825618\n",
      "Epoch: 924, Avg. Train Loss: 0.00017003973656290664, Avg. Test Loss: 0.00017933959315996617\n",
      "Epoch: 925, Avg. Train Loss: 0.00016896285354917826, Avg. Test Loss: 0.0001876318419817835\n",
      "Epoch: 926, Avg. Train Loss: 0.00017027864009304362, Avg. Test Loss: 0.00018179624748881906\n",
      "Epoch: 927, Avg. Train Loss: 0.00017031810421030968, Avg. Test Loss: 0.0001846710074460134\n",
      "Epoch: 928, Avg. Train Loss: 0.00017686887897366962, Avg. Test Loss: 0.00018872074724640697\n",
      "Epoch: 929, Avg. Train Loss: 0.0001718550338409841, Avg. Test Loss: 0.00017711955297272652\n",
      "Epoch: 930, Avg. Train Loss: 0.00016870030180312867, Avg. Test Loss: 0.00017733332060743123\n",
      "Epoch: 931, Avg. Train Loss: 0.0001697371217021502, Avg. Test Loss: 0.00017930712783709168\n",
      "Epoch: 932, Avg. Train Loss: 0.00016786722225396958, Avg. Test Loss: 0.00017623728490434587\n",
      "Epoch: 933, Avg. Train Loss: 0.00016996754789562506, Avg. Test Loss: 0.00018529970839153975\n",
      "Epoch: 934, Avg. Train Loss: 0.00016952710676949124, Avg. Test Loss: 0.0001761895982781425\n",
      "Epoch: 935, Avg. Train Loss: 0.00016837357712617187, Avg. Test Loss: 0.00017728874809108675\n",
      "Epoch: 936, Avg. Train Loss: 0.00016633302567602504, Avg. Test Loss: 0.00017526609008200467\n",
      "Epoch: 937, Avg. Train Loss: 0.0001670396440056001, Avg. Test Loss: 0.00017599893908482045\n",
      "Epoch: 938, Avg. Train Loss: 0.0001660247352299129, Avg. Test Loss: 0.00017350961570627987\n",
      "Epoch: 939, Avg. Train Loss: 0.0001688061676632483, Avg. Test Loss: 0.00019187774159945548\n",
      "Epoch: 940, Avg. Train Loss: 0.00017048061932274682, Avg. Test Loss: 0.00017724779900163412\n",
      "Epoch: 941, Avg. Train Loss: 0.00016615885921732285, Avg. Test Loss: 0.00017378470511175692\n",
      "Epoch: 942, Avg. Train Loss: 0.00016638568668832007, Avg. Test Loss: 0.0001775791752152145\n",
      "Epoch: 943, Avg. Train Loss: 0.0001656874255575023, Avg. Test Loss: 0.00018218699551653117\n",
      "Epoch: 944, Avg. Train Loss: 0.00016584099394940707, Avg. Test Loss: 0.00017266441136598587\n",
      "Epoch: 945, Avg. Train Loss: 0.0001645699521759525, Avg. Test Loss: 0.00017351195856463164\n",
      "Epoch: 946, Avg. Train Loss: 0.00016660021643728277, Avg. Test Loss: 0.000173483305843547\n",
      "Epoch: 947, Avg. Train Loss: 0.0001649759553486568, Avg. Test Loss: 0.00017241135356016457\n",
      "Epoch: 948, Avg. Train Loss: 0.00016744435442676552, Avg. Test Loss: 0.00018159298633690923\n",
      "Epoch: 949, Avg. Train Loss: 0.0001641896436245419, Avg. Test Loss: 0.00017112892237491906\n",
      "Epoch: 950, Avg. Train Loss: 0.0001632154433240811, Avg. Test Loss: 0.0001766042405506596\n",
      "Epoch: 951, Avg. Train Loss: 0.00016306854783135013, Avg. Test Loss: 0.00017323280917480588\n",
      "Epoch: 952, Avg. Train Loss: 0.00016420138972746424, Avg. Test Loss: 0.00017038999067153782\n",
      "Epoch: 953, Avg. Train Loss: 0.00016368958905480023, Avg. Test Loss: 0.00017516192747280002\n",
      "Epoch: 954, Avg. Train Loss: 0.00016503621584486737, Avg. Test Loss: 0.0001739009312586859\n",
      "Epoch: 955, Avg. Train Loss: 0.0001642788529563912, Avg. Test Loss: 0.00016984755347948521\n",
      "Epoch: 956, Avg. Train Loss: 0.00016181918671950266, Avg. Test Loss: 0.0001747134665492922\n",
      "Epoch: 957, Avg. Train Loss: 0.00016486922991028877, Avg. Test Loss: 0.00016940892965067178\n",
      "Epoch: 958, Avg. Train Loss: 0.00016296635413011752, Avg. Test Loss: 0.00016986475384328514\n",
      "Epoch: 959, Avg. Train Loss: 0.00016308053285641553, Avg. Test Loss: 0.00017442791431676596\n",
      "Epoch: 960, Avg. Train Loss: 0.00016363347179343014, Avg. Test Loss: 0.00017070725152734667\n",
      "Epoch: 961, Avg. Train Loss: 0.0001628230106583688, Avg. Test Loss: 0.00016821909230202436\n",
      "Epoch: 962, Avg. Train Loss: 0.00016101040920719157, Avg. Test Loss: 0.00017215557454619557\n",
      "Epoch: 963, Avg. Train Loss: 0.00016366307580367078, Avg. Test Loss: 0.00016934324230533093\n",
      "Epoch: 964, Avg. Train Loss: 0.00016110156646518167, Avg. Test Loss: 0.00017590915376786143\n",
      "Epoch: 965, Avg. Train Loss: 0.00016186368512260445, Avg. Test Loss: 0.00017335139273200184\n",
      "Epoch: 966, Avg. Train Loss: 0.00016268979227386935, Avg. Test Loss: 0.0001817881129682064\n",
      "Epoch: 967, Avg. Train Loss: 0.00016801047063064436, Avg. Test Loss: 0.00016738231352064759\n",
      "Epoch: 968, Avg. Train Loss: 0.00016188329568966617, Avg. Test Loss: 0.00017117093375418335\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 969, Avg. Train Loss: 0.0001604869957677587, Avg. Test Loss: 0.00016874294669833034\n",
      "Epoch: 970, Avg. Train Loss: 0.00016079552310551407, Avg. Test Loss: 0.00016864051576703787\n",
      "Epoch: 971, Avg. Train Loss: 0.0001590968851476561, Avg. Test Loss: 0.00016805857012514025\n",
      "Epoch: 972, Avg. Train Loss: 0.00015991469973774064, Avg. Test Loss: 0.00017007955466397107\n",
      "Epoch: 973, Avg. Train Loss: 0.00015889893003013852, Avg. Test Loss: 0.00016869042883627117\n",
      "Epoch: 974, Avg. Train Loss: 0.0001606205194040613, Avg. Test Loss: 0.00017128388572018594\n",
      "Epoch: 975, Avg. Train Loss: 0.00015889958283582398, Avg. Test Loss: 0.00016501233039889485\n",
      "Epoch: 976, Avg. Train Loss: 0.00015953644605212693, Avg. Test Loss: 0.0001753228425513953\n",
      "Epoch: 977, Avg. Train Loss: 0.0001601169598532494, Avg. Test Loss: 0.0001716297265375033\n",
      "Epoch: 978, Avg. Train Loss: 0.00015897458983682702, Avg. Test Loss: 0.00017449761799070984\n",
      "Epoch: 979, Avg. Train Loss: 0.0001612539822100337, Avg. Test Loss: 0.0001737817656248808\n",
      "Epoch: 980, Avg. Train Loss: 0.00015910486535028402, Avg. Test Loss: 0.00016596922068856657\n",
      "Epoch: 981, Avg. Train Loss: 0.00016126316920637564, Avg. Test Loss: 0.00017772427236195654\n",
      "Epoch: 982, Avg. Train Loss: 0.00016069384853539684, Avg. Test Loss: 0.0001656713429838419\n",
      "Epoch: 983, Avg. Train Loss: 0.00015927906463539964, Avg. Test Loss: 0.00016728145419619977\n",
      "Epoch: 984, Avg. Train Loss: 0.00015870847151787994, Avg. Test Loss: 0.00016383551701437682\n",
      "Epoch: 985, Avg. Train Loss: 0.00015880089851507786, Avg. Test Loss: 0.00017112033674493432\n",
      "Epoch: 986, Avg. Train Loss: 0.0001573420608914349, Avg. Test Loss: 0.00016968454292509705\n",
      "Epoch: 987, Avg. Train Loss: 0.00016200867194552407, Avg. Test Loss: 0.0001631209597690031\n",
      "Epoch: 988, Avg. Train Loss: 0.00015710343858552013, Avg. Test Loss: 0.00016861538460943848\n",
      "Epoch: 989, Avg. Train Loss: 0.0001575998886797014, Avg. Test Loss: 0.0001657748653087765\n",
      "Epoch: 990, Avg. Train Loss: 0.00015720390500825678, Avg. Test Loss: 0.0001701648870948702\n",
      "Epoch: 991, Avg. Train Loss: 0.0001571195563545104, Avg. Test Loss: 0.0001632305938983336\n",
      "Epoch: 992, Avg. Train Loss: 0.0001552187716507158, Avg. Test Loss: 0.00016797709395177662\n",
      "Epoch: 993, Avg. Train Loss: 0.00015685605568822126, Avg. Test Loss: 0.00016535382019355893\n",
      "Epoch: 994, Avg. Train Loss: 0.00015714026372988036, Avg. Test Loss: 0.00016270842752419412\n",
      "Epoch: 995, Avg. Train Loss: 0.0001559597270855637, Avg. Test Loss: 0.00016866408986970782\n",
      "Epoch: 996, Avg. Train Loss: 0.00015872824486334224, Avg. Test Loss: 0.00016236906230915338\n",
      "Epoch: 997, Avg. Train Loss: 0.0001579997962920082, Avg. Test Loss: 0.00016293671797029674\n",
      "Epoch: 998, Avg. Train Loss: 0.00015879265840847566, Avg. Test Loss: 0.0001635613589314744\n",
      "Epoch: 999, Avg. Train Loss: 0.00015591502698614846, Avg. Test Loss: 0.00016497436445206404\n",
      "Epoch: 1000, Avg. Train Loss: 0.00015675403694838806, Avg. Test Loss: 0.00016547477571293712\n",
      "Epoch: 1001, Avg. Train Loss: 0.00015449441149072764, Avg. Test Loss: 0.00016254211368504912\n",
      "Epoch: 1002, Avg. Train Loss: 0.00015358709348473957, Avg. Test Loss: 0.00016143760876730084\n",
      "Epoch: 1003, Avg. Train Loss: 0.00015653033712391504, Avg. Test Loss: 0.00016179104568436742\n",
      "Epoch: 1004, Avg. Train Loss: 0.00015400762420667466, Avg. Test Loss: 0.00016443131607957184\n",
      "Epoch: 1005, Avg. Train Loss: 0.00015388942136819106, Avg. Test Loss: 0.00016381371824536473\n",
      "Epoch: 1006, Avg. Train Loss: 0.00015619090253346448, Avg. Test Loss: 0.00016389602387789637\n",
      "Epoch: 1007, Avg. Train Loss: 0.00015469601981580084, Avg. Test Loss: 0.0001717394043225795\n",
      "Epoch: 1008, Avg. Train Loss: 0.00015546232333331, Avg. Test Loss: 0.00016723142471164465\n",
      "Epoch: 1009, Avg. Train Loss: 0.00015469554840143076, Avg. Test Loss: 0.00015988957602530718\n",
      "Epoch: 1010, Avg. Train Loss: 0.00015506752513533154, Avg. Test Loss: 0.0001648042380111292\n",
      "Epoch: 1011, Avg. Train Loss: 0.00015528853590123702, Avg. Test Loss: 0.00016262017015833408\n",
      "Epoch: 1012, Avg. Train Loss: 0.0001552429217384955, Avg. Test Loss: 0.00016151924501173198\n",
      "Epoch: 1013, Avg. Train Loss: 0.0001557995741212264, Avg. Test Loss: 0.00016682689602021128\n",
      "Epoch: 1014, Avg. Train Loss: 0.00015617119382557913, Avg. Test Loss: 0.00016180188686121255\n",
      "Epoch: 1015, Avg. Train Loss: 0.00015269270130205726, Avg. Test Loss: 0.00016079477791208774\n",
      "Epoch: 1016, Avg. Train Loss: 0.00015367379210358702, Avg. Test Loss: 0.00016446343215648085\n",
      "Epoch: 1017, Avg. Train Loss: 0.00015271147327270185, Avg. Test Loss: 0.00016017798043321818\n",
      "Epoch: 1018, Avg. Train Loss: 0.00015347553241109953, Avg. Test Loss: 0.00015898440324235708\n",
      "Epoch: 1019, Avg. Train Loss: 0.00015243372763507068, Avg. Test Loss: 0.00016262457938864827\n",
      "Epoch: 1020, Avg. Train Loss: 0.00015207013145067492, Avg. Test Loss: 0.00016135809710249305\n",
      "Epoch: 1021, Avg. Train Loss: 0.00015525777653661058, Avg. Test Loss: 0.00016025571676436812\n",
      "Epoch: 1022, Avg. Train Loss: 0.0001523512483948062, Avg. Test Loss: 0.000156972513650544\n",
      "Epoch: 1023, Avg. Train Loss: 0.00015124661758607037, Avg. Test Loss: 0.0001628464087843895\n",
      "Epoch: 1024, Avg. Train Loss: 0.00015287130338757104, Avg. Test Loss: 0.00015951116802170873\n",
      "Epoch: 1025, Avg. Train Loss: 0.00015111639046619193, Avg. Test Loss: 0.00016028327809181064\n",
      "Epoch: 1026, Avg. Train Loss: 0.00015141721476454202, Avg. Test Loss: 0.0001585968566359952\n",
      "Epoch: 1027, Avg. Train Loss: 0.00015214223720588137, Avg. Test Loss: 0.0001682171132415533\n",
      "Epoch: 1028, Avg. Train Loss: 0.00015301951565942185, Avg. Test Loss: 0.00015764663112349808\n",
      "Epoch: 1029, Avg. Train Loss: 0.0001522687515568768, Avg. Test Loss: 0.00015929310757201165\n",
      "Epoch: 1030, Avg. Train Loss: 0.00015128622620723883, Avg. Test Loss: 0.00016308699559886009\n",
      "Epoch: 1031, Avg. Train Loss: 0.0001504211138316625, Avg. Test Loss: 0.00016209864406846464\n",
      "Epoch: 1032, Avg. Train Loss: 0.00015204645751509815, Avg. Test Loss: 0.0001577826333232224\n",
      "Epoch: 1033, Avg. Train Loss: 0.00015046043784444242, Avg. Test Loss: 0.00016051757847890258\n",
      "Epoch: 1034, Avg. Train Loss: 0.00015078890841281, Avg. Test Loss: 0.0001625552831683308\n",
      "Epoch: 1035, Avg. Train Loss: 0.0001532748672531831, Avg. Test Loss: 0.0001651066995691508\n",
      "Epoch: 1036, Avg. Train Loss: 0.00015229937352435015, Avg. Test Loss: 0.00015797786181792617\n",
      "Epoch: 1037, Avg. Train Loss: 0.00015078775982675684, Avg. Test Loss: 0.00015616457676514983\n",
      "Epoch: 1038, Avg. Train Loss: 0.00015028116264824518, Avg. Test Loss: 0.00015573384007439017\n",
      "Epoch: 1039, Avg. Train Loss: 0.00015104658120625847, Avg. Test Loss: 0.00015972362598404288\n",
      "Epoch: 1040, Avg. Train Loss: 0.00015124177213671596, Avg. Test Loss: 0.00016177725046873093\n",
      "Epoch: 1041, Avg. Train Loss: 0.00015061931091707285, Avg. Test Loss: 0.00015655296738259494\n",
      "Epoch: 1042, Avg. Train Loss: 0.00015234068810376664, Avg. Test Loss: 0.0001584209530847147\n",
      "Epoch: 1043, Avg. Train Loss: 0.00015239285096677757, Avg. Test Loss: 0.00015939708100631833\n",
      "Epoch: 1044, Avg. Train Loss: 0.0001506884721091537, Avg. Test Loss: 0.00015652012370992452\n",
      "Epoch: 1045, Avg. Train Loss: 0.0001510905570940786, Avg. Test Loss: 0.00016368384240195155\n",
      "Epoch: 1046, Avg. Train Loss: 0.00015059254960655125, Avg. Test Loss: 0.00015780016838107258\n",
      "Epoch: 1047, Avg. Train Loss: 0.00014932335118849783, Avg. Test Loss: 0.00016576197231188416\n",
      "Epoch: 1048, Avg. Train Loss: 0.0001489148660682055, Avg. Test Loss: 0.00015716055349912494\n",
      "Epoch: 1049, Avg. Train Loss: 0.00015047518705656795, Avg. Test Loss: 0.0001625815057195723\n",
      "Epoch: 1050, Avg. Train Loss: 0.00015353485143223647, Avg. Test Loss: 0.00015537308354396373\n",
      "Epoch: 1051, Avg. Train Loss: 0.00014936751523596603, Avg. Test Loss: 0.00015624126535840333\n",
      "Epoch: 1052, Avg. Train Loss: 0.00014916100782250206, Avg. Test Loss: 0.00015968154184520245\n",
      "Epoch: 1053, Avg. Train Loss: 0.00015228352005875042, Avg. Test Loss: 0.00015793197962921113\n",
      "Epoch: 1054, Avg. Train Loss: 0.00015021594130260827, Avg. Test Loss: 0.0001541555830044672\n",
      "Epoch: 1055, Avg. Train Loss: 0.00015044935266920475, Avg. Test Loss: 0.00015545457426924258\n",
      "Epoch: 1056, Avg. Train Loss: 0.00014781142411710217, Avg. Test Loss: 0.00015392195200547576\n",
      "Epoch: 1057, Avg. Train Loss: 0.00015058050468174178, Avg. Test Loss: 0.00015514573897235096\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1058, Avg. Train Loss: 0.00015124460637601914, Avg. Test Loss: 0.0001600788236828521\n",
      "Epoch: 1059, Avg. Train Loss: 0.00014886208525642232, Avg. Test Loss: 0.0001554488844703883\n",
      "Epoch: 1060, Avg. Train Loss: 0.0001499608861618177, Avg. Test Loss: 0.00015435511886607856\n",
      "Epoch: 1061, Avg. Train Loss: 0.00015244159852912607, Avg. Test Loss: 0.00015373664791695774\n",
      "Epoch: 1062, Avg. Train Loss: 0.00014948022895665882, Avg. Test Loss: 0.00015398561663459986\n",
      "Epoch: 1063, Avg. Train Loss: 0.00014774685050090126, Avg. Test Loss: 0.00015696266200393438\n",
      "Epoch: 1064, Avg. Train Loss: 0.00014802423166381844, Avg. Test Loss: 0.00017086164734791964\n",
      "Epoch: 1065, Avg. Train Loss: 0.0001502333700976356, Avg. Test Loss: 0.0001560643286211416\n",
      "Epoch: 1066, Avg. Train Loss: 0.00014971841910453297, Avg. Test Loss: 0.0001590355677763\n",
      "Epoch: 1067, Avg. Train Loss: 0.0001488496792410652, Avg. Test Loss: 0.00015616485325153917\n",
      "Epoch: 1068, Avg. Train Loss: 0.00014881703117320877, Avg. Test Loss: 0.00015314547636080533\n",
      "Epoch: 1069, Avg. Train Loss: 0.00014799379751757655, Avg. Test Loss: 0.00015390927728731185\n",
      "Epoch: 1070, Avg. Train Loss: 0.0001483581872889772, Avg. Test Loss: 0.00015292881289497018\n",
      "Epoch: 1071, Avg. Train Loss: 0.00014816668239248874, Avg. Test Loss: 0.0001548260188428685\n",
      "Epoch: 1072, Avg. Train Loss: 0.0001505396486568633, Avg. Test Loss: 0.00015995086869224906\n",
      "Epoch: 1073, Avg. Train Loss: 0.00014870097660351286, Avg. Test Loss: 0.0001595101348357275\n",
      "Epoch: 1074, Avg. Train Loss: 0.00014866393825667369, Avg. Test Loss: 0.00015478802379220724\n",
      "Epoch: 1075, Avg. Train Loss: 0.00014663118730992252, Avg. Test Loss: 0.0001585320133017376\n",
      "Epoch: 1076, Avg. Train Loss: 0.00014770190471101032, Avg. Test Loss: 0.00015647213149350137\n",
      "Epoch: 1077, Avg. Train Loss: 0.00014970601748859206, Avg. Test Loss: 0.0001582208788022399\n",
      "Epoch: 1078, Avg. Train Loss: 0.00014764566392756913, Avg. Test Loss: 0.0001528262218926102\n",
      "Epoch: 1079, Avg. Train Loss: 0.00014745210111953403, Avg. Test Loss: 0.0001534448965685442\n",
      "Epoch: 1080, Avg. Train Loss: 0.0001478514053349838, Avg. Test Loss: 0.00015204757801257074\n",
      "Epoch: 1081, Avg. Train Loss: 0.0001477889806644038, Avg. Test Loss: 0.00015286513371393085\n",
      "Epoch: 1082, Avg. Train Loss: 0.00014669195712316608, Avg. Test Loss: 0.00015161270857788622\n",
      "Epoch: 1083, Avg. Train Loss: 0.00014917590475348798, Avg. Test Loss: 0.00015285209519788623\n",
      "Epoch: 1084, Avg. Train Loss: 0.0001466580606363497, Avg. Test Loss: 0.0001524158869870007\n",
      "Epoch: 1085, Avg. Train Loss: 0.00014769653370062452, Avg. Test Loss: 0.0001532646274426952\n",
      "Epoch: 1086, Avg. Train Loss: 0.0001476035523769814, Avg. Test Loss: 0.00015350585454143584\n",
      "Epoch: 1087, Avg. Train Loss: 0.00014990530258347822, Avg. Test Loss: 0.00016788503853604198\n",
      "Epoch: 1088, Avg. Train Loss: 0.00015173713083725508, Avg. Test Loss: 0.0001527640997665003\n",
      "Epoch: 1089, Avg. Train Loss: 0.00014734366430825186, Avg. Test Loss: 0.0001539721415610984\n",
      "Epoch: 1090, Avg. Train Loss: 0.00014726201994182152, Avg. Test Loss: 0.00015327277651522309\n",
      "Epoch: 1091, Avg. Train Loss: 0.00014796830966884575, Avg. Test Loss: 0.00015616841847077012\n",
      "Epoch: 1092, Avg. Train Loss: 0.00014805070971961806, Avg. Test Loss: 0.00015198298206087202\n",
      "Epoch: 1093, Avg. Train Loss: 0.0001463453122279282, Avg. Test Loss: 0.0001539517834316939\n",
      "Epoch: 1094, Avg. Train Loss: 0.0001475304631830388, Avg. Test Loss: 0.0001518765784567222\n",
      "Epoch: 1095, Avg. Train Loss: 0.0001485702086938545, Avg. Test Loss: 0.00015390721091534942\n",
      "Epoch: 1096, Avg. Train Loss: 0.0001472470395911355, Avg. Test Loss: 0.0001515761687187478\n",
      "Epoch: 1097, Avg. Train Loss: 0.00014667818390461074, Avg. Test Loss: 0.00015343879931606352\n",
      "Epoch: 1098, Avg. Train Loss: 0.00014785697973376618, Avg. Test Loss: 0.0001534081093268469\n",
      "Epoch: 1099, Avg. Train Loss: 0.00014816299940426943, Avg. Test Loss: 0.00015445634198840708\n",
      "Epoch: 1100, Avg. Train Loss: 0.00014741213885298388, Avg. Test Loss: 0.00015341538528446108\n",
      "Epoch: 1101, Avg. Train Loss: 0.00014801996152274052, Avg. Test Loss: 0.00015351905312854797\n",
      "Epoch: 1102, Avg. Train Loss: 0.00014882330271025557, Avg. Test Loss: 0.00015902174345683306\n",
      "Epoch: 1103, Avg. Train Loss: 0.00014760187789148024, Avg. Test Loss: 0.00015252608864102513\n",
      "Epoch: 1104, Avg. Train Loss: 0.0001459610590922408, Avg. Test Loss: 0.00015195731248240918\n",
      "Epoch: 1105, Avg. Train Loss: 0.00014511726764139047, Avg. Test Loss: 0.00015106280625332147\n",
      "Epoch: 1106, Avg. Train Loss: 0.00014608835924665855, Avg. Test Loss: 0.00015503374743275344\n",
      "Epoch: 1107, Avg. Train Loss: 0.00014774159184483769, Avg. Test Loss: 0.00015123849152587354\n",
      "Epoch: 1108, Avg. Train Loss: 0.00014817140465818866, Avg. Test Loss: 0.00015256252663675696\n",
      "Epoch: 1109, Avg. Train Loss: 0.00014668920816485444, Avg. Test Loss: 0.00015078489377629012\n",
      "Epoch: 1110, Avg. Train Loss: 0.00014830228762950228, Avg. Test Loss: 0.00016206674627028406\n",
      "Epoch: 1111, Avg. Train Loss: 0.0001473695613026922, Avg. Test Loss: 0.00015176492161117494\n",
      "Epoch: 1112, Avg. Train Loss: 0.00014509556261378578, Avg. Test Loss: 0.0001540915691293776\n",
      "Epoch: 1113, Avg. Train Loss: 0.00014780132407268378, Avg. Test Loss: 0.00015328959852922708\n",
      "Epoch: 1114, Avg. Train Loss: 0.0001461728848923041, Avg. Test Loss: 0.00015057454584166408\n",
      "Epoch: 1115, Avg. Train Loss: 0.00014645849431724135, Avg. Test Loss: 0.00015464388707187027\n",
      "Epoch: 1116, Avg. Train Loss: 0.00014663665984529828, Avg. Test Loss: 0.00015195095329545438\n",
      "Epoch: 1117, Avg. Train Loss: 0.00014735116971234337, Avg. Test Loss: 0.00015148888633120805\n",
      "Epoch: 1118, Avg. Train Loss: 0.00014677395344289497, Avg. Test Loss: 0.00015368213644251227\n",
      "Epoch: 1119, Avg. Train Loss: 0.00014618065358453625, Avg. Test Loss: 0.00015158588939812034\n",
      "Epoch: 1120, Avg. Train Loss: 0.00014580404223484355, Avg. Test Loss: 0.0001500696234870702\n",
      "Epoch: 1121, Avg. Train Loss: 0.00014734424232386138, Avg. Test Loss: 0.0001530771842226386\n",
      "Epoch: 1122, Avg. Train Loss: 0.00014654139827038052, Avg. Test Loss: 0.00015723459364380687\n",
      "Epoch: 1123, Avg. Train Loss: 0.00014646365753981437, Avg. Test Loss: 0.00015047592751216143\n",
      "Epoch: 1124, Avg. Train Loss: 0.00014512280312226002, Avg. Test Loss: 0.00015071535017341375\n",
      "Epoch: 1125, Avg. Train Loss: 0.00014617006655858267, Avg. Test Loss: 0.00015110202366486192\n",
      "Epoch: 1126, Avg. Train Loss: 0.00014512917449221362, Avg. Test Loss: 0.00015056802658364177\n",
      "Epoch: 1127, Avg. Train Loss: 0.00014623987108068325, Avg. Test Loss: 0.00015123320918064564\n",
      "Epoch: 1128, Avg. Train Loss: 0.00014722413995281556, Avg. Test Loss: 0.0001518539502285421\n",
      "Epoch: 1129, Avg. Train Loss: 0.0001454480502721962, Avg. Test Loss: 0.00015124090714380145\n",
      "Epoch: 1130, Avg. Train Loss: 0.00014592072287531092, Avg. Test Loss: 0.00015503630856983364\n",
      "Epoch: 1131, Avg. Train Loss: 0.0001456659266232448, Avg. Test Loss: 0.0001502438390161842\n",
      "Epoch: 1132, Avg. Train Loss: 0.00014606809147449515, Avg. Test Loss: 0.00015107331273611635\n",
      "Epoch: 1133, Avg. Train Loss: 0.0001462232175981626, Avg. Test Loss: 0.00015123217599466443\n",
      "Epoch: 1134, Avg. Train Loss: 0.00014482941552942488, Avg. Test Loss: 0.00014981765707489103\n",
      "Epoch: 1135, Avg. Train Loss: 0.00014425043949348374, Avg. Test Loss: 0.00014970480697229505\n",
      "Epoch: 1136, Avg. Train Loss: 0.00014503790894090089, Avg. Test Loss: 0.00014952040510252118\n",
      "Epoch: 1137, Avg. Train Loss: 0.00014545020090990027, Avg. Test Loss: 0.00015638495096936822\n",
      "Epoch: 1138, Avg. Train Loss: 0.0001468883954573336, Avg. Test Loss: 0.00015071025700308383\n",
      "Epoch: 1139, Avg. Train Loss: 0.00014708802370668584, Avg. Test Loss: 0.0001561216777190566\n",
      "Epoch: 1140, Avg. Train Loss: 0.00014629937826146825, Avg. Test Loss: 0.00015852827345952392\n",
      "Epoch: 1141, Avg. Train Loss: 0.00014503519754683556, Avg. Test Loss: 0.0001491877337684855\n",
      "Epoch: 1142, Avg. Train Loss: 0.00014408190801014128, Avg. Test Loss: 0.00014987000031396747\n",
      "Epoch: 1143, Avg. Train Loss: 0.0001441553785996295, Avg. Test Loss: 0.0001527670247014612\n",
      "Epoch: 1144, Avg. Train Loss: 0.00014686539767819003, Avg. Test Loss: 0.00015128360246308148\n",
      "Epoch: 1145, Avg. Train Loss: 0.00014405567293748433, Avg. Test Loss: 0.00014906839351169765\n",
      "Epoch: 1146, Avg. Train Loss: 0.00014553901598637187, Avg. Test Loss: 0.0001505713298683986\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1147, Avg. Train Loss: 0.00014545310892402952, Avg. Test Loss: 0.00015416413953062147\n",
      "Epoch: 1148, Avg. Train Loss: 0.00014447326078837695, Avg. Test Loss: 0.00015372417692560703\n",
      "Epoch: 1149, Avg. Train Loss: 0.00014336076517708514, Avg. Test Loss: 0.0001530875888420269\n",
      "Epoch: 1150, Avg. Train Loss: 0.00014635138951382752, Avg. Test Loss: 0.000149672050611116\n",
      "Epoch: 1151, Avg. Train Loss: 0.00014554383842339523, Avg. Test Loss: 0.00015141020412556827\n",
      "Epoch: 1152, Avg. Train Loss: 0.00014296270802692878, Avg. Test Loss: 0.00014964162255637348\n",
      "Epoch: 1153, Avg. Train Loss: 0.0001446163247279866, Avg. Test Loss: 0.0001484412932768464\n",
      "Epoch: 1154, Avg. Train Loss: 0.00014395530702448776, Avg. Test Loss: 0.00015067405183799565\n",
      "Epoch: 1155, Avg. Train Loss: 0.00014639969713455282, Avg. Test Loss: 0.00015035696560516953\n",
      "Epoch: 1156, Avg. Train Loss: 0.00014275055260906474, Avg. Test Loss: 0.00015658439951948822\n",
      "Epoch: 1157, Avg. Train Loss: 0.00014385396071850474, Avg. Test Loss: 0.0001477210462326184\n",
      "Epoch: 1158, Avg. Train Loss: 0.0001426247685611638, Avg. Test Loss: 0.0001513285969849676\n",
      "Epoch: 1159, Avg. Train Loss: 0.00014347479060064828, Avg. Test Loss: 0.00015043496387079358\n",
      "Epoch: 1160, Avg. Train Loss: 0.00014480191748589277, Avg. Test Loss: 0.0001567195577081293\n",
      "Epoch: 1161, Avg. Train Loss: 0.00014376798766491892, Avg. Test Loss: 0.00014739800826646388\n",
      "Epoch: 1162, Avg. Train Loss: 0.00014433823999688897, Avg. Test Loss: 0.00015555926074739546\n",
      "Epoch: 1163, Avg. Train Loss: 0.00014307887393569705, Avg. Test Loss: 0.0001490949944127351\n",
      "Epoch: 1164, Avg. Train Loss: 0.00014291380750026207, Avg. Test Loss: 0.0001487551344325766\n",
      "Epoch: 1165, Avg. Train Loss: 0.00014232571282813889, Avg. Test Loss: 0.00014953989011701196\n",
      "Epoch: 1166, Avg. Train Loss: 0.00014376864520843725, Avg. Test Loss: 0.00014787937107030302\n",
      "Epoch: 1167, Avg. Train Loss: 0.00014482432946584425, Avg. Test Loss: 0.00015185099618975073\n",
      "Epoch: 1168, Avg. Train Loss: 0.00014668962475572996, Avg. Test Loss: 0.00015110183448996395\n",
      "Epoch: 1169, Avg. Train Loss: 0.0001428216498827042, Avg. Test Loss: 0.00014698476297780871\n",
      "Epoch: 1170, Avg. Train Loss: 0.00014474472778221203, Avg. Test Loss: 0.00015170990081969649\n",
      "Epoch: 1171, Avg. Train Loss: 0.0001429702002327716, Avg. Test Loss: 0.00014849205035716295\n",
      "Epoch: 1172, Avg. Train Loss: 0.0001445893045287406, Avg. Test Loss: 0.00015599052130710334\n",
      "Epoch: 1173, Avg. Train Loss: 0.00014364601588039117, Avg. Test Loss: 0.00015040360449347645\n",
      "Epoch: 1174, Avg. Train Loss: 0.00014155783939586822, Avg. Test Loss: 0.00014752299466636032\n",
      "Epoch: 1175, Avg. Train Loss: 0.0001412695062246585, Avg. Test Loss: 0.0001473490265198052\n",
      "Epoch: 1176, Avg. Train Loss: 0.00014169689614412396, Avg. Test Loss: 0.0001485698448959738\n",
      "Epoch: 1177, Avg. Train Loss: 0.00014174824376146547, Avg. Test Loss: 0.00015310895105358213\n",
      "Epoch: 1178, Avg. Train Loss: 0.00014216015315046102, Avg. Test Loss: 0.00014706635556649417\n",
      "Epoch: 1179, Avg. Train Loss: 0.0001414434657415895, Avg. Test Loss: 0.0001477520418120548\n",
      "Epoch: 1180, Avg. Train Loss: 0.00014431527064474257, Avg. Test Loss: 0.00014915781503077596\n",
      "Epoch: 1181, Avg. Train Loss: 0.0001429610037607639, Avg. Test Loss: 0.000147562735946849\n",
      "Epoch: 1182, Avg. Train Loss: 0.00014119130406301295, Avg. Test Loss: 0.00014625450421590358\n",
      "Epoch: 1183, Avg. Train Loss: 0.00014208815331966074, Avg. Test Loss: 0.0001518370845587924\n",
      "Epoch: 1184, Avg. Train Loss: 0.00014385080836756633, Avg. Test Loss: 0.0001538237411295995\n",
      "Epoch: 1185, Avg. Train Loss: 0.00014192731946105743, Avg. Test Loss: 0.0001466819376219064\n",
      "Epoch: 1186, Avg. Train Loss: 0.00014049963275008552, Avg. Test Loss: 0.00014953306526876986\n",
      "Epoch: 1187, Avg. Train Loss: 0.0001422843391950199, Avg. Test Loss: 0.00014960666885599494\n",
      "Epoch: 1188, Avg. Train Loss: 0.00014262164869822215, Avg. Test Loss: 0.000147483850014396\n",
      "Epoch: 1189, Avg. Train Loss: 0.00014239209731174417, Avg. Test Loss: 0.00014711709809489548\n",
      "Epoch: 1190, Avg. Train Loss: 0.00014151559721646009, Avg. Test Loss: 0.00014687643852084875\n",
      "Epoch: 1191, Avg. Train Loss: 0.00014140655125523808, Avg. Test Loss: 0.00014576417743228376\n",
      "Epoch: 1192, Avg. Train Loss: 0.00014181302448864594, Avg. Test Loss: 0.00014965253649279475\n",
      "Epoch: 1193, Avg. Train Loss: 0.00014068624803384897, Avg. Test Loss: 0.0001462792424717918\n",
      "Epoch: 1194, Avg. Train Loss: 0.0001418316394339727, Avg. Test Loss: 0.00014684550114907324\n",
      "Epoch: 1195, Avg. Train Loss: 0.0001407787088727102, Avg. Test Loss: 0.00015032185183372349\n",
      "Epoch: 1196, Avg. Train Loss: 0.00014280880291047397, Avg. Test Loss: 0.0001491023285780102\n",
      "Epoch: 1197, Avg. Train Loss: 0.00014247571870814577, Avg. Test Loss: 0.00014685105998069048\n",
      "Epoch: 1198, Avg. Train Loss: 0.00014549185864378287, Avg. Test Loss: 0.00015312446339521557\n",
      "Epoch: 1199, Avg. Train Loss: 0.00014128189616522557, Avg. Test Loss: 0.00014965105219744146\n",
      "Epoch: 1200, Avg. Train Loss: 0.00014155471513351036, Avg. Test Loss: 0.00014796889445278794\n",
      "Epoch: 1201, Avg. Train Loss: 0.00014182211402099753, Avg. Test Loss: 0.00014702761836815625\n",
      "Epoch: 1202, Avg. Train Loss: 0.0001410851180607583, Avg. Test Loss: 0.0001517828495707363\n",
      "Epoch: 1203, Avg. Train Loss: 0.00014056220090931802, Avg. Test Loss: 0.00015196487947832793\n",
      "Epoch: 1204, Avg. Train Loss: 0.00014162846660880415, Avg. Test Loss: 0.00014669078518636525\n",
      "Epoch: 1205, Avg. Train Loss: 0.000142469021781391, Avg. Test Loss: 0.0001453431905247271\n",
      "Epoch: 1206, Avg. Train Loss: 0.00014100346049607926, Avg. Test Loss: 0.0001452590513508767\n",
      "Epoch: 1207, Avg. Train Loss: 0.00014262065544540367, Avg. Test Loss: 0.0001496871409472078\n",
      "Epoch: 1208, Avg. Train Loss: 0.00014088760829953, Avg. Test Loss: 0.00014548022591043264\n",
      "Epoch: 1209, Avg. Train Loss: 0.0001405831428074148, Avg. Test Loss: 0.00014859485963825136\n",
      "Epoch: 1210, Avg. Train Loss: 0.00014122289051789097, Avg. Test Loss: 0.00014720481703989208\n",
      "Epoch: 1211, Avg. Train Loss: 0.0001418152177668458, Avg. Test Loss: 0.0001476632314734161\n",
      "Epoch: 1212, Avg. Train Loss: 0.00014016847024660904, Avg. Test Loss: 0.00014808130799792707\n",
      "Epoch: 1213, Avg. Train Loss: 0.00014111065261098447, Avg. Test Loss: 0.00014700523752253503\n",
      "Epoch: 1214, Avg. Train Loss: 0.0001413591648045884, Avg. Test Loss: 0.0001550983142806217\n",
      "Epoch: 1215, Avg. Train Loss: 0.000141610320708931, Avg. Test Loss: 0.00014742676285095513\n",
      "Epoch: 1216, Avg. Train Loss: 0.00014088529792917503, Avg. Test Loss: 0.00014742629718966782\n",
      "Epoch: 1217, Avg. Train Loss: 0.00014205047553459313, Avg. Test Loss: 0.00014569234917871654\n",
      "Epoch: 1218, Avg. Train Loss: 0.00014179352762957298, Avg. Test Loss: 0.0001474352175137028\n",
      "Epoch: 1219, Avg. Train Loss: 0.00014362568719323378, Avg. Test Loss: 0.00015482117305509746\n",
      "Epoch: 1220, Avg. Train Loss: 0.0001423523336957577, Avg. Test Loss: 0.00014620428555645049\n",
      "Epoch: 1221, Avg. Train Loss: 0.00014161317051539934, Avg. Test Loss: 0.00014688797818962485\n",
      "Epoch: 1222, Avg. Train Loss: 0.00014083662989473533, Avg. Test Loss: 0.00014618239947594702\n",
      "Epoch: 1223, Avg. Train Loss: 0.00013999480498294063, Avg. Test Loss: 0.00014486252621281892\n",
      "Epoch: 1224, Avg. Train Loss: 0.00014026954751136865, Avg. Test Loss: 0.0001460542407585308\n",
      "Epoch: 1225, Avg. Train Loss: 0.00014039076598047084, Avg. Test Loss: 0.00014680005551781505\n",
      "Epoch: 1226, Avg. Train Loss: 0.00014003463526700386, Avg. Test Loss: 0.00014823685341980308\n",
      "Epoch: 1227, Avg. Train Loss: 0.00014083946345720526, Avg. Test Loss: 0.0001443262299289927\n",
      "Epoch: 1228, Avg. Train Loss: 0.00014047677862880274, Avg. Test Loss: 0.0001442625216441229\n",
      "Epoch: 1229, Avg. Train Loss: 0.00013978713375467503, Avg. Test Loss: 0.00014698925951961428\n",
      "Epoch: 1230, Avg. Train Loss: 0.00014270950707087162, Avg. Test Loss: 0.00014556160022038966\n",
      "Epoch: 1231, Avg. Train Loss: 0.00014219123011909772, Avg. Test Loss: 0.00015700857329647988\n",
      "Epoch: 1232, Avg. Train Loss: 0.000140885193696852, Avg. Test Loss: 0.00015620050544384867\n",
      "Epoch: 1233, Avg. Train Loss: 0.00013965735791337698, Avg. Test Loss: 0.0001453965378459543\n",
      "Epoch: 1234, Avg. Train Loss: 0.00014033367069503076, Avg. Test Loss: 0.00014897370419930667\n",
      "Epoch: 1235, Avg. Train Loss: 0.00013968546138426593, Avg. Test Loss: 0.00014808033301960677\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1236, Avg. Train Loss: 0.00014099459194978915, Avg. Test Loss: 0.0001456538011552766\n",
      "Epoch: 1237, Avg. Train Loss: 0.0001403756876581695, Avg. Test Loss: 0.00014529351028613746\n",
      "Epoch: 1238, Avg. Train Loss: 0.0001423923983333394, Avg. Test Loss: 0.00014442039537243545\n",
      "Epoch: 1239, Avg. Train Loss: 0.00014087781418374804, Avg. Test Loss: 0.00014731545525137335\n",
      "Epoch: 1240, Avg. Train Loss: 0.00014211511751095396, Avg. Test Loss: 0.00014668617222923785\n",
      "Epoch: 1241, Avg. Train Loss: 0.00014054800805413749, Avg. Test Loss: 0.00014492298942059278\n",
      "Epoch: 1242, Avg. Train Loss: 0.00014043608369024166, Avg. Test Loss: 0.000146413134643808\n",
      "Epoch: 1243, Avg. Train Loss: 0.00013998082059240617, Avg. Test Loss: 0.00015177513705566525\n",
      "Epoch: 1244, Avg. Train Loss: 0.0001406753760610902, Avg. Test Loss: 0.0001470906427130103\n",
      "Epoch: 1245, Avg. Train Loss: 0.0001395312330799264, Avg. Test Loss: 0.0001498902274761349\n",
      "Epoch: 1246, Avg. Train Loss: 0.0001398135300828577, Avg. Test Loss: 0.00014833916793577373\n",
      "Epoch: 1247, Avg. Train Loss: 0.00013957776672066037, Avg. Test Loss: 0.00014679580635856837\n",
      "Epoch: 1248, Avg. Train Loss: 0.00014021533333593547, Avg. Test Loss: 0.00015317935321945697\n",
      "Epoch: 1249, Avg. Train Loss: 0.00014119320664132492, Avg. Test Loss: 0.00014601547445636243\n",
      "Epoch: 1250, Avg. Train Loss: 0.00013912268332205713, Avg. Test Loss: 0.0001448147086193785\n",
      "Epoch: 1251, Avg. Train Loss: 0.00014009173765919323, Avg. Test Loss: 0.0001514570612926036\n",
      "Epoch: 1252, Avg. Train Loss: 0.0001402337166350768, Avg. Test Loss: 0.00014704281056765467\n",
      "Epoch: 1253, Avg. Train Loss: 0.00014002095629748088, Avg. Test Loss: 0.00015613350842613727\n",
      "Epoch: 1254, Avg. Train Loss: 0.0001423907385689618, Avg. Test Loss: 0.00015225469542201608\n",
      "Epoch: 1255, Avg. Train Loss: 0.00014193586228133806, Avg. Test Loss: 0.00014498221571557224\n",
      "Epoch: 1256, Avg. Train Loss: 0.00013991394641993263, Avg. Test Loss: 0.00014404761896003038\n",
      "Epoch: 1257, Avg. Train Loss: 0.0001424554810550627, Avg. Test Loss: 0.00014920807734597474\n",
      "Epoch: 1258, Avg. Train Loss: 0.00013953300756754268, Avg. Test Loss: 0.00014729078975506127\n",
      "Epoch: 1259, Avg. Train Loss: 0.00014054818419999507, Avg. Test Loss: 0.00014695593563374132\n",
      "Epoch: 1260, Avg. Train Loss: 0.00014100359078648305, Avg. Test Loss: 0.00015135560533963144\n",
      "Epoch: 1261, Avg. Train Loss: 0.00014098858234721647, Avg. Test Loss: 0.0001451283023925498\n",
      "Epoch: 1262, Avg. Train Loss: 0.00014121082664175002, Avg. Test Loss: 0.00014721874322276562\n",
      "Epoch: 1263, Avg. Train Loss: 0.0001405208749929443, Avg. Test Loss: 0.00014523800928145647\n",
      "Epoch: 1264, Avg. Train Loss: 0.00014055294555281614, Avg. Test Loss: 0.00015039282152429223\n",
      "Epoch: 1265, Avg. Train Loss: 0.00014081742102821726, Avg. Test Loss: 0.0001482485531596467\n",
      "Epoch: 1266, Avg. Train Loss: 0.00013877563875677542, Avg. Test Loss: 0.0001441068743588403\n",
      "Epoch: 1267, Avg. Train Loss: 0.00013923167378295128, Avg. Test Loss: 0.00014586452743969858\n",
      "Epoch: 1268, Avg. Train Loss: 0.0001392355322401949, Avg. Test Loss: 0.0001481491344748065\n",
      "Epoch: 1269, Avg. Train Loss: 0.00013910369239585085, Avg. Test Loss: 0.00014636786363553256\n",
      "Epoch: 1270, Avg. Train Loss: 0.0001416191097273123, Avg. Test Loss: 0.00015403932775370777\n",
      "Epoch: 1271, Avg. Train Loss: 0.00014106777150097282, Avg. Test Loss: 0.00014409802679438144\n",
      "Epoch: 1272, Avg. Train Loss: 0.0001397241105942792, Avg. Test Loss: 0.00014596054097637534\n",
      "Epoch: 1273, Avg. Train Loss: 0.00014054275735086479, Avg. Test Loss: 0.00014818549971096218\n",
      "Epoch: 1274, Avg. Train Loss: 0.00014042967340237525, Avg. Test Loss: 0.00014723921776749194\n",
      "Epoch: 1275, Avg. Train Loss: 0.0001384672833346697, Avg. Test Loss: 0.00014782517973799258\n",
      "Epoch: 1276, Avg. Train Loss: 0.00014095699758442161, Avg. Test Loss: 0.00014477978402283043\n",
      "Epoch: 1277, Avg. Train Loss: 0.0001407303910994859, Avg. Test Loss: 0.00014610958169214427\n",
      "Epoch: 1278, Avg. Train Loss: 0.0001401326974087698, Avg. Test Loss: 0.00014626808115281165\n",
      "Epoch: 1279, Avg. Train Loss: 0.00013954493726148854, Avg. Test Loss: 0.00014510101755149662\n",
      "Epoch: 1280, Avg. Train Loss: 0.00013942464402346157, Avg. Test Loss: 0.0001479125494370237\n",
      "Epoch: 1281, Avg. Train Loss: 0.00014008720490680791, Avg. Test Loss: 0.00014361288049258292\n",
      "Epoch: 1282, Avg. Train Loss: 0.00013977140330352148, Avg. Test Loss: 0.00014778701006434858\n",
      "Epoch: 1283, Avg. Train Loss: 0.00014007723007654382, Avg. Test Loss: 0.00014954582729842514\n",
      "Epoch: 1284, Avg. Train Loss: 0.000140573987960653, Avg. Test Loss: 0.00015111960237845778\n",
      "Epoch: 1285, Avg. Train Loss: 0.0001412423423675517, Avg. Test Loss: 0.00014510765322484076\n",
      "Epoch: 1286, Avg. Train Loss: 0.0001384758840241946, Avg. Test Loss: 0.00014360823843162507\n",
      "Epoch: 1287, Avg. Train Loss: 0.00014035623580850877, Avg. Test Loss: 0.00015570834511891007\n",
      "Epoch: 1288, Avg. Train Loss: 0.0001388265643685753, Avg. Test Loss: 0.00014522604760713875\n",
      "Epoch: 1289, Avg. Train Loss: 0.0001398836251356379, Avg. Test Loss: 0.00014861641102470458\n",
      "Epoch: 1290, Avg. Train Loss: 0.0001409499700246162, Avg. Test Loss: 0.0001453887962270528\n",
      "Epoch: 1291, Avg. Train Loss: 0.00014003493611939078, Avg. Test Loss: 0.0001539293152745813\n",
      "Epoch: 1292, Avg. Train Loss: 0.0001400904790877343, Avg. Test Loss: 0.0001446620444767177\n",
      "Epoch: 1293, Avg. Train Loss: 0.00013888136451240888, Avg. Test Loss: 0.00014695552818011492\n",
      "Epoch: 1294, Avg. Train Loss: 0.00013917134154241447, Avg. Test Loss: 0.0001454471203032881\n",
      "Epoch: 1295, Avg. Train Loss: 0.00014233173749025175, Avg. Test Loss: 0.00014566363824997097\n",
      "Epoch: 1296, Avg. Train Loss: 0.00014072501061343436, Avg. Test Loss: 0.00014778875629417598\n",
      "Epoch: 1297, Avg. Train Loss: 0.00013961589307697533, Avg. Test Loss: 0.00014844012912362814\n",
      "Epoch: 1298, Avg. Train Loss: 0.00014015521395946095, Avg. Test Loss: 0.00014335951709654182\n",
      "Epoch: 1299, Avg. Train Loss: 0.0001386218967571378, Avg. Test Loss: 0.00014508316235151142\n",
      "Epoch: 1300, Avg. Train Loss: 0.00013924967450208877, Avg. Test Loss: 0.0001452875294489786\n",
      "Epoch: 1301, Avg. Train Loss: 0.00013840537458024703, Avg. Test Loss: 0.0001470164133934304\n",
      "Epoch: 1302, Avg. Train Loss: 0.00013875252896172622, Avg. Test Loss: 0.00014454580377787352\n",
      "Epoch: 1303, Avg. Train Loss: 0.0001400219805154213, Avg. Test Loss: 0.0001443576766178012\n",
      "Epoch: 1304, Avg. Train Loss: 0.00013989422637509009, Avg. Test Loss: 0.00014671185635961592\n",
      "Epoch: 1305, Avg. Train Loss: 0.0001403511739417174, Avg. Test Loss: 0.00015075372357387096\n",
      "Epoch: 1306, Avg. Train Loss: 0.00014006321590534563, Avg. Test Loss: 0.00015012001676950604\n",
      "Epoch: 1307, Avg. Train Loss: 0.00013900644702262918, Avg. Test Loss: 0.00014738587196916342\n",
      "Epoch: 1308, Avg. Train Loss: 0.00014233694758352845, Avg. Test Loss: 0.0001590534666320309\n",
      "Epoch: 1309, Avg. Train Loss: 0.00014148611435937412, Avg. Test Loss: 0.00014456397911999375\n",
      "Epoch: 1310, Avg. Train Loss: 0.00014045429795027473, Avg. Test Loss: 0.00014425147674046457\n",
      "Epoch: 1311, Avg. Train Loss: 0.00013890380881114884, Avg. Test Loss: 0.00014887383440509439\n",
      "Epoch: 1312, Avg. Train Loss: 0.0001396715242028518, Avg. Test Loss: 0.00014314432337414473\n",
      "Epoch: 1313, Avg. Train Loss: 0.00013850691462975254, Avg. Test Loss: 0.0001434511214029044\n",
      "Epoch: 1314, Avg. Train Loss: 0.00013892057075620044, Avg. Test Loss: 0.00014515446673613042\n",
      "Epoch: 1315, Avg. Train Loss: 0.0001385355978083342, Avg. Test Loss: 0.000145144818816334\n",
      "Epoch: 1316, Avg. Train Loss: 0.00013960841711513092, Avg. Test Loss: 0.0001455177116440609\n",
      "Epoch: 1317, Avg. Train Loss: 0.0001405837490808132, Avg. Test Loss: 0.00014565129822585732\n",
      "Epoch: 1318, Avg. Train Loss: 0.00014192521163305745, Avg. Test Loss: 0.00015294122567865998\n",
      "Epoch: 1319, Avg. Train Loss: 0.00014104628576734645, Avg. Test Loss: 0.00014687365910504013\n",
      "Epoch: 1320, Avg. Train Loss: 0.00013944812404630748, Avg. Test Loss: 0.00014539163385052234\n",
      "Epoch: 1321, Avg. Train Loss: 0.00013931438433098455, Avg. Test Loss: 0.00014962645946070552\n",
      "Epoch: 1322, Avg. Train Loss: 0.00013844468522556993, Avg. Test Loss: 0.00014681620814371854\n",
      "Epoch: 1323, Avg. Train Loss: 0.00013814059486829265, Avg. Test Loss: 0.00014525001461151987\n",
      "Epoch: 1324, Avg. Train Loss: 0.00013831345808454031, Avg. Test Loss: 0.0001449399715056643\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1325, Avg. Train Loss: 0.00013813871699439492, Avg. Test Loss: 0.00014941816334612668\n",
      "Epoch: 1326, Avg. Train Loss: 0.0001393254202666021, Avg. Test Loss: 0.00014531260239891708\n",
      "Epoch: 1327, Avg. Train Loss: 0.00013865171769244033, Avg. Test Loss: 0.00014429284783545882\n",
      "Epoch: 1328, Avg. Train Loss: 0.00013815633327223707, Avg. Test Loss: 0.00014267161895986646\n",
      "Epoch: 1329, Avg. Train Loss: 0.00013869657718608978, Avg. Test Loss: 0.00014598121924791485\n",
      "Epoch: 1330, Avg. Train Loss: 0.00013950969776826326, Avg. Test Loss: 0.00014428999566007406\n",
      "Epoch: 1331, Avg. Train Loss: 0.0001390529515595327, Avg. Test Loss: 0.00014440214727073908\n",
      "Epoch: 1332, Avg. Train Loss: 0.00013925427764513378, Avg. Test Loss: 0.00014493260823655874\n",
      "Epoch: 1333, Avg. Train Loss: 0.00013765901344730844, Avg. Test Loss: 0.00014335177547764033\n",
      "Epoch: 1334, Avg. Train Loss: 0.00013775015886071637, Avg. Test Loss: 0.00014385963731911033\n",
      "Epoch: 1335, Avg. Train Loss: 0.00014116005365585172, Avg. Test Loss: 0.00014784377708565444\n",
      "Epoch: 1336, Avg. Train Loss: 0.00013934490189692654, Avg. Test Loss: 0.00014338608889374882\n",
      "Epoch: 1337, Avg. Train Loss: 0.000138411529701972, Avg. Test Loss: 0.0001453930453862995\n",
      "Epoch: 1338, Avg. Train Loss: 0.00013773462824458473, Avg. Test Loss: 0.00014656917483080178\n",
      "Epoch: 1339, Avg. Train Loss: 0.00013854326565240963, Avg. Test Loss: 0.0001484192325733602\n",
      "Epoch: 1340, Avg. Train Loss: 0.00013900421854909942, Avg. Test Loss: 0.00014653883408755064\n",
      "Epoch: 1341, Avg. Train Loss: 0.00014011935922479647, Avg. Test Loss: 0.00014418170030694455\n",
      "Epoch: 1342, Avg. Train Loss: 0.00013874319221602406, Avg. Test Loss: 0.0001460183848394081\n",
      "Epoch: 1343, Avg. Train Loss: 0.00013885926759834292, Avg. Test Loss: 0.00014449012815020978\n",
      "Epoch: 1344, Avg. Train Loss: 0.00014088875079408373, Avg. Test Loss: 0.00015544505731668323\n",
      "Epoch: 1345, Avg. Train Loss: 0.0001414639575455641, Avg. Test Loss: 0.00014533643843606114\n",
      "Epoch: 1346, Avg. Train Loss: 0.00013839270104654133, Avg. Test Loss: 0.00014765119703952223\n",
      "Epoch: 1347, Avg. Train Loss: 0.0001378767243126234, Avg. Test Loss: 0.00014312041457742453\n",
      "Epoch: 1348, Avg. Train Loss: 0.00013838401389156663, Avg. Test Loss: 0.00014431227464228868\n",
      "Epoch: 1349, Avg. Train Loss: 0.0001392166951243484, Avg. Test Loss: 0.000142889199196361\n",
      "Epoch: 1350, Avg. Train Loss: 0.000138726991704167, Avg. Test Loss: 0.0001446521928301081\n",
      "Epoch: 1351, Avg. Train Loss: 0.0001386400798828406, Avg. Test Loss: 0.00014352444850374013\n",
      "Epoch: 1352, Avg. Train Loss: 0.00013749107588515726, Avg. Test Loss: 0.00014373294834513217\n",
      "Epoch: 1353, Avg. Train Loss: 0.00013978161519463716, Avg. Test Loss: 0.0001464198576286435\n",
      "Epoch: 1354, Avg. Train Loss: 0.0001411230970366295, Avg. Test Loss: 0.00014654634287580848\n",
      "Epoch: 1355, Avg. Train Loss: 0.00013855406689609206, Avg. Test Loss: 0.00014660377928521484\n",
      "Epoch: 1356, Avg. Train Loss: 0.00013967012501928176, Avg. Test Loss: 0.00014237899449653924\n",
      "Epoch: 1357, Avg. Train Loss: 0.00013802898878524037, Avg. Test Loss: 0.00014367887342814356\n",
      "Epoch: 1358, Avg. Train Loss: 0.00013858228069080344, Avg. Test Loss: 0.00014552235370501876\n",
      "Epoch: 1359, Avg. Train Loss: 0.00013778833834844273, Avg. Test Loss: 0.0001426615344826132\n",
      "Epoch: 1360, Avg. Train Loss: 0.00013857543909093797, Avg. Test Loss: 0.00014942458074074239\n",
      "Epoch: 1361, Avg. Train Loss: 0.00014095469770498227, Avg. Test Loss: 0.00014615262625738978\n",
      "Epoch: 1362, Avg. Train Loss: 0.00013868121696273297, Avg. Test Loss: 0.0001449758419767022\n",
      "Epoch: 1363, Avg. Train Loss: 0.00013825065607941427, Avg. Test Loss: 0.00014273937267716974\n",
      "Epoch: 1364, Avg. Train Loss: 0.00013795598487228934, Avg. Test Loss: 0.00014450159505940974\n",
      "Epoch: 1365, Avg. Train Loss: 0.0001391556396874664, Avg. Test Loss: 0.0001427886018063873\n",
      "Epoch: 1366, Avg. Train Loss: 0.00013873401232643138, Avg. Test Loss: 0.00014739272592123598\n",
      "Epoch: 1367, Avg. Train Loss: 0.00013963112419438658, Avg. Test Loss: 0.0001469466951675713\n",
      "Epoch: 1368, Avg. Train Loss: 0.00013972314729133274, Avg. Test Loss: 0.00015409558545798063\n",
      "Epoch: 1369, Avg. Train Loss: 0.00013877160686100724, Avg. Test Loss: 0.00014451854804065078\n",
      "Epoch: 1370, Avg. Train Loss: 0.00013858575639883489, Avg. Test Loss: 0.00015624701336491853\n",
      "Epoch: 1371, Avg. Train Loss: 0.00014128763097349207, Avg. Test Loss: 0.0001443907240172848\n",
      "Epoch: 1372, Avg. Train Loss: 0.00013875757999918533, Avg. Test Loss: 0.00014479276433121413\n",
      "Epoch: 1373, Avg. Train Loss: 0.00013971848475616858, Avg. Test Loss: 0.00014324461517389864\n",
      "Epoch: 1374, Avg. Train Loss: 0.00013889554281567418, Avg. Test Loss: 0.00014745088992640376\n",
      "Epoch: 1375, Avg. Train Loss: 0.0001382771708534186, Avg. Test Loss: 0.00014381900837179273\n",
      "Epoch: 1376, Avg. Train Loss: 0.00013810070942231822, Avg. Test Loss: 0.00014437417848967016\n",
      "Epoch: 1377, Avg. Train Loss: 0.00013869545990357522, Avg. Test Loss: 0.00014481741527561098\n",
      "Epoch: 1378, Avg. Train Loss: 0.00013961824879515916, Avg. Test Loss: 0.00014526241284329444\n",
      "Epoch: 1379, Avg. Train Loss: 0.00013780817176285742, Avg. Test Loss: 0.00014469838060904294\n",
      "Epoch: 1380, Avg. Train Loss: 0.00014023492968949858, Avg. Test Loss: 0.0001450236450182274\n",
      "Epoch: 1381, Avg. Train Loss: 0.00013750981739830485, Avg. Test Loss: 0.0001435339800082147\n",
      "Epoch: 1382, Avg. Train Loss: 0.00013874457786292878, Avg. Test Loss: 0.00015583138156216592\n",
      "Epoch: 1383, Avg. Train Loss: 0.00013902570902055866, Avg. Test Loss: 0.00014581953291781247\n",
      "Epoch: 1384, Avg. Train Loss: 0.00013846844579580477, Avg. Test Loss: 0.00014360380009748042\n",
      "Epoch: 1385, Avg. Train Loss: 0.0001378273024551332, Avg. Test Loss: 0.00014459533849731088\n",
      "Epoch: 1386, Avg. Train Loss: 0.0001390144336551731, Avg. Test Loss: 0.00014406273839995265\n",
      "Epoch: 1387, Avg. Train Loss: 0.0001379600849590091, Avg. Test Loss: 0.00014553045912180096\n",
      "Epoch: 1388, Avg. Train Loss: 0.0001396743342453657, Avg. Test Loss: 0.0001437122846255079\n",
      "Epoch: 1389, Avg. Train Loss: 0.0001389502454955174, Avg. Test Loss: 0.00014239104348234832\n",
      "Epoch: 1390, Avg. Train Loss: 0.0001393936305079436, Avg. Test Loss: 0.00014626966731157154\n",
      "Epoch: 1391, Avg. Train Loss: 0.00013865478543922046, Avg. Test Loss: 0.0001479453349020332\n",
      "Epoch: 1392, Avg. Train Loss: 0.00013884056737202457, Avg. Test Loss: 0.00014522603305522352\n",
      "Epoch: 1393, Avg. Train Loss: 0.00013851195060767148, Avg. Test Loss: 0.00014521999401040375\n",
      "Epoch: 1394, Avg. Train Loss: 0.00013834284939992695, Avg. Test Loss: 0.0001495698670623824\n",
      "Epoch: 1395, Avg. Train Loss: 0.0001392748356095602, Avg. Test Loss: 0.00014562458090949804\n",
      "Epoch: 1396, Avg. Train Loss: 0.00013872328739569976, Avg. Test Loss: 0.0001443105866201222\n",
      "Epoch: 1397, Avg. Train Loss: 0.0001388126715197401, Avg. Test Loss: 0.00014297703455667943\n",
      "Epoch: 1398, Avg. Train Loss: 0.0001390496455674428, Avg. Test Loss: 0.00014402989472728223\n",
      "Epoch: 1399, Avg. Train Loss: 0.00013897689123675876, Avg. Test Loss: 0.00014464299601968378\n",
      "Epoch: 1400, Avg. Train Loss: 0.00013798384248349426, Avg. Test Loss: 0.00014448261936195195\n",
      "Finished Training\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2af2ef4ca9b0>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Now let's train the initial network \n",
    "\n",
    "model = offCenterLineNet()\n",
    "model = model.to(dev)\n",
    "model.apply(weights_init_uniform)\n",
    "\n",
    "model.train();\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=.01) \n",
    "# scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=500, gamma=0.1)\n",
    "\n",
    "n_epochs = 1400\n",
    "\n",
    "mse_loss = nn.MSELoss()\n",
    "ce_loss = nn.CrossEntropyLoss()\n",
    "\n",
    "for epoch in range(0,n_epochs):  # loop over the dataset multiple times\n",
    "    \n",
    "    if epoch == 0:\n",
    "        train_loss_over_time = [] # to track the loss as the network trains\n",
    "        test_loss_over_time = []\n",
    "        \n",
    "    if epoch == 10:\n",
    "        optimizer = torch.optim.Adam(model.parameters(),lr=.002) \n",
    "        \n",
    "    running_loss = 0\n",
    "    num_batches = 0\n",
    "    \n",
    "    for batch_i, data in enumerate(train_loader):\n",
    "        \n",
    "        # get the input images and their corresponding labels\n",
    "        num_batches += 1\n",
    "\n",
    "        inputs, output_gt, _, _ = data\n",
    "        inputs, output_gt = inputs.to(dev), output_gt.to(dev)\n",
    "        \n",
    "        # zero the parameter (weight) gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # forward pass to get outputs\n",
    "        output_line_params = model(inputs)\n",
    "        \n",
    "\n",
    "        # make the ground truth\n",
    "        c = -output_gt[:,2]*torch.cos(output_gt[:,0]) + output_gt[:,1]*torch.sin(output_gt[:,0])\n",
    "        gt_line_params = torch.stack((-torch.sin(output_gt[:,0]),torch.cos(output_gt[:,0]),c),dim=1)\n",
    "        \n",
    "        # calculate the loss\n",
    "#         print(output_line_params[:,:,0,50])\n",
    "        \n",
    "        loss = mse_loss(output_line_params,gt_line_params)\n",
    "        \n",
    "        # backward pass to calculate the parameter gradients\n",
    "        loss.backward()\n",
    "\n",
    "        # update the parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        # to convert loss into a scalar and add it to running_loss, we use .item()\n",
    "        running_loss += loss.item()\n",
    "      \n",
    "\n",
    "#     scheduler.step()\n",
    "    \n",
    "    # Calculate test data loss after each epoch\n",
    "    with torch.no_grad():\n",
    "        test_loss = 0\n",
    "        num_batches_test = 0\n",
    "        for batch_i, data in enumerate(test_loader):\n",
    "            num_batches_test += 1\n",
    "\n",
    "            # Add code here\n",
    "            inputs, output_gt, _, _ = data\n",
    "            inputs, output_gt = inputs.to(dev), output_gt.to(dev)\n",
    "\n",
    "\n",
    "            # zero the parameter (weight) gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward pass to get outputs\n",
    "            output_line_params = model(inputs)\n",
    "\n",
    "            # make the ground truth\n",
    "            c = -output_gt[:,2]*torch.cos(output_gt[:,0]) + output_gt[:,1]*torch.sin(output_gt[:,0])\n",
    "            gt_line_params = torch.stack((-torch.sin(output_gt[:,0]),torch.cos(output_gt[:,0]),c),dim=1)\n",
    "    \n",
    "\n",
    "            # calculate the loss\n",
    "    #         print(output_line_params[:,:,0,50])\n",
    "\n",
    "            loss = mse_loss(output_line_params,gt_line_params)\n",
    "            \n",
    "            test_loss += loss\n",
    "                    \n",
    "        test_loss_over_time.append(test_loss/num_batches_test)\n",
    "\n",
    "    # Calculate model loss:\n",
    "    avg_loss = running_loss/num_batches\n",
    "    train_loss_over_time.append(avg_loss)\n",
    "    \n",
    "#     print('Epoch: {}, Avg. Train Loss: {},'.format(epoch + 1, train_loss_over_time[-1]))\n",
    "\n",
    "\n",
    "    print('Epoch: {}, Avg. Train Loss: {}, Avg. Test Loss: {}'.format(epoch + 1, train_loss_over_time[-1], test_loss_over_time[-1]))\n",
    "    \n",
    "print('Finished Training')\n",
    "\n",
    "plt.figure()\n",
    "plt.semilogy(np.arange(0,n_epochs),train_loss_over_time[0:])\n",
    "plt.semilogy(np.arange(0,n_epochs),test_loss_over_time[0:])\n",
    "plt.legend(['Training loss', 'Testing loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "af059bf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor(0.5064), tensor(0.5348), tensor(0.5896), tensor(0.5276), tensor(0.5186), tensor(0.6113), tensor(0.5879), tensor(0.5649), tensor(0.5537), tensor(0.5687), tensor(0.5636), tensor(0.5550), tensor(0.5539), tensor(0.5169), tensor(0.5258)]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1080 with 9 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the Results\n",
    "\n",
    "model.eval();\n",
    "\n",
    "ang_loss_all = []\n",
    "\n",
    "for batch_i, data in enumerate(test_loader):\n",
    "    # get the input images and their corresponding labels\n",
    "    inputs, output_gt, _, _ = data\n",
    "    inputs, output_gt = inputs.to(dev), output_gt.to(dev)\n",
    "    \n",
    "\n",
    "    # forward pass to get outputs\n",
    "    outputs = model(inputs).squeeze().detach().cpu()\n",
    "    \n",
    "    gt = output_gt.cpu().squeeze()\n",
    "    \n",
    "    c = -output_gt[:,2]*torch.cos(output_gt[:,0]) + output_gt[:,1]*torch.sin(output_gt[:,0])\n",
    "    angle_params = torch.stack((-torch.sin(output_gt[:,0]),torch.cos(output_gt[:,0]),c),axis=1).detach().cpu()\n",
    "  \n",
    "    # Calculate angular loss\n",
    "    ang_loss = torch.mean(torch.abs(torch.rad2deg(torch.atan2(-angle_params[:,0]*outputs[:,1] + angle_params[:,1]*outputs[:,0]\n",
    "                                         ,angle_params[:,1]*outputs[:,1]+angle_params[:,0]*outputs[:,0]).cpu())))\n",
    "\n",
    "    ang_loss_all.append(ang_loss)\n",
    "\n",
    "    \n",
    "print(ang_loss_all)\n",
    "\n",
    "plt.figure(figsize=[15, 15])\n",
    "\n",
    "for ii in range(9):\n",
    "    \n",
    "    plt.subplot(3,3,ii+1)\n",
    "    plt.imshow(inputs[ii].cpu().squeeze(),cmap='gray', vmin=0, vmax=1)\n",
    "    \n",
    "    # Plot the ground truth lines\n",
    "    x_sample = torch.linspace(-1,1,inputs.shape[-1])\n",
    "    y_sample = -angle_params[ii,0]/angle_params[ii,1]*x_sample - angle_params[ii,2]/angle_params[ii,1]\n",
    "    \n",
    "    plt.plot(x_sample*W/2+W/2,y_sample*W/2+W/2,'b')\n",
    "    plt.xlim([0,W])\n",
    "    plt.ylim(([0,W]))\n",
    "    \n",
    "    # Plot the estimated lines\n",
    "    y_est = -outputs[ii,0]/outputs[ii,1]*x_sample - outputs[ii,2]/outputs[ii,1]\n",
    "    plt.plot(x_sample*W/2+W/2,y_est*W/2+W/2,'r')\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a68904",
   "metadata": {},
   "source": [
    "## train on noisy, multicolor data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "239522a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1080 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load dataset \n",
    "\n",
    "data_folder = 'foj_data/grayscale_lines/'\n",
    "\n",
    "with open(data_folder + 'line_data_16_100000_grey_multicolor_noise_random_uncentered.pkl','rb') as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "# wedges = data['wedges']\n",
    "wedges_grey = data['wedges_grey']\n",
    "params = data['params']\n",
    "boundaries = data['boundaries']\n",
    "wedges = data['wedges']\n",
    "\n",
    "\n",
    "line_data = LineDataset(wedges_grey, params, boundaries, wedges)#, transform=trainTransform)\n",
    "data_size = len(line_data)\n",
    "\n",
    "print(data_size)\n",
    "\n",
    "train_proportion = .85\n",
    "# Split dataset into training and testing\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(line_data, [int(data_size*train_proportion), int(data_size*(1-train_proportion))], generator=torch.Generator().manual_seed(42))\n",
    "\n",
    "# Create loaders for the training and testing data\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=1000, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=500, shuffle=False) #len(test_dataset)\n",
    "\n",
    "\n",
    "W,H = 16,16\n",
    "\n",
    "img_show = 0\n",
    "plt.figure(figsize=[15, 15])\n",
    "plt.subplot(131)\n",
    "plt.imshow(wedges[img_show,:,:].squeeze().permute(1,2,0).cpu())\n",
    "plt.title('RGB Image')\n",
    "plt.axis('off');\n",
    "plt.subplot(132)\n",
    "plt.imshow(wedges_grey[img_show,:,:].squeeze().cpu(),cmap='gray', vmin=0, vmax=1)\n",
    "plt.title('Grayscale Image')\n",
    "plt.axis('off');\n",
    "plt.subplot(133)\n",
    "plt.imshow(boundaries[img_show,:,:].squeeze().cpu(),cmap='gray', vmin=0, vmax=1)\n",
    "plt.title('Boundaries')\n",
    "plt.axis('off');\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "ef98d494",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1            [-1, 8, 14, 14]              80\n",
      "              ReLU-2            [-1, 8, 14, 14]               0\n",
      "            Conv2d-3            [-1, 8, 12, 12]             584\n",
      "              ReLU-4            [-1, 8, 12, 12]               0\n",
      "            Conv2d-5            [-1, 1, 10, 10]              73\n",
      "         MaxPool2d-6              [-1, 1, 5, 5]               0\n",
      "            Linear-7                    [-1, 3]              78\n",
      "================================================================\n",
      "Total params: 815\n",
      "Trainable params: 815\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.04\n",
      "Params size (MB): 0.00\n",
      "Estimated Total Size (MB): 0.05\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "class offCenterLineNet(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "                \n",
    "        self.conv1 = nn.Conv2d(1, 8, kernel_size=3) #64 is good\n",
    "        self.conv2 = nn.Conv2d(8, 8, kernel_size=3)\n",
    "        self.conv3 = nn.Conv2d(8, 1, kernel_size=3)\n",
    "#         self.conv3 = nn.Conv2d(4, 1, kernel_size=3)\n",
    "#         self.conv3 = nn.Conv2d(128, 1, kernel_size=3)\n",
    "        self.fc = nn.LazyLinear(3)\n",
    "        self.maxpool = nn.MaxPool2d(2)\n",
    "        self.avgpool = nn.AvgPool2d(2)#,stride=1)\n",
    "        self.activate = nn.ReLU()\n",
    "#         self.batchnorm = nn.BatchNorm2d(16)\n",
    "    \n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.conv1(x)\n",
    "        x = self.activate(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.activate(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.maxpool(x)\n",
    "#         x = self.avgpool(x)\n",
    "        x = x.view(x.shape[0],-1)\n",
    "        \n",
    "        x = self.fc(x)\n",
    "         \n",
    "        # We're defining\n",
    "        # a = - sin(theta)\n",
    "        # b = cos(theta)\n",
    "        # c = -cy*cos(theta)+cx*sin(theta)\n",
    "        # Hence, we want to normalize the vector by 1/sqrt(a^2 + b^2)\n",
    "        norm_factor = (torch.norm(x[:,:2],p=2,dim=1)).unsqueeze(1)       \n",
    "        out = x/(norm_factor)#+eps)\n",
    "#         print('Output shape=',x.shape)\n",
    "\n",
    "#         out = x\n",
    "        \n",
    "        return out\n",
    "    \n",
    "model = offCenterLineNet()\n",
    "model = model.to(dev)\n",
    "summary(model, input_size=(1, H, W))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "a7e1bfdf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Avg. Train Loss: 0.7034099436858121, Avg. Test Loss: 0.6913908123970032\n",
      "Epoch: 2, Avg. Train Loss: 0.6755715559510623, Avg. Test Loss: 0.6603599786758423\n",
      "Epoch: 3, Avg. Train Loss: 0.6443942701115327, Avg. Test Loss: 0.6302202939987183\n",
      "Epoch: 4, Avg. Train Loss: 0.6165621953852036, Avg. Test Loss: 0.6051456928253174\n",
      "Epoch: 5, Avg. Train Loss: 0.5942968333468718, Avg. Test Loss: 0.585791826248169\n",
      "Epoch: 6, Avg. Train Loss: 0.5773453502094045, Avg. Test Loss: 0.5711895823478699\n",
      "Epoch: 7, Avg. Train Loss: 0.5644639071296244, Avg. Test Loss: 0.5601245760917664\n",
      "Epoch: 8, Avg. Train Loss: 0.5545233775587642, Avg. Test Loss: 0.54685378074646\n",
      "Epoch: 9, Avg. Train Loss: 0.5407782919266645, Avg. Test Loss: 0.5422813296318054\n",
      "Epoch: 10, Avg. Train Loss: 0.533346871768727, Avg. Test Loss: 0.5346519351005554\n",
      "Epoch: 11, Avg. Train Loss: 0.2926804872120128, Avg. Test Loss: 0.19699250161647797\n",
      "Epoch: 12, Avg. Train Loss: 0.17118162915987126, Avg. Test Loss: 0.4785272777080536\n",
      "Epoch: 13, Avg. Train Loss: 0.3545229252646951, Avg. Test Loss: 0.30815237760543823\n",
      "Epoch: 14, Avg. Train Loss: 0.30195860512116374, Avg. Test Loss: 0.2972407042980194\n",
      "Epoch: 15, Avg. Train Loss: 0.29032057138050305, Avg. Test Loss: 0.2855580151081085\n",
      "Epoch: 16, Avg. Train Loss: 0.28581623470082, Avg. Test Loss: 0.2606707513332367\n",
      "Epoch: 17, Avg. Train Loss: 0.1852639773312737, Avg. Test Loss: 0.1811188906431198\n",
      "Epoch: 18, Avg. Train Loss: 0.1822064294534571, Avg. Test Loss: 0.11501413583755493\n",
      "Epoch: 19, Avg. Train Loss: 0.10430580403874902, Avg. Test Loss: 0.09985747933387756\n",
      "Epoch: 20, Avg. Train Loss: 0.09323986435637754, Avg. Test Loss: 0.08984119445085526\n",
      "Epoch: 21, Avg. Train Loss: 0.08313815208042369, Avg. Test Loss: 0.09986356645822525\n",
      "Epoch: 22, Avg. Train Loss: 0.07505830885732875, Avg. Test Loss: 0.0727485790848732\n",
      "Epoch: 23, Avg. Train Loss: 0.06819176090990796, Avg. Test Loss: 0.06581860035657883\n",
      "Epoch: 24, Avg. Train Loss: 0.06246704209376784, Avg. Test Loss: 0.061438944190740585\n",
      "Epoch: 25, Avg. Train Loss: 0.05864641210612129, Avg. Test Loss: 0.05806247517466545\n",
      "Epoch: 26, Avg. Train Loss: 0.05580651922261014, Avg. Test Loss: 0.05557931587100029\n",
      "Epoch: 27, Avg. Train Loss: 0.053336557658279646, Avg. Test Loss: 0.053068432956933975\n",
      "Epoch: 28, Avg. Train Loss: 0.051122367162914836, Avg. Test Loss: 0.05122922360897064\n",
      "Epoch: 29, Avg. Train Loss: 0.04936408019241165, Avg. Test Loss: 0.0496571846306324\n",
      "Epoch: 30, Avg. Train Loss: 0.04790922512902933, Avg. Test Loss: 0.04826628789305687\n",
      "Epoch: 31, Avg. Train Loss: 0.04658505969187793, Avg. Test Loss: 0.0469757504761219\n",
      "Epoch: 32, Avg. Train Loss: 0.04534791738671415, Avg. Test Loss: 0.04575430974364281\n",
      "Epoch: 33, Avg. Train Loss: 0.044178350839544744, Avg. Test Loss: 0.0445924736559391\n",
      "Epoch: 34, Avg. Train Loss: 0.043056296688668866, Avg. Test Loss: 0.043482936918735504\n",
      "Epoch: 35, Avg. Train Loss: 0.04196898691794452, Avg. Test Loss: 0.042418405413627625\n",
      "Epoch: 36, Avg. Train Loss: 0.04090831932776114, Avg. Test Loss: 0.041432611644268036\n",
      "Epoch: 37, Avg. Train Loss: 0.03986883557894651, Avg. Test Loss: 0.040589749813079834\n",
      "Epoch: 38, Avg. Train Loss: 0.03884826793390162, Avg. Test Loss: 0.03982390835881233\n",
      "Epoch: 39, Avg. Train Loss: 0.03784345616312588, Avg. Test Loss: 0.038636453449726105\n",
      "Epoch: 40, Avg. Train Loss: 0.036854736682246717, Avg. Test Loss: 0.037399329245090485\n",
      "Epoch: 41, Avg. Train Loss: 0.03588059290367014, Avg. Test Loss: 0.03627524524927139\n",
      "Epoch: 42, Avg. Train Loss: 0.03492201956755975, Avg. Test Loss: 0.03524860739707947\n",
      "Epoch: 43, Avg. Train Loss: 0.03397778706515536, Avg. Test Loss: 0.0342554934322834\n",
      "Epoch: 44, Avg. Train Loss: 0.033048646743683255, Avg. Test Loss: 0.033307816833257675\n",
      "Epoch: 45, Avg. Train Loss: 0.032135039984303365, Avg. Test Loss: 0.03236372768878937\n",
      "Epoch: 46, Avg. Train Loss: 0.03123610832673662, Avg. Test Loss: 0.03145209699869156\n",
      "Epoch: 47, Avg. Train Loss: 0.030354138244600856, Avg. Test Loss: 0.030550815165042877\n",
      "Epoch: 48, Avg. Train Loss: 0.02948685752994874, Avg. Test Loss: 0.029672348871827126\n",
      "Epoch: 49, Avg. Train Loss: 0.028636365077074837, Avg. Test Loss: 0.028811609372496605\n",
      "Epoch: 50, Avg. Train Loss: 0.027802087037878877, Avg. Test Loss: 0.027965839952230453\n",
      "Epoch: 51, Avg. Train Loss: 0.02698397840208867, Avg. Test Loss: 0.02714085578918457\n",
      "Epoch: 52, Avg. Train Loss: 0.026182362415334757, Avg. Test Loss: 0.026333454996347427\n",
      "Epoch: 53, Avg. Train Loss: 0.025397696499438845, Avg. Test Loss: 0.0255434587597847\n",
      "Epoch: 54, Avg. Train Loss: 0.02463026907952393, Avg. Test Loss: 0.024769252166152\n",
      "Epoch: 55, Avg. Train Loss: 0.023879081120385844, Avg. Test Loss: 0.024011464789509773\n",
      "Epoch: 56, Avg. Train Loss: 0.023145156112663885, Avg. Test Loss: 0.02327261120080948\n",
      "Epoch: 57, Avg. Train Loss: 0.022427608226152026, Avg. Test Loss: 0.02255004271864891\n",
      "Epoch: 58, Avg. Train Loss: 0.021727709800881498, Avg. Test Loss: 0.02184535749256611\n",
      "Epoch: 59, Avg. Train Loss: 0.02104415262446684, Avg. Test Loss: 0.02116062492132187\n",
      "Epoch: 60, Avg. Train Loss: 0.020378582486334968, Avg. Test Loss: 0.020488394424319267\n",
      "Epoch: 61, Avg. Train Loss: 0.0197302039274398, Avg. Test Loss: 0.019837651401758194\n",
      "Epoch: 62, Avg. Train Loss: 0.01909823965500383, Avg. Test Loss: 0.019201019778847694\n",
      "Epoch: 63, Avg. Train Loss: 0.018483212546390647, Avg. Test Loss: 0.018584778532385826\n",
      "Epoch: 64, Avg. Train Loss: 0.01788552263203789, Avg. Test Loss: 0.017981791868805885\n",
      "Epoch: 65, Avg. Train Loss: 0.01730457833584617, Avg. Test Loss: 0.017397990450263023\n",
      "Epoch: 66, Avg. Train Loss: 0.01674044982475393, Avg. Test Loss: 0.016832033172249794\n",
      "Epoch: 67, Avg. Train Loss: 0.016193504894480987, Avg. Test Loss: 0.016281764954328537\n",
      "Epoch: 68, Avg. Train Loss: 0.01566274156246115, Avg. Test Loss: 0.015749648213386536\n",
      "Epoch: 69, Avg. Train Loss: 0.015149492134942728, Avg. Test Loss: 0.01523345336318016\n",
      "Epoch: 70, Avg. Train Loss: 0.014651292584398214, Avg. Test Loss: 0.014733544550836086\n",
      "Epoch: 71, Avg. Train Loss: 0.014170192379285308, Avg. Test Loss: 0.014251523651182652\n",
      "Epoch: 72, Avg. Train Loss: 0.013705633197198896, Avg. Test Loss: 0.013784692622721195\n",
      "Epoch: 73, Avg. Train Loss: 0.013257439335917725, Avg. Test Loss: 0.013335936702787876\n",
      "Epoch: 74, Avg. Train Loss: 0.012824944812147056, Avg. Test Loss: 0.012902726419270039\n",
      "Epoch: 75, Avg. Train Loss: 0.012408364224521552, Avg. Test Loss: 0.012484082020819187\n",
      "Epoch: 76, Avg. Train Loss: 0.012008579710827154, Avg. Test Loss: 0.012082846835255623\n",
      "Epoch: 77, Avg. Train Loss: 0.011623611147789394, Avg. Test Loss: 0.01170098315924406\n",
      "Epoch: 78, Avg. Train Loss: 0.01125521883368492, Avg. Test Loss: 0.01132919266819954\n",
      "Epoch: 79, Avg. Train Loss: 0.01090156205875032, Avg. Test Loss: 0.010974687524139881\n",
      "Epoch: 80, Avg. Train Loss: 0.010562840882031356, Avg. Test Loss: 0.010637040250003338\n",
      "Epoch: 81, Avg. Train Loss: 0.010240866758805863, Avg. Test Loss: 0.010314845480024815\n",
      "Epoch: 82, Avg. Train Loss: 0.009932698725777515, Avg. Test Loss: 0.01000597607344389\n",
      "Epoch: 83, Avg. Train Loss: 0.009639013295664507, Avg. Test Loss: 0.009713692590594292\n",
      "Epoch: 84, Avg. Train Loss: 0.009360806019428899, Avg. Test Loss: 0.009437506087124348\n",
      "Epoch: 85, Avg. Train Loss: 0.009095920918180662, Avg. Test Loss: 0.009175819344818592\n",
      "Epoch: 86, Avg. Train Loss: 0.00884756107321557, Avg. Test Loss: 0.008920906111598015\n",
      "Epoch: 87, Avg. Train Loss: 0.008607610687613487, Avg. Test Loss: 0.008686017245054245\n",
      "Epoch: 88, Avg. Train Loss: 0.008383059112683815, Avg. Test Loss: 0.008462173864245415\n",
      "Epoch: 89, Avg. Train Loss: 0.008171152860364492, Avg. Test Loss: 0.008250427432358265\n",
      "Epoch: 90, Avg. Train Loss: 0.007972199617720702, Avg. Test Loss: 0.008052285760641098\n",
      "Epoch: 91, Avg. Train Loss: 0.007785439452923396, Avg. Test Loss: 0.007873833179473877\n",
      "Epoch: 92, Avg. Train Loss: 0.007608305377995266, Avg. Test Loss: 0.007691631559282541\n",
      "Epoch: 93, Avg. Train Loss: 0.007441160241689752, Avg. Test Loss: 0.00752609595656395\n",
      "Epoch: 94, Avg. Train Loss: 0.007285929098725319, Avg. Test Loss: 0.007372777909040451\n",
      "Epoch: 95, Avg. Train Loss: 0.007140339489149696, Avg. Test Loss: 0.00723504601046443\n",
      "Epoch: 96, Avg. Train Loss: 0.0070029082817628105, Avg. Test Loss: 0.007091861218214035\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 97, Avg. Train Loss: 0.006877151449375293, Avg. Test Loss: 0.006966766901314259\n",
      "Epoch: 98, Avg. Train Loss: 0.006752995861803784, Avg. Test Loss: 0.006846577860414982\n",
      "Epoch: 99, Avg. Train Loss: 0.006637983818483704, Avg. Test Loss: 0.006733075249940157\n",
      "Epoch: 100, Avg. Train Loss: 0.00653133905657074, Avg. Test Loss: 0.00662595359608531\n",
      "Epoch: 101, Avg. Train Loss: 0.006431362361592405, Avg. Test Loss: 0.006530491169542074\n",
      "Epoch: 102, Avg. Train Loss: 0.006335897639612941, Avg. Test Loss: 0.006430727895349264\n",
      "Epoch: 103, Avg. Train Loss: 0.006244544553406098, Avg. Test Loss: 0.006343131419271231\n",
      "Epoch: 104, Avg. Train Loss: 0.006158507456455161, Avg. Test Loss: 0.006259688641875982\n",
      "Epoch: 105, Avg. Train Loss: 0.00607558194657459, Avg. Test Loss: 0.0061773802153766155\n",
      "Epoch: 106, Avg. Train Loss: 0.005997593361226951, Avg. Test Loss: 0.0060964119620621204\n",
      "Epoch: 107, Avg. Train Loss: 0.00592134928002077, Avg. Test Loss: 0.006020873785018921\n",
      "Epoch: 108, Avg. Train Loss: 0.005847649993922781, Avg. Test Loss: 0.005954456981271505\n",
      "Epoch: 109, Avg. Train Loss: 0.005778282579472836, Avg. Test Loss: 0.0058799912221729755\n",
      "Epoch: 110, Avg. Train Loss: 0.005708716776879395, Avg. Test Loss: 0.005813474301248789\n",
      "Epoch: 111, Avg. Train Loss: 0.005643561893307111, Avg. Test Loss: 0.005747664719820023\n",
      "Epoch: 112, Avg. Train Loss: 0.005577070090700598, Avg. Test Loss: 0.005680680740624666\n",
      "Epoch: 113, Avg. Train Loss: 0.005513518374851522, Avg. Test Loss: 0.005614624358713627\n",
      "Epoch: 114, Avg. Train Loss: 0.005451522373101291, Avg. Test Loss: 0.005564086139202118\n",
      "Epoch: 115, Avg. Train Loss: 0.0053887178299619875, Avg. Test Loss: 0.005488581955432892\n",
      "Epoch: 116, Avg. Train Loss: 0.005327685840208741, Avg. Test Loss: 0.005428815260529518\n",
      "Epoch: 117, Avg. Train Loss: 0.00526671705986647, Avg. Test Loss: 0.005368417594581842\n",
      "Epoch: 118, Avg. Train Loss: 0.005208408673677375, Avg. Test Loss: 0.005306324455887079\n",
      "Epoch: 119, Avg. Train Loss: 0.005147418927620439, Avg. Test Loss: 0.005248297471553087\n",
      "Epoch: 120, Avg. Train Loss: 0.005088225018013926, Avg. Test Loss: 0.005188940558582544\n",
      "Epoch: 121, Avg. Train Loss: 0.0050329538171782215, Avg. Test Loss: 0.005143184680491686\n",
      "Epoch: 122, Avg. Train Loss: 0.0049718555227360305, Avg. Test Loss: 0.005080153699964285\n",
      "Epoch: 123, Avg. Train Loss: 0.004915931853739655, Avg. Test Loss: 0.005030359607189894\n",
      "Epoch: 124, Avg. Train Loss: 0.004860154511954855, Avg. Test Loss: 0.0049571143463253975\n",
      "Epoch: 125, Avg. Train Loss: 0.004803890537689714, Avg. Test Loss: 0.0048997909761965275\n",
      "Epoch: 126, Avg. Train Loss: 0.004747009518391946, Avg. Test Loss: 0.004849120508879423\n",
      "Epoch: 127, Avg. Train Loss: 0.004691679474404629, Avg. Test Loss: 0.004786945413798094\n",
      "Epoch: 128, Avg. Train Loss: 0.0046333023346960545, Avg. Test Loss: 0.004730267450213432\n",
      "Epoch: 129, Avg. Train Loss: 0.004579076647539349, Avg. Test Loss: 0.0046768467873334885\n",
      "Epoch: 130, Avg. Train Loss: 0.0045231750563663594, Avg. Test Loss: 0.004621034488081932\n",
      "Epoch: 131, Avg. Train Loss: 0.004470047897056621, Avg. Test Loss: 0.004568780772387981\n",
      "Epoch: 132, Avg. Train Loss: 0.004419509984333726, Avg. Test Loss: 0.0045333015732467175\n",
      "Epoch: 133, Avg. Train Loss: 0.0043647888828726375, Avg. Test Loss: 0.004456708207726479\n",
      "Epoch: 134, Avg. Train Loss: 0.00430725234122399, Avg. Test Loss: 0.004398016259074211\n",
      "Epoch: 135, Avg. Train Loss: 0.004252871271113262, Avg. Test Loss: 0.0043427771888673306\n",
      "Epoch: 136, Avg. Train Loss: 0.004199883552706417, Avg. Test Loss: 0.004286837298423052\n",
      "Epoch: 137, Avg. Train Loss: 0.004147230294149588, Avg. Test Loss: 0.0042314049787819386\n",
      "Epoch: 138, Avg. Train Loss: 0.00409493784639327, Avg. Test Loss: 0.00418624235317111\n",
      "Epoch: 139, Avg. Train Loss: 0.0040445568779593, Avg. Test Loss: 0.004128466360270977\n",
      "Epoch: 140, Avg. Train Loss: 0.003990689933519153, Avg. Test Loss: 0.00407465361058712\n",
      "Epoch: 141, Avg. Train Loss: 0.00393793111502686, Avg. Test Loss: 0.004019691608846188\n",
      "Epoch: 142, Avg. Train Loss: 0.00388869928634342, Avg. Test Loss: 0.003963258117437363\n",
      "Epoch: 143, Avg. Train Loss: 0.0038383585510446743, Avg. Test Loss: 0.003910324070602655\n",
      "Epoch: 144, Avg. Train Loss: 0.0037900852888603422, Avg. Test Loss: 0.003874950809404254\n",
      "Epoch: 145, Avg. Train Loss: 0.0037336702047682862, Avg. Test Loss: 0.003807639703154564\n",
      "Epoch: 146, Avg. Train Loss: 0.0036833038745338427, Avg. Test Loss: 0.0037543033249676228\n",
      "Epoch: 147, Avg. Train Loss: 0.0036394834408865254, Avg. Test Loss: 0.0037034929264336824\n",
      "Epoch: 148, Avg. Train Loss: 0.003587564675356535, Avg. Test Loss: 0.0036565090995281935\n",
      "Epoch: 149, Avg. Train Loss: 0.0035412862513433483, Avg. Test Loss: 0.0036095676477998495\n",
      "Epoch: 150, Avg. Train Loss: 0.003491936336435816, Avg. Test Loss: 0.003553461516276002\n",
      "Epoch: 151, Avg. Train Loss: 0.0034479287863873383, Avg. Test Loss: 0.0035053133033216\n",
      "Epoch: 152, Avg. Train Loss: 0.003400874567930313, Avg. Test Loss: 0.0034831129014492035\n",
      "Epoch: 153, Avg. Train Loss: 0.0033674359759863683, Avg. Test Loss: 0.0034390336368232965\n",
      "Epoch: 154, Avg. Train Loss: 0.0033164431176641407, Avg. Test Loss: 0.0033665623050183058\n",
      "Epoch: 155, Avg. Train Loss: 0.003259226677062757, Avg. Test Loss: 0.0033161367755383253\n",
      "Epoch: 156, Avg. Train Loss: 0.0032163693158722977, Avg. Test Loss: 0.0032696484122425318\n",
      "Epoch: 157, Avg. Train Loss: 0.0031754379270269592, Avg. Test Loss: 0.0032314895652234554\n",
      "Epoch: 158, Avg. Train Loss: 0.0031338170718620806, Avg. Test Loss: 0.0031830070074647665\n",
      "Epoch: 159, Avg. Train Loss: 0.0030966586679877606, Avg. Test Loss: 0.003155836369842291\n",
      "Epoch: 160, Avg. Train Loss: 0.003051121795878691, Avg. Test Loss: 0.0031154716853052378\n",
      "Epoch: 161, Avg. Train Loss: 0.0030178194317747563, Avg. Test Loss: 0.003061461029574275\n",
      "Epoch: 162, Avg. Train Loss: 0.002973546361660256, Avg. Test Loss: 0.0030171985272318125\n",
      "Epoch: 163, Avg. Train Loss: 0.0029382878503597834, Avg. Test Loss: 0.0029743623454123735\n",
      "Epoch: 164, Avg. Train Loss: 0.0028963770142153783, Avg. Test Loss: 0.002937786979600787\n",
      "Epoch: 165, Avg. Train Loss: 0.0028601472485153116, Avg. Test Loss: 0.0029010942671447992\n",
      "Epoch: 166, Avg. Train Loss: 0.002825509603409206, Avg. Test Loss: 0.0028669119346886873\n",
      "Epoch: 167, Avg. Train Loss: 0.002796400461674613, Avg. Test Loss: 0.0028285952284932137\n",
      "Epoch: 168, Avg. Train Loss: 0.0027598180753343245, Avg. Test Loss: 0.0028126263059675694\n",
      "Epoch: 169, Avg. Train Loss: 0.0027263970662127525, Avg. Test Loss: 0.0027576894499361515\n",
      "Epoch: 170, Avg. Train Loss: 0.0026925399296862237, Avg. Test Loss: 0.0027332897298038006\n",
      "Epoch: 171, Avg. Train Loss: 0.002665963804568438, Avg. Test Loss: 0.0026927951257675886\n",
      "Epoch: 172, Avg. Train Loss: 0.0026306351345470724, Avg. Test Loss: 0.0026657918933779\n",
      "Epoch: 173, Avg. Train Loss: 0.002608731295913458, Avg. Test Loss: 0.0026635443791747093\n",
      "Epoch: 174, Avg. Train Loss: 0.0025736986275981455, Avg. Test Loss: 0.0026119002141058445\n",
      "Epoch: 175, Avg. Train Loss: 0.0025460250073057766, Avg. Test Loss: 0.0025840254966169596\n",
      "Epoch: 176, Avg. Train Loss: 0.002518549457411556, Avg. Test Loss: 0.0025555298198014498\n",
      "Epoch: 177, Avg. Train Loss: 0.002499924800084794, Avg. Test Loss: 0.0025468701496720314\n",
      "Epoch: 178, Avg. Train Loss: 0.002473137155175209, Avg. Test Loss: 0.002547220792621374\n",
      "Epoch: 179, Avg. Train Loss: 0.0024405108764767648, Avg. Test Loss: 0.0024693880695849657\n",
      "Epoch: 180, Avg. Train Loss: 0.0024240900433677086, Avg. Test Loss: 0.002440102631226182\n",
      "Epoch: 181, Avg. Train Loss: 0.002391992350492407, Avg. Test Loss: 0.0024589397944509983\n",
      "Epoch: 182, Avg. Train Loss: 0.0023746900808285266, Avg. Test Loss: 0.002392545575276017\n",
      "Epoch: 183, Avg. Train Loss: 0.0023496142150286367, Avg. Test Loss: 0.002381125930696726\n",
      "Epoch: 184, Avg. Train Loss: 0.0023240224650020107, Avg. Test Loss: 0.002344876993447542\n",
      "Epoch: 185, Avg. Train Loss: 0.00230571110458935, Avg. Test Loss: 0.002329230774194002\n",
      "Epoch: 186, Avg. Train Loss: 0.0022819204776383497, Avg. Test Loss: 0.0023058352526277304\n",
      "Epoch: 187, Avg. Train Loss: 0.0022602665566784494, Avg. Test Loss: 0.0023068590089678764\n",
      "Epoch: 188, Avg. Train Loss: 0.0022411675096544272, Avg. Test Loss: 0.002266202587634325\n",
      "Epoch: 189, Avg. Train Loss: 0.0022334154065260115, Avg. Test Loss: 0.0022721546702086926\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 190, Avg. Train Loss: 0.002201377195032204, Avg. Test Loss: 0.0022268323227763176\n",
      "Epoch: 191, Avg. Train Loss: 0.002192118952927344, Avg. Test Loss: 0.0022246178705245256\n",
      "Epoch: 192, Avg. Train Loss: 0.0021669688114129447, Avg. Test Loss: 0.0021835584193468094\n",
      "Epoch: 193, Avg. Train Loss: 0.0021487529512823505, Avg. Test Loss: 0.002170127583667636\n",
      "Epoch: 194, Avg. Train Loss: 0.0021305139108067925, Avg. Test Loss: 0.0021480268333107233\n",
      "Epoch: 195, Avg. Train Loss: 0.0021070612471222002, Avg. Test Loss: 0.002130481880158186\n",
      "Epoch: 196, Avg. Train Loss: 0.002092783713220235, Avg. Test Loss: 0.0021172817796468735\n",
      "Epoch: 197, Avg. Train Loss: 0.0020795603460796617, Avg. Test Loss: 0.0021209511905908585\n",
      "Epoch: 198, Avg. Train Loss: 0.0020656171569819835, Avg. Test Loss: 0.0020891346503049135\n",
      "Epoch: 199, Avg. Train Loss: 0.0020404668442685816, Avg. Test Loss: 0.00206012767739594\n",
      "Epoch: 200, Avg. Train Loss: 0.002025669116033789, Avg. Test Loss: 0.002044901717454195\n",
      "Epoch: 201, Avg. Train Loss: 0.002010758117060451, Avg. Test Loss: 0.002038606209680438\n",
      "Epoch: 202, Avg. Train Loss: 0.002000273102620507, Avg. Test Loss: 0.0020464404951781034\n",
      "Epoch: 203, Avg. Train Loss: 0.0019974606604698827, Avg. Test Loss: 0.0020146172028034925\n",
      "Epoch: 204, Avg. Train Loss: 0.001981426919262637, Avg. Test Loss: 0.0019952503498643637\n",
      "Epoch: 205, Avg. Train Loss: 0.0019732966416460625, Avg. Test Loss: 0.0019901217892766\n",
      "Epoch: 206, Avg. Train Loss: 0.001959969867568682, Avg. Test Loss: 0.002032996853813529\n",
      "Epoch: 207, Avg. Train Loss: 0.0019534635261687287, Avg. Test Loss: 0.0019648359157145023\n",
      "Epoch: 208, Avg. Train Loss: 0.0019446426714934846, Avg. Test Loss: 0.001995184225961566\n",
      "Epoch: 209, Avg. Train Loss: 0.001929679630762514, Avg. Test Loss: 0.0019499566406011581\n",
      "Epoch: 210, Avg. Train Loss: 0.0019219899728127262, Avg. Test Loss: 0.0019401739118620753\n",
      "Epoch: 211, Avg. Train Loss: 0.0019107624176232254, Avg. Test Loss: 0.0019305256428197026\n",
      "Epoch: 212, Avg. Train Loss: 0.0019060048562310199, Avg. Test Loss: 0.0019342342857271433\n",
      "Epoch: 213, Avg. Train Loss: 0.0019013230935396516, Avg. Test Loss: 0.0019150800071656704\n",
      "Epoch: 214, Avg. Train Loss: 0.0018954445621656144, Avg. Test Loss: 0.0019189352169632912\n",
      "Epoch: 215, Avg. Train Loss: 0.0018875468262087773, Avg. Test Loss: 0.0019409460946917534\n",
      "Epoch: 216, Avg. Train Loss: 0.0018831786973511472, Avg. Test Loss: 0.001896103611215949\n",
      "Epoch: 217, Avg. Train Loss: 0.001873706661931732, Avg. Test Loss: 0.0018936775159090757\n",
      "Epoch: 218, Avg. Train Loss: 0.0018652806359836284, Avg. Test Loss: 0.0018986487993970513\n",
      "Epoch: 219, Avg. Train Loss: 0.0018593484207111246, Avg. Test Loss: 0.0018906135810539126\n",
      "Epoch: 220, Avg. Train Loss: 0.001862834272084429, Avg. Test Loss: 0.0018743884284049273\n",
      "Epoch: 238, Avg. Train Loss: 0.0017915429752867887, Avg. Test Loss: 0.0018205094384029508\n",
      "Epoch: 239, Avg. Train Loss: 0.0017952559803448179, Avg. Test Loss: 0.001897253911010921\n",
      "Epoch: 240, Avg. Train Loss: 0.0017940203727716032, Avg. Test Loss: 0.0018025144236162305\n",
      "Epoch: 241, Avg. Train Loss: 0.0017795642235261552, Avg. Test Loss: 0.0018081447342410684\n",
      "Epoch: 242, Avg. Train Loss: 0.0017768093562849304, Avg. Test Loss: 0.001805123989470303\n",
      "Epoch: 243, Avg. Train Loss: 0.0017769091447596165, Avg. Test Loss: 0.00180698256008327\n",
      "Epoch: 244, Avg. Train Loss: 0.0017753714640789172, Avg. Test Loss: 0.0018022021977230906\n",
      "Epoch: 245, Avg. Train Loss: 0.001765162159469636, Avg. Test Loss: 0.00182509480509907\n",
      "Epoch: 246, Avg. Train Loss: 0.0017654585117912469, Avg. Test Loss: 0.0017890107119455934\n",
      "Epoch: 247, Avg. Train Loss: 0.00176341579953099, Avg. Test Loss: 0.0018224307568743825\n",
      "Epoch: 248, Avg. Train Loss: 0.0017588249448796407, Avg. Test Loss: 0.001788263558410108\n",
      "Epoch: 249, Avg. Train Loss: 0.0017538020921432796, Avg. Test Loss: 0.001782977138645947\n",
      "Epoch: 250, Avg. Train Loss: 0.001753958363962524, Avg. Test Loss: 0.0017801991198211908\n",
      "Epoch: 251, Avg. Train Loss: 0.0017514246967895066, Avg. Test Loss: 0.0017895607743412256\n",
      "Epoch: 252, Avg. Train Loss: 0.0017498853780767497, Avg. Test Loss: 0.0018065969925373793\n",
      "Epoch: 253, Avg. Train Loss: 0.0017475112793309724, Avg. Test Loss: 0.0017729437677189708\n",
      "Epoch: 254, Avg. Train Loss: 0.001751711590708617, Avg. Test Loss: 0.0018039201386272907\n",
      "Epoch: 255, Avg. Train Loss: 0.001753319049363627, Avg. Test Loss: 0.0017895124619826674\n",
      "Epoch: 256, Avg. Train Loss: 0.0017446851837174858, Avg. Test Loss: 0.0017903463449329138\n",
      "Epoch: 257, Avg. Train Loss: 0.0017397219383650843, Avg. Test Loss: 0.0017804158851504326\n",
      "Epoch: 258, Avg. Train Loss: 0.0017399169833344573, Avg. Test Loss: 0.001764250104315579\n",
      "Epoch: 259, Avg. Train Loss: 0.001737904266509063, Avg. Test Loss: 0.001765692955814302\n",
      "Epoch: 260, Avg. Train Loss: 0.001738050000687294, Avg. Test Loss: 0.0017671262612566352\n",
      "Epoch: 261, Avg. Train Loss: 0.001735841841710841, Avg. Test Loss: 0.0017667412757873535\n",
      "Epoch: 262, Avg. Train Loss: 0.0017313203856568126, Avg. Test Loss: 0.0017519801622256637\n",
      "Epoch: 263, Avg. Train Loss: 0.0017277646823512282, Avg. Test Loss: 0.0017567529575899243\n",
      "Epoch: 264, Avg. Train Loss: 0.0017400168307016, Avg. Test Loss: 0.0017727501690387726\n",
      "Epoch: 265, Avg. Train Loss: 0.001726431422866881, Avg. Test Loss: 0.0017729942919686437\n",
      "Epoch: 266, Avg. Train Loss: 0.0017264298423576882, Avg. Test Loss: 0.0017584002343937755\n",
      "Epoch: 267, Avg. Train Loss: 0.001726995553711758, Avg. Test Loss: 0.0017455419292673469\n",
      "Epoch: 268, Avg. Train Loss: 0.0017227815601098186, Avg. Test Loss: 0.001756340148858726\n",
      "Epoch: 269, Avg. Train Loss: 0.0017216602463603896, Avg. Test Loss: 0.0017661979654803872\n",
      "Epoch: 270, Avg. Train Loss: 0.0017215925419483992, Avg. Test Loss: 0.0017431689193472266\n",
      "Epoch: 271, Avg. Train Loss: 0.0017125773996881702, Avg. Test Loss: 0.0017595819663256407\n",
      "Epoch: 272, Avg. Train Loss: 0.0017183315775850239, Avg. Test Loss: 0.0017465018900111318\n",
      "Epoch: 273, Avg. Train Loss: 0.0017098951824557256, Avg. Test Loss: 0.001737126731313765\n",
      "Epoch: 274, Avg. Train Loss: 0.0017129304394235506, Avg. Test Loss: 0.0017429481958970428\n",
      "Epoch: 275, Avg. Train Loss: 0.001713908971835147, Avg. Test Loss: 0.0017699653981253505\n",
      "Epoch: 276, Avg. Train Loss: 0.001711075520142913, Avg. Test Loss: 0.0017531603807583451\n",
      "Epoch: 277, Avg. Train Loss: 0.0017123291556559064, Avg. Test Loss: 0.001735121477395296\n",
      "Epoch: 278, Avg. Train Loss: 0.0017077422919957077, Avg. Test Loss: 0.0017290491377934813\n",
      "Epoch: 279, Avg. Train Loss: 0.001712870823822039, Avg. Test Loss: 0.0017537885578349233\n",
      "Epoch: 280, Avg. Train Loss: 0.0017091411658946205, Avg. Test Loss: 0.0017359654884785414\n",
      "Epoch: 281, Avg. Train Loss: 0.0017034701496253118, Avg. Test Loss: 0.001725287758745253\n",
      "Epoch: 282, Avg. Train Loss: 0.001702437556677443, Avg. Test Loss: 0.0017274010460823774\n",
      "Epoch: 283, Avg. Train Loss: 0.0016994142850093982, Avg. Test Loss: 0.0017392566660419106\n",
      "Epoch: 284, Avg. Train Loss: 0.0017014329417553895, Avg. Test Loss: 0.0017280455213040113\n",
      "Epoch: 285, Avg. Train Loss: 0.0017016945064396542, Avg. Test Loss: 0.0017230776138603687\n",
      "Epoch: 286, Avg. Train Loss: 0.0017003354643855026, Avg. Test Loss: 0.0017372316215187311\n",
      "Epoch: 287, Avg. Train Loss: 0.001697782868081156, Avg. Test Loss: 0.0017182256560772657\n",
      "Epoch: 288, Avg. Train Loss: 0.001702180488363785, Avg. Test Loss: 0.0017474920023232698\n",
      "Epoch: 289, Avg. Train Loss: 0.0016991060747600655, Avg. Test Loss: 0.0017399040516465902\n",
      "Epoch: 290, Avg. Train Loss: 0.0016964026836349684, Avg. Test Loss: 0.0017378793563693762\n",
      "Epoch: 291, Avg. Train Loss: 0.0016947325606666067, Avg. Test Loss: 0.0017440197989344597\n",
      "Epoch: 292, Avg. Train Loss: 0.0016890760826166061, Avg. Test Loss: 0.00172597321216017\n",
      "Epoch: 293, Avg. Train Loss: 0.0016928361824658864, Avg. Test Loss: 0.0017179046990349889\n",
      "Epoch: 294, Avg. Train Loss: 0.001695677379201002, Avg. Test Loss: 0.0017211136873811483\n",
      "Epoch: 295, Avg. Train Loss: 0.0016909465070485193, Avg. Test Loss: 0.0017204773612320423\n",
      "Epoch: 296, Avg. Train Loss: 0.0016845869530430612, Avg. Test Loss: 0.0017106756567955017\n",
      "Epoch: 297, Avg. Train Loss: 0.001684833293342415, Avg. Test Loss: 0.0017160953721031547\n",
      "Epoch: 298, Avg. Train Loss: 0.0016883826622849, Avg. Test Loss: 0.0017266813665628433\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 299, Avg. Train Loss: 0.0016880836269325193, Avg. Test Loss: 0.0017308839596807957\n",
      "Epoch: 300, Avg. Train Loss: 0.0016947507570662043, Avg. Test Loss: 0.0017089340835809708\n",
      "Epoch: 301, Avg. Train Loss: 0.0016808323219747229, Avg. Test Loss: 0.0017279472667723894\n",
      "Epoch: 302, Avg. Train Loss: 0.0016926321050371317, Avg. Test Loss: 0.0017267323564738035\n",
      "Epoch: 303, Avg. Train Loss: 0.0016788518248016344, Avg. Test Loss: 0.0017162656877189875\n",
      "Epoch: 304, Avg. Train Loss: 0.001686593802536235, Avg. Test Loss: 0.0017234233673661947\n",
      "Epoch: 305, Avg. Train Loss: 0.0016893355203244616, Avg. Test Loss: 0.0017159685958176851\n",
      "Epoch: 306, Avg. Train Loss: 0.0016767046633450423, Avg. Test Loss: 0.001701900502666831\n",
      "Epoch: 307, Avg. Train Loss: 0.0016747999703511595, Avg. Test Loss: 0.001706756534986198\n",
      "Epoch: 308, Avg. Train Loss: 0.0016752038342768656, Avg. Test Loss: 0.0017285107169300318\n",
      "Epoch: 309, Avg. Train Loss: 0.0016780923161765233, Avg. Test Loss: 0.0017074095085263252\n",
      "Epoch: 310, Avg. Train Loss: 0.001681737564778065, Avg. Test Loss: 0.001698381151072681\n",
      "Epoch: 311, Avg. Train Loss: 0.0016722698901396463, Avg. Test Loss: 0.0017092959024012089\n",
      "Epoch: 312, Avg. Train Loss: 0.0016827225876862512, Avg. Test Loss: 0.001713161589577794\n",
      "Epoch: 313, Avg. Train Loss: 0.0016754406079759494, Avg. Test Loss: 0.001715920981951058\n",
      "Epoch: 314, Avg. Train Loss: 0.0016784692415967584, Avg. Test Loss: 0.0016938371118158102\n",
      "Epoch: 315, Avg. Train Loss: 0.0016741431592141882, Avg. Test Loss: 0.0017079354729503393\n",
      "Epoch: 316, Avg. Train Loss: 0.0016800971331951372, Avg. Test Loss: 0.0016959297936409712\n",
      "Epoch: 317, Avg. Train Loss: 0.0016757076702025883, Avg. Test Loss: 0.0016955912578850985\n",
      "Epoch: 318, Avg. Train Loss: 0.0016673322917674395, Avg. Test Loss: 0.0016971799777820706\n",
      "Epoch: 319, Avg. Train Loss: 0.001667946040192071, Avg. Test Loss: 0.001727725611999631\n",
      "Epoch: 320, Avg. Train Loss: 0.001667814888060093, Avg. Test Loss: 0.0016871009720489383\n",
      "Epoch: 321, Avg. Train Loss: 0.0016683741842451342, Avg. Test Loss: 0.001696856808848679\n",
      "Epoch: 322, Avg. Train Loss: 0.0016639911665526383, Avg. Test Loss: 0.0016937804175540805\n",
      "Epoch: 323, Avg. Train Loss: 0.0016666969202239724, Avg. Test Loss: 0.0016836231807246804\n",
      "Epoch: 324, Avg. Train Loss: 0.0016531499732724008, Avg. Test Loss: 0.0016785835614427924\n",
      "Epoch: 325, Avg. Train Loss: 0.0016237902249593068, Avg. Test Loss: 0.0016312641091644764\n",
      "Epoch: 326, Avg. Train Loss: 0.0015734846881755135, Avg. Test Loss: 0.0015423076692968607\n",
      "Epoch: 327, Avg. Train Loss: 0.001473202812485397, Avg. Test Loss: 0.0014450717717409134\n",
      "Epoch: 328, Avg. Train Loss: 0.0013576540260520928, Avg. Test Loss: 0.0013191234320402145\n",
      "Epoch: 329, Avg. Train Loss: 0.0012621756054132301, Avg. Test Loss: 0.0012406237656250596\n",
      "Epoch: 330, Avg. Train Loss: 0.0011953401475158685, Avg. Test Loss: 0.001180758117698133\n",
      "Epoch: 331, Avg. Train Loss: 0.001151015646481777, Avg. Test Loss: 0.001169839408248663\n",
      "Epoch: 332, Avg. Train Loss: 0.001112946418716627, Avg. Test Loss: 0.0011193308746442199\n",
      "Epoch: 333, Avg. Train Loss: 0.0010873638798811417, Avg. Test Loss: 0.0011059576645493507\n",
      "Epoch: 334, Avg. Train Loss: 0.0010635693098747117, Avg. Test Loss: 0.0010755207622423768\n",
      "Epoch: 335, Avg. Train Loss: 0.0010492925682817312, Avg. Test Loss: 0.0010545792756602168\n",
      "Epoch: 336, Avg. Train Loss: 0.0010327986585359802, Avg. Test Loss: 0.0010575916385278106\n",
      "Epoch: 337, Avg. Train Loss: 0.0010175230132196756, Avg. Test Loss: 0.0010299381101503968\n",
      "Epoch: 338, Avg. Train Loss: 0.0010115969713832087, Avg. Test Loss: 0.0010151057504117489\n",
      "Epoch: 339, Avg. Train Loss: 0.0009947810013888076, Avg. Test Loss: 0.001005485188215971\n",
      "Epoch: 340, Avg. Train Loss: 0.0009857313748558654, Avg. Test Loss: 0.0009930486558005214\n",
      "Epoch: 341, Avg. Train Loss: 0.0009793083539561315, Avg. Test Loss: 0.0009863362647593021\n",
      "Epoch: 342, Avg. Train Loss: 0.0009661567479591159, Avg. Test Loss: 0.0009750857134349644\n",
      "Epoch: 343, Avg. Train Loss: 0.000956245100892642, Avg. Test Loss: 0.0009636740433052182\n",
      "Epoch: 344, Avg. Train Loss: 0.0009463965659961104, Avg. Test Loss: 0.0009644744568504393\n",
      "Epoch: 345, Avg. Train Loss: 0.0009394244736005716, Avg. Test Loss: 0.0009520209860056639\n",
      "Epoch: 346, Avg. Train Loss: 0.0009215590817963376, Avg. Test Loss: 0.0009331950568594038\n",
      "Epoch: 347, Avg. Train Loss: 0.0009132930269355283, Avg. Test Loss: 0.0009131318656727672\n",
      "Epoch: 348, Avg. Train Loss: 0.0009044781197136378, Avg. Test Loss: 0.0009156322339549661\n",
      "Epoch: 349, Avg. Train Loss: 0.0008919988478095655, Avg. Test Loss: 0.0008869808516465127\n",
      "Epoch: 350, Avg. Train Loss: 0.000878205755040707, Avg. Test Loss: 0.0008834859472699463\n",
      "Epoch: 351, Avg. Train Loss: 0.0008682551540379577, Avg. Test Loss: 0.0008675561402924359\n",
      "Epoch: 352, Avg. Train Loss: 0.0008509450455141418, Avg. Test Loss: 0.0008573181112296879\n",
      "Epoch: 353, Avg. Train Loss: 0.0008432339349597254, Avg. Test Loss: 0.0008528177859261632\n",
      "Epoch: 354, Avg. Train Loss: 0.0008273475796586889, Avg. Test Loss: 0.0008269802201539278\n",
      "Epoch: 355, Avg. Train Loss: 0.0008144861717215355, Avg. Test Loss: 0.0008141919388435781\n",
      "Epoch: 356, Avg. Train Loss: 0.0008065551985055209, Avg. Test Loss: 0.000821050547529012\n",
      "Epoch: 357, Avg. Train Loss: 0.0007886756327934563, Avg. Test Loss: 0.0007867133244872093\n",
      "Epoch: 358, Avg. Train Loss: 0.0007755354238564477, Avg. Test Loss: 0.0007712009246461093\n",
      "Epoch: 359, Avg. Train Loss: 0.000760975038386224, Avg. Test Loss: 0.0007621601107530296\n",
      "Epoch: 360, Avg. Train Loss: 0.000753341759007205, Avg. Test Loss: 0.0007534640026278794\n",
      "Epoch: 361, Avg. Train Loss: 0.0007480517913149122, Avg. Test Loss: 0.0007367765647359192\n",
      "Epoch: 362, Avg. Train Loss: 0.0007287473561625709, Avg. Test Loss: 0.0007233808282762766\n",
      "Epoch: 363, Avg. Train Loss: 0.0007267179460648228, Avg. Test Loss: 0.0007562667015008628\n",
      "Epoch: 364, Avg. Train Loss: 0.0007085216080989031, Avg. Test Loss: 0.0007032211869955063\n",
      "Epoch: 365, Avg. Train Loss: 0.0006932915373267058, Avg. Test Loss: 0.0006936633144505322\n",
      "Epoch: 366, Avg. Train Loss: 0.0006821511772132534, Avg. Test Loss: 0.0006769360625185072\n",
      "Epoch: 367, Avg. Train Loss: 0.000674861145671457, Avg. Test Loss: 0.0006709267036058009\n",
      "Epoch: 368, Avg. Train Loss: 0.0006604664739878739, Avg. Test Loss: 0.0006684514228254557\n",
      "Epoch: 369, Avg. Train Loss: 0.0006560743642587434, Avg. Test Loss: 0.0006522247567772865\n",
      "Epoch: 370, Avg. Train Loss: 0.0006470389575149645, Avg. Test Loss: 0.0006383017171174288\n",
      "Epoch: 371, Avg. Train Loss: 0.0006352008827140226, Avg. Test Loss: 0.0006282785325311124\n",
      "Epoch: 372, Avg. Train Loss: 0.0006261631093152306, Avg. Test Loss: 0.0006211611907929182\n",
      "Epoch: 373, Avg. Train Loss: 0.0006246904760380002, Avg. Test Loss: 0.0006201473879627883\n",
      "Epoch: 374, Avg. Train Loss: 0.0006219743374351631, Avg. Test Loss: 0.0006269677542150021\n",
      "Epoch: 375, Avg. Train Loss: 0.0006132985478924477, Avg. Test Loss: 0.0006135071744211018\n",
      "Epoch: 376, Avg. Train Loss: 0.0006007175111924024, Avg. Test Loss: 0.0005954713560640812\n",
      "Epoch: 377, Avg. Train Loss: 0.0005957289872800602, Avg. Test Loss: 0.0005915522342547774\n",
      "Epoch: 378, Avg. Train Loss: 0.0005932475803146029, Avg. Test Loss: 0.0005870049935765564\n",
      "Epoch: 379, Avg. Train Loss: 0.0005846451488597428, Avg. Test Loss: 0.0005829069414176047\n",
      "Epoch: 380, Avg. Train Loss: 0.0005845651112715988, Avg. Test Loss: 0.0005735961021855474\n",
      "Epoch: 381, Avg. Train Loss: 0.0005748886656125678, Avg. Test Loss: 0.0005726923700422049\n",
      "Epoch: 382, Avg. Train Loss: 0.0005761154598611243, Avg. Test Loss: 0.0005701451445929706\n",
      "Epoch: 383, Avg. Train Loss: 0.0005701620035859591, Avg. Test Loss: 0.0005658380105160177\n",
      "Epoch: 384, Avg. Train Loss: 0.000570396105211009, Avg. Test Loss: 0.0005602932651527226\n",
      "Epoch: 385, Avg. Train Loss: 0.0005636732258340892, Avg. Test Loss: 0.0005578675190918148\n",
      "Epoch: 386, Avg. Train Loss: 0.0005623284289065529, Avg. Test Loss: 0.0005557201220653951\n",
      "Epoch: 387, Avg. Train Loss: 0.0005615888389430063, Avg. Test Loss: 0.0005577334086410701\n",
      "Epoch: 388, Avg. Train Loss: 0.000559991313938928, Avg. Test Loss: 0.0005454528727568686\n",
      "Epoch: 389, Avg. Train Loss: 0.0005560875473105732, Avg. Test Loss: 0.0005459412350319326\n",
      "Epoch: 390, Avg. Train Loss: 0.0005467898725970264, Avg. Test Loss: 0.0005484704743139446\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 391, Avg. Train Loss: 0.0005474746857276734, Avg. Test Loss: 0.0005516225355677307\n",
      "Epoch: 392, Avg. Train Loss: 0.0005471891045625158, Avg. Test Loss: 0.0005495095974765718\n",
      "Epoch: 393, Avg. Train Loss: 0.0005514152539784418, Avg. Test Loss: 0.000543903443031013\n",
      "Epoch: 394, Avg. Train Loss: 0.0005403366035727017, Avg. Test Loss: 0.0005426252027973533\n",
      "Epoch: 395, Avg. Train Loss: 0.0005351089875843814, Avg. Test Loss: 0.00053162791300565\n",
      "Epoch: 396, Avg. Train Loss: 0.0005449213666211375, Avg. Test Loss: 0.0005354539025574923\n",
      "Epoch: 397, Avg. Train Loss: 0.0005372596825883888, Avg. Test Loss: 0.000526112737134099\n",
      "Epoch: 398, Avg. Train Loss: 0.0005308291220845764, Avg. Test Loss: 0.0005262745544314384\n",
      "Epoch: 399, Avg. Train Loss: 0.0005289983761031181, Avg. Test Loss: 0.0005256362492218614\n",
      "Epoch: 400, Avg. Train Loss: 0.0005270533027428695, Avg. Test Loss: 0.0005238255253061652\n",
      "Epoch: 401, Avg. Train Loss: 0.0005340933080707841, Avg. Test Loss: 0.0005181888118386269\n",
      "Epoch: 402, Avg. Train Loss: 0.0005268193962846828, Avg. Test Loss: 0.000518531072884798\n",
      "Epoch: 403, Avg. Train Loss: 0.0005257259349010008, Avg. Test Loss: 0.0005314785521477461\n",
      "Epoch: 404, Avg. Train Loss: 0.0005302806905306438, Avg. Test Loss: 0.000520919740665704\n",
      "Epoch: 405, Avg. Train Loss: 0.0005206839150666972, Avg. Test Loss: 0.000520781846717\n",
      "Epoch: 406, Avg. Train Loss: 0.0005181587020428303, Avg. Test Loss: 0.0005185220506973565\n",
      "Epoch: 407, Avg. Train Loss: 0.00051392807474579, Avg. Test Loss: 0.0005184630863368511\n",
      "Epoch: 408, Avg. Train Loss: 0.0005242431300062248, Avg. Test Loss: 0.0005124268354848027\n",
      "Epoch: 409, Avg. Train Loss: 0.0005166622286196798, Avg. Test Loss: 0.0005142720183357596\n",
      "Epoch: 410, Avg. Train Loss: 0.0005122348364880856, Avg. Test Loss: 0.0005083382129669189\n",
      "Epoch: 411, Avg. Train Loss: 0.0005140360917293412, Avg. Test Loss: 0.000510446319822222\n",
      "Epoch: 412, Avg. Train Loss: 0.000519085509072551, Avg. Test Loss: 0.0005086396122351289\n",
      "Epoch: 413, Avg. Train Loss: 0.0005084647540249588, Avg. Test Loss: 0.000534110062289983\n",
      "Epoch: 414, Avg. Train Loss: 0.0005116996916887514, Avg. Test Loss: 0.0005200984887778759\n",
      "Epoch: 415, Avg. Train Loss: 0.0005248333998572301, Avg. Test Loss: 0.000625152257271111\n",
      "Epoch: 416, Avg. Train Loss: 0.0005136558077270713, Avg. Test Loss: 0.000501189730130136\n",
      "Epoch: 417, Avg. Train Loss: 0.000504322472946061, Avg. Test Loss: 0.0005016899085603654\n",
      "Epoch: 418, Avg. Train Loss: 0.0005042536447838168, Avg. Test Loss: 0.0005017117946408689\n",
      "Epoch: 419, Avg. Train Loss: 0.0005017875947112985, Avg. Test Loss: 0.0005275121075101197\n",
      "Epoch: 420, Avg. Train Loss: 0.0005160194742904209, Avg. Test Loss: 0.0005030228639952838\n",
      "Epoch: 421, Avg. Train Loss: 0.0005060787394861964, Avg. Test Loss: 0.0005002220277674496\n",
      "Epoch: 422, Avg. Train Loss: 0.0005028993014574928, Avg. Test Loss: 0.0004971246235072613\n",
      "Epoch: 423, Avg. Train Loss: 0.0005064455114359803, Avg. Test Loss: 0.0005542203434742987\n",
      "Epoch: 424, Avg. Train Loss: 0.0005018444646232049, Avg. Test Loss: 0.0004958818317390978\n",
      "Epoch: 425, Avg. Train Loss: 0.0005087847451624625, Avg. Test Loss: 0.0005037658847868443\n",
      "Epoch: 426, Avg. Train Loss: 0.0005088108115802136, Avg. Test Loss: 0.0005062528070993721\n",
      "Epoch: 427, Avg. Train Loss: 0.0004943229949704426, Avg. Test Loss: 0.0004894671146757901\n",
      "Epoch: 428, Avg. Train Loss: 0.0004990500675322597, Avg. Test Loss: 0.000490815204102546\n",
      "Epoch: 429, Avg. Train Loss: 0.0004950572650961797, Avg. Test Loss: 0.0004893799195997417\n",
      "Epoch: 430, Avg. Train Loss: 0.0004948363800341373, Avg. Test Loss: 0.0004956926568411291\n",
      "Epoch: 431, Avg. Train Loss: 0.0005011187667739303, Avg. Test Loss: 0.0004943500971421599\n",
      "Epoch: 432, Avg. Train Loss: 0.0004959993807407205, Avg. Test Loss: 0.0004982130485586822\n",
      "Epoch: 433, Avg. Train Loss: 0.0004934672033414245, Avg. Test Loss: 0.000489648780785501\n",
      "Epoch: 434, Avg. Train Loss: 0.0004931502770084669, Avg. Test Loss: 0.000490490929223597\n",
      "Epoch: 435, Avg. Train Loss: 0.0004896577940705944, Avg. Test Loss: 0.0004850492696277797\n",
      "Epoch: 436, Avg. Train Loss: 0.0004920145325527034, Avg. Test Loss: 0.0005032146000303328\n",
      "Epoch: 437, Avg. Train Loss: 0.0004915190220344812, Avg. Test Loss: 0.0004886261885985732\n",
      "Epoch: 438, Avg. Train Loss: 0.0005022638682823848, Avg. Test Loss: 0.0004961938830092549\n",
      "Epoch: 439, Avg. Train Loss: 0.0005053251149708077, Avg. Test Loss: 0.0005290560075081885\n",
      "Epoch: 440, Avg. Train Loss: 0.0004901695517165696, Avg. Test Loss: 0.00048638484440743923\n",
      "Epoch: 441, Avg. Train Loss: 0.00048726502607357414, Avg. Test Loss: 0.00048421340761706233\n",
      "Epoch: 442, Avg. Train Loss: 0.000494040666243938, Avg. Test Loss: 0.0004820415051653981\n",
      "Epoch: 443, Avg. Train Loss: 0.000485539052854566, Avg. Test Loss: 0.00048303103540092707\n",
      "Epoch: 444, Avg. Train Loss: 0.0004918063538806403, Avg. Test Loss: 0.00047967032878659666\n",
      "Epoch: 445, Avg. Train Loss: 0.0004855635966283872, Avg. Test Loss: 0.00048204505583271384\n",
      "Epoch: 446, Avg. Train Loss: 0.0004900244304307682, Avg. Test Loss: 0.0005036094225943089\n",
      "Epoch: 447, Avg. Train Loss: 0.0004953951081808876, Avg. Test Loss: 0.0004903215449303389\n",
      "Epoch: 448, Avg. Train Loss: 0.0004961244217530988, Avg. Test Loss: 0.000555613951291889\n",
      "Epoch: 449, Avg. Train Loss: 0.0004863932204898447, Avg. Test Loss: 0.00048593065002933145\n",
      "Epoch: 450, Avg. Train Loss: 0.00048658949227127084, Avg. Test Loss: 0.00047819651081226766\n",
      "Epoch: 451, Avg. Train Loss: 0.00048194030703812397, Avg. Test Loss: 0.0004767143400385976\n",
      "Epoch: 452, Avg. Train Loss: 0.00048517552889226117, Avg. Test Loss: 0.0005109792109578848\n",
      "Epoch: 453, Avg. Train Loss: 0.0004897975366261294, Avg. Test Loss: 0.00047623729915358126\n",
      "Epoch: 454, Avg. Train Loss: 0.0004809195675668033, Avg. Test Loss: 0.0004829899698961526\n",
      "Epoch: 455, Avg. Train Loss: 0.0004815147316548973, Avg. Test Loss: 0.0005002254620194435\n",
      "Epoch: 456, Avg. Train Loss: 0.0004832065975813962, Avg. Test Loss: 0.0004924508975818753\n",
      "Epoch: 457, Avg. Train Loss: 0.0004852218704079004, Avg. Test Loss: 0.00047280261060222983\n",
      "Epoch: 458, Avg. Train Loss: 0.0004903705369489377, Avg. Test Loss: 0.000502931303344667\n",
      "Epoch: 459, Avg. Train Loss: 0.00048632405540796327, Avg. Test Loss: 0.00047331448877230287\n",
      "Epoch: 460, Avg. Train Loss: 0.00048467078287264, Avg. Test Loss: 0.0005256650620140135\n",
      "Epoch: 461, Avg. Train Loss: 0.00047839442747371163, Avg. Test Loss: 0.0005102103459648788\n",
      "Epoch: 462, Avg. Train Loss: 0.0004852397634428652, Avg. Test Loss: 0.0004767993523273617\n",
      "Epoch: 463, Avg. Train Loss: 0.000478138672598802, Avg. Test Loss: 0.0004781266616191715\n",
      "Epoch: 464, Avg. Train Loss: 0.0004830354995861211, Avg. Test Loss: 0.00048166714259423316\n",
      "Epoch: 465, Avg. Train Loss: 0.0004781961102066014, Avg. Test Loss: 0.00047789368545636535\n",
      "Epoch: 466, Avg. Train Loss: 0.0004774710423696567, Avg. Test Loss: 0.0004737628041766584\n",
      "Epoch: 467, Avg. Train Loss: 0.00047504188739420737, Avg. Test Loss: 0.00047491263831034303\n",
      "Epoch: 468, Avg. Train Loss: 0.0004822267421439071, Avg. Test Loss: 0.00048484664876013994\n",
      "Epoch: 469, Avg. Train Loss: 0.0004881119615781833, Avg. Test Loss: 0.0004743309982586652\n",
      "Epoch: 470, Avg. Train Loss: 0.0004758177147082546, Avg. Test Loss: 0.0004901256179437041\n",
      "Epoch: 471, Avg. Train Loss: 0.0004835979814422043, Avg. Test Loss: 0.0004765874473378062\n",
      "Epoch: 472, Avg. Train Loss: 0.00047775948803652733, Avg. Test Loss: 0.0004658975813072175\n",
      "Epoch: 473, Avg. Train Loss: 0.00047815581509733904, Avg. Test Loss: 0.0004862169153057039\n",
      "Epoch: 474, Avg. Train Loss: 0.00048517310231759703, Avg. Test Loss: 0.0004820669419132173\n",
      "Epoch: 475, Avg. Train Loss: 0.00047984444810187114, Avg. Test Loss: 0.0004689098568633199\n",
      "Epoch: 476, Avg. Train Loss: 0.00047522280604907257, Avg. Test Loss: 0.0004796995490323752\n",
      "Epoch: 477, Avg. Train Loss: 0.0004850160107975278, Avg. Test Loss: 0.00047755130799487233\n",
      "Epoch: 478, Avg. Train Loss: 0.0004721353330430301, Avg. Test Loss: 0.0004749395593535155\n",
      "Epoch: 479, Avg. Train Loss: 0.00047350177603006804, Avg. Test Loss: 0.00046642706729471684\n",
      "Epoch: 480, Avg. Train Loss: 0.000478317349231528, Avg. Test Loss: 0.0004665257874876261\n",
      "Epoch: 481, Avg. Train Loss: 0.00047599609379711397, Avg. Test Loss: 0.0004762501921504736\n",
      "Epoch: 482, Avg. Train Loss: 0.00047523486667641385, Avg. Test Loss: 0.00049238046631217\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 483, Avg. Train Loss: 0.0004739085277405513, Avg. Test Loss: 0.0004644349683076143\n",
      "Epoch: 484, Avg. Train Loss: 0.0004749506342169993, Avg. Test Loss: 0.0004689241177402437\n",
      "Epoch: 485, Avg. Train Loss: 0.00047935826929888743, Avg. Test Loss: 0.00047007648390717804\n",
      "Epoch: 486, Avg. Train Loss: 0.0004718729298260501, Avg. Test Loss: 0.0004673282674048096\n",
      "Epoch: 487, Avg. Train Loss: 0.00047280254828579283, Avg. Test Loss: 0.00047014662413857877\n",
      "Epoch: 488, Avg. Train Loss: 0.00047492072917521, Avg. Test Loss: 0.0004624943539965898\n",
      "Epoch: 489, Avg. Train Loss: 0.00046912390800357305, Avg. Test Loss: 0.00046601981739513576\n",
      "Epoch: 490, Avg. Train Loss: 0.0004751401991062962, Avg. Test Loss: 0.00046270430902950466\n",
      "Epoch: 491, Avg. Train Loss: 0.0004674616523141808, Avg. Test Loss: 0.00047454607556574047\n",
      "Epoch: 492, Avg. Train Loss: 0.00047484620111337044, Avg. Test Loss: 0.00046640000073239207\n",
      "Epoch: 493, Avg. Train Loss: 0.00047265041126486133, Avg. Test Loss: 0.0004696320102084428\n",
      "Epoch: 494, Avg. Train Loss: 0.0004669549563379191, Avg. Test Loss: 0.0004602770786732435\n",
      "Epoch: 495, Avg. Train Loss: 0.0004709327052456929, Avg. Test Loss: 0.0004829515528399497\n",
      "Epoch: 496, Avg. Train Loss: 0.0004724646076176535, Avg. Test Loss: 0.0005115835228934884\n",
      "Epoch: 497, Avg. Train Loss: 0.00047500515733297697, Avg. Test Loss: 0.0004739949945360422\n",
      "Epoch: 498, Avg. Train Loss: 0.00046771726030034615, Avg. Test Loss: 0.00046298844972625375\n",
      "Epoch: 499, Avg. Train Loss: 0.00046791766379850313, Avg. Test Loss: 0.0005378694622777402\n",
      "Epoch: 500, Avg. Train Loss: 0.00047341776765225563, Avg. Test Loss: 0.000477314431918785\n",
      "Epoch: 501, Avg. Train Loss: 0.0004689107772291583, Avg. Test Loss: 0.00046102231135591865\n",
      "Epoch: 502, Avg. Train Loss: 0.0004728918429464102, Avg. Test Loss: 0.00045728610712103546\n",
      "Epoch: 503, Avg. Train Loss: 0.00046696587814949454, Avg. Test Loss: 0.0004700505523942411\n",
      "Epoch: 504, Avg. Train Loss: 0.00046752153772532064, Avg. Test Loss: 0.00046294566709548235\n",
      "Epoch: 505, Avg. Train Loss: 0.0004797084876747035, Avg. Test Loss: 0.00046656234189867973\n",
      "Epoch: 506, Avg. Train Loss: 0.00047078886658281964, Avg. Test Loss: 0.0004591887118294835\n",
      "Epoch: 507, Avg. Train Loss: 0.0004685324863256777, Avg. Test Loss: 0.0004836245207116008\n",
      "Epoch: 508, Avg. Train Loss: 0.00047508785501122476, Avg. Test Loss: 0.00045756311737932265\n",
      "Epoch: 509, Avg. Train Loss: 0.00046801706947221914, Avg. Test Loss: 0.0004606049624271691\n",
      "Epoch: 510, Avg. Train Loss: 0.000471675386036034, Avg. Test Loss: 0.0005020271055400372\n",
      "Epoch: 511, Avg. Train Loss: 0.00046562081038513604, Avg. Test Loss: 0.00045501612476073205\n",
      "Epoch: 512, Avg. Train Loss: 0.0004619302864953437, Avg. Test Loss: 0.00046034142724238336\n",
      "Epoch: 513, Avg. Train Loss: 0.0004645870888934416, Avg. Test Loss: 0.0004581029061228037\n",
      "Epoch: 514, Avg. Train Loss: 0.0004832988334408797, Avg. Test Loss: 0.0004686513275373727\n",
      "Epoch: 515, Avg. Train Loss: 0.0004657647113644463, Avg. Test Loss: 0.0004773261898662895\n",
      "Epoch: 516, Avg. Train Loss: 0.0004815675862653948, Avg. Test Loss: 0.0004578885855153203\n",
      "Epoch: 517, Avg. Train Loss: 0.00046172353733495315, Avg. Test Loss: 0.0004565028357319534\n",
      "Epoch: 518, Avg. Train Loss: 0.0004657461807843955, Avg. Test Loss: 0.0004576643113978207\n",
      "Epoch: 519, Avg. Train Loss: 0.00046393549179329593, Avg. Test Loss: 0.0004575105558615178\n",
      "Epoch: 520, Avg. Train Loss: 0.00048590678249157087, Avg. Test Loss: 0.00048639680608175695\n",
      "Epoch: 521, Avg. Train Loss: 0.000465427157263655, Avg. Test Loss: 0.00045454653445631266\n",
      "Epoch: 522, Avg. Train Loss: 0.00045986316194209984, Avg. Test Loss: 0.0004580284294206649\n",
      "Epoch: 523, Avg. Train Loss: 0.00046173247529248545, Avg. Test Loss: 0.0004557499196380377\n",
      "Epoch: 524, Avg. Train Loss: 0.0004640080188811921, Avg. Test Loss: 0.00045522567234002054\n",
      "Epoch: 525, Avg. Train Loss: 0.00046606291332008205, Avg. Test Loss: 0.0004557949723675847\n",
      "Epoch: 526, Avg. Train Loss: 0.00046073430806727094, Avg. Test Loss: 0.00046669167932122946\n",
      "Epoch: 527, Avg. Train Loss: 0.00046924934071926945, Avg. Test Loss: 0.0004587358853314072\n",
      "Epoch: 528, Avg. Train Loss: 0.0004713452640263473, Avg. Test Loss: 0.00047466016258113086\n",
      "Epoch: 529, Avg. Train Loss: 0.0004752274267101551, Avg. Test Loss: 0.00045918975956737995\n",
      "Epoch: 530, Avg. Train Loss: 0.00046896014348877705, Avg. Test Loss: 0.0004605968133546412\n",
      "Epoch: 531, Avg. Train Loss: 0.00045776065500617466, Avg. Test Loss: 0.00045539348502643406\n",
      "Epoch: 532, Avg. Train Loss: 0.00046633980784784344, Avg. Test Loss: 0.0004564860137179494\n",
      "Epoch: 533, Avg. Train Loss: 0.0004629512834499645, Avg. Test Loss: 0.0005006606224924326\n",
      "Epoch: 534, Avg. Train Loss: 0.0004922404481262407, Avg. Test Loss: 0.00046720303362235427\n",
      "Epoch: 535, Avg. Train Loss: 0.00046299664536491035, Avg. Test Loss: 0.0004540716181509197\n",
      "Epoch: 536, Avg. Train Loss: 0.0004621111277682597, Avg. Test Loss: 0.00045254151336848736\n",
      "Epoch: 537, Avg. Train Loss: 0.00046379002365831506, Avg. Test Loss: 0.0004550429875962436\n",
      "Epoch: 538, Avg. Train Loss: 0.0004579565374810687, Avg. Test Loss: 0.00045335383038036525\n",
      "Epoch: 539, Avg. Train Loss: 0.0004688731891185264, Avg. Test Loss: 0.0005506600718945265\n",
      "Epoch: 540, Avg. Train Loss: 0.0004806245444342494, Avg. Test Loss: 0.0004550438607111573\n",
      "Epoch: 541, Avg. Train Loss: 0.000466703499585171, Avg. Test Loss: 0.0004523340903688222\n",
      "Epoch: 542, Avg. Train Loss: 0.00045779185294283223, Avg. Test Loss: 0.0004701016587205231\n",
      "Epoch: 543, Avg. Train Loss: 0.0004597224589601597, Avg. Test Loss: 0.00046302651753649116\n",
      "Epoch: 544, Avg. Train Loss: 0.00046154265565907256, Avg. Test Loss: 0.0004657795943785459\n",
      "Epoch: 545, Avg. Train Loss: 0.00045722497195717604, Avg. Test Loss: 0.00045672361738979816\n",
      "Epoch: 546, Avg. Train Loss: 0.00045825745259849904, Avg. Test Loss: 0.0004536002525128424\n",
      "Epoch: 547, Avg. Train Loss: 0.00046332855298019505, Avg. Test Loss: 0.0004549332079477608\n",
      "Epoch: 548, Avg. Train Loss: 0.0004674501994432991, Avg. Test Loss: 0.0004735899274237454\n",
      "Epoch: 549, Avg. Train Loss: 0.00046636514119146504, Avg. Test Loss: 0.00045211618999019265\n",
      "Epoch: 550, Avg. Train Loss: 0.00047312110546045006, Avg. Test Loss: 0.0004586625727824867\n",
      "Epoch: 551, Avg. Train Loss: 0.000465130468707203, Avg. Test Loss: 0.00045920893899165094\n",
      "Epoch: 552, Avg. Train Loss: 0.00045797801302636373, Avg. Test Loss: 0.0004705858591478318\n",
      "Epoch: 553, Avg. Train Loss: 0.000462293326991665, Avg. Test Loss: 0.00048203737242147326\n",
      "Epoch: 554, Avg. Train Loss: 0.00045867551337270174, Avg. Test Loss: 0.0004607797018252313\n",
      "Epoch: 555, Avg. Train Loss: 0.00045926916919758216, Avg. Test Loss: 0.0004588675801642239\n",
      "Epoch: 556, Avg. Train Loss: 0.0004856655576184173, Avg. Test Loss: 0.0004523669194895774\n",
      "Epoch: 557, Avg. Train Loss: 0.00046422781854155745, Avg. Test Loss: 0.0004532888706307858\n",
      "Epoch: 558, Avg. Train Loss: 0.0004578546905095744, Avg. Test Loss: 0.0004578052321448922\n",
      "Epoch: 559, Avg. Train Loss: 0.0004559011058197083, Avg. Test Loss: 0.0004543272661976516\n",
      "Epoch: 560, Avg. Train Loss: 0.000483925300924217, Avg. Test Loss: 0.00045697324094362557\n",
      "Epoch: 561, Avg. Train Loss: 0.00045720508513862594, Avg. Test Loss: 0.00046314505743794143\n",
      "Epoch: 562, Avg. Train Loss: 0.00045539097079788063, Avg. Test Loss: 0.0004585311107803136\n",
      "Epoch: 563, Avg. Train Loss: 0.0004669342258506838, Avg. Test Loss: 0.0004622514243237674\n",
      "Epoch: 564, Avg. Train Loss: 0.0004755736595731886, Avg. Test Loss: 0.0004611938202288002\n",
      "Epoch: 565, Avg. Train Loss: 0.0004729877592420534, Avg. Test Loss: 0.0004617837839759886\n",
      "Epoch: 566, Avg. Train Loss: 0.00046064938856836627, Avg. Test Loss: 0.0004501307266764343\n",
      "Epoch: 567, Avg. Train Loss: 0.0004594023260698818, Avg. Test Loss: 0.00045018483069725335\n",
      "Epoch: 568, Avg. Train Loss: 0.00046131779398659575, Avg. Test Loss: 0.0004629252653103322\n",
      "Epoch: 569, Avg. Train Loss: 0.00045635508380227667, Avg. Test Loss: 0.00046216213377192616\n",
      "Epoch: 570, Avg. Train Loss: 0.00046596097150434026, Avg. Test Loss: 0.00045157811837270856\n",
      "Epoch: 571, Avg. Train Loss: 0.0004604086368892561, Avg. Test Loss: 0.000458310532849282\n",
      "Epoch: 572, Avg. Train Loss: 0.0004583934017265325, Avg. Test Loss: 0.0004655519442167133\n",
      "Epoch: 573, Avg. Train Loss: 0.00045996343662195346, Avg. Test Loss: 0.0004516658082138747\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 574, Avg. Train Loss: 0.00047331978669664, Avg. Test Loss: 0.00045899118413217366\n",
      "Epoch: 575, Avg. Train Loss: 0.00045259342124849994, Avg. Test Loss: 0.0004617566883098334\n",
      "Epoch: 576, Avg. Train Loss: 0.0004541151941178695, Avg. Test Loss: 0.0004515773616731167\n",
      "Epoch: 577, Avg. Train Loss: 0.0004627011380815769, Avg. Test Loss: 0.00045600271550938487\n",
      "Epoch: 578, Avg. Train Loss: 0.0004548502048504922, Avg. Test Loss: 0.00045986147597432137\n",
      "Epoch: 579, Avg. Train Loss: 0.00045493996448760086, Avg. Test Loss: 0.00047577431541867554\n",
      "Epoch: 580, Avg. Train Loss: 0.0004650957618757863, Avg. Test Loss: 0.0004519739013630897\n",
      "Epoch: 581, Avg. Train Loss: 0.00045920072349391, Avg. Test Loss: 0.00046302491682581604\n",
      "Epoch: 582, Avg. Train Loss: 0.000472668612800429, Avg. Test Loss: 0.00045841632527299225\n",
      "Epoch: 583, Avg. Train Loss: 0.00045842177522204377, Avg. Test Loss: 0.0004612787743099034\n",
      "Epoch: 584, Avg. Train Loss: 0.000452690281535444, Avg. Test Loss: 0.0004625042784027755\n",
      "Epoch: 585, Avg. Train Loss: 0.0004505141562891795, Avg. Test Loss: 0.00044599323882721364\n",
      "Epoch: 586, Avg. Train Loss: 0.0004665172265102977, Avg. Test Loss: 0.0004805815115105361\n",
      "Epoch: 587, Avg. Train Loss: 0.0004627716785762459, Avg. Test Loss: 0.00044563127448782325\n",
      "Epoch: 588, Avg. Train Loss: 0.00045381279744426996, Avg. Test Loss: 0.0004554364422801882\n",
      "Epoch: 589, Avg. Train Loss: 0.000451022176318528, Avg. Test Loss: 0.0004456066817510873\n",
      "Epoch: 590, Avg. Train Loss: 0.00045613936449894133, Avg. Test Loss: 0.0004511468578130007\n",
      "Epoch: 591, Avg. Train Loss: 0.0004561788361410008, Avg. Test Loss: 0.000475605163956061\n",
      "Epoch: 592, Avg. Train Loss: 0.0004593746695557938, Avg. Test Loss: 0.00045889129978604615\n",
      "Epoch: 593, Avg. Train Loss: 0.00045623048105934526, Avg. Test Loss: 0.0004643961146939546\n",
      "Epoch: 594, Avg. Train Loss: 0.0004550736106466502, Avg. Test Loss: 0.00045318718184717\n",
      "Epoch: 595, Avg. Train Loss: 0.00045758475077009814, Avg. Test Loss: 0.0004463022924028337\n",
      "Epoch: 596, Avg. Train Loss: 0.00045371585190022255, Avg. Test Loss: 0.00045304838567972183\n",
      "Epoch: 597, Avg. Train Loss: 0.0004610992536660941, Avg. Test Loss: 0.0004535150364972651\n",
      "Epoch: 598, Avg. Train Loss: 0.0004527883217259146, Avg. Test Loss: 0.0004616505466401577\n",
      "Epoch: 599, Avg. Train Loss: 0.0004558549978195087, Avg. Test Loss: 0.0004637872916646302\n",
      "Epoch: 600, Avg. Train Loss: 0.0004535965087330517, Avg. Test Loss: 0.0004482830408960581\n",
      "Finished Training\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2af3008aaef0>"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Now let's train the initial network \n",
    "\n",
    "model = offCenterLineNet()\n",
    "model = model.to(dev)\n",
    "model.apply(weights_init_uniform)\n",
    "\n",
    "model.train();\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=.01) \n",
    "# scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=500, gamma=0.1)\n",
    "\n",
    "n_epochs = 600\n",
    "\n",
    "mse_loss = nn.MSELoss()\n",
    "ce_loss = nn.CrossEntropyLoss()\n",
    "\n",
    "for epoch in range(0,n_epochs):  # loop over the dataset multiple times\n",
    "    \n",
    "    if epoch == 0:\n",
    "        train_loss_over_time = [] # to track the loss as the network trains\n",
    "        test_loss_over_time = []\n",
    "        \n",
    "    if epoch == 10:\n",
    "        optimizer = torch.optim.Adam(model.parameters(),lr=.002) \n",
    "        \n",
    "    running_loss = 0\n",
    "    num_batches = 0\n",
    "    \n",
    "    for batch_i, data in enumerate(train_loader):\n",
    "        \n",
    "        # get the input images and their corresponding labels\n",
    "        num_batches += 1\n",
    "\n",
    "        inputs, output_gt, _, _ = data\n",
    "        inputs, output_gt = inputs.to(dev), output_gt.to(dev)\n",
    "        \n",
    "        # zero the parameter (weight) gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # forward pass to get outputs\n",
    "        output_line_params = model(inputs)\n",
    "        \n",
    "\n",
    "        # make the ground truth\n",
    "        c = -output_gt[:,2]*torch.cos(output_gt[:,0]) + output_gt[:,1]*torch.sin(output_gt[:,0])\n",
    "        gt_line_params = torch.stack((-torch.sin(output_gt[:,0]),torch.cos(output_gt[:,0]),c),dim=1)\n",
    "        \n",
    "        # calculate the loss\n",
    "#         print(output_line_params[:,:,0,50])\n",
    "        \n",
    "        loss = mse_loss(output_line_params,gt_line_params)\n",
    "        \n",
    "        # backward pass to calculate the parameter gradients\n",
    "        loss.backward()\n",
    "\n",
    "        # update the parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        # to convert loss into a scalar and add it to running_loss, we use .item()\n",
    "        running_loss += loss.item()\n",
    "      \n",
    "\n",
    "#     scheduler.step()\n",
    "    \n",
    "    # Calculate test data loss after each epoch\n",
    "    with torch.no_grad():\n",
    "        test_loss = 0\n",
    "        num_batches_test = 0\n",
    "        for batch_i, data in enumerate(test_loader):\n",
    "            num_batches_test += 1\n",
    "\n",
    "            # Add code here\n",
    "            inputs, output_gt, _, _ = data\n",
    "            inputs, output_gt = inputs.to(dev), output_gt.to(dev)\n",
    "\n",
    "\n",
    "            # zero the parameter (weight) gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward pass to get outputs\n",
    "            output_line_params = model(inputs)\n",
    "\n",
    "            # make the ground truth\n",
    "            c = -output_gt[:,2]*torch.cos(output_gt[:,0]) + output_gt[:,1]*torch.sin(output_gt[:,0])\n",
    "            gt_line_params = torch.stack((-torch.sin(output_gt[:,0]),torch.cos(output_gt[:,0]),c),dim=1)\n",
    "    \n",
    "\n",
    "            # calculate the loss\n",
    "    #         print(output_line_params[:,:,0,50])\n",
    "\n",
    "            loss = mse_loss(output_line_params,gt_line_params)\n",
    "            \n",
    "            test_loss += loss\n",
    "                    \n",
    "        test_loss_over_time.append(test_loss/num_batches_test)\n",
    "\n",
    "    # Calculate model loss:\n",
    "    avg_loss = running_loss/num_batches\n",
    "    train_loss_over_time.append(avg_loss)\n",
    "    \n",
    "#     print('Epoch: {}, Avg. Train Loss: {},'.format(epoch + 1, train_loss_over_time[-1]))\n",
    "\n",
    "\n",
    "    print('Epoch: {}, Avg. Train Loss: {}, Avg. Test Loss: {}'.format(epoch + 1, train_loss_over_time[-1], test_loss_over_time[-1]))\n",
    "    \n",
    "print('Finished Training')\n",
    "\n",
    "plt.figure()\n",
    "plt.semilogy(np.arange(0,n_epochs),train_loss_over_time[0:])\n",
    "plt.semilogy(np.arange(0,n_epochs),test_loss_over_time[0:])\n",
    "plt.legend(['Training loss', 'Testing loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "3098a918",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2af30079c390>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.semilogy(np.arange(0,epoch),train_loss_over_time[:epoch])\n",
    "plt.semilogy(np.arange(0,epoch),test_loss_over_time[:epoch])\n",
    "plt.legend(['Training loss', 'Testing loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7528ca9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "91a7ad77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor(1.1464), tensor(1.1157), tensor(1.1484), tensor(1.1136), tensor(1.1034), tensor(1.1614), tensor(1.1369), tensor(1.1525), tensor(1.2298), tensor(1.2178), tensor(1.0511), tensor(1.1598), tensor(1.0701), tensor(1.1556), tensor(1.1116), tensor(1.1793), tensor(1.1710), tensor(1.1910), tensor(1.1800), tensor(1.0953), tensor(1.1461), tensor(1.1578), tensor(1.1888), tensor(1.1427), tensor(1.2122), tensor(1.0976), tensor(1.1272), tensor(1.2407), tensor(1.1588), tensor(1.1522)]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1080 with 9 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the Results\n",
    "\n",
    "model.eval();\n",
    "\n",
    "ang_loss_all = []\n",
    "\n",
    "for batch_i, data in enumerate(test_loader):\n",
    "    # get the input images and their corresponding labels\n",
    "    inputs, output_gt, _, _ = data\n",
    "    inputs, output_gt = inputs.to(dev), output_gt.to(dev)\n",
    "    \n",
    "\n",
    "    # forward pass to get outputs\n",
    "    outputs = model(inputs).squeeze().detach().cpu()\n",
    "    \n",
    "    gt = output_gt.cpu().squeeze()\n",
    "    \n",
    "    c = -output_gt[:,2]*torch.cos(output_gt[:,0]) + output_gt[:,1]*torch.sin(output_gt[:,0])\n",
    "    angle_params = torch.stack((-torch.sin(output_gt[:,0]),torch.cos(output_gt[:,0]),c),axis=1).detach().cpu()\n",
    "  \n",
    "    # Calculate angular loss\n",
    "    ang_loss = torch.mean(torch.abs(torch.rad2deg(torch.atan2(-angle_params[:,0]*outputs[:,1] + angle_params[:,1]*outputs[:,0]\n",
    "                                         ,angle_params[:,1]*outputs[:,1]+angle_params[:,0]*outputs[:,0]).cpu())))\n",
    "\n",
    "    ang_loss_all.append(ang_loss)\n",
    "\n",
    "    \n",
    "print(ang_loss_all)\n",
    "\n",
    "plt.figure(figsize=[15, 15])\n",
    "\n",
    "for ii in range(9):\n",
    "    \n",
    "    plt.subplot(3,3,ii+1)\n",
    "    plt.imshow(inputs[ii].cpu().squeeze(),cmap='gray', vmin=0, vmax=1)\n",
    "    \n",
    "    # Plot the ground truth lines\n",
    "    x_sample = torch.linspace(-1,1,inputs.shape[-1])\n",
    "    y_sample = -angle_params[ii,0]/angle_params[ii,1]*x_sample - angle_params[ii,2]/angle_params[ii,1]\n",
    "    \n",
    "    plt.plot(x_sample*W/2+W/2,y_sample*W/2+W/2,'b')\n",
    "    plt.xlim([0,W])\n",
    "    plt.ylim(([0,W]))\n",
    "    \n",
    "    # Plot the estimated lines\n",
    "    y_est = -outputs[ii,0]/outputs[ii,1]*x_sample - outputs[ii,2]/outputs[ii,1]\n",
    "    plt.plot(x_sample*W/2+W/2,y_est*W/2+W/2,'r')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68531be9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cc30c915",
   "metadata": {},
   "source": [
    "# 8x8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "a80315b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1080 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load dataset \n",
    "\n",
    "data_folder = 'foj_data/grayscale_lines/'\n",
    "\n",
    "with open(data_folder + 'line_data_8_50000_grey_bicolor_noise_random_uncentered.pkl','rb') as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "# wedges = data['wedges']\n",
    "wedges_grey = data['wedges_grey']\n",
    "params = data['params']\n",
    "boundaries = data['boundaries']\n",
    "wedges = data['wedges']\n",
    "\n",
    "\n",
    "line_data = LineDataset(wedges_grey, params, boundaries, wedges)#, transform=trainTransform)\n",
    "data_size = len(line_data)\n",
    "\n",
    "print(data_size)\n",
    "\n",
    "train_proportion = .85\n",
    "# Split dataset into training and testing\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(line_data, [int(data_size*train_proportion), int(data_size*(1-train_proportion))], generator=torch.Generator().manual_seed(42))\n",
    "\n",
    "# Create loaders for the training and testing data\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=1000, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=500, shuffle=False) #len(test_dataset)\n",
    "\n",
    "\n",
    "W,H = 8,8\n",
    "\n",
    "img_show = 0\n",
    "plt.figure(figsize=[15, 15])\n",
    "plt.subplot(131)\n",
    "plt.imshow(wedges[img_show,:,:].squeeze().permute(1,2,0).cpu())\n",
    "plt.title('RGB Image')\n",
    "plt.axis('off');\n",
    "plt.subplot(132)\n",
    "plt.imshow(wedges_grey[img_show,:,:].squeeze().cpu(),cmap='gray', vmin=0, vmax=1)\n",
    "plt.title('Grayscale Image')\n",
    "plt.axis('off');\n",
    "plt.subplot(133)\n",
    "plt.imshow(boundaries[img_show,:,:].squeeze().cpu(),cmap='gray', vmin=0, vmax=1)\n",
    "plt.title('Boundaries')\n",
    "plt.axis('off');\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "4d778ed8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1              [-1, 8, 6, 6]              80\n",
      "              ReLU-2              [-1, 8, 6, 6]               0\n",
      "            Conv2d-3              [-1, 8, 4, 4]             584\n",
      "         MaxPool2d-4              [-1, 8, 2, 2]               0\n",
      "            Linear-5                    [-1, 3]              99\n",
      "================================================================\n",
      "Total params: 763\n",
      "Trainable params: 763\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.01\n",
      "Params size (MB): 0.00\n",
      "Estimated Total Size (MB): 0.01\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "class offCenterLineNet(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "                \n",
    "        self.conv1 = nn.Conv2d(1, 8, kernel_size=3) #64 is good\n",
    "        self.conv2 = nn.Conv2d(8, 8, kernel_size=3)\n",
    "#         self.conv3 = nn.Conv2d(16, 16, kernel_size=3)\n",
    "#         self.conv3 = nn.Conv2d(128, 1, kernel_size=3)\n",
    "        self.fc = nn.LazyLinear(3)\n",
    "        self.maxpool = nn.MaxPool2d(2)\n",
    "#         self.avgpool = nn.AvgPool2d(2)#,stride=1)\n",
    "        self.activate = nn.ReLU()\n",
    "        self.norm = nn.LazyInstanceNorm2d()\n",
    "    \n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.conv1(x)\n",
    "        x = self.activate(x)\n",
    "#         x = self.norm(x)\n",
    "        x = self.conv2(x)\n",
    "#         x = self.activate(x)\n",
    "        x = self.maxpool(x)\n",
    "#         x = self.conv3(x)\n",
    "\n",
    "#         x = self.avgpool(x)\n",
    "        x = x.view(x.shape[0],-1)\n",
    "        \n",
    "        x = self.fc(x)\n",
    "         \n",
    "        # We're defining\n",
    "        # a = - sin(theta)\n",
    "        # b = cos(theta)\n",
    "        # c = -cy*cos(theta)+cx*sin(theta)\n",
    "        # Hence, we want to normalize the vector by 1/sqrt(a^2 + b^2)\n",
    "        norm_factor = (torch.norm(x[:,:2],p=2,dim=1)).unsqueeze(1)       \n",
    "        out = x/(norm_factor)#+eps)\n",
    "#         print('Output shape=',x.shape)\n",
    "\n",
    "#         out = x\n",
    "        \n",
    "        return out\n",
    "    \n",
    "model = offCenterLineNet()\n",
    "model = model.to(dev)\n",
    "summary(model, input_size=(1, H, W))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "80d61383",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Avg. Train Loss: 0.4774912013563999, Avg. Test Loss: 0.29443514347076416\n",
      "Epoch: 2, Avg. Train Loss: 0.584262041504993, Avg. Test Loss: 0.6460795402526855\n",
      "Epoch: 3, Avg. Train Loss: 0.6508678558260895, Avg. Test Loss: 0.6343761682510376\n",
      "Epoch: 4, Avg. Train Loss: 0.6354743685833243, Avg. Test Loss: 0.6169326901435852\n",
      "Epoch: 5, Avg. Train Loss: 0.6173038302465926, Avg. Test Loss: 0.5998091697692871\n",
      "Epoch: 6, Avg. Train Loss: 0.6011011240094207, Avg. Test Loss: 0.5837528705596924\n",
      "Epoch: 7, Avg. Train Loss: 0.585664011711298, Avg. Test Loss: 0.5691300630569458\n",
      "Epoch: 8, Avg. Train Loss: 0.5718394628790922, Avg. Test Loss: 0.5561233758926392\n",
      "Epoch: 9, Avg. Train Loss: 0.5599697398584943, Avg. Test Loss: 0.5448012351989746\n",
      "Epoch: 10, Avg. Train Loss: 0.5494337941324988, Avg. Test Loss: 0.5350387692451477\n",
      "Epoch: 11, Avg. Train Loss: 0.331086308110592, Avg. Test Loss: 0.10388834774494171\n",
      "Epoch: 12, Avg. Train Loss: 0.057909576438887174, Avg. Test Loss: 0.03874005377292633\n",
      "Epoch: 13, Avg. Train Loss: 0.032882520322536316, Avg. Test Loss: 0.037429239600896835\n",
      "Epoch: 14, Avg. Train Loss: 0.027194570013603498, Avg. Test Loss: 0.023524412885308266\n",
      "Epoch: 15, Avg. Train Loss: 0.02184151143355425, Avg. Test Loss: 0.04281015321612358\n",
      "Epoch: 16, Avg. Train Loss: 0.05164415428284989, Avg. Test Loss: 0.06948000192642212\n",
      "Epoch: 17, Avg. Train Loss: 0.04628699913967487, Avg. Test Loss: 0.03418874368071556\n",
      "Epoch: 18, Avg. Train Loss: 0.02960906749547914, Avg. Test Loss: 0.026010015979409218\n",
      "Epoch: 19, Avg. Train Loss: 0.02427143404303595, Avg. Test Loss: 0.022483566775918007\n",
      "Epoch: 20, Avg. Train Loss: 0.02137165741865025, Avg. Test Loss: 0.020449981093406677\n",
      "Epoch: 21, Avg. Train Loss: 0.019765926135140797, Avg. Test Loss: 0.01950191520154476\n",
      "Epoch: 22, Avg. Train Loss: 0.01900926583208317, Avg. Test Loss: 0.01899423822760582\n",
      "Epoch: 23, Avg. Train Loss: 0.018592591332488282, Avg. Test Loss: 0.018652958795428276\n",
      "Epoch: 24, Avg. Train Loss: 0.018243298367705454, Avg. Test Loss: 0.018362991511821747\n",
      "Epoch: 25, Avg. Train Loss: 0.01793192530613999, Avg. Test Loss: 0.01810603402554989\n",
      "Epoch: 26, Avg. Train Loss: 0.017638624537476274, Avg. Test Loss: 0.017806606367230415\n",
      "Epoch: 27, Avg. Train Loss: 0.017378395033437154, Avg. Test Loss: 0.017583539709448814\n",
      "Epoch: 28, Avg. Train Loss: 0.01712693063932103, Avg. Test Loss: 0.017343055456876755\n",
      "Epoch: 29, Avg. Train Loss: 0.016859668155395708, Avg. Test Loss: 0.017076484858989716\n",
      "Epoch: 30, Avg. Train Loss: 0.016630987766696963, Avg. Test Loss: 0.016889670863747597\n",
      "Epoch: 31, Avg. Train Loss: 0.01635768641392852, Avg. Test Loss: 0.016674989834427834\n",
      "Epoch: 32, Avg. Train Loss: 0.016164158925760622, Avg. Test Loss: 0.016412770375609398\n",
      "Epoch: 33, Avg. Train Loss: 0.015908616140138273, Avg. Test Loss: 0.01617109589278698\n",
      "Epoch: 34, Avg. Train Loss: 0.01568389131665923, Avg. Test Loss: 0.01597685180604458\n",
      "Epoch: 35, Avg. Train Loss: 0.015448521562786989, Avg. Test Loss: 0.015741238370537758\n",
      "Epoch: 36, Avg. Train Loss: 0.015249788912749567, Avg. Test Loss: 0.015506238676607609\n",
      "Epoch: 37, Avg. Train Loss: 0.0150493455314359, Avg. Test Loss: 0.015313752926886082\n",
      "Epoch: 38, Avg. Train Loss: 0.014814985634455846, Avg. Test Loss: 0.015106959268450737\n",
      "Epoch: 39, Avg. Train Loss: 0.014582459424990554, Avg. Test Loss: 0.014909861609339714\n",
      "Epoch: 40, Avg. Train Loss: 0.014382808642505213, Avg. Test Loss: 0.014688405208289623\n",
      "Epoch: 41, Avg. Train Loss: 0.014171544289173083, Avg. Test Loss: 0.014490746892988682\n",
      "Epoch: 42, Avg. Train Loss: 0.01397535917457453, Avg. Test Loss: 0.01427465584129095\n",
      "Epoch: 43, Avg. Train Loss: 0.013743547506110614, Avg. Test Loss: 0.014087135903537273\n",
      "Epoch: 44, Avg. Train Loss: 0.013541392505515453, Avg. Test Loss: 0.013866876251995564\n",
      "Epoch: 45, Avg. Train Loss: 0.01336891329738983, Avg. Test Loss: 0.01365790143609047\n",
      "Epoch: 46, Avg. Train Loss: 0.013165989479179992, Avg. Test Loss: 0.0134517727419734\n",
      "Epoch: 47, Avg. Train Loss: 0.012974682242371315, Avg. Test Loss: 0.01327312458306551\n",
      "Epoch: 48, Avg. Train Loss: 0.012799470945326396, Avg. Test Loss: 0.01310507021844387\n",
      "Epoch: 49, Avg. Train Loss: 0.012606004902789758, Avg. Test Loss: 0.012890939600765705\n",
      "Epoch: 50, Avg. Train Loss: 0.01242882899160302, Avg. Test Loss: 0.012727695517241955\n",
      "Epoch: 51, Avg. Train Loss: 0.012278411125894203, Avg. Test Loss: 0.012570416554808617\n",
      "Epoch: 52, Avg. Train Loss: 0.012114893450120161, Avg. Test Loss: 0.012412722222507\n",
      "Epoch: 53, Avg. Train Loss: 0.011976851540249448, Avg. Test Loss: 0.01228167861700058\n",
      "Epoch: 54, Avg. Train Loss: 0.011819965444331946, Avg. Test Loss: 0.012105011381208897\n",
      "Epoch: 55, Avg. Train Loss: 0.011689179771861364, Avg. Test Loss: 0.012006727047264576\n",
      "Epoch: 56, Avg. Train Loss: 0.011575234382478304, Avg. Test Loss: 0.011861295439302921\n",
      "Epoch: 57, Avg. Train Loss: 0.011476117619421593, Avg. Test Loss: 0.011737081222236156\n",
      "Epoch: 58, Avg. Train Loss: 0.01133117437102767, Avg. Test Loss: 0.011653142049908638\n",
      "Epoch: 59, Avg. Train Loss: 0.011224422517210939, Avg. Test Loss: 0.011536294594407082\n",
      "Epoch: 60, Avg. Train Loss: 0.011139083870275075, Avg. Test Loss: 0.011469447053968906\n",
      "Epoch: 61, Avg. Train Loss: 0.011044845829696157, Avg. Test Loss: 0.01134107168763876\n",
      "Epoch: 62, Avg. Train Loss: 0.0109553404239028, Avg. Test Loss: 0.011251559481024742\n",
      "Epoch: 63, Avg. Train Loss: 0.010862852100196272, Avg. Test Loss: 0.011185601353645325\n",
      "Epoch: 64, Avg. Train Loss: 0.010795975168950336, Avg. Test Loss: 0.011091434396803379\n",
      "Epoch: 65, Avg. Train Loss: 0.01070572438021732, Avg. Test Loss: 0.011022643186151981\n",
      "Epoch: 66, Avg. Train Loss: 0.010634458255629206, Avg. Test Loss: 0.01094546727836132\n",
      "Epoch: 67, Avg. Train Loss: 0.010578690464933252, Avg. Test Loss: 0.010914155282080173\n",
      "Epoch: 68, Avg. Train Loss: 0.010505543610211028, Avg. Test Loss: 0.010803686454892159\n",
      "Epoch: 69, Avg. Train Loss: 0.010424392232887967, Avg. Test Loss: 0.010752950794994831\n",
      "Epoch: 70, Avg. Train Loss: 0.010371024352173472, Avg. Test Loss: 0.010686999186873436\n",
      "Epoch: 71, Avg. Train Loss: 0.010323655964849993, Avg. Test Loss: 0.01067638210952282\n",
      "Epoch: 72, Avg. Train Loss: 0.010258168675178704, Avg. Test Loss: 0.010564805008471012\n",
      "Epoch: 73, Avg. Train Loss: 0.010181682530877202, Avg. Test Loss: 0.010511930100619793\n",
      "Epoch: 74, Avg. Train Loss: 0.010106621959874796, Avg. Test Loss: 0.010431813076138496\n",
      "Epoch: 75, Avg. Train Loss: 0.01005730738993301, Avg. Test Loss: 0.010431429371237755\n",
      "Epoch: 76, Avg. Train Loss: 0.0099954116699654, Avg. Test Loss: 0.010311583988368511\n",
      "Epoch: 77, Avg. Train Loss: 0.009940037893694501, Avg. Test Loss: 0.010250015184283257\n",
      "Epoch: 78, Avg. Train Loss: 0.009868737743344418, Avg. Test Loss: 0.010194545611739159\n",
      "Epoch: 79, Avg. Train Loss: 0.00982260649893866, Avg. Test Loss: 0.01014693547040224\n",
      "Epoch: 80, Avg. Train Loss: 0.009768014882019786, Avg. Test Loss: 0.010074724443256855\n",
      "Epoch: 81, Avg. Train Loss: 0.009720770707137363, Avg. Test Loss: 0.010052801109850407\n",
      "Epoch: 82, Avg. Train Loss: 0.009634939260607543, Avg. Test Loss: 0.009994574822485447\n",
      "Epoch: 83, Avg. Train Loss: 0.009608585517420325, Avg. Test Loss: 0.009929098188877106\n",
      "Epoch: 84, Avg. Train Loss: 0.009535357572658117, Avg. Test Loss: 0.009852001443505287\n",
      "Epoch: 85, Avg. Train Loss: 0.00947357738000709, Avg. Test Loss: 0.00977879948914051\n",
      "Epoch: 86, Avg. Train Loss: 0.009435743266759916, Avg. Test Loss: 0.009722759015858173\n",
      "Epoch: 87, Avg. Train Loss: 0.009367127382997857, Avg. Test Loss: 0.009660734795033932\n",
      "Epoch: 88, Avg. Train Loss: 0.00931051739513181, Avg. Test Loss: 0.009660826995968819\n",
      "Epoch: 89, Avg. Train Loss: 0.009260279667931933, Avg. Test Loss: 0.00956057570874691\n",
      "Epoch: 90, Avg. Train Loss: 0.009189846275677515, Avg. Test Loss: 0.009478618390858173\n",
      "Epoch: 91, Avg. Train Loss: 0.009136260963629845, Avg. Test Loss: 0.00942439679056406\n",
      "Epoch: 92, Avg. Train Loss: 0.00908433383893828, Avg. Test Loss: 0.0093728918582201\n",
      "Epoch: 93, Avg. Train Loss: 0.009025542498674504, Avg. Test Loss: 0.009306436404585838\n",
      "Epoch: 94, Avg. Train Loss: 0.008950580886110317, Avg. Test Loss: 0.009318418800830841\n",
      "Epoch: 95, Avg. Train Loss: 0.008906215299354044, Avg. Test Loss: 0.009193315170705318\n",
      "Epoch: 96, Avg. Train Loss: 0.008844227508403534, Avg. Test Loss: 0.009146979078650475\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 97, Avg. Train Loss: 0.008815567106614972, Avg. Test Loss: 0.00907719973474741\n",
      "Epoch: 98, Avg. Train Loss: 0.008721326434508313, Avg. Test Loss: 0.008997729979455471\n",
      "Epoch: 99, Avg. Train Loss: 0.008662198821819105, Avg. Test Loss: 0.008960898034274578\n",
      "Epoch: 100, Avg. Train Loss: 0.008613471569883268, Avg. Test Loss: 0.008891853503882885\n",
      "Epoch: 101, Avg. Train Loss: 0.008566463420297517, Avg. Test Loss: 0.008836626075208187\n",
      "Epoch: 102, Avg. Train Loss: 0.008491974724673255, Avg. Test Loss: 0.008749911561608315\n",
      "Epoch: 103, Avg. Train Loss: 0.00841999038794013, Avg. Test Loss: 0.00870814174413681\n",
      "Epoch: 104, Avg. Train Loss: 0.008380833710002344, Avg. Test Loss: 0.008677489124238491\n",
      "Epoch: 105, Avg. Train Loss: 0.00832023998982338, Avg. Test Loss: 0.008552368730306625\n",
      "Epoch: 106, Avg. Train Loss: 0.008243389525125886, Avg. Test Loss: 0.008495117537677288\n",
      "Epoch: 107, Avg. Train Loss: 0.008192830480808435, Avg. Test Loss: 0.008431952446699142\n",
      "Epoch: 108, Avg. Train Loss: 0.008135185555316681, Avg. Test Loss: 0.008372355252504349\n",
      "Epoch: 109, Avg. Train Loss: 0.00811582601217683, Avg. Test Loss: 0.008315579034388065\n",
      "Epoch: 110, Avg. Train Loss: 0.008038016361032808, Avg. Test Loss: 0.00826797354966402\n",
      "Epoch: 111, Avg. Train Loss: 0.007990077982635, Avg. Test Loss: 0.008220071904361248\n",
      "Epoch: 112, Avg. Train Loss: 0.007919659827251074, Avg. Test Loss: 0.008134688250720501\n",
      "Epoch: 113, Avg. Train Loss: 0.007860734094973914, Avg. Test Loss: 0.00807903241366148\n",
      "Epoch: 114, Avg. Train Loss: 0.007816304571839959, Avg. Test Loss: 0.008026443421840668\n",
      "Epoch: 115, Avg. Train Loss: 0.0077557159197884935, Avg. Test Loss: 0.007966656237840652\n",
      "Epoch: 116, Avg. Train Loss: 0.007703994693191245, Avg. Test Loss: 0.007911202497780323\n",
      "Epoch: 117, Avg. Train Loss: 0.007670413486139719, Avg. Test Loss: 0.007912985049188137\n",
      "Epoch: 118, Avg. Train Loss: 0.00761115632214865, Avg. Test Loss: 0.00781750027090311\n",
      "Epoch: 119, Avg. Train Loss: 0.007594174120661824, Avg. Test Loss: 0.007839648053050041\n",
      "Epoch: 120, Avg. Train Loss: 0.007526029702709164, Avg. Test Loss: 0.0077259596437215805\n",
      "Epoch: 121, Avg. Train Loss: 0.007482339292331491, Avg. Test Loss: 0.0076763443648815155\n",
      "Epoch: 122, Avg. Train Loss: 0.007427397519783225, Avg. Test Loss: 0.007622608449310064\n",
      "Epoch: 123, Avg. Train Loss: 0.007380137956419656, Avg. Test Loss: 0.007578373420983553\n",
      "Epoch: 124, Avg. Train Loss: 0.007359592070759729, Avg. Test Loss: 0.0075566815212368965\n",
      "Epoch: 125, Avg. Train Loss: 0.007331518467169168, Avg. Test Loss: 0.00749439001083374\n",
      "Epoch: 126, Avg. Train Loss: 0.007283667557288048, Avg. Test Loss: 0.007445086259394884\n",
      "Epoch: 127, Avg. Train Loss: 0.007233759756524896, Avg. Test Loss: 0.007405410520732403\n",
      "Epoch: 128, Avg. Train Loss: 0.0071989257689998596, Avg. Test Loss: 0.00736602395772934\n",
      "Epoch: 129, Avg. Train Loss: 0.007166725864937139, Avg. Test Loss: 0.007455755025148392\n",
      "Epoch: 130, Avg. Train Loss: 0.007126700685381196, Avg. Test Loss: 0.00729365786537528\n",
      "Epoch: 131, Avg. Train Loss: 0.007085790976795347, Avg. Test Loss: 0.007262496743351221\n",
      "Epoch: 132, Avg. Train Loss: 0.007098221945641346, Avg. Test Loss: 0.0072359610348939896\n",
      "Epoch: 133, Avg. Train Loss: 0.007065697594784027, Avg. Test Loss: 0.0072144935838878155\n",
      "Epoch: 134, Avg. Train Loss: 0.007009261179455491, Avg. Test Loss: 0.0072752065025269985\n",
      "Epoch: 135, Avg. Train Loss: 0.006982950212130713, Avg. Test Loss: 0.007146615069359541\n",
      "Epoch: 136, Avg. Train Loss: 0.006953334121769944, Avg. Test Loss: 0.007221713662147522\n",
      "Epoch: 137, Avg. Train Loss: 0.0069345424146673015, Avg. Test Loss: 0.00708046555519104\n",
      "Epoch: 138, Avg. Train Loss: 0.006904327624672374, Avg. Test Loss: 0.007035448681563139\n",
      "Epoch: 139, Avg. Train Loss: 0.006901886010932368, Avg. Test Loss: 0.007076814770698547\n",
      "Epoch: 140, Avg. Train Loss: 0.0068508059890984106, Avg. Test Loss: 0.007006639614701271\n",
      "Epoch: 141, Avg. Train Loss: 0.006818176896939444, Avg. Test Loss: 0.006978429388254881\n",
      "Epoch: 142, Avg. Train Loss: 0.006798869648645091, Avg. Test Loss: 0.0069282082840800285\n",
      "Epoch: 143, Avg. Train Loss: 0.0067726750100074815, Avg. Test Loss: 0.0069344439543783665\n",
      "Epoch: 144, Avg. Train Loss: 0.006731406200763791, Avg. Test Loss: 0.0069006034173071384\n",
      "Epoch: 145, Avg. Train Loss: 0.00672606606209694, Avg. Test Loss: 0.006879480089992285\n",
      "Epoch: 146, Avg. Train Loss: 0.006687003177005884, Avg. Test Loss: 0.006823613774031401\n",
      "Epoch: 147, Avg. Train Loss: 0.006659801497102477, Avg. Test Loss: 0.006817162036895752\n",
      "Epoch: 148, Avg. Train Loss: 0.006660107425738906, Avg. Test Loss: 0.006800998467952013\n",
      "Epoch: 149, Avg. Train Loss: 0.006600555790544942, Avg. Test Loss: 0.006762001197785139\n",
      "Epoch: 150, Avg. Train Loss: 0.006614144144276547, Avg. Test Loss: 0.006729261018335819\n",
      "Epoch: 151, Avg. Train Loss: 0.006596609213671019, Avg. Test Loss: 0.006714303512126207\n",
      "Epoch: 152, Avg. Train Loss: 0.006536565504448358, Avg. Test Loss: 0.006817457731813192\n",
      "Epoch: 153, Avg. Train Loss: 0.00652153302677149, Avg. Test Loss: 0.006660310551524162\n",
      "Epoch: 154, Avg. Train Loss: 0.006527238590426223, Avg. Test Loss: 0.006667656358331442\n",
      "Epoch: 155, Avg. Train Loss: 0.006484593145635932, Avg. Test Loss: 0.006694362964481115\n",
      "Epoch: 156, Avg. Train Loss: 0.0065172386767212735, Avg. Test Loss: 0.006762819830328226\n",
      "Epoch: 157, Avg. Train Loss: 0.006481617526692706, Avg. Test Loss: 0.006586499512195587\n",
      "Epoch: 158, Avg. Train Loss: 0.006415526783310397, Avg. Test Loss: 0.00655693793669343\n",
      "Epoch: 159, Avg. Train Loss: 0.0064011083829195, Avg. Test Loss: 0.006600816268473864\n",
      "Epoch: 160, Avg. Train Loss: 0.00639689206903757, Avg. Test Loss: 0.006510171107947826\n",
      "Epoch: 161, Avg. Train Loss: 0.006372285725245642, Avg. Test Loss: 0.0064999922178685665\n",
      "Epoch: 162, Avg. Train Loss: 0.006344362660202869, Avg. Test Loss: 0.0065095326863229275\n",
      "Epoch: 163, Avg. Train Loss: 0.006316768752714229, Avg. Test Loss: 0.006439025979489088\n",
      "Epoch: 164, Avg. Train Loss: 0.006308576308710631, Avg. Test Loss: 0.006421218626201153\n",
      "Epoch: 165, Avg. Train Loss: 0.006295855113759984, Avg. Test Loss: 0.006474468391388655\n",
      "Epoch: 166, Avg. Train Loss: 0.006265094601224328, Avg. Test Loss: 0.006394532509148121\n",
      "Epoch: 167, Avg. Train Loss: 0.006234908736375875, Avg. Test Loss: 0.006418504752218723\n",
      "Epoch: 168, Avg. Train Loss: 0.006234692019778628, Avg. Test Loss: 0.006354869343340397\n",
      "Epoch: 169, Avg. Train Loss: 0.0062037626562943295, Avg. Test Loss: 0.0063873715698719025\n",
      "Epoch: 170, Avg. Train Loss: 0.00618759544869495, Avg. Test Loss: 0.006304594688117504\n",
      "Epoch: 171, Avg. Train Loss: 0.0061665809561693395, Avg. Test Loss: 0.006302596535533667\n",
      "Epoch: 172, Avg. Train Loss: 0.006144402808574743, Avg. Test Loss: 0.006283778231590986\n",
      "Epoch: 173, Avg. Train Loss: 0.006108167927798836, Avg. Test Loss: 0.0062784780748188496\n",
      "Epoch: 174, Avg. Train Loss: 0.0060806622360508105, Avg. Test Loss: 0.006259922869503498\n",
      "Epoch: 175, Avg. Train Loss: 0.006083883041905803, Avg. Test Loss: 0.006231400649994612\n",
      "Epoch: 176, Avg. Train Loss: 0.006075804966480233, Avg. Test Loss: 0.006294609978795052\n",
      "Epoch: 177, Avg. Train Loss: 0.0060665443712888765, Avg. Test Loss: 0.006180245894938707\n",
      "Epoch: 178, Avg. Train Loss: 0.00600747078613833, Avg. Test Loss: 0.0061520966701209545\n",
      "Epoch: 179, Avg. Train Loss: 0.005991332926029383, Avg. Test Loss: 0.0062249586917459965\n",
      "Epoch: 180, Avg. Train Loss: 0.005983725709970607, Avg. Test Loss: 0.006147034000605345\n",
      "Epoch: 181, Avg. Train Loss: 0.005968328781945761, Avg. Test Loss: 0.006123402155935764\n",
      "Epoch: 182, Avg. Train Loss: 0.005948857653366272, Avg. Test Loss: 0.006057668011635542\n",
      "Epoch: 183, Avg. Train Loss: 0.005900488776523013, Avg. Test Loss: 0.006056586280465126\n",
      "Epoch: 184, Avg. Train Loss: 0.005932037252932787, Avg. Test Loss: 0.006102200131863356\n",
      "Epoch: 185, Avg. Train Loss: 0.005956712113909943, Avg. Test Loss: 0.006050673313438892\n",
      "Epoch: 186, Avg. Train Loss: 0.005864993322554023, Avg. Test Loss: 0.0061267586424946785\n",
      "Epoch: 187, Avg. Train Loss: 0.0058941709224221315, Avg. Test Loss: 0.006019528489559889\n",
      "Epoch: 188, Avg. Train Loss: 0.005817939808895421, Avg. Test Loss: 0.00598389795050025\n",
      "Epoch: 189, Avg. Train Loss: 0.005862794805664656, Avg. Test Loss: 0.005927728489041328\n",
      "Epoch: 190, Avg. Train Loss: 0.0057674728355608705, Avg. Test Loss: 0.006033261772245169\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 191, Avg. Train Loss: 0.005791373832454515, Avg. Test Loss: 0.0059390589594841\n",
      "Epoch: 192, Avg. Train Loss: 0.005766691131040801, Avg. Test Loss: 0.005928416736423969\n",
      "Epoch: 193, Avg. Train Loss: 0.0057919131873478726, Avg. Test Loss: 0.00597142381593585\n",
      "Epoch: 194, Avg. Train Loss: 0.005735276082833839, Avg. Test Loss: 0.005946088116616011\n",
      "Epoch: 195, Avg. Train Loss: 0.005700469038687473, Avg. Test Loss: 0.005836394615471363\n",
      "Epoch: 196, Avg. Train Loss: 0.005662900309056737, Avg. Test Loss: 0.005803679581731558\n",
      "Epoch: 197, Avg. Train Loss: 0.005625106036922959, Avg. Test Loss: 0.005914045963436365\n",
      "Epoch: 198, Avg. Train Loss: 0.005660309748680785, Avg. Test Loss: 0.005881282966583967\n",
      "Epoch: 199, Avg. Train Loss: 0.005621694244964178, Avg. Test Loss: 0.005774805322289467\n",
      "Epoch: 200, Avg. Train Loss: 0.005587871034824571, Avg. Test Loss: 0.005873503629118204\n",
      "Epoch: 201, Avg. Train Loss: 0.0055999740590016505, Avg. Test Loss: 0.005731028504669666\n",
      "Epoch: 202, Avg. Train Loss: 0.005539724884857965, Avg. Test Loss: 0.005695806350558996\n",
      "Epoch: 203, Avg. Train Loss: 0.005541009308640347, Avg. Test Loss: 0.005689335986971855\n",
      "Epoch: 204, Avg. Train Loss: 0.005533734423130057, Avg. Test Loss: 0.005665813572704792\n",
      "Epoch: 205, Avg. Train Loss: 0.005508993589860755, Avg. Test Loss: 0.005753861274570227\n",
      "Epoch: 206, Avg. Train Loss: 0.005494848954989467, Avg. Test Loss: 0.00567008787766099\n",
      "Epoch: 207, Avg. Train Loss: 0.005469601915412864, Avg. Test Loss: 0.005644490476697683\n",
      "Epoch: 208, Avg. Train Loss: 0.0054566126078540505, Avg. Test Loss: 0.00561201386153698\n",
      "Epoch: 209, Avg. Train Loss: 0.005438849514047074, Avg. Test Loss: 0.005588996224105358\n",
      "Epoch: 210, Avg. Train Loss: 0.005428599486084178, Avg. Test Loss: 0.005557084921747446\n",
      "Epoch: 211, Avg. Train Loss: 0.005390866692069658, Avg. Test Loss: 0.005592406261712313\n",
      "Epoch: 212, Avg. Train Loss: 0.005371157404815041, Avg. Test Loss: 0.00554334931075573\n",
      "Epoch: 213, Avg. Train Loss: 0.005342201210645049, Avg. Test Loss: 0.005549293011426926\n",
      "Epoch: 214, Avg. Train Loss: 0.005360187128792668, Avg. Test Loss: 0.0055332547053694725\n",
      "Epoch: 215, Avg. Train Loss: 0.005322147301549829, Avg. Test Loss: 0.005558168515563011\n",
      "Epoch: 216, Avg. Train Loss: 0.0053245096337483375, Avg. Test Loss: 0.005531766451895237\n",
      "Epoch: 217, Avg. Train Loss: 0.005309833787641553, Avg. Test Loss: 0.005621294025331736\n",
      "Epoch: 218, Avg. Train Loss: 0.00527478241210067, Avg. Test Loss: 0.0054687210358679295\n",
      "Epoch: 219, Avg. Train Loss: 0.005244586237727902, Avg. Test Loss: 0.005460652988404036\n",
      "Epoch: 220, Avg. Train Loss: 0.0052290081024863, Avg. Test Loss: 0.005447522737085819\n",
      "Epoch: 221, Avg. Train Loss: 0.005222696117883505, Avg. Test Loss: 0.0053864093497395515\n",
      "Epoch: 222, Avg. Train Loss: 0.005208162634178649, Avg. Test Loss: 0.005364520940929651\n",
      "Epoch: 223, Avg. Train Loss: 0.0052253757820053155, Avg. Test Loss: 0.005486797541379929\n",
      "Epoch: 224, Avg. Train Loss: 0.005167124803762796, Avg. Test Loss: 0.00534822465851903\n",
      "Epoch: 225, Avg. Train Loss: 0.005151967669642249, Avg. Test Loss: 0.005356046836823225\n",
      "Epoch: 226, Avg. Train Loss: 0.00515211415801977, Avg. Test Loss: 0.005382188595831394\n",
      "Epoch: 227, Avg. Train Loss: 0.0051584336473498235, Avg. Test Loss: 0.005310975015163422\n",
      "Epoch: 228, Avg. Train Loss: 0.005130185474923184, Avg. Test Loss: 0.005301765166223049\n",
      "Epoch: 229, Avg. Train Loss: 0.0050856230000770365, Avg. Test Loss: 0.0052556609734892845\n",
      "Epoch: 230, Avg. Train Loss: 0.005069058854132891, Avg. Test Loss: 0.005261363927274942\n",
      "Epoch: 231, Avg. Train Loss: 0.005087112119897853, Avg. Test Loss: 0.00534975016489625\n",
      "Epoch: 232, Avg. Train Loss: 0.005044362442784531, Avg. Test Loss: 0.005225549452006817\n",
      "Epoch: 233, Avg. Train Loss: 0.005028862506151199, Avg. Test Loss: 0.005292441695928574\n",
      "Epoch: 234, Avg. Train Loss: 0.005023575756092405, Avg. Test Loss: 0.005225279834121466\n",
      "Epoch: 235, Avg. Train Loss: 0.005004710431189038, Avg. Test Loss: 0.0052319858223199844\n",
      "Epoch: 236, Avg. Train Loss: 0.0049841212606880556, Avg. Test Loss: 0.005321740172803402\n",
      "Epoch: 237, Avg. Train Loss: 0.004997769262381765, Avg. Test Loss: 0.005177288316190243\n",
      "Epoch: 238, Avg. Train Loss: 0.004964200444086347, Avg. Test Loss: 0.005160433240234852\n",
      "Epoch: 239, Avg. Train Loss: 0.00494465601175677, Avg. Test Loss: 0.0051550609059631824\n",
      "Epoch: 240, Avg. Train Loss: 0.004953885191055231, Avg. Test Loss: 0.00511937914416194\n",
      "Epoch: 241, Avg. Train Loss: 0.004930914552925631, Avg. Test Loss: 0.005208136979490519\n",
      "Epoch: 242, Avg. Train Loss: 0.004946556613715582, Avg. Test Loss: 0.005084992852061987\n",
      "Epoch: 243, Avg. Train Loss: 0.004917641581837521, Avg. Test Loss: 0.005126499105244875\n",
      "Epoch: 244, Avg. Train Loss: 0.004874660568528397, Avg. Test Loss: 0.005059013143181801\n",
      "Epoch: 245, Avg. Train Loss: 0.004868736209044623, Avg. Test Loss: 0.005107766017317772\n",
      "Epoch: 246, Avg. Train Loss: 0.004845864745939887, Avg. Test Loss: 0.005106495693325996\n",
      "Epoch: 247, Avg. Train Loss: 0.004836060626562251, Avg. Test Loss: 0.005031508859246969\n",
      "Epoch: 248, Avg. Train Loss: 0.004837446856897238, Avg. Test Loss: 0.00503619946539402\n",
      "Epoch: 249, Avg. Train Loss: 0.004850513767451048, Avg. Test Loss: 0.00511588342487812\n",
      "Epoch: 250, Avg. Train Loss: 0.004818777272174525, Avg. Test Loss: 0.005023222416639328\n",
      "Epoch: 251, Avg. Train Loss: 0.004773541115397631, Avg. Test Loss: 0.004980487748980522\n",
      "Epoch: 252, Avg. Train Loss: 0.004763033793329499, Avg. Test Loss: 0.0050442093051970005\n",
      "Epoch: 253, Avg. Train Loss: 0.00473645402031929, Avg. Test Loss: 0.0049831154756248\n",
      "Epoch: 254, Avg. Train Loss: 0.004750054687001678, Avg. Test Loss: 0.004946197383105755\n",
      "Epoch: 255, Avg. Train Loss: 0.004725330043584108, Avg. Test Loss: 0.005096648819744587\n",
      "Epoch: 256, Avg. Train Loss: 0.0047261423301384895, Avg. Test Loss: 0.004969327710568905\n",
      "Epoch: 257, Avg. Train Loss: 0.004699040854046511, Avg. Test Loss: 0.00489736907184124\n",
      "Epoch: 258, Avg. Train Loss: 0.0046955876832091535, Avg. Test Loss: 0.004904312081634998\n",
      "Epoch: 259, Avg. Train Loss: 0.004698914551544328, Avg. Test Loss: 0.0049278209917247295\n",
      "Epoch: 260, Avg. Train Loss: 0.004655434999095146, Avg. Test Loss: 0.004865902476012707\n",
      "Epoch: 261, Avg. Train Loss: 0.004648207502742839, Avg. Test Loss: 0.004877688828855753\n",
      "Epoch: 262, Avg. Train Loss: 0.0046160546737874664, Avg. Test Loss: 0.0048334188759326935\n",
      "Epoch: 263, Avg. Train Loss: 0.004613121711584025, Avg. Test Loss: 0.004965524654835463\n",
      "Epoch: 264, Avg. Train Loss: 0.004606251680660386, Avg. Test Loss: 0.004832425620406866\n",
      "Epoch: 265, Avg. Train Loss: 0.004603351704603018, Avg. Test Loss: 0.004817998968064785\n",
      "Epoch: 266, Avg. Train Loss: 0.004560237425531066, Avg. Test Loss: 0.004788501653820276\n",
      "Epoch: 267, Avg. Train Loss: 0.004578726669383603, Avg. Test Loss: 0.004773416090756655\n",
      "Epoch: 268, Avg. Train Loss: 0.004572612796585227, Avg. Test Loss: 0.004808252211660147\n",
      "Epoch: 269, Avg. Train Loss: 0.004567160032862841, Avg. Test Loss: 0.004830880556255579\n",
      "Epoch: 270, Avg. Train Loss: 0.004542340979326603, Avg. Test Loss: 0.004780919756740332\n",
      "Epoch: 271, Avg. Train Loss: 0.004531984921371521, Avg. Test Loss: 0.004842692520469427\n",
      "Epoch: 272, Avg. Train Loss: 0.004551100122287523, Avg. Test Loss: 0.004906554706394672\n",
      "Epoch: 273, Avg. Train Loss: 0.004505255107962808, Avg. Test Loss: 0.00477122375741601\n",
      "Epoch: 274, Avg. Train Loss: 0.004480593859456306, Avg. Test Loss: 0.004726525396108627\n",
      "Epoch: 275, Avg. Train Loss: 0.00445396289619249, Avg. Test Loss: 0.004693313036113977\n",
      "Epoch: 276, Avg. Train Loss: 0.004435156201293995, Avg. Test Loss: 0.00470065139234066\n",
      "Epoch: 277, Avg. Train Loss: 0.0044244265855225015, Avg. Test Loss: 0.0047553060576319695\n",
      "Epoch: 278, Avg. Train Loss: 0.004435010644239049, Avg. Test Loss: 0.004657820798456669\n",
      "Epoch: 279, Avg. Train Loss: 0.004398880104079496, Avg. Test Loss: 0.0046958038583397865\n",
      "Epoch: 280, Avg. Train Loss: 0.00440046472778154, Avg. Test Loss: 0.004598589614033699\n",
      "Epoch: 281, Avg. Train Loss: 0.004381102877993917, Avg. Test Loss: 0.004601696971803904\n",
      "Epoch: 282, Avg. Train Loss: 0.004351565581854693, Avg. Test Loss: 0.004595761653035879\n",
      "Epoch: 283, Avg. Train Loss: 0.004329832032496153, Avg. Test Loss: 0.004622552543878555\n",
      "Epoch: 284, Avg. Train Loss: 0.004333557718065243, Avg. Test Loss: 0.004553980194032192\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 285, Avg. Train Loss: 0.00432214519918658, Avg. Test Loss: 0.004548077471554279\n",
      "Epoch: 286, Avg. Train Loss: 0.004341838415712118, Avg. Test Loss: 0.004537908360362053\n",
      "Epoch: 287, Avg. Train Loss: 0.004305737520849636, Avg. Test Loss: 0.0044991085305809975\n",
      "Epoch: 288, Avg. Train Loss: 0.004277084250176369, Avg. Test Loss: 0.004544470924884081\n",
      "Epoch: 289, Avg. Train Loss: 0.004250634082614682, Avg. Test Loss: 0.004480340983718634\n",
      "Epoch: 290, Avg. Train Loss: 0.004226532835123497, Avg. Test Loss: 0.004466659855097532\n",
      "Epoch: 291, Avg. Train Loss: 0.004227303948556614, Avg. Test Loss: 0.0045334333553910255\n",
      "Epoch: 292, Avg. Train Loss: 0.00421999664002553, Avg. Test Loss: 0.0044519128277897835\n",
      "Epoch: 293, Avg. Train Loss: 0.0041945254495150824, Avg. Test Loss: 0.004476997070014477\n",
      "Epoch: 294, Avg. Train Loss: 0.004209779208352746, Avg. Test Loss: 0.004542933776974678\n",
      "Epoch: 295, Avg. Train Loss: 0.004204412147965889, Avg. Test Loss: 0.004425159655511379\n",
      "Epoch: 296, Avg. Train Loss: 0.004150169175984555, Avg. Test Loss: 0.004399740137159824\n",
      "Epoch: 297, Avg. Train Loss: 0.004148181035118394, Avg. Test Loss: 0.004402667284011841\n",
      "Epoch: 298, Avg. Train Loss: 0.00416630475651906, Avg. Test Loss: 0.004414192400872707\n",
      "Epoch: 299, Avg. Train Loss: 0.004123394604945599, Avg. Test Loss: 0.004377863369882107\n",
      "Epoch: 300, Avg. Train Loss: 0.004135937224207229, Avg. Test Loss: 0.004376404918730259\n",
      "Epoch: 301, Avg. Train Loss: 0.004098073054148361, Avg. Test Loss: 0.00432616239413619\n",
      "Epoch: 302, Avg. Train Loss: 0.004080962952832843, Avg. Test Loss: 0.004304099828004837\n",
      "Epoch: 303, Avg. Train Loss: 0.0041086976578849, Avg. Test Loss: 0.0044180420227348804\n",
      "Epoch: 304, Avg. Train Loss: 0.004076080434674094, Avg. Test Loss: 0.0043309032917022705\n",
      "Epoch: 305, Avg. Train Loss: 0.004068502463227095, Avg. Test Loss: 0.004389108158648014\n",
      "Epoch: 306, Avg. Train Loss: 0.004077475252669565, Avg. Test Loss: 0.004260958172380924\n",
      "Epoch: 307, Avg. Train Loss: 0.004043286097734127, Avg. Test Loss: 0.004265916999429464\n",
      "Epoch: 308, Avg. Train Loss: 0.0040236303723568834, Avg. Test Loss: 0.0042370702140033245\n",
      "Epoch: 309, Avg. Train Loss: 0.004004830483693716, Avg. Test Loss: 0.0042395880445837975\n",
      "Epoch: 310, Avg. Train Loss: 0.003999217072241875, Avg. Test Loss: 0.004271058831363916\n",
      "Epoch: 311, Avg. Train Loss: 0.004000642748419629, Avg. Test Loss: 0.004249804653227329\n",
      "Epoch: 312, Avg. Train Loss: 0.003982150304499407, Avg. Test Loss: 0.00422125868499279\n",
      "Epoch: 313, Avg. Train Loss: 0.003972826471422301, Avg. Test Loss: 0.004186253063380718\n",
      "Epoch: 314, Avg. Train Loss: 0.003963479712648794, Avg. Test Loss: 0.004183610901236534\n",
      "Epoch: 315, Avg. Train Loss: 0.003978350887421605, Avg. Test Loss: 0.004215673543512821\n",
      "Epoch: 316, Avg. Train Loss: 0.003964296780353369, Avg. Test Loss: 0.004220164380967617\n",
      "Epoch: 317, Avg. Train Loss: 0.003937562792237068, Avg. Test Loss: 0.004194434732198715\n",
      "Epoch: 318, Avg. Train Loss: 0.003926664265955604, Avg. Test Loss: 0.004129901062697172\n",
      "Epoch: 319, Avg. Train Loss: 0.003913617822839771, Avg. Test Loss: 0.0041596004739403725\n",
      "Epoch: 320, Avg. Train Loss: 0.0039041872396198816, Avg. Test Loss: 0.00411995267495513\n",
      "Epoch: 321, Avg. Train Loss: 0.003889543702825904, Avg. Test Loss: 0.004141481127589941\n",
      "Epoch: 322, Avg. Train Loss: 0.003881195267705723, Avg. Test Loss: 0.00415392592549324\n",
      "Epoch: 323, Avg. Train Loss: 0.0038874864329172427, Avg. Test Loss: 0.004153806250542402\n",
      "Epoch: 324, Avg. Train Loss: 0.003876218491038957, Avg. Test Loss: 0.004174868110567331\n",
      "Epoch: 325, Avg. Train Loss: 0.0038596735942329086, Avg. Test Loss: 0.004071899689733982\n",
      "Epoch: 326, Avg. Train Loss: 0.0038513166147695725, Avg. Test Loss: 0.00407575024291873\n",
      "Epoch: 327, Avg. Train Loss: 0.0038359535663107106, Avg. Test Loss: 0.0040629152208566666\n",
      "Epoch: 328, Avg. Train Loss: 0.003854593895592315, Avg. Test Loss: 0.0040551587007939816\n",
      "Epoch: 329, Avg. Train Loss: 0.0038284548818198747, Avg. Test Loss: 0.00404266407713294\n",
      "Epoch: 330, Avg. Train Loss: 0.003833424343272697, Avg. Test Loss: 0.0042252796702086926\n",
      "Epoch: 331, Avg. Train Loss: 0.0038408039592553018, Avg. Test Loss: 0.004081314895302057\n",
      "Epoch: 332, Avg. Train Loss: 0.003842417096589194, Avg. Test Loss: 0.004063967615365982\n",
      "Epoch: 333, Avg. Train Loss: 0.003817857849563277, Avg. Test Loss: 0.004040102940052748\n",
      "Epoch: 334, Avg. Train Loss: 0.003800863373028331, Avg. Test Loss: 0.004028225317597389\n",
      "Epoch: 335, Avg. Train Loss: 0.0037820196905454925, Avg. Test Loss: 0.0040434375405311584\n",
      "Epoch: 336, Avg. Train Loss: 0.003787518760492635, Avg. Test Loss: 0.004007481038570404\n",
      "Epoch: 337, Avg. Train Loss: 0.00379429021741935, Avg. Test Loss: 0.0040079569444060326\n",
      "Epoch: 338, Avg. Train Loss: 0.0038104369738247504, Avg. Test Loss: 0.003997717052698135\n",
      "Epoch: 339, Avg. Train Loss: 0.0037783221070936254, Avg. Test Loss: 0.004024831112474203\n",
      "Epoch: 340, Avg. Train Loss: 0.0037824111330041358, Avg. Test Loss: 0.004067006520926952\n",
      "Epoch: 341, Avg. Train Loss: 0.00375912984464924, Avg. Test Loss: 0.00406569242477417\n",
      "Epoch: 342, Avg. Train Loss: 0.0037787061531183333, Avg. Test Loss: 0.0039603556506335735\n",
      "Epoch: 343, Avg. Train Loss: 0.003747829598872814, Avg. Test Loss: 0.00398607924580574\n",
      "Epoch: 344, Avg. Train Loss: 0.003757769144465064, Avg. Test Loss: 0.003944025374948978\n",
      "Epoch: 345, Avg. Train Loss: 0.0037431280171975148, Avg. Test Loss: 0.003971807658672333\n",
      "Epoch: 346, Avg. Train Loss: 0.0037439449820234334, Avg. Test Loss: 0.003948419354856014\n",
      "Epoch: 347, Avg. Train Loss: 0.0037346496788221734, Avg. Test Loss: 0.003985357470810413\n",
      "Epoch: 348, Avg. Train Loss: 0.003750781848117016, Avg. Test Loss: 0.003927922807633877\n",
      "Epoch: 349, Avg. Train Loss: 0.003713290147526666, Avg. Test Loss: 0.003930727951228619\n",
      "Epoch: 350, Avg. Train Loss: 0.003703141595821741, Avg. Test Loss: 0.003919358830899\n",
      "Epoch: 351, Avg. Train Loss: 0.003698766718856817, Avg. Test Loss: 0.003924819640815258\n",
      "Epoch: 352, Avg. Train Loss: 0.0036914713929818814, Avg. Test Loss: 0.003920501098036766\n",
      "Epoch: 353, Avg. Train Loss: 0.003695515125210202, Avg. Test Loss: 0.003910561092197895\n",
      "Epoch: 354, Avg. Train Loss: 0.0036919234905305296, Avg. Test Loss: 0.00391190592199564\n",
      "Epoch: 355, Avg. Train Loss: 0.00369776260151073, Avg. Test Loss: 0.003966756165027618\n",
      "Epoch: 356, Avg. Train Loss: 0.00372082062152236, Avg. Test Loss: 0.0039024921134114265\n",
      "Epoch: 357, Avg. Train Loss: 0.003683186883410049, Avg. Test Loss: 0.0039039587136358023\n",
      "Epoch: 358, Avg. Train Loss: 0.0036791248062928747, Avg. Test Loss: 0.003886497812345624\n",
      "Epoch: 359, Avg. Train Loss: 0.0036656491317634664, Avg. Test Loss: 0.003904499812051654\n",
      "Epoch: 360, Avg. Train Loss: 0.003674522729937074, Avg. Test Loss: 0.003888672450557351\n",
      "Epoch: 361, Avg. Train Loss: 0.0036591399396054968, Avg. Test Loss: 0.003937717527151108\n",
      "Epoch: 362, Avg. Train Loss: 0.003672598644571249, Avg. Test Loss: 0.0038628987967967987\n",
      "Epoch: 363, Avg. Train Loss: 0.003657000994872908, Avg. Test Loss: 0.003859597723931074\n",
      "Epoch: 364, Avg. Train Loss: 0.003650275546364313, Avg. Test Loss: 0.003870251588523388\n",
      "Epoch: 365, Avg. Train Loss: 0.003648463636636734, Avg. Test Loss: 0.003863651305437088\n",
      "Epoch: 366, Avg. Train Loss: 0.003655900068711056, Avg. Test Loss: 0.0038519941736012697\n",
      "Epoch: 367, Avg. Train Loss: 0.0036319726103440273, Avg. Test Loss: 0.0038546251598745584\n",
      "Epoch: 368, Avg. Train Loss: 0.0036387372556207485, Avg. Test Loss: 0.0038580941036343575\n",
      "Epoch: 369, Avg. Train Loss: 0.0036394091236383415, Avg. Test Loss: 0.003846151288598776\n",
      "Epoch: 370, Avg. Train Loss: 0.0036246530646674856, Avg. Test Loss: 0.0038477920461446047\n",
      "Epoch: 371, Avg. Train Loss: 0.0036286469927967286, Avg. Test Loss: 0.0038336210418492556\n",
      "Epoch: 372, Avg. Train Loss: 0.0036154921264062788, Avg. Test Loss: 0.003883324796333909\n",
      "Epoch: 373, Avg. Train Loss: 0.0036263946811993454, Avg. Test Loss: 0.0038406914100050926\n",
      "Epoch: 374, Avg. Train Loss: 0.003612889236835546, Avg. Test Loss: 0.0038561562541872263\n",
      "Epoch: 375, Avg. Train Loss: 0.003598572827095902, Avg. Test Loss: 0.0038925076369196177\n",
      "Epoch: 376, Avg. Train Loss: 0.003626927370638695, Avg. Test Loss: 0.003919692710042\n",
      "Epoch: 377, Avg. Train Loss: 0.00363057462476887, Avg. Test Loss: 0.0038111445028334856\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 378, Avg. Train Loss: 0.0036088003787796857, Avg. Test Loss: 0.0038052177987992764\n",
      "Epoch: 379, Avg. Train Loss: 0.003596587247366822, Avg. Test Loss: 0.003935076761990786\n",
      "Epoch: 380, Avg. Train Loss: 0.003596373768739922, Avg. Test Loss: 0.0038416185416281223\n",
      "Epoch: 381, Avg. Train Loss: 0.003592604024032521, Avg. Test Loss: 0.0038471315056085587\n",
      "Epoch: 382, Avg. Train Loss: 0.003577280545953748, Avg. Test Loss: 0.003818928962573409\n",
      "Epoch: 383, Avg. Train Loss: 0.0035914465037802626, Avg. Test Loss: 0.003826068714261055\n",
      "Epoch: 384, Avg. Train Loss: 0.003577916790882862, Avg. Test Loss: 0.003826127154752612\n",
      "Epoch: 385, Avg. Train Loss: 0.0035794764583887057, Avg. Test Loss: 0.003806040622293949\n",
      "Epoch: 386, Avg. Train Loss: 0.0035607733893706357, Avg. Test Loss: 0.0037790199276059866\n",
      "Epoch: 387, Avg. Train Loss: 0.0035691931248144353, Avg. Test Loss: 0.0038079393561929464\n",
      "Epoch: 388, Avg. Train Loss: 0.003554790123734017, Avg. Test Loss: 0.003785223001614213\n",
      "Epoch: 389, Avg. Train Loss: 0.003547759428836925, Avg. Test Loss: 0.003912266343832016\n",
      "Epoch: 390, Avg. Train Loss: 0.003569945925846696, Avg. Test Loss: 0.0038362303748726845\n",
      "Epoch: 391, Avg. Train Loss: 0.003574672160496892, Avg. Test Loss: 0.0038069486618041992\n",
      "Epoch: 392, Avg. Train Loss: 0.0035456212313282626, Avg. Test Loss: 0.003767732996493578\n",
      "Epoch: 393, Avg. Train Loss: 0.0035316345314386974, Avg. Test Loss: 0.0038523508701473475\n",
      "Epoch: 394, Avg. Train Loss: 0.0035888151763830076, Avg. Test Loss: 0.0037720967084169388\n",
      "Epoch: 395, Avg. Train Loss: 0.003536520661179756, Avg. Test Loss: 0.00376852392219007\n",
      "Epoch: 396, Avg. Train Loss: 0.003567114060874595, Avg. Test Loss: 0.0038053395692259073\n",
      "Epoch: 397, Avg. Train Loss: 0.003530579012667024, Avg. Test Loss: 0.003744082525372505\n",
      "Epoch: 398, Avg. Train Loss: 0.0035361530594960893, Avg. Test Loss: 0.003748467657715082\n",
      "Epoch: 399, Avg. Train Loss: 0.0035395671039559814, Avg. Test Loss: 0.0037607697304338217\n",
      "Epoch: 400, Avg. Train Loss: 0.0035374926262383543, Avg. Test Loss: 0.003780409460887313\n",
      "Epoch: 401, Avg. Train Loss: 0.0035080173605143332, Avg. Test Loss: 0.0037235997151583433\n",
      "Epoch: 402, Avg. Train Loss: 0.003514629084790169, Avg. Test Loss: 0.00374054629355669\n",
      "Epoch: 403, Avg. Train Loss: 0.003503340220641951, Avg. Test Loss: 0.0037312337663024664\n",
      "Epoch: 404, Avg. Train Loss: 0.0035060529683738255, Avg. Test Loss: 0.0037772255018353462\n",
      "Epoch: 405, Avg. Train Loss: 0.003503453219309449, Avg. Test Loss: 0.0037119851913303137\n",
      "Epoch: 406, Avg. Train Loss: 0.0035058339397141406, Avg. Test Loss: 0.0038433524314314127\n",
      "Epoch: 407, Avg. Train Loss: 0.0035178806676074517, Avg. Test Loss: 0.0037119430489838123\n",
      "Epoch: 408, Avg. Train Loss: 0.0035202607978135347, Avg. Test Loss: 0.0037168096750974655\n",
      "Epoch: 409, Avg. Train Loss: 0.003485714935502687, Avg. Test Loss: 0.0037048514932394028\n",
      "Epoch: 410, Avg. Train Loss: 0.003501280064716242, Avg. Test Loss: 0.0037598751951009035\n",
      "Epoch: 411, Avg. Train Loss: 0.0035001989129151024, Avg. Test Loss: 0.0037059106398373842\n",
      "Epoch: 412, Avg. Train Loss: 0.0034868982945417248, Avg. Test Loss: 0.003704203525558114\n",
      "Epoch: 413, Avg. Train Loss: 0.0034713331111815085, Avg. Test Loss: 0.0037270388565957546\n",
      "Epoch: 414, Avg. Train Loss: 0.0034693778860707615, Avg. Test Loss: 0.0037208173889666796\n",
      "Epoch: 415, Avg. Train Loss: 0.003472709465165471, Avg. Test Loss: 0.003678008681163192\n",
      "Epoch: 416, Avg. Train Loss: 0.003456779928921267, Avg. Test Loss: 0.0036701366771012545\n",
      "Epoch: 417, Avg. Train Loss: 0.0034513832827986674, Avg. Test Loss: 0.003684869734570384\n",
      "Epoch: 418, Avg. Train Loss: 0.0034745545505524373, Avg. Test Loss: 0.003690376179292798\n",
      "Epoch: 419, Avg. Train Loss: 0.0034751462219499572, Avg. Test Loss: 0.003736678743734956\n",
      "Epoch: 420, Avg. Train Loss: 0.003450597988354952, Avg. Test Loss: 0.0036569538060575724\n",
      "Epoch: 421, Avg. Train Loss: 0.0034584718983793673, Avg. Test Loss: 0.003755833487957716\n",
      "Epoch: 422, Avg. Train Loss: 0.00346763736330146, Avg. Test Loss: 0.00366400764323771\n",
      "Epoch: 423, Avg. Train Loss: 0.003429338633797543, Avg. Test Loss: 0.0037746618036180735\n",
      "Epoch: 424, Avg. Train Loss: 0.0034785007971317268, Avg. Test Loss: 0.003671174868941307\n",
      "Epoch: 425, Avg. Train Loss: 0.0034282968628631776, Avg. Test Loss: 0.003748540300875902\n",
      "Epoch: 426, Avg. Train Loss: 0.0034556375805635093, Avg. Test Loss: 0.003765726462006569\n",
      "Epoch: 427, Avg. Train Loss: 0.003469536579105743, Avg. Test Loss: 0.003661429975181818\n",
      "Epoch: 428, Avg. Train Loss: 0.003426652791541676, Avg. Test Loss: 0.003656527493149042\n",
      "Epoch: 429, Avg. Train Loss: 0.0034207385899715646, Avg. Test Loss: 0.0036312544252723455\n",
      "Epoch: 430, Avg. Train Loss: 0.0034097648539775332, Avg. Test Loss: 0.003629035782068968\n",
      "Epoch: 431, Avg. Train Loss: 0.003415670289203178, Avg. Test Loss: 0.003642932279035449\n",
      "Epoch: 432, Avg. Train Loss: 0.0034064359768012234, Avg. Test Loss: 0.0036203358322381973\n",
      "Epoch: 433, Avg. Train Loss: 0.003400512256248053, Avg. Test Loss: 0.0037081739865243435\n",
      "Epoch: 434, Avg. Train Loss: 0.003408813664992881, Avg. Test Loss: 0.003643137402832508\n",
      "Epoch: 435, Avg. Train Loss: 0.003408747649383406, Avg. Test Loss: 0.003620963543653488\n",
      "Epoch: 436, Avg. Train Loss: 0.00342338566321793, Avg. Test Loss: 0.0036144203040748835\n",
      "Epoch: 437, Avg. Train Loss: 0.0034053540290441622, Avg. Test Loss: 0.0036485439632087946\n",
      "Epoch: 438, Avg. Train Loss: 0.0033856185727081326, Avg. Test Loss: 0.0035980879329144955\n",
      "Epoch: 439, Avg. Train Loss: 0.003435357825743944, Avg. Test Loss: 0.0036560758017003536\n",
      "Epoch: 440, Avg. Train Loss: 0.0034353449821558804, Avg. Test Loss: 0.00359649327583611\n",
      "Epoch: 441, Avg. Train Loss: 0.003384908883247611, Avg. Test Loss: 0.0036428950261324644\n",
      "Epoch: 442, Avg. Train Loss: 0.003400647086849393, Avg. Test Loss: 0.003613298060372472\n",
      "Epoch: 443, Avg. Train Loss: 0.0033902149528351635, Avg. Test Loss: 0.003609697800129652\n",
      "Epoch: 444, Avg. Train Loss: 0.0033762470580810723, Avg. Test Loss: 0.0035823427606374025\n",
      "Epoch: 445, Avg. Train Loss: 0.0033727333296177, Avg. Test Loss: 0.003592696040868759\n",
      "Epoch: 446, Avg. Train Loss: 0.0033930427676369976, Avg. Test Loss: 0.0037113488651812077\n",
      "Epoch: 447, Avg. Train Loss: 0.003374353376065576, Avg. Test Loss: 0.0035800819750875235\n",
      "Epoch: 448, Avg. Train Loss: 0.0033670569185254187, Avg. Test Loss: 0.003590527456253767\n",
      "Epoch: 449, Avg. Train Loss: 0.0033465477876191917, Avg. Test Loss: 0.0035693557001650333\n",
      "Epoch: 450, Avg. Train Loss: 0.003354450357471441, Avg. Test Loss: 0.0035745203495025635\n",
      "Epoch: 451, Avg. Train Loss: 0.0033693756897349, Avg. Test Loss: 0.00356128066778183\n",
      "Epoch: 452, Avg. Train Loss: 0.003339023740832196, Avg. Test Loss: 0.0035611072089523077\n",
      "Epoch: 453, Avg. Train Loss: 0.0033435101599194285, Avg. Test Loss: 0.0035759792663156986\n",
      "Epoch: 454, Avg. Train Loss: 0.0033510506456327993, Avg. Test Loss: 0.0036003838758915663\n",
      "Epoch: 455, Avg. Train Loss: 0.0033415254790249258, Avg. Test Loss: 0.0035795995499938726\n",
      "Epoch: 456, Avg. Train Loss: 0.003341663109008656, Avg. Test Loss: 0.0035658434499055147\n",
      "Epoch: 457, Avg. Train Loss: 0.0033574131653145993, Avg. Test Loss: 0.003610361134633422\n",
      "Epoch: 458, Avg. Train Loss: 0.003365405878528606, Avg. Test Loss: 0.003553751390427351\n",
      "Epoch: 459, Avg. Train Loss: 0.0033515969204694724, Avg. Test Loss: 0.0035567290615290403\n",
      "Epoch: 460, Avg. Train Loss: 0.003329036020955374, Avg. Test Loss: 0.0035774356219917536\n",
      "Epoch: 461, Avg. Train Loss: 0.0033397443570889708, Avg. Test Loss: 0.0035310296807438135\n",
      "Epoch: 462, Avg. Train Loss: 0.0033480101860626495, Avg. Test Loss: 0.003613171400502324\n",
      "Epoch: 463, Avg. Train Loss: 0.0033459899524703276, Avg. Test Loss: 0.0037461775355041027\n",
      "Epoch: 464, Avg. Train Loss: 0.003337506816700794, Avg. Test Loss: 0.0035419927444308996\n",
      "Epoch: 465, Avg. Train Loss: 0.0033277565949098313, Avg. Test Loss: 0.0035190049093216658\n",
      "Epoch: 466, Avg. Train Loss: 0.0033157086378873086, Avg. Test Loss: 0.0035201061982661486\n",
      "Epoch: 467, Avg. Train Loss: 0.003324544755741954, Avg. Test Loss: 0.0035175285302102566\n",
      "Epoch: 468, Avg. Train Loss: 0.0033074034659495185, Avg. Test Loss: 0.0035295819398015738\n",
      "Epoch: 469, Avg. Train Loss: 0.003334510892759575, Avg. Test Loss: 0.0035190784838050604\n",
      "Epoch: 470, Avg. Train Loss: 0.003312603494715552, Avg. Test Loss: 0.003531781490892172\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 471, Avg. Train Loss: 0.0033106522547990775, Avg. Test Loss: 0.0035600161645561457\n",
      "Epoch: 472, Avg. Train Loss: 0.00332518570060127, Avg. Test Loss: 0.0035311169922351837\n",
      "Epoch: 473, Avg. Train Loss: 0.003303807120510312, Avg. Test Loss: 0.0035054998006671667\n",
      "Epoch: 474, Avg. Train Loss: 0.003321341856187859, Avg. Test Loss: 0.003494028002023697\n",
      "Epoch: 475, Avg. Train Loss: 0.003294838744020739, Avg. Test Loss: 0.0035081924870610237\n",
      "Epoch: 476, Avg. Train Loss: 0.003290459492005581, Avg. Test Loss: 0.0034985512029379606\n",
      "Epoch: 477, Avg. Train Loss: 0.0032836523361850617, Avg. Test Loss: 0.0034947937820106745\n",
      "Epoch: 478, Avg. Train Loss: 0.0033091905061155558, Avg. Test Loss: 0.0035890615545213223\n",
      "Epoch: 479, Avg. Train Loss: 0.003316303574328506, Avg. Test Loss: 0.0035256724804639816\n",
      "Epoch: 480, Avg. Train Loss: 0.0032933625381786464, Avg. Test Loss: 0.003699267515912652\n",
      "Epoch: 481, Avg. Train Loss: 0.0032916201906668585, Avg. Test Loss: 0.00354763213545084\n",
      "Epoch: 482, Avg. Train Loss: 0.0032711545232856688, Avg. Test Loss: 0.0034874642733484507\n",
      "Epoch: 483, Avg. Train Loss: 0.0032779556688267825, Avg. Test Loss: 0.0035106814466416836\n",
      "Epoch: 484, Avg. Train Loss: 0.003284995379142983, Avg. Test Loss: 0.003485551569610834\n",
      "Epoch: 485, Avg. Train Loss: 0.003267529962021251, Avg. Test Loss: 0.0034801147412508726\n",
      "Epoch: 486, Avg. Train Loss: 0.003266212232627494, Avg. Test Loss: 0.003508141729980707\n",
      "Epoch: 487, Avg. Train Loss: 0.00326324118907715, Avg. Test Loss: 0.0034950675908476114\n",
      "Epoch: 488, Avg. Train Loss: 0.0032715450669097345, Avg. Test Loss: 0.0034743323922157288\n",
      "Epoch: 489, Avg. Train Loss: 0.003273144640504967, Avg. Test Loss: 0.0034859345760196447\n",
      "Epoch: 490, Avg. Train Loss: 0.00326601043343544, Avg. Test Loss: 0.003495601238682866\n",
      "Epoch: 491, Avg. Train Loss: 0.0032569526662227025, Avg. Test Loss: 0.0034944668877869844\n",
      "Epoch: 492, Avg. Train Loss: 0.0032561935354457343, Avg. Test Loss: 0.0034707814920693636\n",
      "Epoch: 493, Avg. Train Loss: 0.0032484913732163433, Avg. Test Loss: 0.003531606402248144\n",
      "Epoch: 494, Avg. Train Loss: 0.003275552342190992, Avg. Test Loss: 0.003474355209618807\n",
      "Epoch: 495, Avg. Train Loss: 0.0032615763849990313, Avg. Test Loss: 0.0035982849076390266\n",
      "Epoch: 496, Avg. Train Loss: 0.0032733339859649193, Avg. Test Loss: 0.0034543767105787992\n",
      "Epoch: 497, Avg. Train Loss: 0.003258826492657495, Avg. Test Loss: 0.0034439745359122753\n",
      "Epoch: 498, Avg. Train Loss: 0.0032522224734515643, Avg. Test Loss: 0.0034538214094936848\n",
      "Epoch: 499, Avg. Train Loss: 0.003266650576924169, Avg. Test Loss: 0.003444178495556116\n",
      "Epoch: 500, Avg. Train Loss: 0.0032484590963915336, Avg. Test Loss: 0.0034867017529904842\n",
      "Epoch: 501, Avg. Train Loss: 0.003231317741623105, Avg. Test Loss: 0.003460214240476489\n",
      "Epoch: 502, Avg. Train Loss: 0.0032404986004410095, Avg. Test Loss: 0.003511217422783375\n",
      "Epoch: 503, Avg. Train Loss: 0.003259948460211934, Avg. Test Loss: 0.0034332529176026583\n",
      "Epoch: 504, Avg. Train Loss: 0.003229001656088025, Avg. Test Loss: 0.003443928901106119\n",
      "Epoch: 505, Avg. Train Loss: 0.0032281078409057023, Avg. Test Loss: 0.003479697508737445\n",
      "Epoch: 506, Avg. Train Loss: 0.0032360064363930116, Avg. Test Loss: 0.0034389656502753496\n",
      "Epoch: 507, Avg. Train Loss: 0.0032322033806595693, Avg. Test Loss: 0.0035093771293759346\n",
      "Epoch: 508, Avg. Train Loss: 0.0032139576451722966, Avg. Test Loss: 0.0034449936356395483\n",
      "Epoch: 509, Avg. Train Loss: 0.0032282941758112853, Avg. Test Loss: 0.0034226307179778814\n",
      "Epoch: 510, Avg. Train Loss: 0.003230719393942245, Avg. Test Loss: 0.0034285367000848055\n",
      "Epoch: 511, Avg. Train Loss: 0.0032069816167444682, Avg. Test Loss: 0.003430507844313979\n",
      "Epoch: 512, Avg. Train Loss: 0.0031999412945709948, Avg. Test Loss: 0.00343165616504848\n",
      "Epoch: 513, Avg. Train Loss: 0.003215913173504347, Avg. Test Loss: 0.003412425285205245\n",
      "Epoch: 514, Avg. Train Loss: 0.003265881818870819, Avg. Test Loss: 0.0034269692841917276\n",
      "Epoch: 515, Avg. Train Loss: 0.0032008303448471218, Avg. Test Loss: 0.003436706494539976\n",
      "Epoch: 516, Avg. Train Loss: 0.003191337108525426, Avg. Test Loss: 0.0034063966013491154\n",
      "Epoch: 517, Avg. Train Loss: 0.0031954479717844447, Avg. Test Loss: 0.003396339248865843\n",
      "Epoch: 518, Avg. Train Loss: 0.0032155033320101886, Avg. Test Loss: 0.0036701338831335306\n",
      "Epoch: 519, Avg. Train Loss: 0.00321182981133461, Avg. Test Loss: 0.003438438754528761\n",
      "Epoch: 520, Avg. Train Loss: 0.0032031783606683794, Avg. Test Loss: 0.0034001662861555815\n",
      "Epoch: 521, Avg. Train Loss: 0.003186873945429228, Avg. Test Loss: 0.003406524658203125\n",
      "Epoch: 522, Avg. Train Loss: 0.0032049772264652475, Avg. Test Loss: 0.0033832003828138113\n",
      "Epoch: 523, Avg. Train Loss: 0.003186785675541953, Avg. Test Loss: 0.003395872190594673\n",
      "Epoch: 524, Avg. Train Loss: 0.0032111501353684554, Avg. Test Loss: 0.003382269758731127\n",
      "Epoch: 525, Avg. Train Loss: 0.003174531874571775, Avg. Test Loss: 0.0034238046500831842\n",
      "Epoch: 526, Avg. Train Loss: 0.003186893616911284, Avg. Test Loss: 0.003459543688222766\n",
      "Epoch: 527, Avg. Train Loss: 0.003199024190909641, Avg. Test Loss: 0.0034216870553791523\n",
      "Epoch: 528, Avg. Train Loss: 0.0032053125296654396, Avg. Test Loss: 0.003420434892177582\n",
      "Epoch: 529, Avg. Train Loss: 0.003181328352670683, Avg. Test Loss: 0.0033848106395453215\n",
      "Epoch: 530, Avg. Train Loss: 0.0032015030954552944, Avg. Test Loss: 0.003434406826272607\n",
      "Epoch: 531, Avg. Train Loss: 0.0031951923074937144, Avg. Test Loss: 0.0033759181387722492\n",
      "Epoch: 532, Avg. Train Loss: 0.0031858208415986495, Avg. Test Loss: 0.003395632840692997\n",
      "Epoch: 533, Avg. Train Loss: 0.0031683052846685398, Avg. Test Loss: 0.0033919615671038628\n",
      "Epoch: 534, Avg. Train Loss: 0.003175816563672798, Avg. Test Loss: 0.003427153220400214\n",
      "Epoch: 535, Avg. Train Loss: 0.003154364733978413, Avg. Test Loss: 0.0034091444686055183\n",
      "Epoch: 536, Avg. Train Loss: 0.0031739017698740545, Avg. Test Loss: 0.0033922609873116016\n",
      "Epoch: 537, Avg. Train Loss: 0.003213221965314344, Avg. Test Loss: 0.003525681560859084\n",
      "Epoch: 538, Avg. Train Loss: 0.003198410985384916, Avg. Test Loss: 0.0034238528460264206\n",
      "Epoch: 539, Avg. Train Loss: 0.003162961431540722, Avg. Test Loss: 0.003382426919415593\n",
      "Epoch: 540, Avg. Train Loss: 0.0031540271241304488, Avg. Test Loss: 0.0033474708907306194\n",
      "Epoch: 541, Avg. Train Loss: 0.0031524555930911107, Avg. Test Loss: 0.0033519635908305645\n",
      "Epoch: 542, Avg. Train Loss: 0.0031797314918231828, Avg. Test Loss: 0.0033609801903367043\n",
      "Epoch: 543, Avg. Train Loss: 0.0031446622316400673, Avg. Test Loss: 0.003388187848031521\n",
      "Epoch: 544, Avg. Train Loss: 0.003151800304781212, Avg. Test Loss: 0.00338505650870502\n",
      "Epoch: 545, Avg. Train Loss: 0.00314598721668644, Avg. Test Loss: 0.0033577904105186462\n",
      "Epoch: 546, Avg. Train Loss: 0.003169572007907338, Avg. Test Loss: 0.003343849442899227\n",
      "Epoch: 547, Avg. Train Loss: 0.0031784340511834207, Avg. Test Loss: 0.003352036001160741\n",
      "Epoch: 548, Avg. Train Loss: 0.003140651886243113, Avg. Test Loss: 0.0033387313596904278\n",
      "Epoch: 549, Avg. Train Loss: 0.003127903623376475, Avg. Test Loss: 0.0033468264155089855\n",
      "Epoch: 550, Avg. Train Loss: 0.003147105112411948, Avg. Test Loss: 0.0033606814686208963\n",
      "Epoch: 551, Avg. Train Loss: 0.0031365236906378074, Avg. Test Loss: 0.0033897256944328547\n",
      "Epoch: 552, Avg. Train Loss: 0.003156171922117125, Avg. Test Loss: 0.003476585727185011\n",
      "Epoch: 553, Avg. Train Loss: 0.003154180895233917, Avg. Test Loss: 0.003341889474540949\n",
      "Epoch: 554, Avg. Train Loss: 0.0031514859455096167, Avg. Test Loss: 0.0033778701908886433\n",
      "Epoch: 555, Avg. Train Loss: 0.0031363161139969908, Avg. Test Loss: 0.0033258511684834957\n",
      "Epoch: 556, Avg. Train Loss: 0.003121735403574137, Avg. Test Loss: 0.0033854905050247908\n",
      "Epoch: 557, Avg. Train Loss: 0.0031442694030268943, Avg. Test Loss: 0.00343351811170578\n",
      "Epoch: 558, Avg. Train Loss: 0.003154425139993776, Avg. Test Loss: 0.003464940469712019\n",
      "Epoch: 559, Avg. Train Loss: 0.003148182316921478, Avg. Test Loss: 0.0033877836540341377\n",
      "Epoch: 560, Avg. Train Loss: 0.003128165292531945, Avg. Test Loss: 0.003397224936634302\n",
      "Epoch: 561, Avg. Train Loss: 0.003138461637548929, Avg. Test Loss: 0.0033433702774345875\n",
      "Epoch: 562, Avg. Train Loss: 0.0031157751123659138, Avg. Test Loss: 0.00332829961553216\n",
      "Epoch: 563, Avg. Train Loss: 0.003121823781754735, Avg. Test Loss: 0.003401406342163682\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 564, Avg. Train Loss: 0.0031763147237862267, Avg. Test Loss: 0.0033639399334788322\n",
      "Epoch: 565, Avg. Train Loss: 0.003123631386822739, Avg. Test Loss: 0.0033770340960472822\n",
      "Epoch: 566, Avg. Train Loss: 0.003122076435491096, Avg. Test Loss: 0.003331830259412527\n",
      "Epoch: 567, Avg. Train Loss: 0.003128718996290551, Avg. Test Loss: 0.0033196010626852512\n",
      "Epoch: 568, Avg. Train Loss: 0.0031147073185461205, Avg. Test Loss: 0.003304810030385852\n",
      "Epoch: 569, Avg. Train Loss: 0.0031111751206565736, Avg. Test Loss: 0.003429518546909094\n",
      "Epoch: 570, Avg. Train Loss: 0.0031090485755094262, Avg. Test Loss: 0.003308061044663191\n",
      "Epoch: 571, Avg. Train Loss: 0.0031007915561975436, Avg. Test Loss: 0.0033630600664764643\n",
      "Epoch: 572, Avg. Train Loss: 0.0031306206703532575, Avg. Test Loss: 0.0033182899933308363\n",
      "Epoch: 573, Avg. Train Loss: 0.0031084283742360596, Avg. Test Loss: 0.00329866586253047\n",
      "Epoch: 574, Avg. Train Loss: 0.0031024435221022645, Avg. Test Loss: 0.003520980942994356\n",
      "Epoch: 575, Avg. Train Loss: 0.003163596647683271, Avg. Test Loss: 0.0033180739264935255\n",
      "Epoch: 576, Avg. Train Loss: 0.003152586882500801, Avg. Test Loss: 0.003317186376079917\n",
      "Epoch: 577, Avg. Train Loss: 0.003106395291641008, Avg. Test Loss: 0.0032964199781417847\n",
      "Epoch: 578, Avg. Train Loss: 0.003101181287621689, Avg. Test Loss: 0.0033399038948118687\n",
      "Epoch: 579, Avg. Train Loss: 0.0031107705476325614, Avg. Test Loss: 0.003326832316815853\n",
      "Epoch: 580, Avg. Train Loss: 0.0031047737507452797, Avg. Test Loss: 0.0033047774340957403\n",
      "Epoch: 581, Avg. Train Loss: 0.0031088393907127685, Avg. Test Loss: 0.0033204189967364073\n",
      "Epoch: 582, Avg. Train Loss: 0.0030850485931042324, Avg. Test Loss: 0.0033145698253065348\n",
      "Epoch: 583, Avg. Train Loss: 0.0030943797576392807, Avg. Test Loss: 0.0032997047528624535\n",
      "Epoch: 584, Avg. Train Loss: 0.00310268696007687, Avg. Test Loss: 0.003280278528109193\n",
      "Epoch: 585, Avg. Train Loss: 0.003100730879448874, Avg. Test Loss: 0.0033680421765893698\n",
      "Epoch: 586, Avg. Train Loss: 0.003106817841356577, Avg. Test Loss: 0.0032832275610417128\n",
      "Epoch: 587, Avg. Train Loss: 0.0030882000804034085, Avg. Test Loss: 0.0032789157703518867\n",
      "Epoch: 588, Avg. Train Loss: 0.0031057468041517707, Avg. Test Loss: 0.0033824380952864885\n",
      "Epoch: 589, Avg. Train Loss: 0.0030967956571298283, Avg. Test Loss: 0.0032738102599978447\n",
      "Epoch: 590, Avg. Train Loss: 0.003069219688430082, Avg. Test Loss: 0.0032695187255740166\n",
      "Epoch: 591, Avg. Train Loss: 0.0030676151820740035, Avg. Test Loss: 0.0032930325251072645\n",
      "Epoch: 592, Avg. Train Loss: 0.0031114911530600036, Avg. Test Loss: 0.003314377274364233\n",
      "Epoch: 593, Avg. Train Loss: 0.003104816477875723, Avg. Test Loss: 0.0035162377171218395\n",
      "Epoch: 594, Avg. Train Loss: 0.0031168671097433153, Avg. Test Loss: 0.003278230782598257\n",
      "Epoch: 595, Avg. Train Loss: 0.003104552789049786, Avg. Test Loss: 0.0034004414919763803\n",
      "Epoch: 596, Avg. Train Loss: 0.0031110908576222353, Avg. Test Loss: 0.003293073270469904\n",
      "Epoch: 597, Avg. Train Loss: 0.003098015538091923, Avg. Test Loss: 0.003292229026556015\n",
      "Epoch: 598, Avg. Train Loss: 0.003071817823923951, Avg. Test Loss: 0.0032750156242400408\n",
      "Epoch: 599, Avg. Train Loss: 0.003076731552218282, Avg. Test Loss: 0.0032721434254199266\n",
      "Epoch: 600, Avg. Train Loss: 0.0030891597920725514, Avg. Test Loss: 0.003277385141700506\n",
      "Epoch: 601, Avg. Train Loss: 0.0030568743416996198, Avg. Test Loss: 0.0032790040131658316\n",
      "Epoch: 602, Avg. Train Loss: 0.0030792804142503543, Avg. Test Loss: 0.0032602555584162474\n",
      "Epoch: 603, Avg. Train Loss: 0.0030714964039277198, Avg. Test Loss: 0.003268307540565729\n",
      "Epoch: 604, Avg. Train Loss: 0.003076271722526398, Avg. Test Loss: 0.0033439684193581343\n",
      "Epoch: 605, Avg. Train Loss: 0.0030645284379377615, Avg. Test Loss: 0.003304715733975172\n",
      "Epoch: 606, Avg. Train Loss: 0.003063569359784556, Avg. Test Loss: 0.0033284700475633144\n",
      "Epoch: 607, Avg. Train Loss: 0.0031161599868345397, Avg. Test Loss: 0.003488070797175169\n",
      "Epoch: 608, Avg. Train Loss: 0.003074307124628577, Avg. Test Loss: 0.003341319039463997\n",
      "Epoch: 609, Avg. Train Loss: 0.003079139519222947, Avg. Test Loss: 0.0033161567989736795\n",
      "Epoch: 610, Avg. Train Loss: 0.0030628237548435844, Avg. Test Loss: 0.003288506530225277\n",
      "Epoch: 611, Avg. Train Loss: 0.003077761979427102, Avg. Test Loss: 0.0033526644110679626\n",
      "Epoch: 612, Avg. Train Loss: 0.003072309887123316, Avg. Test Loss: 0.003270108252763748\n",
      "Epoch: 613, Avg. Train Loss: 0.003059572810956905, Avg. Test Loss: 0.0032640292774885893\n",
      "Epoch: 614, Avg. Train Loss: 0.0030446398710875316, Avg. Test Loss: 0.0033202962949872017\n",
      "Epoch: 615, Avg. Train Loss: 0.0030406157182919424, Avg. Test Loss: 0.003239912912249565\n",
      "Epoch: 616, Avg. Train Loss: 0.003084564007558795, Avg. Test Loss: 0.0033013042993843555\n",
      "Epoch: 617, Avg. Train Loss: 0.00305118054411439, Avg. Test Loss: 0.0032839314080774784\n",
      "Epoch: 618, Avg. Train Loss: 0.0030544342982127917, Avg. Test Loss: 0.0032409927807748318\n",
      "Epoch: 619, Avg. Train Loss: 0.003040473783648638, Avg. Test Loss: 0.0032350742258131504\n",
      "Epoch: 620, Avg. Train Loss: 0.003055959560930036, Avg. Test Loss: 0.0033824278507381678\n",
      "Epoch: 621, Avg. Train Loss: 0.003062622480874145, Avg. Test Loss: 0.0032922127284109592\n",
      "Epoch: 622, Avg. Train Loss: 0.003047961893296519, Avg. Test Loss: 0.0032315102871507406\n",
      "Epoch: 623, Avg. Train Loss: 0.0030419057787417674, Avg. Test Loss: 0.0032465204130858183\n",
      "Epoch: 624, Avg. Train Loss: 0.0030486753351206698, Avg. Test Loss: 0.003270054468885064\n",
      "Epoch: 625, Avg. Train Loss: 0.003063479016080152, Avg. Test Loss: 0.003263839753344655\n",
      "Epoch: 626, Avg. Train Loss: 0.0030637205643362776, Avg. Test Loss: 0.003232229733839631\n",
      "Epoch: 627, Avg. Train Loss: 0.0030533054486176995, Avg. Test Loss: 0.0032794158905744553\n",
      "Epoch: 628, Avg. Train Loss: 0.003023640956556381, Avg. Test Loss: 0.0032343789935112\n",
      "Epoch: 629, Avg. Train Loss: 0.003034326778508203, Avg. Test Loss: 0.003288957057520747\n",
      "Epoch: 630, Avg. Train Loss: 0.0030470927094304284, Avg. Test Loss: 0.00322649790905416\n",
      "Epoch: 631, Avg. Train Loss: 0.003065192254346817, Avg. Test Loss: 0.0032960723619908094\n",
      "Epoch: 632, Avg. Train Loss: 0.0030248045466493728, Avg. Test Loss: 0.003221088321879506\n",
      "Epoch: 633, Avg. Train Loss: 0.0030404890854951253, Avg. Test Loss: 0.0032247225753962994\n",
      "Epoch: 634, Avg. Train Loss: 0.003018695433342526, Avg. Test Loss: 0.003282200777903199\n",
      "Epoch: 635, Avg. Train Loss: 0.003042297318664401, Avg. Test Loss: 0.003215204458683729\n",
      "Epoch: 636, Avg. Train Loss: 0.003022979511771091, Avg. Test Loss: 0.0032240606378763914\n",
      "Epoch: 637, Avg. Train Loss: 0.0030266458363553813, Avg. Test Loss: 0.003307387698441744\n",
      "Epoch: 638, Avg. Train Loss: 0.0030460100685961024, Avg. Test Loss: 0.003221851075068116\n",
      "Epoch: 639, Avg. Train Loss: 0.0030774499105592798, Avg. Test Loss: 0.0032234471291303635\n",
      "Epoch: 640, Avg. Train Loss: 0.003041294641619505, Avg. Test Loss: 0.003222409402951598\n",
      "Epoch: 641, Avg. Train Loss: 0.00301054755204119, Avg. Test Loss: 0.0032260825391858816\n",
      "Epoch: 642, Avg. Train Loss: 0.0030159609294821356, Avg. Test Loss: 0.0032677750568836927\n",
      "Epoch: 643, Avg. Train Loss: 0.003037947354578348, Avg. Test Loss: 0.003208617214113474\n",
      "Epoch: 644, Avg. Train Loss: 0.0030268352034739975, Avg. Test Loss: 0.003237929427996278\n",
      "Epoch: 645, Avg. Train Loss: 0.0030256909004217664, Avg. Test Loss: 0.0032798806205391884\n",
      "Epoch: 646, Avg. Train Loss: 0.0030247788378145804, Avg. Test Loss: 0.0032388728577643633\n",
      "Epoch: 647, Avg. Train Loss: 0.0030302579763756936, Avg. Test Loss: 0.0032928590662777424\n",
      "Epoch: 648, Avg. Train Loss: 0.0030505513978125744, Avg. Test Loss: 0.0032277973368763924\n",
      "Epoch: 649, Avg. Train Loss: 0.003011834851011287, Avg. Test Loss: 0.0032084034755825996\n",
      "Epoch: 650, Avg. Train Loss: 0.003021011719220253, Avg. Test Loss: 0.0032066151034086943\n",
      "Epoch: 651, Avg. Train Loss: 0.0030133905441521907, Avg. Test Loss: 0.003270227462053299\n",
      "Epoch: 652, Avg. Train Loss: 0.0030372399338629355, Avg. Test Loss: 0.0032072127796709538\n",
      "Epoch: 653, Avg. Train Loss: 0.0030154919111018263, Avg. Test Loss: 0.003202092368155718\n",
      "Epoch: 654, Avg. Train Loss: 0.0030170305155564187, Avg. Test Loss: 0.003344675526022911\n",
      "Epoch: 655, Avg. Train Loss: 0.0030274138255261406, Avg. Test Loss: 0.0032664150930941105\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 656, Avg. Train Loss: 0.0030219683499443668, Avg. Test Loss: 0.003191576572135091\n",
      "Epoch: 657, Avg. Train Loss: 0.0030031612922632417, Avg. Test Loss: 0.0032003470696508884\n",
      "Epoch: 658, Avg. Train Loss: 0.0030280953370641138, Avg. Test Loss: 0.0032112428452819586\n",
      "Epoch: 659, Avg. Train Loss: 0.003016875482835742, Avg. Test Loss: 0.00357709638774395\n",
      "Epoch: 660, Avg. Train Loss: 0.003065376650801925, Avg. Test Loss: 0.0032291861716657877\n",
      "Epoch: 661, Avg. Train Loss: 0.0030048263020986733, Avg. Test Loss: 0.0032125485595315695\n",
      "Epoch: 662, Avg. Train Loss: 0.0030307976128316895, Avg. Test Loss: 0.003275137161836028\n",
      "Epoch: 663, Avg. Train Loss: 0.003033767838767448, Avg. Test Loss: 0.003223783103749156\n",
      "Epoch: 664, Avg. Train Loss: 0.0030027914380784644, Avg. Test Loss: 0.003182138316333294\n",
      "Epoch: 665, Avg. Train Loss: 0.002995222476635908, Avg. Test Loss: 0.003196414327248931\n",
      "Epoch: 666, Avg. Train Loss: 0.002994950590005448, Avg. Test Loss: 0.0031819024588912725\n",
      "Epoch: 667, Avg. Train Loss: 0.0029963672182760958, Avg. Test Loss: 0.0032346458174288273\n",
      "Epoch: 668, Avg. Train Loss: 0.002997504920850313, Avg. Test Loss: 0.003208902897313237\n",
      "Epoch: 669, Avg. Train Loss: 0.0029887985059081816, Avg. Test Loss: 0.003187541849911213\n",
      "Epoch: 670, Avg. Train Loss: 0.00299127061504784, Avg. Test Loss: 0.003177195554599166\n",
      "Epoch: 671, Avg. Train Loss: 0.0030209592727641035, Avg. Test Loss: 0.0032029468566179276\n",
      "Epoch: 672, Avg. Train Loss: 0.002981212212119338, Avg. Test Loss: 0.0031816791743040085\n",
      "Epoch: 673, Avg. Train Loss: 0.002987076436321056, Avg. Test Loss: 0.003228295361623168\n",
      "Epoch: 674, Avg. Train Loss: 0.003023739216502669, Avg. Test Loss: 0.0032521095126867294\n",
      "Epoch: 675, Avg. Train Loss: 0.0030263155742093575, Avg. Test Loss: 0.003179736901074648\n",
      "Epoch: 676, Avg. Train Loss: 0.0030316476720970036, Avg. Test Loss: 0.0032088481821119785\n",
      "Epoch: 677, Avg. Train Loss: 0.0030131234495012565, Avg. Test Loss: 0.003189696930348873\n",
      "Epoch: 678, Avg. Train Loss: 0.0029971683668622443, Avg. Test Loss: 0.0032362928614020348\n",
      "Epoch: 679, Avg. Train Loss: 0.0030693909651491533, Avg. Test Loss: 0.003211135743185878\n",
      "Epoch: 680, Avg. Train Loss: 0.002996014295752312, Avg. Test Loss: 0.003231462324038148\n",
      "Epoch: 681, Avg. Train Loss: 0.0029817012864229984, Avg. Test Loss: 0.0031672550830990076\n",
      "Epoch: 682, Avg. Train Loss: 0.002984186152516063, Avg. Test Loss: 0.003183686640113592\n",
      "Epoch: 683, Avg. Train Loss: 0.003004248281074471, Avg. Test Loss: 0.0032661305740475655\n",
      "Epoch: 684, Avg. Train Loss: 0.003008760928804445, Avg. Test Loss: 0.0031831173691898584\n",
      "Epoch: 685, Avg. Train Loss: 0.002969405559692965, Avg. Test Loss: 0.003173402277752757\n",
      "Epoch: 686, Avg. Train Loss: 0.0029860579701097207, Avg. Test Loss: 0.0031947740353643894\n",
      "Epoch: 687, Avg. Train Loss: 0.002964766419947494, Avg. Test Loss: 0.0031859898008406162\n",
      "Epoch: 688, Avg. Train Loss: 0.002964769186841887, Avg. Test Loss: 0.0033186525106430054\n",
      "Epoch: 689, Avg. Train Loss: 0.0029824824386471232, Avg. Test Loss: 0.003175684018060565\n",
      "Epoch: 690, Avg. Train Loss: 0.002974932233608046, Avg. Test Loss: 0.0031862796749919653\n",
      "Epoch: 691, Avg. Train Loss: 0.0029778071993225535, Avg. Test Loss: 0.003275665221735835\n",
      "Epoch: 692, Avg. Train Loss: 0.0030053496349949477, Avg. Test Loss: 0.0031597150955349207\n",
      "Epoch: 693, Avg. Train Loss: 0.003009278013176003, Avg. Test Loss: 0.0031937826424837112\n",
      "Epoch: 694, Avg. Train Loss: 0.0030079401520535696, Avg. Test Loss: 0.0031958632171154022\n",
      "Epoch: 695, Avg. Train Loss: 0.0029654575695911814, Avg. Test Loss: 0.0031767564360052347\n",
      "Epoch: 696, Avg. Train Loss: 0.0029597682282761777, Avg. Test Loss: 0.0031561481300741434\n",
      "Epoch: 697, Avg. Train Loss: 0.00296364284965188, Avg. Test Loss: 0.003194889286532998\n",
      "Epoch: 698, Avg. Train Loss: 0.0029641986163982817, Avg. Test Loss: 0.003171385731548071\n",
      "Epoch: 699, Avg. Train Loss: 0.002972652789118678, Avg. Test Loss: 0.0031921088229864836\n",
      "Epoch: 700, Avg. Train Loss: 0.002969089088701578, Avg. Test Loss: 0.0031964313238859177\n",
      "Epoch: 701, Avg. Train Loss: 0.0029794428508382203, Avg. Test Loss: 0.003239082871004939\n",
      "Epoch: 702, Avg. Train Loss: 0.0029583143633465435, Avg. Test Loss: 0.0031843273900449276\n",
      "Epoch: 703, Avg. Train Loss: 0.0029752273870588737, Avg. Test Loss: 0.0031650036107748747\n",
      "Epoch: 704, Avg. Train Loss: 0.00299750289576518, Avg. Test Loss: 0.0031621798407286406\n",
      "Epoch: 705, Avg. Train Loss: 0.002961049397844215, Avg. Test Loss: 0.003209883812814951\n",
      "Epoch: 706, Avg. Train Loss: 0.0029823520318280126, Avg. Test Loss: 0.0031470453832298517\n",
      "Epoch: 707, Avg. Train Loss: 0.0029497809740606437, Avg. Test Loss: 0.0031506423838436604\n",
      "Epoch: 708, Avg. Train Loss: 0.0029656446517206904, Avg. Test Loss: 0.0032054726034402847\n",
      "Epoch: 709, Avg. Train Loss: 0.002981372713652808, Avg. Test Loss: 0.00324399140663445\n",
      "Epoch: 710, Avg. Train Loss: 0.0029753091322734606, Avg. Test Loss: 0.003161641303449869\n",
      "Epoch: 711, Avg. Train Loss: 0.0029489833016901517, Avg. Test Loss: 0.003204606007784605\n",
      "Epoch: 712, Avg. Train Loss: 0.002972484885736607, Avg. Test Loss: 0.0031437722500413656\n",
      "Epoch: 713, Avg. Train Loss: 0.00295678855374802, Avg. Test Loss: 0.003165541449561715\n",
      "Epoch: 714, Avg. Train Loss: 0.00297532738511299, Avg. Test Loss: 0.0031635889317840338\n",
      "Epoch: 715, Avg. Train Loss: 0.0029479924827640835, Avg. Test Loss: 0.0031829422805458307\n",
      "Epoch: 716, Avg. Train Loss: 0.0029567726779469224, Avg. Test Loss: 0.0031637209467589855\n",
      "Epoch: 717, Avg. Train Loss: 0.0029475016053766012, Avg. Test Loss: 0.003135144244879484\n",
      "Epoch: 718, Avg. Train Loss: 0.0029760650521534126, Avg. Test Loss: 0.00333756348118186\n",
      "Epoch: 719, Avg. Train Loss: 0.0029626063796756572, Avg. Test Loss: 0.0031563241500407457\n",
      "Epoch: 720, Avg. Train Loss: 0.002966064894788487, Avg. Test Loss: 0.0031704481225460768\n",
      "Epoch: 721, Avg. Train Loss: 0.0029645410615431016, Avg. Test Loss: 0.003161349566653371\n",
      "Epoch: 722, Avg. Train Loss: 0.0029624312531289668, Avg. Test Loss: 0.0031618496868759394\n",
      "Epoch: 723, Avg. Train Loss: 0.002953331267764402, Avg. Test Loss: 0.0032359883189201355\n",
      "Epoch: 724, Avg. Train Loss: 0.0029549074337579485, Avg. Test Loss: 0.0031509478576481342\n",
      "Epoch: 725, Avg. Train Loss: 0.0029402066856016253, Avg. Test Loss: 0.003168443450704217\n",
      "Epoch: 726, Avg. Train Loss: 0.002994752348249042, Avg. Test Loss: 0.003149134572595358\n",
      "Epoch: 727, Avg. Train Loss: 0.002953727967863859, Avg. Test Loss: 0.0031616257037967443\n",
      "Epoch: 728, Avg. Train Loss: 0.0029512824826375687, Avg. Test Loss: 0.0031565993558615446\n",
      "Epoch: 729, Avg. Train Loss: 0.0029452030796037858, Avg. Test Loss: 0.0031292454805225134\n",
      "Epoch: 730, Avg. Train Loss: 0.002943251493148679, Avg. Test Loss: 0.0031412560492753983\n",
      "Epoch: 731, Avg. Train Loss: 0.002953669776446944, Avg. Test Loss: 0.0032589815091341734\n",
      "Epoch: 732, Avg. Train Loss: 0.0029645652326127122, Avg. Test Loss: 0.00317469984292984\n",
      "Epoch: 733, Avg. Train Loss: 0.0029387901493803012, Avg. Test Loss: 0.003125980729237199\n",
      "Epoch: 734, Avg. Train Loss: 0.0029299345116542523, Avg. Test Loss: 0.0031363707967102528\n",
      "Epoch: 735, Avg. Train Loss: 0.0029861914741178583, Avg. Test Loss: 0.0031932773999869823\n",
      "Epoch: 736, Avg. Train Loss: 0.002966658629173803, Avg. Test Loss: 0.0032706218771636486\n",
      "Epoch: 737, Avg. Train Loss: 0.002961176940304942, Avg. Test Loss: 0.0031445438507944345\n",
      "Epoch: 738, Avg. Train Loss: 0.0029415767423288768, Avg. Test Loss: 0.0031266200821846724\n",
      "Epoch: 739, Avg. Train Loss: 0.002945152934380742, Avg. Test Loss: 0.003249015426263213\n",
      "Epoch: 740, Avg. Train Loss: 0.002992402881297261, Avg. Test Loss: 0.0031284047290682793\n",
      "Epoch: 741, Avg. Train Loss: 0.002942103161584846, Avg. Test Loss: 0.003132289508357644\n",
      "Epoch: 742, Avg. Train Loss: 0.002928065585492309, Avg. Test Loss: 0.0031382148154079914\n",
      "Epoch: 743, Avg. Train Loss: 0.0029198778197602475, Avg. Test Loss: 0.003137954045087099\n",
      "Epoch: 744, Avg. Train Loss: 0.002969580079797049, Avg. Test Loss: 0.003115415805950761\n",
      "Epoch: 745, Avg. Train Loss: 0.002919020358646332, Avg. Test Loss: 0.0032124556601047516\n",
      "Epoch: 746, Avg. Train Loss: 0.002967046730783443, Avg. Test Loss: 0.0031195536721497774\n",
      "Epoch: 747, Avg. Train Loss: 0.0029530011788876944, Avg. Test Loss: 0.0031525748781859875\n",
      "Epoch: 748, Avg. Train Loss: 0.0029536700796682475, Avg. Test Loss: 0.0031264035496860743\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 749, Avg. Train Loss: 0.0029375732139965824, Avg. Test Loss: 0.0031137950718402863\n",
      "Epoch: 750, Avg. Train Loss: 0.00293447699419461, Avg. Test Loss: 0.0031520065385848284\n",
      "Epoch: 751, Avg. Train Loss: 0.0029598383265439163, Avg. Test Loss: 0.0031887332443147898\n",
      "Epoch: 752, Avg. Train Loss: 0.0029505938833016294, Avg. Test Loss: 0.003155527636408806\n",
      "Epoch: 753, Avg. Train Loss: 0.0029225435086287733, Avg. Test Loss: 0.003113283310085535\n",
      "Epoch: 754, Avg. Train Loss: 0.002952955868961506, Avg. Test Loss: 0.0031468619126826525\n",
      "Epoch: 755, Avg. Train Loss: 0.002924419067756728, Avg. Test Loss: 0.003179240506142378\n",
      "Epoch: 756, Avg. Train Loss: 0.0029366352097239604, Avg. Test Loss: 0.003128417767584324\n",
      "Epoch: 757, Avg. Train Loss: 0.0029522685799747705, Avg. Test Loss: 0.003178318263962865\n",
      "Epoch: 758, Avg. Train Loss: 0.0029429161520458237, Avg. Test Loss: 0.0031130698043853045\n",
      "Epoch: 759, Avg. Train Loss: 0.002946799550595325, Avg. Test Loss: 0.003118244232609868\n",
      "Epoch: 760, Avg. Train Loss: 0.0029271780350787003, Avg. Test Loss: 0.003105540294200182\n",
      "Epoch: 761, Avg. Train Loss: 0.002943871299151418, Avg. Test Loss: 0.003115943167358637\n",
      "Epoch: 762, Avg. Train Loss: 0.0029167949254516254, Avg. Test Loss: 0.0031467352528125048\n",
      "Epoch: 763, Avg. Train Loss: 0.002973119040604594, Avg. Test Loss: 0.003169130301102996\n",
      "Epoch: 764, Avg. Train Loss: 0.0029283122397785965, Avg. Test Loss: 0.0031551693100482225\n",
      "Epoch: 765, Avg. Train Loss: 0.0029179480381656526, Avg. Test Loss: 0.003182892221957445\n",
      "Epoch: 766, Avg. Train Loss: 0.0029615244481625944, Avg. Test Loss: 0.003112499602138996\n",
      "Epoch: 767, Avg. Train Loss: 0.0029076529006192156, Avg. Test Loss: 0.0031356383115053177\n",
      "Epoch: 768, Avg. Train Loss: 0.002909766347688991, Avg. Test Loss: 0.0031015460845083\n",
      "Epoch: 769, Avg. Train Loss: 0.0029231898248368916, Avg. Test Loss: 0.0031165070831775665\n",
      "Epoch: 770, Avg. Train Loss: 0.0029251535997054604, Avg. Test Loss: 0.0031098490580916405\n",
      "Epoch: 771, Avg. Train Loss: 0.0029388441877482934, Avg. Test Loss: 0.0031460486352443695\n",
      "Epoch: 772, Avg. Train Loss: 0.0029450542845784926, Avg. Test Loss: 0.0032356258016079664\n",
      "Epoch: 773, Avg. Train Loss: 0.002948210645077187, Avg. Test Loss: 0.0031176372431218624\n",
      "Epoch: 774, Avg. Train Loss: 0.0029434778045343106, Avg. Test Loss: 0.0033030840568244457\n",
      "Epoch: 775, Avg. Train Loss: 0.002988001104270996, Avg. Test Loss: 0.0031920787878334522\n",
      "Epoch: 776, Avg. Train Loss: 0.0029110720727679343, Avg. Test Loss: 0.0031051707919687033\n",
      "Epoch: 777, Avg. Train Loss: 0.0029219726187198663, Avg. Test Loss: 0.0032235567923635244\n",
      "Epoch: 778, Avg. Train Loss: 0.002952612384200789, Avg. Test Loss: 0.003157313447445631\n",
      "Epoch: 779, Avg. Train Loss: 0.0029193483845352435, Avg. Test Loss: 0.003124878741800785\n",
      "Epoch: 780, Avg. Train Loss: 0.0028975169921597074, Avg. Test Loss: 0.0031143289525061846\n",
      "Epoch: 781, Avg. Train Loss: 0.0029247687956274943, Avg. Test Loss: 0.0031117822509258986\n",
      "Epoch: 782, Avg. Train Loss: 0.0029027315376456394, Avg. Test Loss: 0.003106781980022788\n",
      "Epoch: 783, Avg. Train Loss: 0.0029083791102261043, Avg. Test Loss: 0.003113930579274893\n",
      "Epoch: 784, Avg. Train Loss: 0.002916057236752538, Avg. Test Loss: 0.0031847681384533644\n",
      "Epoch: 785, Avg. Train Loss: 0.0029429191842588573, Avg. Test Loss: 0.003115082625299692\n",
      "Epoch: 786, Avg. Train Loss: 0.0028943882247996194, Avg. Test Loss: 0.0030901499558240175\n",
      "Epoch: 787, Avg. Train Loss: 0.002914761030656654, Avg. Test Loss: 0.003147053997963667\n",
      "Epoch: 788, Avg. Train Loss: 0.002914114557423217, Avg. Test Loss: 0.003139483043923974\n",
      "Epoch: 789, Avg. Train Loss: 0.002903247549913304, Avg. Test Loss: 0.00316795171238482\n",
      "Epoch: 790, Avg. Train Loss: 0.0028958483490833017, Avg. Test Loss: 0.003169748466461897\n",
      "Epoch: 791, Avg. Train Loss: 0.0029745241951977097, Avg. Test Loss: 0.0031132963486015797\n",
      "Epoch: 792, Avg. Train Loss: 0.0029156885900383078, Avg. Test Loss: 0.003089879872277379\n",
      "Epoch: 793, Avg. Train Loss: 0.002934585834398519, Avg. Test Loss: 0.0030984668992459774\n",
      "Epoch: 794, Avg. Train Loss: 0.0029167834950914215, Avg. Test Loss: 0.0031787361949682236\n",
      "Epoch: 795, Avg. Train Loss: 0.002944928702226905, Avg. Test Loss: 0.0031553192529827356\n",
      "Epoch: 796, Avg. Train Loss: 0.002918332820584954, Avg. Test Loss: 0.0033432189375162125\n",
      "Epoch: 797, Avg. Train Loss: 0.0029630448106069897, Avg. Test Loss: 0.003145503345876932\n",
      "Epoch: 798, Avg. Train Loss: 0.00292336534665421, Avg. Test Loss: 0.003098683198913932\n",
      "Epoch: 799, Avg. Train Loss: 0.0028990254369239475, Avg. Test Loss: 0.0030919620767235756\n",
      "Epoch: 800, Avg. Train Loss: 0.002892916854254382, Avg. Test Loss: 0.003120320849120617\n",
      "Epoch: 801, Avg. Train Loss: 0.002887840436901464, Avg. Test Loss: 0.0030931916553527117\n",
      "Epoch: 802, Avg. Train Loss: 0.002907887176978727, Avg. Test Loss: 0.0032443543896079063\n",
      "Epoch: 803, Avg. Train Loss: 0.00289491125447459, Avg. Test Loss: 0.003081951290369034\n",
      "Epoch: 804, Avg. Train Loss: 0.002890284925829186, Avg. Test Loss: 0.003154819132760167\n",
      "Epoch: 805, Avg. Train Loss: 0.0029225949317130237, Avg. Test Loss: 0.0032376989256590605\n",
      "Epoch: 806, Avg. Train Loss: 0.0029107931579008353, Avg. Test Loss: 0.0032040313817560673\n",
      "Epoch: 807, Avg. Train Loss: 0.0029074380087644553, Avg. Test Loss: 0.003073827363550663\n",
      "Epoch: 808, Avg. Train Loss: 0.002886016739445717, Avg. Test Loss: 0.003086460754275322\n",
      "Epoch: 809, Avg. Train Loss: 0.0028727334317599617, Avg. Test Loss: 0.0030859378166496754\n",
      "Epoch: 810, Avg. Train Loss: 0.002916089567724009, Avg. Test Loss: 0.0031470146495848894\n",
      "Epoch: 811, Avg. Train Loss: 0.0028903214964842382, Avg. Test Loss: 0.0030914766248315573\n",
      "Epoch: 812, Avg. Train Loss: 0.0029016501855018526, Avg. Test Loss: 0.003068410325795412\n",
      "Epoch: 813, Avg. Train Loss: 0.0028781880472981652, Avg. Test Loss: 0.00307285925373435\n",
      "Epoch: 814, Avg. Train Loss: 0.002896712627261877, Avg. Test Loss: 0.0031059023458510637\n",
      "Epoch: 815, Avg. Train Loss: 0.00290030017386862, Avg. Test Loss: 0.0030792774632573128\n",
      "Epoch: 816, Avg. Train Loss: 0.002946309674921077, Avg. Test Loss: 0.00314948707818985\n",
      "Epoch: 817, Avg. Train Loss: 0.0028868876126876405, Avg. Test Loss: 0.00318408221937716\n",
      "Epoch: 818, Avg. Train Loss: 0.0029360758043219183, Avg. Test Loss: 0.0030790683813393116\n",
      "Epoch: 819, Avg. Train Loss: 0.002891409833547334, Avg. Test Loss: 0.0031225509010255337\n",
      "Epoch: 820, Avg. Train Loss: 0.0028927064728165087, Avg. Test Loss: 0.003111931262537837\n",
      "Epoch: 821, Avg. Train Loss: 0.0028815288746426274, Avg. Test Loss: 0.0030632137786597013\n",
      "Epoch: 822, Avg. Train Loss: 0.002871778409191689, Avg. Test Loss: 0.0031069281976670027\n",
      "Epoch: 823, Avg. Train Loss: 0.0028748637834173996, Avg. Test Loss: 0.003061202121898532\n",
      "Epoch: 824, Avg. Train Loss: 0.002881465750464866, Avg. Test Loss: 0.003064387943595648\n",
      "Epoch: 825, Avg. Train Loss: 0.002894275345254776, Avg. Test Loss: 0.00315601727925241\n",
      "Epoch: 826, Avg. Train Loss: 0.0028737267468471168, Avg. Test Loss: 0.0030925110913813114\n",
      "Epoch: 827, Avg. Train Loss: 0.002878029159335203, Avg. Test Loss: 0.0030880167614668608\n",
      "Epoch: 828, Avg. Train Loss: 0.002895874020015431, Avg. Test Loss: 0.003062386531382799\n",
      "Epoch: 829, Avg. Train Loss: 0.0028860208112746477, Avg. Test Loss: 0.0030686657410115004\n",
      "Epoch: 830, Avg. Train Loss: 0.0028836588797614324, Avg. Test Loss: 0.0030607806984335184\n",
      "Epoch: 831, Avg. Train Loss: 0.00288689928670782, Avg. Test Loss: 0.0030612137634307146\n",
      "Epoch: 832, Avg. Train Loss: 0.002866174013158956, Avg. Test Loss: 0.0030505440663546324\n",
      "Epoch: 833, Avg. Train Loss: 0.0028672309668171542, Avg. Test Loss: 0.0030490930657833815\n",
      "Epoch: 834, Avg. Train Loss: 0.002873177862141368, Avg. Test Loss: 0.0030523627065122128\n",
      "Epoch: 835, Avg. Train Loss: 0.002891900229029531, Avg. Test Loss: 0.003085093107074499\n",
      "Epoch: 836, Avg. Train Loss: 0.00288353294004188, Avg. Test Loss: 0.003073819912970066\n",
      "Epoch: 837, Avg. Train Loss: 0.0028761109867847935, Avg. Test Loss: 0.0030484322924166918\n",
      "Epoch: 838, Avg. Train Loss: 0.0029041240273346733, Avg. Test Loss: 0.003073776373639703\n",
      "Epoch: 839, Avg. Train Loss: 0.0028952796250408474, Avg. Test Loss: 0.003052906133234501\n",
      "Epoch: 840, Avg. Train Loss: 0.0028629430602196346, Avg. Test Loss: 0.003068271093070507\n",
      "Epoch: 841, Avg. Train Loss: 0.0028785195656467317, Avg. Test Loss: 0.0031579858623445034\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 842, Avg. Train Loss: 0.0029012142399022747, Avg. Test Loss: 0.0031155776232481003\n",
      "Epoch: 843, Avg. Train Loss: 0.0028674506993834363, Avg. Test Loss: 0.0030852905474603176\n",
      "Epoch: 844, Avg. Train Loss: 0.002881282030843025, Avg. Test Loss: 0.003058139467611909\n",
      "Epoch: 845, Avg. Train Loss: 0.002895679633501311, Avg. Test Loss: 0.0032988106831908226\n",
      "Epoch: 846, Avg. Train Loss: 0.0029342693363338017, Avg. Test Loss: 0.0030800439417362213\n",
      "Epoch: 847, Avg. Train Loss: 0.002852555537639662, Avg. Test Loss: 0.0031802509911358356\n",
      "Epoch: 848, Avg. Train Loss: 0.0028765109790012586, Avg. Test Loss: 0.0030701702926307917\n",
      "Epoch: 849, Avg. Train Loss: 0.0028510948718893665, Avg. Test Loss: 0.0030450501944869757\n",
      "Epoch: 850, Avg. Train Loss: 0.002870733541068296, Avg. Test Loss: 0.0030520863365381956\n",
      "Epoch: 851, Avg. Train Loss: 0.00285153828431354, Avg. Test Loss: 0.0030541662126779556\n",
      "Epoch: 852, Avg. Train Loss: 0.0028633331544264114, Avg. Test Loss: 0.0030745072290301323\n",
      "Epoch: 853, Avg. Train Loss: 0.002859857778043248, Avg. Test Loss: 0.0030287469271570444\n",
      "Epoch: 854, Avg. Train Loss: 0.00286204727409884, Avg. Test Loss: 0.0031032224651426077\n",
      "Epoch: 855, Avg. Train Loss: 0.0028532676907732737, Avg. Test Loss: 0.0030729954596608877\n",
      "Epoch: 856, Avg. Train Loss: 0.0028792076235160577, Avg. Test Loss: 0.003198153804987669\n",
      "Epoch: 857, Avg. Train Loss: 0.002888898170271585, Avg. Test Loss: 0.0030373167246580124\n",
      "Epoch: 858, Avg. Train Loss: 0.00285951912316472, Avg. Test Loss: 0.003046781523153186\n",
      "Epoch: 859, Avg. Train Loss: 0.0028620700698432536, Avg. Test Loss: 0.003021770156919956\n",
      "Epoch: 860, Avg. Train Loss: 0.0028489308518379235, Avg. Test Loss: 0.003041201503947377\n",
      "Epoch: 861, Avg. Train Loss: 0.0028473874337451403, Avg. Test Loss: 0.0030611297115683556\n",
      "Epoch: 862, Avg. Train Loss: 0.0028754135128110647, Avg. Test Loss: 0.003045176388695836\n",
      "Epoch: 863, Avg. Train Loss: 0.0028586974529939335, Avg. Test Loss: 0.003051759907975793\n",
      "Epoch: 864, Avg. Train Loss: 0.002889235265726267, Avg. Test Loss: 0.003039425937458873\n",
      "Epoch: 865, Avg. Train Loss: 0.0028600534586625736, Avg. Test Loss: 0.003109443001449108\n",
      "Epoch: 866, Avg. Train Loss: 0.0028613362418011177, Avg. Test Loss: 0.0030346529092639685\n",
      "Epoch: 867, Avg. Train Loss: 0.00284033521013551, Avg. Test Loss: 0.0031272489577531815\n",
      "Epoch: 868, Avg. Train Loss: 0.002882727752114798, Avg. Test Loss: 0.0030423388816416264\n",
      "Epoch: 869, Avg. Train Loss: 0.0028501853433459306, Avg. Test Loss: 0.0030672333668917418\n",
      "Epoch: 870, Avg. Train Loss: 0.0028449910053940015, Avg. Test Loss: 0.003063331125304103\n",
      "Epoch: 871, Avg. Train Loss: 0.0028927346182510603, Avg. Test Loss: 0.0030271902214735746\n",
      "Epoch: 872, Avg. Train Loss: 0.002833827804817363, Avg. Test Loss: 0.0030356019269675016\n",
      "Epoch: 873, Avg. Train Loss: 0.0028601981602002714, Avg. Test Loss: 0.0030348512809723616\n",
      "Epoch: 874, Avg. Train Loss: 0.0028828036765632934, Avg. Test Loss: 0.003175145946443081\n",
      "Epoch: 875, Avg. Train Loss: 0.002875031080356864, Avg. Test Loss: 0.0030357076320797205\n",
      "Epoch: 876, Avg. Train Loss: 0.002831439801686725, Avg. Test Loss: 0.0030295192264020443\n",
      "Epoch: 877, Avg. Train Loss: 0.0028341691995169534, Avg. Test Loss: 0.003029164159670472\n",
      "Epoch: 878, Avg. Train Loss: 0.002859436711946199, Avg. Test Loss: 0.0030668640974909067\n",
      "Epoch: 879, Avg. Train Loss: 0.002845398919267017, Avg. Test Loss: 0.003040353301912546\n",
      "Epoch: 880, Avg. Train Loss: 0.0028591832568392503, Avg. Test Loss: 0.0030472700018435717\n",
      "Epoch: 881, Avg. Train Loss: 0.0028552837334140098, Avg. Test Loss: 0.003028303384780884\n",
      "Epoch: 882, Avg. Train Loss: 0.0028355798554108584, Avg. Test Loss: 0.003048279322683811\n",
      "Epoch: 883, Avg. Train Loss: 0.0028451985657908197, Avg. Test Loss: 0.0030034405644983053\n",
      "Epoch: 884, Avg. Train Loss: 0.0028513335774457732, Avg. Test Loss: 0.003017045557498932\n",
      "Epoch: 885, Avg. Train Loss: 0.0028323312290012836, Avg. Test Loss: 0.003006882965564728\n",
      "Epoch: 886, Avg. Train Loss: 0.0028427733530745256, Avg. Test Loss: 0.0031002832110971212\n",
      "Epoch: 887, Avg. Train Loss: 0.0028725827957481838, Avg. Test Loss: 0.0030647683888673782\n",
      "Epoch: 888, Avg. Train Loss: 0.0028426866967577575, Avg. Test Loss: 0.0030216549057513475\n",
      "Epoch: 889, Avg. Train Loss: 0.0028302041911195184, Avg. Test Loss: 0.0031790852081030607\n",
      "Epoch: 890, Avg. Train Loss: 0.002901490582802961, Avg. Test Loss: 0.003052824642509222\n",
      "Epoch: 891, Avg. Train Loss: 0.0028420669990483413, Avg. Test Loss: 0.0030586610082536936\n",
      "Epoch: 892, Avg. Train Loss: 0.0028241358448339755, Avg. Test Loss: 0.003001870820298791\n",
      "Epoch: 893, Avg. Train Loss: 0.0028260601413717798, Avg. Test Loss: 0.0030048892367631197\n",
      "Epoch: 894, Avg. Train Loss: 0.0028320621092652164, Avg. Test Loss: 0.0030395095236599445\n",
      "Epoch: 895, Avg. Train Loss: 0.0028400882472132526, Avg. Test Loss: 0.003060262417420745\n",
      "Epoch: 896, Avg. Train Loss: 0.0028238040557521027, Avg. Test Loss: 0.0030600186437368393\n",
      "Epoch: 897, Avg. Train Loss: 0.0028297282311372284, Avg. Test Loss: 0.0029943364206701517\n",
      "Epoch: 898, Avg. Train Loss: 0.002851987685358455, Avg. Test Loss: 0.0030010216869413853\n",
      "Epoch: 899, Avg. Train Loss: 0.0028404262469171786, Avg. Test Loss: 0.0030085176695138216\n",
      "Epoch: 900, Avg. Train Loss: 0.00284108386894818, Avg. Test Loss: 0.0030271385330706835\n",
      "Epoch: 901, Avg. Train Loss: 0.0028254713722353064, Avg. Test Loss: 0.00312141259200871\n",
      "Epoch: 902, Avg. Train Loss: 0.0028719090542561093, Avg. Test Loss: 0.0030636799056082964\n",
      "Epoch: 903, Avg. Train Loss: 0.002823718162903259, Avg. Test Loss: 0.003002777462825179\n",
      "Epoch: 904, Avg. Train Loss: 0.002849253701306013, Avg. Test Loss: 0.0029938011430203915\n",
      "Epoch: 905, Avg. Train Loss: 0.002818581718561608, Avg. Test Loss: 0.00300572719424963\n",
      "Epoch: 906, Avg. Train Loss: 0.0028403380961525577, Avg. Test Loss: 0.0030934184323996305\n",
      "Epoch: 907, Avg. Train Loss: 0.00285263656811832, Avg. Test Loss: 0.003005059203132987\n",
      "Epoch: 908, Avg. Train Loss: 0.002819473497829465, Avg. Test Loss: 0.0029977960512042046\n",
      "Epoch: 909, Avg. Train Loss: 0.0028248028288227183, Avg. Test Loss: 0.003010246204212308\n",
      "Epoch: 910, Avg. Train Loss: 0.0028473416473283326, Avg. Test Loss: 0.00299554574303329\n",
      "Epoch: 911, Avg. Train Loss: 0.0028456443065214294, Avg. Test Loss: 0.0030248172115534544\n",
      "Epoch: 912, Avg. Train Loss: 0.002814295604218577, Avg. Test Loss: 0.003017829032614827\n",
      "Epoch: 913, Avg. Train Loss: 0.002812094201312162, Avg. Test Loss: 0.0030019956175237894\n",
      "Epoch: 914, Avg. Train Loss: 0.002840093120412771, Avg. Test Loss: 0.0030528162606060505\n",
      "Epoch: 915, Avg. Train Loss: 0.002866058686185022, Avg. Test Loss: 0.0030559590086340904\n",
      "Epoch: 916, Avg. Train Loss: 0.002803638507070583, Avg. Test Loss: 0.0031297432724386454\n",
      "Epoch: 917, Avg. Train Loss: 0.002820239413183096, Avg. Test Loss: 0.003133277175948024\n",
      "Epoch: 918, Avg. Train Loss: 0.0028198369356348765, Avg. Test Loss: 0.0030501189175993204\n",
      "Epoch: 919, Avg. Train Loss: 0.0028243470817890973, Avg. Test Loss: 0.0030026754830032587\n",
      "Epoch: 920, Avg. Train Loss: 0.002827284873874728, Avg. Test Loss: 0.003172959666699171\n",
      "Epoch: 921, Avg. Train Loss: 0.0028594876639544964, Avg. Test Loss: 0.0030272819567471743\n",
      "Epoch: 922, Avg. Train Loss: 0.0028221372157595185, Avg. Test Loss: 0.003005622886121273\n",
      "Epoch: 923, Avg. Train Loss: 0.0028033853822582683, Avg. Test Loss: 0.002994750626385212\n",
      "Epoch: 924, Avg. Train Loss: 0.0028205721823195387, Avg. Test Loss: 0.0030155915301293135\n",
      "Epoch: 925, Avg. Train Loss: 0.0028518496113721023, Avg. Test Loss: 0.0031696350779384375\n",
      "Epoch: 926, Avg. Train Loss: 0.002813635561831815, Avg. Test Loss: 0.0030385430436581373\n",
      "Epoch: 927, Avg. Train Loss: 0.0028329012958809388, Avg. Test Loss: 0.0029972605407238007\n",
      "Epoch: 928, Avg. Train Loss: 0.0028431597490643345, Avg. Test Loss: 0.0030004323925822973\n",
      "Epoch: 929, Avg. Train Loss: 0.002799146667902553, Avg. Test Loss: 0.003068893449380994\n",
      "Epoch: 930, Avg. Train Loss: 0.0028342829020910486, Avg. Test Loss: 0.002987100975587964\n",
      "Epoch: 931, Avg. Train Loss: 0.002797858258925898, Avg. Test Loss: 0.003000312251970172\n",
      "Epoch: 932, Avg. Train Loss: 0.002834008335200853, Avg. Test Loss: 0.0029883147217333317\n",
      "Epoch: 933, Avg. Train Loss: 0.0028086506090191908, Avg. Test Loss: 0.002983443671837449\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 934, Avg. Train Loss: 0.002806122290230421, Avg. Test Loss: 0.003171725897118449\n",
      "Epoch: 935, Avg. Train Loss: 0.0028357400699670233, Avg. Test Loss: 0.0030320400837808847\n",
      "Epoch: 936, Avg. Train Loss: 0.002841835798219193, Avg. Test Loss: 0.0030738667119294405\n",
      "Epoch: 937, Avg. Train Loss: 0.002803165221933362, Avg. Test Loss: 0.003030167892575264\n",
      "Epoch: 938, Avg. Train Loss: 0.002825538140483374, Avg. Test Loss: 0.002972112037241459\n",
      "Epoch: 939, Avg. Train Loss: 0.002814293302985471, Avg. Test Loss: 0.0031862184405326843\n",
      "Epoch: 940, Avg. Train Loss: 0.0028645318911172625, Avg. Test Loss: 0.0030536483973264694\n",
      "Epoch: 941, Avg. Train Loss: 0.0028175643515274966, Avg. Test Loss: 0.0029938826337456703\n",
      "Epoch: 942, Avg. Train Loss: 0.0028447664537748626, Avg. Test Loss: 0.00300456746481359\n",
      "Epoch: 943, Avg. Train Loss: 0.002797542973746394, Avg. Test Loss: 0.0029987015295773745\n",
      "Epoch: 944, Avg. Train Loss: 0.002854840191037849, Avg. Test Loss: 0.0029957450460642576\n",
      "Epoch: 945, Avg. Train Loss: 0.002819500511598795, Avg. Test Loss: 0.0032139362301677465\n",
      "Epoch: 946, Avg. Train Loss: 0.002814595527990266, Avg. Test Loss: 0.0029678947757929564\n",
      "Epoch: 947, Avg. Train Loss: 0.0028071912319594344, Avg. Test Loss: 0.002976808464154601\n",
      "Epoch: 948, Avg. Train Loss: 0.0028064364654033684, Avg. Test Loss: 0.0029680884908884764\n",
      "Epoch: 949, Avg. Train Loss: 0.002834834418324537, Avg. Test Loss: 0.0029972672928124666\n",
      "Epoch: 950, Avg. Train Loss: 0.0028084698566343894, Avg. Test Loss: 0.003019304946064949\n",
      "Epoch: 951, Avg. Train Loss: 0.0028127378318458796, Avg. Test Loss: 0.0030393004417419434\n",
      "Epoch: 952, Avg. Train Loss: 0.0028164685205664744, Avg. Test Loss: 0.0029856497421860695\n",
      "Epoch: 953, Avg. Train Loss: 0.002795046352413158, Avg. Test Loss: 0.003028689417988062\n",
      "Epoch: 954, Avg. Train Loss: 0.0027996458080705514, Avg. Test Loss: 0.003003503195941448\n",
      "Epoch: 955, Avg. Train Loss: 0.0028285547051318857, Avg. Test Loss: 0.0029776636511087418\n",
      "Epoch: 956, Avg. Train Loss: 0.0028334512689345798, Avg. Test Loss: 0.0031114176381379366\n",
      "Epoch: 957, Avg. Train Loss: 0.0028310894998613487, Avg. Test Loss: 0.003056879388168454\n",
      "Epoch: 958, Avg. Train Loss: 0.0028364878895064424, Avg. Test Loss: 0.0031068050302565098\n",
      "Epoch: 959, Avg. Train Loss: 0.0028158198381492564, Avg. Test Loss: 0.00303214555606246\n",
      "Epoch: 960, Avg. Train Loss: 0.002806013693686488, Avg. Test Loss: 0.0029796308372169733\n",
      "Epoch: 961, Avg. Train Loss: 0.0027842122119266627, Avg. Test Loss: 0.0029755353461951017\n",
      "Epoch: 962, Avg. Train Loss: 0.0028131242711530173, Avg. Test Loss: 0.003049300517886877\n",
      "Epoch: 963, Avg. Train Loss: 0.002794711179164953, Avg. Test Loss: 0.0029924032278358936\n",
      "Epoch: 964, Avg. Train Loss: 0.00278602612508071, Avg. Test Loss: 0.002977096475660801\n",
      "Epoch: 965, Avg. Train Loss: 0.002805505386488729, Avg. Test Loss: 0.0029923939146101475\n",
      "Epoch: 966, Avg. Train Loss: 0.002800832248054618, Avg. Test Loss: 0.0029767444357275963\n",
      "Epoch: 967, Avg. Train Loss: 0.002787173947665927, Avg. Test Loss: 0.0030237960163503885\n",
      "Epoch: 968, Avg. Train Loss: 0.002791711887301401, Avg. Test Loss: 0.0029891924932599068\n",
      "Epoch: 969, Avg. Train Loss: 0.002815900251355975, Avg. Test Loss: 0.0029960479587316513\n",
      "Epoch: 970, Avg. Train Loss: 0.0027988334511255108, Avg. Test Loss: 0.0029796110466122627\n",
      "Epoch: 971, Avg. Train Loss: 0.0028382939784679304, Avg. Test Loss: 0.0030090759973973036\n",
      "Epoch: 972, Avg. Train Loss: 0.0027992146815238304, Avg. Test Loss: 0.0030029267072677612\n",
      "Epoch: 973, Avg. Train Loss: 0.0027993202296107316, Avg. Test Loss: 0.0029596767853945494\n",
      "Epoch: 974, Avg. Train Loss: 0.0027946859251621156, Avg. Test Loss: 0.0029998624231666327\n",
      "Epoch: 975, Avg. Train Loss: 0.002819821677105718, Avg. Test Loss: 0.0030002491548657417\n",
      "Epoch: 976, Avg. Train Loss: 0.002787644530884748, Avg. Test Loss: 0.0029972365591675043\n",
      "Epoch: 977, Avg. Train Loss: 0.002817363304974035, Avg. Test Loss: 0.003007461316883564\n",
      "Epoch: 978, Avg. Train Loss: 0.0027989092618660176, Avg. Test Loss: 0.002952148672193289\n",
      "Epoch: 979, Avg. Train Loss: 0.00277608655241513, Avg. Test Loss: 0.0029686070047318935\n",
      "Epoch: 980, Avg. Train Loss: 0.0027814231607196636, Avg. Test Loss: 0.002998942043632269\n",
      "Epoch: 981, Avg. Train Loss: 0.002778473077341914, Avg. Test Loss: 0.00297356303781271\n",
      "Epoch: 982, Avg. Train Loss: 0.0027856246709043898, Avg. Test Loss: 0.002974854316562414\n",
      "Epoch: 983, Avg. Train Loss: 0.0027820820985145346, Avg. Test Loss: 0.0030905448365956545\n",
      "Epoch: 984, Avg. Train Loss: 0.0028234506729816976, Avg. Test Loss: 0.0029736075084656477\n",
      "Epoch: 985, Avg. Train Loss: 0.002785554523904656, Avg. Test Loss: 0.002966995118185878\n",
      "Epoch: 986, Avg. Train Loss: 0.0028077205859644468, Avg. Test Loss: 0.002953479764983058\n",
      "Epoch: 987, Avg. Train Loss: 0.0027878085627805354, Avg. Test Loss: 0.003011269262060523\n",
      "Epoch: 988, Avg. Train Loss: 0.0027999421310892633, Avg. Test Loss: 0.0029661853332072496\n",
      "Epoch: 989, Avg. Train Loss: 0.002792149765936788, Avg. Test Loss: 0.0030677912291139364\n",
      "Epoch: 990, Avg. Train Loss: 0.002781636861347875, Avg. Test Loss: 0.003130893921479583\n",
      "Epoch: 991, Avg. Train Loss: 0.0027910674445677636, Avg. Test Loss: 0.0029599308036267757\n",
      "Epoch: 992, Avg. Train Loss: 0.002808576076139891, Avg. Test Loss: 0.002955387579277158\n",
      "Epoch: 993, Avg. Train Loss: 0.0028076182271158973, Avg. Test Loss: 0.003003294114023447\n",
      "Epoch: 994, Avg. Train Loss: 0.0028818190628446118, Avg. Test Loss: 0.0029815398156642914\n",
      "Epoch: 995, Avg. Train Loss: 0.0027870559404322573, Avg. Test Loss: 0.0029926744755357504\n",
      "Epoch: 996, Avg. Train Loss: 0.002774473252641254, Avg. Test Loss: 0.0029783339705318213\n",
      "Epoch: 997, Avg. Train Loss: 0.002763349725323361, Avg. Test Loss: 0.002956171752884984\n",
      "Epoch: 998, Avg. Train Loss: 0.00278921392854563, Avg. Test Loss: 0.0029657455161213875\n",
      "Epoch: 999, Avg. Train Loss: 0.002799743559038223, Avg. Test Loss: 0.0030843119602650404\n",
      "Epoch: 1000, Avg. Train Loss: 0.0027803638679256967, Avg. Test Loss: 0.0030645288061350584\n",
      "Epoch: 1001, Avg. Train Loss: 0.0027829545907416316, Avg. Test Loss: 0.0029614591039717197\n",
      "Epoch: 1002, Avg. Train Loss: 0.0027697133279383874, Avg. Test Loss: 0.0029867636039853096\n",
      "Epoch: 1003, Avg. Train Loss: 0.0028131207732786964, Avg. Test Loss: 0.0029762210324406624\n",
      "Epoch: 1004, Avg. Train Loss: 0.002787031791021311, Avg. Test Loss: 0.0030070622451603413\n",
      "Epoch: 1005, Avg. Train Loss: 0.0027923979146709274, Avg. Test Loss: 0.0029862173832952976\n",
      "Epoch: 1006, Avg. Train Loss: 0.002796345076328793, Avg. Test Loss: 0.0029628840275108814\n",
      "Epoch: 1007, Avg. Train Loss: 0.0027936036037930915, Avg. Test Loss: 0.00294869695790112\n",
      "Epoch: 1008, Avg. Train Loss: 0.0027848028599522833, Avg. Test Loss: 0.0029596276581287384\n",
      "Epoch: 1009, Avg. Train Loss: 0.002763065206276816, Avg. Test Loss: 0.0029703329782932997\n",
      "Epoch: 1010, Avg. Train Loss: 0.0027737716418626004, Avg. Test Loss: 0.002950794994831085\n",
      "Epoch: 1011, Avg. Train Loss: 0.0028903834131914514, Avg. Test Loss: 0.0031840670853853226\n",
      "Epoch: 1012, Avg. Train Loss: 0.0028022650715916657, Avg. Test Loss: 0.00297247851267457\n",
      "Epoch: 1013, Avg. Train Loss: 0.0027672734902088724, Avg. Test Loss: 0.002945316256955266\n",
      "Epoch: 1014, Avg. Train Loss: 0.002774168071228751, Avg. Test Loss: 0.002985231811180711\n",
      "Epoch: 1015, Avg. Train Loss: 0.0027687156757036616, Avg. Test Loss: 0.0029442650265991688\n",
      "Epoch: 1016, Avg. Train Loss: 0.0027667589723890606, Avg. Test Loss: 0.0029646761249750853\n",
      "Epoch: 1017, Avg. Train Loss: 0.002819451248966331, Avg. Test Loss: 0.003126029623672366\n",
      "Epoch: 1018, Avg. Train Loss: 0.002802788826831898, Avg. Test Loss: 0.0029667075723409653\n",
      "Epoch: 1019, Avg. Train Loss: 0.0027787095682998727, Avg. Test Loss: 0.0029851733706891537\n",
      "Epoch: 1020, Avg. Train Loss: 0.002796395053697187, Avg. Test Loss: 0.0029718882869929075\n",
      "Epoch: 1021, Avg. Train Loss: 0.0027707815495168053, Avg. Test Loss: 0.0029621021822094917\n",
      "Epoch: 1022, Avg. Train Loss: 0.002777866060780578, Avg. Test Loss: 0.002962249331176281\n",
      "Epoch: 1023, Avg. Train Loss: 0.0027748253088184568, Avg. Test Loss: 0.002984309336170554\n",
      "Epoch: 1024, Avg. Train Loss: 0.0027656896841214145, Avg. Test Loss: 0.0029524259734898806\n",
      "Epoch: 1025, Avg. Train Loss: 0.0027730416690627505, Avg. Test Loss: 0.002969515509903431\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1026, Avg. Train Loss: 0.002779560412691776, Avg. Test Loss: 0.0029450200963765383\n",
      "Epoch: 1027, Avg. Train Loss: 0.0027675487826643295, Avg. Test Loss: 0.0029358190950006247\n",
      "Epoch: 1028, Avg. Train Loss: 0.0027528805549927923, Avg. Test Loss: 0.0029669967480003834\n",
      "Epoch: 1029, Avg. Train Loss: 0.002766199897281652, Avg. Test Loss: 0.0029488864820450544\n",
      "Epoch: 1030, Avg. Train Loss: 0.0027498896666910758, Avg. Test Loss: 0.0029969012830406427\n",
      "Epoch: 1031, Avg. Train Loss: 0.0027658416792143915, Avg. Test Loss: 0.002940249862149358\n",
      "Epoch: 1032, Avg. Train Loss: 0.002761460515822089, Avg. Test Loss: 0.002985343337059021\n",
      "Epoch: 1033, Avg. Train Loss: 0.0027807795789179415, Avg. Test Loss: 0.0029909019358456135\n",
      "Epoch: 1034, Avg. Train Loss: 0.0027939159975408816, Avg. Test Loss: 0.002955252770334482\n",
      "Epoch: 1035, Avg. Train Loss: 0.0027893094703295204, Avg. Test Loss: 0.0030385900754481554\n",
      "Epoch: 1036, Avg. Train Loss: 0.0027838187660415505, Avg. Test Loss: 0.002937247743830085\n",
      "Epoch: 1037, Avg. Train Loss: 0.002755231608441749, Avg. Test Loss: 0.0029394954908639193\n",
      "Epoch: 1038, Avg. Train Loss: 0.002765842523902308, Avg. Test Loss: 0.0029360917396843433\n",
      "Epoch: 1039, Avg. Train Loss: 0.002773177512206657, Avg. Test Loss: 0.0029720140155404806\n",
      "Epoch: 1040, Avg. Train Loss: 0.0027791200378953023, Avg. Test Loss: 0.002935613039880991\n",
      "Epoch: 1041, Avg. Train Loss: 0.0027761404445871365, Avg. Test Loss: 0.003052331740036607\n",
      "Epoch: 1042, Avg. Train Loss: 0.0027836880884891334, Avg. Test Loss: 0.002938677789643407\n",
      "Epoch: 1043, Avg. Train Loss: 0.002778476077066951, Avg. Test Loss: 0.0030377807561308146\n",
      "Epoch: 1044, Avg. Train Loss: 0.0027574701992751556, Avg. Test Loss: 0.0029505605343729258\n",
      "Epoch: 1045, Avg. Train Loss: 0.0027533028772923837, Avg. Test Loss: 0.0029366931412369013\n",
      "Epoch: 1046, Avg. Train Loss: 0.00277036358602345, Avg. Test Loss: 0.003020928706973791\n",
      "Epoch: 1047, Avg. Train Loss: 0.0028259039824005475, Avg. Test Loss: 0.0029419930651783943\n",
      "Epoch: 1048, Avg. Train Loss: 0.002766686719084202, Avg. Test Loss: 0.003015590365976095\n",
      "Epoch: 1049, Avg. Train Loss: 0.002762256092716788, Avg. Test Loss: 0.002948733512312174\n",
      "Epoch: 1050, Avg. Train Loss: 0.002780087319267697, Avg. Test Loss: 0.002969446824863553\n",
      "Epoch: 1051, Avg. Train Loss: 0.0027786836049757723, Avg. Test Loss: 0.002932061208412051\n",
      "Epoch: 1052, Avg. Train Loss: 0.0027652111196847158, Avg. Test Loss: 0.002970218425616622\n",
      "Epoch: 1053, Avg. Train Loss: 0.0027537503019841605, Avg. Test Loss: 0.0030238484032452106\n",
      "Epoch: 1054, Avg. Train Loss: 0.0027469224079923575, Avg. Test Loss: 0.0029539468232542276\n",
      "Epoch: 1055, Avg. Train Loss: 0.002745439682892242, Avg. Test Loss: 0.003085541073232889\n",
      "Epoch: 1056, Avg. Train Loss: 0.002748593996647139, Avg. Test Loss: 0.0029843340162187815\n",
      "Epoch: 1057, Avg. Train Loss: 0.002755206110778936, Avg. Test Loss: 0.002937168348580599\n",
      "Epoch: 1058, Avg. Train Loss: 0.0027580734905461933, Avg. Test Loss: 0.002946224994957447\n",
      "Epoch: 1059, Avg. Train Loss: 0.0027780113037848887, Avg. Test Loss: 0.002940849168226123\n",
      "Epoch: 1060, Avg. Train Loss: 0.002759635480943807, Avg. Test Loss: 0.002929433947429061\n",
      "Epoch: 1061, Avg. Train Loss: 0.002747049192399826, Avg. Test Loss: 0.0029282094910740852\n",
      "Epoch: 1062, Avg. Train Loss: 0.002744235352851277, Avg. Test Loss: 0.0029565764125436544\n",
      "Epoch: 1063, Avg. Train Loss: 0.002748019657595906, Avg. Test Loss: 0.002929022302851081\n",
      "Epoch: 1064, Avg. Train Loss: 0.002743135644989305, Avg. Test Loss: 0.0029244651086628437\n",
      "Epoch: 1065, Avg. Train Loss: 0.0027461908757686615, Avg. Test Loss: 0.0029376742895692587\n",
      "Epoch: 1066, Avg. Train Loss: 0.002769743395579416, Avg. Test Loss: 0.0029479432851076126\n",
      "Epoch: 1067, Avg. Train Loss: 0.0027597139719440496, Avg. Test Loss: 0.002972859190776944\n",
      "Epoch: 1068, Avg. Train Loss: 0.0027497022380229344, Avg. Test Loss: 0.003023205790668726\n",
      "Epoch: 1069, Avg. Train Loss: 0.0027970986787316412, Avg. Test Loss: 0.0029535144567489624\n",
      "Epoch: 1070, Avg. Train Loss: 0.002764482143183434, Avg. Test Loss: 0.0029339403845369816\n",
      "Epoch: 1071, Avg. Train Loss: 0.002750205769485166, Avg. Test Loss: 0.002964206039905548\n",
      "Epoch: 1072, Avg. Train Loss: 0.002773017162283839, Avg. Test Loss: 0.0029560551047325134\n",
      "Epoch: 1073, Avg. Train Loss: 0.0027591545882006715, Avg. Test Loss: 0.0030842397827655077\n",
      "Epoch: 1074, Avg. Train Loss: 0.0027733161168302907, Avg. Test Loss: 0.003016972215846181\n",
      "Epoch: 1075, Avg. Train Loss: 0.0027622694127954718, Avg. Test Loss: 0.0029450259171426296\n",
      "Epoch: 1076, Avg. Train Loss: 0.0027553766240300827, Avg. Test Loss: 0.002930839080363512\n",
      "Epoch: 1077, Avg. Train Loss: 0.0027642896084851304, Avg. Test Loss: 0.003044919343665242\n",
      "Epoch: 1078, Avg. Train Loss: 0.0027534662485989027, Avg. Test Loss: 0.0030296635814011097\n",
      "Epoch: 1079, Avg. Train Loss: 0.0027327259222781936, Avg. Test Loss: 0.0029176976531744003\n",
      "Epoch: 1080, Avg. Train Loss: 0.0027516130953594005, Avg. Test Loss: 0.0030459705740213394\n",
      "Epoch: 1081, Avg. Train Loss: 0.0028375399753797887, Avg. Test Loss: 0.002929747337475419\n",
      "Epoch: 1082, Avg. Train Loss: 0.0027552370447665453, Avg. Test Loss: 0.003002376761287451\n",
      "Epoch: 1083, Avg. Train Loss: 0.0027718963967852815, Avg. Test Loss: 0.002921012230217457\n",
      "Epoch: 1084, Avg. Train Loss: 0.002746723532720014, Avg. Test Loss: 0.003007409628480673\n",
      "Epoch: 1085, Avg. Train Loss: 0.0027487526896821206, Avg. Test Loss: 0.00296234549023211\n",
      "Epoch: 1086, Avg. Train Loss: 0.002737026028118508, Avg. Test Loss: 0.002918376587331295\n",
      "Epoch: 1087, Avg. Train Loss: 0.0027533523727554915, Avg. Test Loss: 0.003029764397069812\n",
      "Epoch: 1088, Avg. Train Loss: 0.002784405542580887, Avg. Test Loss: 0.002953758928924799\n",
      "Epoch: 1089, Avg. Train Loss: 0.0027535822524061035, Avg. Test Loss: 0.002913805888965726\n",
      "Epoch: 1090, Avg. Train Loss: 0.0027421142115409292, Avg. Test Loss: 0.0029642966110259295\n",
      "Epoch: 1091, Avg. Train Loss: 0.0027629770555121953, Avg. Test Loss: 0.0029379697516560555\n",
      "Epoch: 1092, Avg. Train Loss: 0.0027555562068469997, Avg. Test Loss: 0.0029133232310414314\n",
      "Epoch: 1093, Avg. Train Loss: 0.002751175606579975, Avg. Test Loss: 0.0029473770409822464\n",
      "Epoch: 1094, Avg. Train Loss: 0.0027398587919251864, Avg. Test Loss: 0.002925669075921178\n",
      "Epoch: 1095, Avg. Train Loss: 0.0027517491929926153, Avg. Test Loss: 0.002935160184279084\n",
      "Epoch: 1096, Avg. Train Loss: 0.0027362717597117256, Avg. Test Loss: 0.0029223752208054066\n",
      "Epoch: 1097, Avg. Train Loss: 0.0027417697088229793, Avg. Test Loss: 0.0030114988330751657\n",
      "Epoch: 1098, Avg. Train Loss: 0.002741550810115282, Avg. Test Loss: 0.0030055460520088673\n",
      "Epoch: 1099, Avg. Train Loss: 0.0027782169907072255, Avg. Test Loss: 0.0029193644877523184\n",
      "Epoch: 1100, Avg. Train Loss: 0.0027739046314774556, Avg. Test Loss: 0.002924592699855566\n",
      "Epoch: 1101, Avg. Train Loss: 0.0027595965224209915, Avg. Test Loss: 0.002924578031525016\n",
      "Epoch: 1102, Avg. Train Loss: 0.0027313742375131263, Avg. Test Loss: 0.0030943509191274643\n",
      "Epoch: 1103, Avg. Train Loss: 0.002794802697851907, Avg. Test Loss: 0.002911275252699852\n",
      "Epoch: 1104, Avg. Train Loss: 0.002751210384980537, Avg. Test Loss: 0.0029296637512743473\n",
      "Epoch: 1105, Avg. Train Loss: 0.0027352480196155783, Avg. Test Loss: 0.0029435863252729177\n",
      "Epoch: 1106, Avg. Train Loss: 0.0027399626181482577, Avg. Test Loss: 0.002998650074005127\n",
      "Epoch: 1107, Avg. Train Loss: 0.002732675614615166, Avg. Test Loss: 0.0029569193720817566\n",
      "Epoch: 1108, Avg. Train Loss: 0.0027500647553351035, Avg. Test Loss: 0.0029608935583382845\n",
      "Epoch: 1109, Avg. Train Loss: 0.002735163052674643, Avg. Test Loss: 0.002924788510426879\n",
      "Epoch: 1110, Avg. Train Loss: 0.0027616506680672947, Avg. Test Loss: 0.002928418107330799\n",
      "Epoch: 1111, Avg. Train Loss: 0.002741463720625223, Avg. Test Loss: 0.002968024928122759\n",
      "Epoch: 1112, Avg. Train Loss: 0.0027456184589239054, Avg. Test Loss: 0.0029436012264341116\n",
      "Epoch: 1113, Avg. Train Loss: 0.0027694756674125445, Avg. Test Loss: 0.0029444994870573282\n",
      "Epoch: 1114, Avg. Train Loss: 0.0027293238604744505, Avg. Test Loss: 0.0030108073260635138\n",
      "Epoch: 1115, Avg. Train Loss: 0.002756164707026856, Avg. Test Loss: 0.002973600523546338\n",
      "Epoch: 1116, Avg. Train Loss: 0.002752858143689674, Avg. Test Loss: 0.003305973717942834\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1117, Avg. Train Loss: 0.0027417623502917067, Avg. Test Loss: 0.0029450152069330215\n",
      "Epoch: 1118, Avg. Train Loss: 0.0027512181983437647, Avg. Test Loss: 0.002912609837949276\n",
      "Epoch: 1119, Avg. Train Loss: 0.002724462286244298, Avg. Test Loss: 0.0029233067762106657\n",
      "Epoch: 1120, Avg. Train Loss: 0.0027356123779142317, Avg. Test Loss: 0.002956551034003496\n",
      "Epoch: 1121, Avg. Train Loss: 0.0027520301004568507, Avg. Test Loss: 0.0029300597961992025\n",
      "Epoch: 1122, Avg. Train Loss: 0.0027617382123893085, Avg. Test Loss: 0.0029335932340472937\n",
      "Epoch: 1123, Avg. Train Loss: 0.0027492683662404846, Avg. Test Loss: 0.0029217095579952\n",
      "Epoch: 1124, Avg. Train Loss: 0.002719376961765594, Avg. Test Loss: 0.0029208899941295385\n",
      "Epoch: 1125, Avg. Train Loss: 0.002738627404797562, Avg. Test Loss: 0.0029209856875240803\n",
      "Epoch: 1126, Avg. Train Loss: 0.0027206713106309953, Avg. Test Loss: 0.002981956349685788\n",
      "Epoch: 1127, Avg. Train Loss: 0.0027644549886327845, Avg. Test Loss: 0.002934984862804413\n",
      "Epoch: 1128, Avg. Train Loss: 0.002735131929173719, Avg. Test Loss: 0.002952348440885544\n",
      "Epoch: 1129, Avg. Train Loss: 0.0027383632340663394, Avg. Test Loss: 0.00299484352581203\n",
      "Epoch: 1130, Avg. Train Loss: 0.0027394672790758833, Avg. Test Loss: 0.0029828830156475306\n",
      "Epoch: 1131, Avg. Train Loss: 0.0027224674907534623, Avg. Test Loss: 0.0029356314335018396\n",
      "Epoch: 1132, Avg. Train Loss: 0.002789760836898241, Avg. Test Loss: 0.0029716198332607746\n",
      "Epoch: 1133, Avg. Train Loss: 0.002737723263846927, Avg. Test Loss: 0.0029300537426024675\n",
      "Epoch: 1134, Avg. Train Loss: 0.0027198814407943988, Avg. Test Loss: 0.002948130015283823\n",
      "Epoch: 1135, Avg. Train Loss: 0.002745001966696839, Avg. Test Loss: 0.002914292737841606\n",
      "Epoch: 1136, Avg. Train Loss: 0.002732149828875134, Avg. Test Loss: 0.002908429829403758\n",
      "Epoch: 1137, Avg. Train Loss: 0.00273144110863985, Avg. Test Loss: 0.002932314295321703\n",
      "Epoch: 1138, Avg. Train Loss: 0.0027282664086669683, Avg. Test Loss: 0.002932446077466011\n",
      "Epoch: 1139, Avg. Train Loss: 0.002754062116362674, Avg. Test Loss: 0.0030269816052168608\n",
      "Epoch: 1140, Avg. Train Loss: 0.0027514510560607496, Avg. Test Loss: 0.0030643076170235872\n",
      "Epoch: 1141, Avg. Train Loss: 0.002737820668275966, Avg. Test Loss: 0.002979251556098461\n",
      "Epoch: 1142, Avg. Train Loss: 0.0027139251293657823, Avg. Test Loss: 0.002899081213399768\n",
      "Epoch: 1143, Avg. Train Loss: 0.0027314314434608053, Avg. Test Loss: 0.0030426345765590668\n",
      "Epoch: 1144, Avg. Train Loss: 0.00275359149524119, Avg. Test Loss: 0.0029695036355406046\n",
      "Epoch: 1145, Avg. Train Loss: 0.002715246600293836, Avg. Test Loss: 0.0029129167087376118\n",
      "Epoch: 1146, Avg. Train Loss: 0.0027262516655461038, Avg. Test Loss: 0.002904278924688697\n",
      "Epoch: 1147, Avg. Train Loss: 0.002740885445111713, Avg. Test Loss: 0.00293392944149673\n",
      "Epoch: 1148, Avg. Train Loss: 0.002748428686890145, Avg. Test Loss: 0.0029220778960734606\n",
      "Epoch: 1149, Avg. Train Loss: 0.002720942796576162, Avg. Test Loss: 0.002890844363719225\n",
      "Epoch: 1150, Avg. Train Loss: 0.002759297627435867, Avg. Test Loss: 0.0030953194946050644\n",
      "Epoch: 1151, Avg. Train Loss: 0.002744008570389692, Avg. Test Loss: 0.0028992164880037308\n",
      "Epoch: 1152, Avg. Train Loss: 0.0027062175145675968, Avg. Test Loss: 0.003020050236955285\n",
      "Epoch: 1153, Avg. Train Loss: 0.0027377589573260655, Avg. Test Loss: 0.0030135230626910925\n",
      "Epoch: 1154, Avg. Train Loss: 0.0027136540874232386, Avg. Test Loss: 0.002897231373935938\n",
      "Epoch: 1155, Avg. Train Loss: 0.002727207527387627, Avg. Test Loss: 0.0029945415444672108\n",
      "Epoch: 1156, Avg. Train Loss: 0.002741929143667221, Avg. Test Loss: 0.002925720764324069\n",
      "Epoch: 1157, Avg. Train Loss: 0.002729966169829632, Avg. Test Loss: 0.002932758769020438\n",
      "Epoch: 1158, Avg. Train Loss: 0.0027167161515112533, Avg. Test Loss: 0.0029135881923139095\n",
      "Epoch: 1159, Avg. Train Loss: 0.0027586642685238014, Avg. Test Loss: 0.003141817171126604\n",
      "Epoch: 1160, Avg. Train Loss: 0.0027637576662697073, Avg. Test Loss: 0.0028945517260581255\n",
      "Epoch: 1161, Avg. Train Loss: 0.0027588355885602013, Avg. Test Loss: 0.0028890841640532017\n",
      "Epoch: 1162, Avg. Train Loss: 0.002738978210186889, Avg. Test Loss: 0.002937935758382082\n",
      "Epoch: 1163, Avg. Train Loss: 0.00274032972168264, Avg. Test Loss: 0.002900690073147416\n",
      "Epoch: 1164, Avg. Train Loss: 0.0027107134147352258, Avg. Test Loss: 0.0029276038985699415\n",
      "Epoch: 1165, Avg. Train Loss: 0.002713253938181456, Avg. Test Loss: 0.0029089082963764668\n",
      "Epoch: 1166, Avg. Train Loss: 0.002722130947594726, Avg. Test Loss: 0.0028909321408718824\n",
      "Epoch: 1167, Avg. Train Loss: 0.0027165574855496023, Avg. Test Loss: 0.002998987678438425\n",
      "Epoch: 1168, Avg. Train Loss: 0.0027177758720638447, Avg. Test Loss: 0.002893633209168911\n",
      "Epoch: 1169, Avg. Train Loss: 0.002717189192988498, Avg. Test Loss: 0.003160095540806651\n",
      "Epoch: 1170, Avg. Train Loss: 0.00274903493456889, Avg. Test Loss: 0.002987057901918888\n",
      "Epoch: 1171, Avg. Train Loss: 0.0027222680252825104, Avg. Test Loss: 0.0029570709448307753\n",
      "Epoch: 1172, Avg. Train Loss: 0.0027265709954812085, Avg. Test Loss: 0.0029377329628914595\n",
      "Epoch: 1173, Avg. Train Loss: 0.0027264359374638905, Avg. Test Loss: 0.00289409258402884\n",
      "Epoch: 1174, Avg. Train Loss: 0.0027246608420513395, Avg. Test Loss: 0.002915474586188793\n",
      "Epoch: 1175, Avg. Train Loss: 0.002734445224970926, Avg. Test Loss: 0.00288276094943285\n",
      "Epoch: 1176, Avg. Train Loss: 0.0027056097940996635, Avg. Test Loss: 0.0029153090436011553\n",
      "Epoch: 1177, Avg. Train Loss: 0.002714296570047736, Avg. Test Loss: 0.0028897887095808983\n",
      "Epoch: 1178, Avg. Train Loss: 0.0027059381232098782, Avg. Test Loss: 0.0028904734645038843\n",
      "Epoch: 1179, Avg. Train Loss: 0.00270540481649859, Avg. Test Loss: 0.0028906117659062147\n",
      "Epoch: 1180, Avg. Train Loss: 0.002744319843301593, Avg. Test Loss: 0.0029222064185887575\n",
      "Epoch: 1181, Avg. Train Loss: 0.002702491033042586, Avg. Test Loss: 0.0028894117567688227\n",
      "Epoch: 1182, Avg. Train Loss: 0.0027554796434679004, Avg. Test Loss: 0.002915613353252411\n",
      "Epoch: 1183, Avg. Train Loss: 0.0027694076808645975, Avg. Test Loss: 0.002916416386142373\n",
      "Epoch: 1184, Avg. Train Loss: 0.0026989940900442213, Avg. Test Loss: 0.0028971575666218996\n",
      "Epoch: 1185, Avg. Train Loss: 0.0027134007839269415, Avg. Test Loss: 0.0028850522357970476\n",
      "Epoch: 1186, Avg. Train Loss: 0.0027094948495370013, Avg. Test Loss: 0.0028810494113713503\n",
      "Epoch: 1187, Avg. Train Loss: 0.002695726144105889, Avg. Test Loss: 0.0029265268240123987\n",
      "Epoch: 1188, Avg. Train Loss: 0.002744380373854277, Avg. Test Loss: 0.0029223598539829254\n",
      "Epoch: 1189, Avg. Train Loss: 0.002732462769504203, Avg. Test Loss: 0.002886083209887147\n",
      "Epoch: 1190, Avg. Train Loss: 0.0027010166898456425, Avg. Test Loss: 0.0030388429295271635\n",
      "Epoch: 1191, Avg. Train Loss: 0.0027711328747140806, Avg. Test Loss: 0.0030641909688711166\n",
      "Epoch: 1192, Avg. Train Loss: 0.0027400138300605293, Avg. Test Loss: 0.0029355003498494625\n",
      "Epoch: 1193, Avg. Train Loss: 0.002723349664403602, Avg. Test Loss: 0.002900461433455348\n",
      "Epoch: 1194, Avg. Train Loss: 0.0027158764559169148, Avg. Test Loss: 0.0028908257372677326\n",
      "Epoch: 1195, Avg. Train Loss: 0.0026987658997694422, Avg. Test Loss: 0.0029250674415379763\n",
      "Epoch: 1196, Avg. Train Loss: 0.00269846141684887, Avg. Test Loss: 0.00291689345613122\n",
      "Epoch: 1197, Avg. Train Loss: 0.002709567855480452, Avg. Test Loss: 0.0028951021376997232\n",
      "Epoch: 1198, Avg. Train Loss: 0.0026972420232067276, Avg. Test Loss: 0.002924673492088914\n",
      "Epoch: 1199, Avg. Train Loss: 0.002703920873098595, Avg. Test Loss: 0.0029072482138872147\n",
      "Epoch: 1200, Avg. Train Loss: 0.002694543916732073, Avg. Test Loss: 0.0029552632477134466\n",
      "Epoch: 1201, Avg. Train Loss: 0.0027006721979570252, Avg. Test Loss: 0.002906701061874628\n",
      "Epoch: 1202, Avg. Train Loss: 0.0027182528066860383, Avg. Test Loss: 0.0028866322245448828\n",
      "Epoch: 1203, Avg. Train Loss: 0.0027274723641227843, Avg. Test Loss: 0.003025433514267206\n",
      "Epoch: 1204, Avg. Train Loss: 0.0027293899573039176, Avg. Test Loss: 0.0028909037355333567\n",
      "Epoch: 1205, Avg. Train Loss: 0.0026915182554444602, Avg. Test Loss: 0.0029021291993558407\n",
      "Epoch: 1206, Avg. Train Loss: 0.002716871059694609, Avg. Test Loss: 0.0029517586808651686\n",
      "Epoch: 1207, Avg. Train Loss: 0.002726142126850264, Avg. Test Loss: 0.002882641041651368\n",
      "Epoch: 1208, Avg. Train Loss: 0.0027441588652775037, Avg. Test Loss: 0.0030317064374685287\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1209, Avg. Train Loss: 0.0027668762648868006, Avg. Test Loss: 0.0029198424890637398\n",
      "Epoch: 1210, Avg. Train Loss: 0.00272773886857511, Avg. Test Loss: 0.0029435649048537016\n",
      "Epoch: 1211, Avg. Train Loss: 0.0027049856563640196, Avg. Test Loss: 0.0028855730779469013\n",
      "Epoch: 1212, Avg. Train Loss: 0.0027052780699937844, Avg. Test Loss: 0.0030001180712133646\n",
      "Epoch: 1213, Avg. Train Loss: 0.0027319778699081304, Avg. Test Loss: 0.002924088854342699\n",
      "Epoch: 1214, Avg. Train Loss: 0.0027301627005515403, Avg. Test Loss: 0.0028929628897458315\n",
      "Epoch: 1215, Avg. Train Loss: 0.002714604886551929, Avg. Test Loss: 0.002886260161176324\n",
      "Epoch: 1216, Avg. Train Loss: 0.002695733681321144, Avg. Test Loss: 0.0028818799182772636\n",
      "Epoch: 1217, Avg. Train Loss: 0.002705495945329583, Avg. Test Loss: 0.002924441359937191\n",
      "Epoch: 1218, Avg. Train Loss: 0.002717085984037366, Avg. Test Loss: 0.002927902853116393\n",
      "Epoch: 1219, Avg. Train Loss: 0.0027151848568559385, Avg. Test Loss: 0.0029613524675369263\n",
      "Epoch: 1220, Avg. Train Loss: 0.002706265461436191, Avg. Test Loss: 0.0028891826514154673\n",
      "Epoch: 1221, Avg. Train Loss: 0.0027190502787138833, Avg. Test Loss: 0.0029722824692726135\n",
      "Epoch: 1222, Avg. Train Loss: 0.002715240216402467, Avg. Test Loss: 0.0029934202320873737\n",
      "Epoch: 1223, Avg. Train Loss: 0.002734746762313122, Avg. Test Loss: 0.002906625624746084\n",
      "Epoch: 1224, Avg. Train Loss: 0.0026930529450954394, Avg. Test Loss: 0.002888419898226857\n",
      "Epoch: 1225, Avg. Train Loss: 0.002684851664356714, Avg. Test Loss: 0.0028810915537178516\n",
      "Epoch: 1226, Avg. Train Loss: 0.002713795583478587, Avg. Test Loss: 0.002931010676547885\n",
      "Epoch: 1227, Avg. Train Loss: 0.002729732234594087, Avg. Test Loss: 0.002909637987613678\n",
      "Epoch: 1228, Avg. Train Loss: 0.0026986838892362145, Avg. Test Loss: 0.002878269413486123\n",
      "Epoch: 1229, Avg. Train Loss: 0.002687686057977898, Avg. Test Loss: 0.0029094938654452562\n",
      "Epoch: 1230, Avg. Train Loss: 0.0026929261281999736, Avg. Test Loss: 0.002883420092985034\n",
      "Epoch: 1231, Avg. Train Loss: 0.0026941566056636877, Avg. Test Loss: 0.002937034936621785\n",
      "Epoch: 1232, Avg. Train Loss: 0.0027307942617944506, Avg. Test Loss: 0.0028748412150889635\n",
      "Epoch: 1233, Avg. Train Loss: 0.0026957877251038024, Avg. Test Loss: 0.002912781899794936\n",
      "Epoch: 1234, Avg. Train Loss: 0.002721648760746385, Avg. Test Loss: 0.0028823507018387318\n",
      "Epoch: 1235, Avg. Train Loss: 0.0026953576814903075, Avg. Test Loss: 0.0029445781838148832\n",
      "Epoch: 1236, Avg. Train Loss: 0.0027490938677950656, Avg. Test Loss: 0.0028883933555334806\n",
      "Epoch: 1237, Avg. Train Loss: 0.002687141840714355, Avg. Test Loss: 0.002899294951930642\n",
      "Epoch: 1238, Avg. Train Loss: 0.0027740282104025747, Avg. Test Loss: 0.0031832417007535696\n",
      "Epoch: 1239, Avg. Train Loss: 0.002755293211098327, Avg. Test Loss: 0.0030334526672959328\n",
      "Epoch: 1240, Avg. Train Loss: 0.0027166111069883026, Avg. Test Loss: 0.0029024516697973013\n",
      "Epoch: 1241, Avg. Train Loss: 0.0027103847282570464, Avg. Test Loss: 0.0028810107614845037\n",
      "Epoch: 1242, Avg. Train Loss: 0.002680444207345677, Avg. Test Loss: 0.0028693131171166897\n",
      "Epoch: 1243, Avg. Train Loss: 0.0026999303507943486, Avg. Test Loss: 0.002929670037701726\n",
      "Epoch: 1244, Avg. Train Loss: 0.002714724523600104, Avg. Test Loss: 0.002885261783376336\n",
      "Epoch: 1245, Avg. Train Loss: 0.0026982933401974826, Avg. Test Loss: 0.0030162231996655464\n",
      "Epoch: 1246, Avg. Train Loss: 0.0027291514304314934, Avg. Test Loss: 0.002948808716610074\n",
      "Epoch: 1247, Avg. Train Loss: 0.0027259012066954097, Avg. Test Loss: 0.003010557033121586\n",
      "Epoch: 1248, Avg. Train Loss: 0.0027328199371262347, Avg. Test Loss: 0.00296245189383626\n",
      "Epoch: 1249, Avg. Train Loss: 0.0026940408346871306, Avg. Test Loss: 0.0028728877659887075\n",
      "Epoch: 1250, Avg. Train Loss: 0.0026905802836598353, Avg. Test Loss: 0.0029031599406152964\n",
      "Epoch: 1251, Avg. Train Loss: 0.002716749955271912, Avg. Test Loss: 0.0028995557222515345\n",
      "Epoch: 1252, Avg. Train Loss: 0.0026872621004491353, Avg. Test Loss: 0.002882209373638034\n",
      "Epoch: 1253, Avg. Train Loss: 0.0026771579544211544, Avg. Test Loss: 0.0028897167649120092\n",
      "Epoch: 1254, Avg. Train Loss: 0.002689665724891563, Avg. Test Loss: 0.0028793811798095703\n",
      "Epoch: 1255, Avg. Train Loss: 0.002682377161934625, Avg. Test Loss: 0.0028618075884878635\n",
      "Epoch: 1256, Avg. Train Loss: 0.002696070744287829, Avg. Test Loss: 0.002895456040278077\n",
      "Epoch: 1257, Avg. Train Loss: 0.0026940615241264187, Avg. Test Loss: 0.0030382948461920023\n",
      "Epoch: 1258, Avg. Train Loss: 0.002729377893427777, Avg. Test Loss: 0.0028761352878063917\n",
      "Epoch: 1259, Avg. Train Loss: 0.0026783832500493804, Avg. Test Loss: 0.002891137497499585\n",
      "Epoch: 1260, Avg. Train Loss: 0.0026874592646869808, Avg. Test Loss: 0.0029728570953011513\n",
      "Epoch: 1261, Avg. Train Loss: 0.0027236964250373285, Avg. Test Loss: 0.002936334814876318\n",
      "Epoch: 1262, Avg. Train Loss: 0.0027415598526077216, Avg. Test Loss: 0.003247800748795271\n",
      "Epoch: 1263, Avg. Train Loss: 0.002841982790160664, Avg. Test Loss: 0.0028736977837979794\n",
      "Epoch: 1264, Avg. Train Loss: 0.0026811432840605806, Avg. Test Loss: 0.002916354686021805\n",
      "Epoch: 1265, Avg. Train Loss: 0.00269025812726901, Avg. Test Loss: 0.002882178872823715\n",
      "Epoch: 1266, Avg. Train Loss: 0.002679522625755432, Avg. Test Loss: 0.002941075013950467\n",
      "Epoch: 1267, Avg. Train Loss: 0.0027122307178932565, Avg. Test Loss: 0.002914138836786151\n",
      "Epoch: 1268, Avg. Train Loss: 0.0027427451121945713, Avg. Test Loss: 0.003047175705432892\n",
      "Epoch: 1269, Avg. Train Loss: 0.002695360399652706, Avg. Test Loss: 0.0028860685415565968\n",
      "Epoch: 1270, Avg. Train Loss: 0.0026935352618957676, Avg. Test Loss: 0.003045574063435197\n",
      "Epoch: 1271, Avg. Train Loss: 0.002692250518648084, Avg. Test Loss: 0.002918655751273036\n",
      "Epoch: 1272, Avg. Train Loss: 0.0026809750178958787, Avg. Test Loss: 0.0029122072737663984\n",
      "Epoch: 1273, Avg. Train Loss: 0.002707143541598736, Avg. Test Loss: 0.0029401741921901703\n",
      "Epoch: 1274, Avg. Train Loss: 0.0026762577607621287, Avg. Test Loss: 0.002871808595955372\n",
      "Epoch: 1275, Avg. Train Loss: 0.0026934866760965695, Avg. Test Loss: 0.002882045693695545\n",
      "Epoch: 1276, Avg. Train Loss: 0.0026978173314831976, Avg. Test Loss: 0.0028771390207111835\n",
      "Epoch: 1277, Avg. Train Loss: 0.0026841438104680112, Avg. Test Loss: 0.002892089309170842\n",
      "Epoch: 1278, Avg. Train Loss: 0.0026878456444327913, Avg. Test Loss: 0.0028804433532059193\n",
      "Epoch: 1279, Avg. Train Loss: 0.0027283665691610684, Avg. Test Loss: 0.0028811681549996138\n",
      "Epoch: 1280, Avg. Train Loss: 0.002689188443730737, Avg. Test Loss: 0.0029143260326236486\n",
      "Epoch: 1281, Avg. Train Loss: 0.00276718772189735, Avg. Test Loss: 0.002919827587902546\n",
      "Epoch: 1282, Avg. Train Loss: 0.002700985344343407, Avg. Test Loss: 0.0029407129622995853\n",
      "Epoch: 1283, Avg. Train Loss: 0.002703871236854168, Avg. Test Loss: 0.002910392126068473\n",
      "Epoch: 1284, Avg. Train Loss: 0.002686521379537014, Avg. Test Loss: 0.0029242374002933502\n",
      "Epoch: 1285, Avg. Train Loss: 0.0026868797817029234, Avg. Test Loss: 0.002861232729628682\n",
      "Epoch: 1286, Avg. Train Loss: 0.0027001722943211016, Avg. Test Loss: 0.002886825939640403\n",
      "Epoch: 1287, Avg. Train Loss: 0.002690189003641176, Avg. Test Loss: 0.002999930176883936\n",
      "Epoch: 1288, Avg. Train Loss: 0.0027097652742076057, Avg. Test Loss: 0.0029273207765072584\n",
      "Epoch: 1289, Avg. Train Loss: 0.002668398616532254, Avg. Test Loss: 0.0029447663109749556\n",
      "Epoch: 1290, Avg. Train Loss: 0.0026778182296385597, Avg. Test Loss: 0.0028777234256267548\n",
      "Epoch: 1291, Avg. Train Loss: 0.0026815630235644274, Avg. Test Loss: 0.0029085895512253046\n",
      "Epoch: 1292, Avg. Train Loss: 0.0026904027584160484, Avg. Test Loss: 0.0029090179596096277\n",
      "Epoch: 1293, Avg. Train Loss: 0.002701173991311428, Avg. Test Loss: 0.002870470518246293\n",
      "Epoch: 1294, Avg. Train Loss: 0.002706295025513269, Avg. Test Loss: 0.002874871948733926\n",
      "Epoch: 1295, Avg. Train Loss: 0.0026997164985554855, Avg. Test Loss: 0.0029571352060884237\n",
      "Epoch: 1296, Avg. Train Loss: 0.0026871034994634777, Avg. Test Loss: 0.002860097214579582\n",
      "Epoch: 1297, Avg. Train Loss: 0.002733104055487486, Avg. Test Loss: 0.002886140253394842\n",
      "Epoch: 1298, Avg. Train Loss: 0.002703343144466364, Avg. Test Loss: 0.002905541565269232\n",
      "Epoch: 1299, Avg. Train Loss: 0.002694052801099281, Avg. Test Loss: 0.0028822303283959627\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1300, Avg. Train Loss: 0.0026899461287918478, Avg. Test Loss: 0.0029027839191257954\n",
      "Epoch: 1301, Avg. Train Loss: 0.0026891714687524147, Avg. Test Loss: 0.002867778530344367\n",
      "Epoch: 1302, Avg. Train Loss: 0.002735271611315913, Avg. Test Loss: 0.0029099425300955772\n",
      "Epoch: 1303, Avg. Train Loss: 0.002681920591871752, Avg. Test Loss: 0.0029265922494232655\n",
      "Epoch: 1304, Avg. Train Loss: 0.00267998319184191, Avg. Test Loss: 0.002916111145168543\n",
      "Epoch: 1305, Avg. Train Loss: 0.002694219513254803, Avg. Test Loss: 0.0028891456313431263\n",
      "Epoch: 1306, Avg. Train Loss: 0.0026866794498853906, Avg. Test Loss: 0.002879582578316331\n",
      "Epoch: 1307, Avg. Train Loss: 0.0027005956291632598, Avg. Test Loss: 0.0028572347946465015\n",
      "Epoch: 1308, Avg. Train Loss: 0.0027206446650589623, Avg. Test Loss: 0.002889249473810196\n",
      "Epoch: 1309, Avg. Train Loss: 0.0026880093135459478, Avg. Test Loss: 0.002956402488052845\n",
      "Epoch: 1310, Avg. Train Loss: 0.00267782449982194, Avg. Test Loss: 0.0028539111372083426\n",
      "Epoch: 1311, Avg. Train Loss: 0.0026815164141183677, Avg. Test Loss: 0.00286688469350338\n",
      "Epoch: 1312, Avg. Train Loss: 0.002673887284905758, Avg. Test Loss: 0.0028701445553451777\n",
      "Epoch: 1313, Avg. Train Loss: 0.0026778311815199465, Avg. Test Loss: 0.0028678146190941334\n",
      "Epoch: 1314, Avg. Train Loss: 0.0026909242503258377, Avg. Test Loss: 0.0029329496901482344\n",
      "Epoch: 1315, Avg. Train Loss: 0.002707008797632054, Avg. Test Loss: 0.002866988070309162\n",
      "Epoch: 1316, Avg. Train Loss: 0.0027282917005724684, Avg. Test Loss: 0.0029344079084694386\n",
      "Epoch: 1317, Avg. Train Loss: 0.0026920282249447217, Avg. Test Loss: 0.002868985990062356\n",
      "Epoch: 1318, Avg. Train Loss: 0.0026737803831523243, Avg. Test Loss: 0.0028933510184288025\n",
      "Epoch: 1319, Avg. Train Loss: 0.0026884248837568733, Avg. Test Loss: 0.0028698428068310022\n",
      "Epoch: 1320, Avg. Train Loss: 0.0026872774726862825, Avg. Test Loss: 0.0029947382863610983\n",
      "Epoch: 1321, Avg. Train Loss: 0.002692728953132796, Avg. Test Loss: 0.0028964076191186905\n",
      "Epoch: 1322, Avg. Train Loss: 0.0026960290621879488, Avg. Test Loss: 0.002867467701435089\n",
      "Epoch: 1323, Avg. Train Loss: 0.0026928880793410676, Avg. Test Loss: 0.002859905594959855\n",
      "Epoch: 1324, Avg. Train Loss: 0.002689865591047808, Avg. Test Loss: 0.0028670341707766056\n",
      "Epoch: 1325, Avg. Train Loss: 0.0027204829993722744, Avg. Test Loss: 0.002943654777482152\n",
      "Epoch: 1326, Avg. Train Loss: 0.0026878302559516457, Avg. Test Loss: 0.0029132943600416183\n",
      "Epoch: 1327, Avg. Train Loss: 0.002695239300644675, Avg. Test Loss: 0.00296006933785975\n",
      "Epoch: 1328, Avg. Train Loss: 0.0026930319686788457, Avg. Test Loss: 0.0028614234179258347\n",
      "Epoch: 1329, Avg. Train Loss: 0.0026884046978815353, Avg. Test Loss: 0.00287236669100821\n",
      "Epoch: 1330, Avg. Train Loss: 0.002707486945139461, Avg. Test Loss: 0.0028915100265294313\n",
      "Epoch: 1331, Avg. Train Loss: 0.00268537416880907, Avg. Test Loss: 0.0028902366757392883\n",
      "Epoch: 1332, Avg. Train Loss: 0.0026758985030789707, Avg. Test Loss: 0.0028973857406526804\n",
      "Epoch: 1333, Avg. Train Loss: 0.002703562833715317, Avg. Test Loss: 0.003013189882040024\n",
      "Epoch: 1334, Avg. Train Loss: 0.0026887591040238392, Avg. Test Loss: 0.002858963096514344\n",
      "Epoch: 1335, Avg. Train Loss: 0.0026739519468487, Avg. Test Loss: 0.0030779403168708086\n",
      "Epoch: 1336, Avg. Train Loss: 0.0027205284609091145, Avg. Test Loss: 0.002872335957363248\n",
      "Epoch: 1337, Avg. Train Loss: 0.0026992787986040807, Avg. Test Loss: 0.002846166491508484\n",
      "Epoch: 1338, Avg. Train Loss: 0.0026857047504203957, Avg. Test Loss: 0.0030179594177752733\n",
      "Epoch: 1339, Avg. Train Loss: 0.002733494171352927, Avg. Test Loss: 0.002903875894844532\n",
      "Epoch: 1340, Avg. Train Loss: 0.002743518867984761, Avg. Test Loss: 0.00287826219573617\n",
      "Epoch: 1341, Avg. Train Loss: 0.002679872830116818, Avg. Test Loss: 0.0028974630404263735\n",
      "Epoch: 1342, Avg. Train Loss: 0.0027047013051721244, Avg. Test Loss: 0.0028847199864685535\n",
      "Epoch: 1343, Avg. Train Loss: 0.0026779785037560518, Avg. Test Loss: 0.0028673906344920397\n",
      "Epoch: 1344, Avg. Train Loss: 0.0026762137774291425, Avg. Test Loss: 0.0028620415832847357\n",
      "Epoch: 1345, Avg. Train Loss: 0.0026927175336019242, Avg. Test Loss: 0.00285756285302341\n",
      "Epoch: 1346, Avg. Train Loss: 0.00269396553292524, Avg. Test Loss: 0.0029076493810862303\n",
      "Epoch: 1347, Avg. Train Loss: 0.0026681371423047644, Avg. Test Loss: 0.0029894907493144274\n",
      "Epoch: 1348, Avg. Train Loss: 0.0026924981096716123, Avg. Test Loss: 0.0029324316419661045\n",
      "Epoch: 1349, Avg. Train Loss: 0.0026518909238971945, Avg. Test Loss: 0.0028630385641008615\n",
      "Epoch: 1350, Avg. Train Loss: 0.0026495072579141273, Avg. Test Loss: 0.0028520890045911074\n",
      "Epoch: 1351, Avg. Train Loss: 0.0026611108007992424, Avg. Test Loss: 0.0028660213574767113\n",
      "Epoch: 1352, Avg. Train Loss: 0.0026952589288094016, Avg. Test Loss: 0.0029115404468029737\n",
      "Epoch: 1353, Avg. Train Loss: 0.0026952147830364317, Avg. Test Loss: 0.002859468339011073\n",
      "Epoch: 1354, Avg. Train Loss: 0.00267503218898593, Avg. Test Loss: 0.0029437304474413395\n",
      "Epoch: 1355, Avg. Train Loss: 0.0026779412183650705, Avg. Test Loss: 0.002936561359092593\n",
      "Epoch: 1356, Avg. Train Loss: 0.0026756622016343265, Avg. Test Loss: 0.0028528922703117132\n",
      "Epoch: 1357, Avg. Train Loss: 0.0026764499868244624, Avg. Test Loss: 0.0028493471909314394\n",
      "Epoch: 1358, Avg. Train Loss: 0.0026756857067000033, Avg. Test Loss: 0.002945572603493929\n",
      "Epoch: 1359, Avg. Train Loss: 0.002717534935664992, Avg. Test Loss: 0.002881356980651617\n",
      "Epoch: 1360, Avg. Train Loss: 0.002669257989023314, Avg. Test Loss: 0.0028511309064924717\n",
      "Epoch: 1361, Avg. Train Loss: 0.0026676783576434437, Avg. Test Loss: 0.00285372044891119\n",
      "Epoch: 1362, Avg. Train Loss: 0.002670738077181023, Avg. Test Loss: 0.0029217188712209463\n",
      "Epoch: 1363, Avg. Train Loss: 0.002754855002168306, Avg. Test Loss: 0.0028757110703736544\n",
      "Epoch: 1364, Avg. Train Loss: 0.0027131248687848795, Avg. Test Loss: 0.002936252625659108\n",
      "Epoch: 1365, Avg. Train Loss: 0.002664527915374831, Avg. Test Loss: 0.0028790952637791634\n",
      "Epoch: 1366, Avg. Train Loss: 0.002692195462322859, Avg. Test Loss: 0.0028699946124106646\n",
      "Epoch: 1367, Avg. Train Loss: 0.002733807220275319, Avg. Test Loss: 0.0028775327373296022\n",
      "Epoch: 1368, Avg. Train Loss: 0.0026910968752967756, Avg. Test Loss: 0.0028640003874897957\n",
      "Epoch: 1369, Avg. Train Loss: 0.0026998486759704215, Avg. Test Loss: 0.00285624573007226\n",
      "Epoch: 1370, Avg. Train Loss: 0.0026619175914674997, Avg. Test Loss: 0.002889808267354965\n",
      "Epoch: 1371, Avg. Train Loss: 0.00267862907589175, Avg. Test Loss: 0.002860607346519828\n",
      "Epoch: 1372, Avg. Train Loss: 0.002675174264410554, Avg. Test Loss: 0.0030632445123046637\n",
      "Epoch: 1373, Avg. Train Loss: 0.002669899302079927, Avg. Test Loss: 0.002839508233591914\n",
      "Epoch: 1374, Avg. Train Loss: 0.0026841343510462796, Avg. Test Loss: 0.0028493183199316263\n",
      "Epoch: 1375, Avg. Train Loss: 0.0026569889620119747, Avg. Test Loss: 0.0029726859647780657\n",
      "Epoch: 1376, Avg. Train Loss: 0.002660796869286271, Avg. Test Loss: 0.0028950178530067205\n",
      "Epoch: 1377, Avg. Train Loss: 0.0026600826477501975, Avg. Test Loss: 0.0028557972982525826\n",
      "Epoch: 1378, Avg. Train Loss: 0.002672854464414508, Avg. Test Loss: 0.003023639554157853\n",
      "Epoch: 1379, Avg. Train Loss: 0.002711901251703154, Avg. Test Loss: 0.0028557574842125177\n",
      "Epoch: 1380, Avg. Train Loss: 0.002676575309272076, Avg. Test Loss: 0.0028770368080586195\n",
      "Epoch: 1381, Avg. Train Loss: 0.002663872535015608, Avg. Test Loss: 0.002850916236639023\n",
      "Epoch: 1382, Avg. Train Loss: 0.002697116359635148, Avg. Test Loss: 0.0029374887235462666\n",
      "Epoch: 1383, Avg. Train Loss: 0.002724527771216492, Avg. Test Loss: 0.003188083181157708\n",
      "Epoch: 1384, Avg. Train Loss: 0.0027575911791605312, Avg. Test Loss: 0.002858554245904088\n",
      "Epoch: 1385, Avg. Train Loss: 0.0026769321249408085, Avg. Test Loss: 0.002873616758733988\n",
      "Epoch: 1386, Avg. Train Loss: 0.0026768006460178035, Avg. Test Loss: 0.0028742640279233456\n",
      "Epoch: 1387, Avg. Train Loss: 0.0026644672873581566, Avg. Test Loss: 0.002853602170944214\n",
      "Epoch: 1388, Avg. Train Loss: 0.0026778314684972513, Avg. Test Loss: 0.0028868692461401224\n",
      "Epoch: 1389, Avg. Train Loss: 0.002686342500626694, Avg. Test Loss: 0.0028633447363972664\n",
      "Epoch: 1390, Avg. Train Loss: 0.0026627586136550403, Avg. Test Loss: 0.0029198613483458757\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1391, Avg. Train Loss: 0.002697114009670047, Avg. Test Loss: 0.002858181484043598\n",
      "Epoch: 1392, Avg. Train Loss: 0.0026631633382897045, Avg. Test Loss: 0.002853811951354146\n",
      "Epoch: 1393, Avg. Train Loss: 0.0026533828376857347, Avg. Test Loss: 0.002936952980235219\n",
      "Epoch: 1394, Avg. Train Loss: 0.0026722384324340625, Avg. Test Loss: 0.0029022078961133957\n",
      "Epoch: 1395, Avg. Train Loss: 0.0026788428793986176, Avg. Test Loss: 0.002852617297321558\n",
      "Epoch: 1396, Avg. Train Loss: 0.002712883472139406, Avg. Test Loss: 0.0028592178132385015\n",
      "Epoch: 1397, Avg. Train Loss: 0.0027325031304255474, Avg. Test Loss: 0.0028901733458042145\n",
      "Epoch: 1398, Avg. Train Loss: 0.0027008640449927295, Avg. Test Loss: 0.002836892381310463\n",
      "Epoch: 1399, Avg. Train Loss: 0.0026655846362023854, Avg. Test Loss: 0.002902824664488435\n",
      "Epoch: 1400, Avg. Train Loss: 0.0026783465656863396, Avg. Test Loss: 0.003095625201240182\n",
      "Epoch: 1401, Avg. Train Loss: 0.002691237028514923, Avg. Test Loss: 0.0029408596456050873\n",
      "Epoch: 1402, Avg. Train Loss: 0.002662087877302669, Avg. Test Loss: 0.0028647740837186575\n",
      "Epoch: 1403, Avg. Train Loss: 0.002680716500076097, Avg. Test Loss: 0.002845572540536523\n",
      "Epoch: 1404, Avg. Train Loss: 0.0026730615320767082, Avg. Test Loss: 0.0028552301228046417\n",
      "Epoch: 1405, Avg. Train Loss: 0.0026853784301513156, Avg. Test Loss: 0.002866151509806514\n",
      "Epoch: 1406, Avg. Train Loss: 0.0026643001312000114, Avg. Test Loss: 0.0029202813748270273\n",
      "Epoch: 1407, Avg. Train Loss: 0.002659626960277904, Avg. Test Loss: 0.00284688756801188\n",
      "Epoch: 1408, Avg. Train Loss: 0.002683481125724177, Avg. Test Loss: 0.0028466046787798405\n",
      "Epoch: 1409, Avg. Train Loss: 0.002653260888575121, Avg. Test Loss: 0.0028414158150553703\n",
      "Epoch: 1410, Avg. Train Loss: 0.002671609231985586, Avg. Test Loss: 0.002904847962781787\n",
      "Epoch: 1411, Avg. Train Loss: 0.0027163753199369407, Avg. Test Loss: 0.002944697393104434\n",
      "Epoch: 1412, Avg. Train Loss: 0.0026599680788295214, Avg. Test Loss: 0.0028597896452993155\n",
      "Epoch: 1413, Avg. Train Loss: 0.002665621569640068, Avg. Test Loss: 0.002869528718292713\n",
      "Epoch: 1414, Avg. Train Loss: 0.002654529609825722, Avg. Test Loss: 0.0028561754152178764\n",
      "Epoch: 1415, Avg. Train Loss: 0.002672546326594297, Avg. Test Loss: 0.002933213487267494\n",
      "Epoch: 1416, Avg. Train Loss: 0.002679187712411201, Avg. Test Loss: 0.0028908303938806057\n",
      "Epoch: 1417, Avg. Train Loss: 0.002697921612538224, Avg. Test Loss: 0.002852406818419695\n",
      "Epoch: 1418, Avg. Train Loss: 0.00265055617079312, Avg. Test Loss: 0.00289388676173985\n",
      "Epoch: 1419, Avg. Train Loss: 0.0027132720015076704, Avg. Test Loss: 0.0028622166719287634\n",
      "Epoch: 1420, Avg. Train Loss: 0.0026517536729400936, Avg. Test Loss: 0.002927044639363885\n",
      "Epoch: 1421, Avg. Train Loss: 0.0026706466613727253, Avg. Test Loss: 0.0028609491419047117\n",
      "Epoch: 1422, Avg. Train Loss: 0.002663919279828321, Avg. Test Loss: 0.0028907624073326588\n",
      "Epoch: 1423, Avg. Train Loss: 0.002673591855306958, Avg. Test Loss: 0.0028308716136962175\n",
      "Epoch: 1424, Avg. Train Loss: 0.002664457048224502, Avg. Test Loss: 0.0028542347718030214\n",
      "Epoch: 1425, Avg. Train Loss: 0.00268010928858678, Avg. Test Loss: 0.0028871221002191305\n",
      "Epoch: 1426, Avg. Train Loss: 0.002693177352464476, Avg. Test Loss: 0.00285944901406765\n",
      "Epoch: 1427, Avg. Train Loss: 0.002646302279128238, Avg. Test Loss: 0.0029707623180001974\n",
      "Epoch: 1428, Avg. Train Loss: 0.0026650738761608683, Avg. Test Loss: 0.0029352379497140646\n",
      "Epoch: 1429, Avg. Train Loss: 0.002663504142790686, Avg. Test Loss: 0.0030103668104857206\n",
      "Epoch: 1430, Avg. Train Loss: 0.002666359718585777, Avg. Test Loss: 0.002832369413226843\n",
      "Epoch: 1431, Avg. Train Loss: 0.0026524972798692625, Avg. Test Loss: 0.002860748441889882\n",
      "Epoch: 1432, Avg. Train Loss: 0.002648302386406549, Avg. Test Loss: 0.002841547131538391\n",
      "Epoch: 1433, Avg. Train Loss: 0.002700065273445013, Avg. Test Loss: 0.0028558240737766027\n",
      "Epoch: 1434, Avg. Train Loss: 0.0027424989127402388, Avg. Test Loss: 0.002921371255069971\n",
      "Epoch: 1435, Avg. Train Loss: 0.0026630629882822897, Avg. Test Loss: 0.00284755346365273\n",
      "Epoch: 1436, Avg. Train Loss: 0.0026655228169591622, Avg. Test Loss: 0.002990578766912222\n",
      "Epoch: 1437, Avg. Train Loss: 0.0026938465781249973, Avg. Test Loss: 0.002892022021114826\n",
      "Epoch: 1438, Avg. Train Loss: 0.0026537412560956423, Avg. Test Loss: 0.002839092630892992\n",
      "Epoch: 1439, Avg. Train Loss: 0.002667703173058324, Avg. Test Loss: 0.0028456703294068575\n",
      "Epoch: 1440, Avg. Train Loss: 0.002669220183824384, Avg. Test Loss: 0.002883318578824401\n",
      "Epoch: 1441, Avg. Train Loss: 0.00275205816467141, Avg. Test Loss: 0.0029822904616594315\n",
      "Epoch: 1442, Avg. Train Loss: 0.002686733287910736, Avg. Test Loss: 0.002912251278758049\n",
      "Epoch: 1443, Avg. Train Loss: 0.0026509627634875997, Avg. Test Loss: 0.0028835118282586336\n",
      "Epoch: 1444, Avg. Train Loss: 0.0026607141602611128, Avg. Test Loss: 0.0028364474419504404\n",
      "Epoch: 1445, Avg. Train Loss: 0.002666457252966803, Avg. Test Loss: 0.0028673650231212378\n",
      "Epoch: 1446, Avg. Train Loss: 0.002706083263335533, Avg. Test Loss: 0.0028527129907160997\n",
      "Epoch: 1447, Avg. Train Loss: 0.002677539488040777, Avg. Test Loss: 0.0029826071113348007\n",
      "Epoch: 1448, Avg. Train Loss: 0.0027180353915968606, Avg. Test Loss: 0.0028441688045859337\n",
      "Epoch: 1449, Avg. Train Loss: 0.002656061662534295, Avg. Test Loss: 0.0028695689979940653\n",
      "Epoch: 1450, Avg. Train Loss: 0.0026433395037730764, Avg. Test Loss: 0.0028440996538847685\n",
      "Epoch: 1451, Avg. Train Loss: 0.0026497897302168744, Avg. Test Loss: 0.0028689957689493895\n",
      "Epoch: 1452, Avg. Train Loss: 0.002668412515980213, Avg. Test Loss: 0.002856980077922344\n",
      "Epoch: 1453, Avg. Train Loss: 0.0026883568430622648, Avg. Test Loss: 0.002867467002943158\n",
      "Epoch: 1454, Avg. Train Loss: 0.0027421763989814493, Avg. Test Loss: 0.0029575428925454617\n",
      "Epoch: 1455, Avg. Train Loss: 0.0027266839616607095, Avg. Test Loss: 0.002930267481133342\n",
      "Epoch: 1456, Avg. Train Loss: 0.0026662008847694756, Avg. Test Loss: 0.002845994895324111\n",
      "Epoch: 1457, Avg. Train Loss: 0.0026557998634268378, Avg. Test Loss: 0.0028508324176073074\n",
      "Epoch: 1458, Avg. Train Loss: 0.0026442228686497653, Avg. Test Loss: 0.0028569099958986044\n",
      "Epoch: 1459, Avg. Train Loss: 0.002668072187969851, Avg. Test Loss: 0.002877000020816922\n",
      "Epoch: 1460, Avg. Train Loss: 0.0026728664199973263, Avg. Test Loss: 0.002828079042956233\n",
      "Epoch: 1461, Avg. Train Loss: 0.002646116225785294, Avg. Test Loss: 0.0029020896181464195\n",
      "Epoch: 1462, Avg. Train Loss: 0.002661369475644342, Avg. Test Loss: 0.0028427010402083397\n",
      "Epoch: 1463, Avg. Train Loss: 0.002640407483721542, Avg. Test Loss: 0.0028356527909636497\n",
      "Epoch: 1464, Avg. Train Loss: 0.0026637406554073095, Avg. Test Loss: 0.002954186173155904\n",
      "Epoch: 1465, Avg. Train Loss: 0.0026633771851139014, Avg. Test Loss: 0.0029442026279866695\n",
      "Epoch: 1466, Avg. Train Loss: 0.0027216154605496762, Avg. Test Loss: 0.0029127735178917646\n",
      "Epoch: 1467, Avg. Train Loss: 0.0026506160299272037, Avg. Test Loss: 0.002826566342264414\n",
      "Epoch: 1468, Avg. Train Loss: 0.0027042462187277716, Avg. Test Loss: 0.002862457651644945\n",
      "Epoch: 1469, Avg. Train Loss: 0.00266346650003174, Avg. Test Loss: 0.0029009238351136446\n",
      "Epoch: 1470, Avg. Train Loss: 0.002672808217751079, Avg. Test Loss: 0.0028567530680447817\n",
      "Epoch: 1471, Avg. Train Loss: 0.0026486031277928243, Avg. Test Loss: 0.002855574944987893\n",
      "Epoch: 1472, Avg. Train Loss: 0.0026920255717583176, Avg. Test Loss: 0.002842869609594345\n",
      "Epoch: 1473, Avg. Train Loss: 0.0026498159588596156, Avg. Test Loss: 0.002905284520238638\n",
      "Epoch: 1474, Avg. Train Loss: 0.002661375783730385, Avg. Test Loss: 0.002884446643292904\n",
      "Epoch: 1475, Avg. Train Loss: 0.002647164321049701, Avg. Test Loss: 0.002826498355716467\n",
      "Epoch: 1476, Avg. Train Loss: 0.0026424463383506896, Avg. Test Loss: 0.0028938499744981527\n",
      "Epoch: 1477, Avg. Train Loss: 0.002658909392478161, Avg. Test Loss: 0.00286143203265965\n",
      "Epoch: 1478, Avg. Train Loss: 0.0026607457981553187, Avg. Test Loss: 0.0029360419139266014\n",
      "Epoch: 1479, Avg. Train Loss: 0.002670868402780142, Avg. Test Loss: 0.002985397819429636\n",
      "Epoch: 1480, Avg. Train Loss: 0.002720116583500491, Avg. Test Loss: 0.002894794102758169\n",
      "Epoch: 1481, Avg. Train Loss: 0.0026511533922234246, Avg. Test Loss: 0.0029042400419712067\n",
      "Epoch: 1482, Avg. Train Loss: 0.002642268650666919, Avg. Test Loss: 0.002894309349358082\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1483, Avg. Train Loss: 0.002656462845977309, Avg. Test Loss: 0.0028362437151372433\n",
      "Epoch: 1484, Avg. Train Loss: 0.0026419523150421854, Avg. Test Loss: 0.002847280353307724\n",
      "Epoch: 1485, Avg. Train Loss: 0.0026591242789182554, Avg. Test Loss: 0.002902386710047722\n",
      "Epoch: 1486, Avg. Train Loss: 0.002653878869835374, Avg. Test Loss: 0.002871220698580146\n",
      "Epoch: 1487, Avg. Train Loss: 0.002663523532710103, Avg. Test Loss: 0.002982845762744546\n",
      "Epoch: 1488, Avg. Train Loss: 0.002683225304408129, Avg. Test Loss: 0.0028720952104777098\n",
      "Epoch: 1489, Avg. Train Loss: 0.0026617706428433575, Avg. Test Loss: 0.0028328062035143375\n",
      "Epoch: 1490, Avg. Train Loss: 0.0026479523986318084, Avg. Test Loss: 0.002836344763636589\n",
      "Epoch: 1491, Avg. Train Loss: 0.0026757513432828493, Avg. Test Loss: 0.002853528130799532\n",
      "Epoch: 1492, Avg. Train Loss: 0.0026537410557529954, Avg. Test Loss: 0.002838140819221735\n",
      "Epoch: 1493, Avg. Train Loss: 0.00274597839344033, Avg. Test Loss: 0.0028858548030257225\n",
      "Epoch: 1494, Avg. Train Loss: 0.00263401523752268, Avg. Test Loss: 0.002852122997865081\n",
      "Epoch: 1495, Avg. Train Loss: 0.002681402608665616, Avg. Test Loss: 0.002883733483031392\n",
      "Epoch: 1496, Avg. Train Loss: 0.0026498712480154843, Avg. Test Loss: 0.002865386661142111\n",
      "Epoch: 1497, Avg. Train Loss: 0.0026733428510555693, Avg. Test Loss: 0.002852445002645254\n",
      "Epoch: 1498, Avg. Train Loss: 0.0026535778252277957, Avg. Test Loss: 0.002837533364072442\n",
      "Epoch: 1499, Avg. Train Loss: 0.0026710385045166625, Avg. Test Loss: 0.0028611402958631516\n",
      "Epoch: 1500, Avg. Train Loss: 0.002674763247933845, Avg. Test Loss: 0.0029060423839837313\n",
      "Epoch: 1501, Avg. Train Loss: 0.002640797177243025, Avg. Test Loss: 0.002832954516634345\n",
      "Epoch: 1502, Avg. Train Loss: 0.0026463348645890173, Avg. Test Loss: 0.002831559395417571\n",
      "Epoch: 1503, Avg. Train Loss: 0.0026614140545906024, Avg. Test Loss: 0.002926415065303445\n",
      "Epoch: 1504, Avg. Train Loss: 0.002667034337253765, Avg. Test Loss: 0.0032829914707690477\n",
      "Epoch: 1505, Avg. Train Loss: 0.0026684478899940503, Avg. Test Loss: 0.002824724419042468\n",
      "Epoch: 1506, Avg. Train Loss: 0.0026507460793783496, Avg. Test Loss: 0.0028374907560646534\n",
      "Epoch: 1507, Avg. Train Loss: 0.002689409172595587, Avg. Test Loss: 0.0028283519204705954\n",
      "Epoch: 1508, Avg. Train Loss: 0.002641242019139057, Avg. Test Loss: 0.002823821036145091\n",
      "Epoch: 1509, Avg. Train Loss: 0.0027001763065887053, Avg. Test Loss: 0.0028549369890242815\n",
      "Epoch: 1510, Avg. Train Loss: 0.0026543748478383518, Avg. Test Loss: 0.0028606595005840063\n",
      "Epoch: 1511, Avg. Train Loss: 0.0026413524458401426, Avg. Test Loss: 0.002843444235622883\n",
      "Epoch: 1512, Avg. Train Loss: 0.002649245404660009, Avg. Test Loss: 0.002833083039149642\n",
      "Epoch: 1513, Avg. Train Loss: 0.0026345293709011965, Avg. Test Loss: 0.0028502652421593666\n",
      "Epoch: 1514, Avg. Train Loss: 0.002634953528772606, Avg. Test Loss: 0.002832506550475955\n",
      "Epoch: 1515, Avg. Train Loss: 0.0026573135658318914, Avg. Test Loss: 0.0029197288677096367\n",
      "Epoch: 1516, Avg. Train Loss: 0.0026637205886546264, Avg. Test Loss: 0.0028752542566508055\n",
      "Epoch: 1517, Avg. Train Loss: 0.002715650664339232, Avg. Test Loss: 0.0030375595670193434\n",
      "Epoch: 1518, Avg. Train Loss: 0.0026752834944704243, Avg. Test Loss: 0.0028342583682388067\n",
      "Epoch: 1519, Avg. Train Loss: 0.0026454897651578798, Avg. Test Loss: 0.002823740243911743\n",
      "Epoch: 1520, Avg. Train Loss: 0.002624325622089727, Avg. Test Loss: 0.0028442824259400368\n",
      "Epoch: 1521, Avg. Train Loss: 0.0026704862410592478, Avg. Test Loss: 0.002955508651211858\n",
      "Epoch: 1522, Avg. Train Loss: 0.0026592049357849496, Avg. Test Loss: 0.0028504696674644947\n",
      "Epoch: 1523, Avg. Train Loss: 0.002643596852024974, Avg. Test Loss: 0.0028416370041668415\n",
      "Epoch: 1524, Avg. Train Loss: 0.0026487671542739454, Avg. Test Loss: 0.0028290071059018373\n",
      "Epoch: 1525, Avg. Train Loss: 0.0026851829011426413, Avg. Test Loss: 0.0028509129770100117\n",
      "Epoch: 1526, Avg. Train Loss: 0.00264897744907716, Avg. Test Loss: 0.002873101504519582\n",
      "Epoch: 1527, Avg. Train Loss: 0.002657041251442807, Avg. Test Loss: 0.0028405676130205393\n",
      "Epoch: 1528, Avg. Train Loss: 0.002628005705340657, Avg. Test Loss: 0.002858246909454465\n",
      "Epoch: 1529, Avg. Train Loss: 0.002653482185979915, Avg. Test Loss: 0.0030940675642341375\n",
      "Epoch: 1530, Avg. Train Loss: 0.0026533271424299064, Avg. Test Loss: 0.0028519558254629374\n",
      "Epoch: 1531, Avg. Train Loss: 0.0026637831497071094, Avg. Test Loss: 0.0028177679050713778\n",
      "Epoch: 1532, Avg. Train Loss: 0.0026445422798048617, Avg. Test Loss: 0.002993565984070301\n",
      "Epoch: 1533, Avg. Train Loss: 0.002669276631718805, Avg. Test Loss: 0.0028241474647074938\n",
      "Epoch: 1534, Avg. Train Loss: 0.0026352343983341788, Avg. Test Loss: 0.0028809136711061\n",
      "Epoch: 1535, Avg. Train Loss: 0.0026334766190239164, Avg. Test Loss: 0.0028501811902970076\n",
      "Epoch: 1536, Avg. Train Loss: 0.002666545376658093, Avg. Test Loss: 0.00294558540917933\n",
      "Epoch: 1537, Avg. Train Loss: 0.0026569154254312433, Avg. Test Loss: 0.0028456938453018665\n",
      "Epoch: 1538, Avg. Train Loss: 0.0026427576599945854, Avg. Test Loss: 0.002988371765241027\n",
      "Epoch: 1539, Avg. Train Loss: 0.0026769142619572405, Avg. Test Loss: 0.0028286902233958244\n",
      "Epoch: 1540, Avg. Train Loss: 0.0026428058342791573, Avg. Test Loss: 0.0028418360743671656\n",
      "Epoch: 1541, Avg. Train Loss: 0.0026505784900469143, Avg. Test Loss: 0.0028259914834052324\n",
      "Epoch: 1542, Avg. Train Loss: 0.002700441051274538, Avg. Test Loss: 0.002826636889949441\n",
      "Epoch: 1543, Avg. Train Loss: 0.0027277168850306163, Avg. Test Loss: 0.0028430514503270388\n",
      "Epoch: 1544, Avg. Train Loss: 0.0027163501579834277, Avg. Test Loss: 0.0028458551969379187\n",
      "Epoch: 1545, Avg. Train Loss: 0.0026528527147981315, Avg. Test Loss: 0.0028324939776211977\n",
      "Epoch: 1546, Avg. Train Loss: 0.002631364487718011, Avg. Test Loss: 0.002817724132910371\n",
      "Epoch: 1547, Avg. Train Loss: 0.0026217202363579078, Avg. Test Loss: 0.002860697917640209\n",
      "Epoch: 1548, Avg. Train Loss: 0.0026387838906673498, Avg. Test Loss: 0.002924572676420212\n",
      "Epoch: 1549, Avg. Train Loss: 0.0026538361968515916, Avg. Test Loss: 0.002818342298269272\n",
      "Epoch: 1550, Avg. Train Loss: 0.002645231842951373, Avg. Test Loss: 0.002901826985180378\n",
      "Epoch: 1551, Avg. Train Loss: 0.002645666434884418, Avg. Test Loss: 0.0028615964110940695\n",
      "Epoch: 1552, Avg. Train Loss: 0.0026679676199375195, Avg. Test Loss: 0.0028873418923467398\n",
      "Epoch: 1553, Avg. Train Loss: 0.002637889366163764, Avg. Test Loss: 0.0028310627676546574\n",
      "Epoch: 1554, Avg. Train Loss: 0.0026850368621824093, Avg. Test Loss: 0.002892955206334591\n",
      "Epoch: 1555, Avg. Train Loss: 0.0026505626846364764, Avg. Test Loss: 0.002826259471476078\n",
      "Epoch: 1556, Avg. Train Loss: 0.0026543852060946613, Avg. Test Loss: 0.0028469169046729803\n",
      "Epoch: 1557, Avg. Train Loss: 0.0027001845152225604, Avg. Test Loss: 0.0028922425117343664\n",
      "Epoch: 1558, Avg. Train Loss: 0.0026483572911211225, Avg. Test Loss: 0.0029072267934679985\n",
      "Epoch: 1559, Avg. Train Loss: 0.002632198654938229, Avg. Test Loss: 0.002876282436773181\n",
      "Epoch: 1560, Avg. Train Loss: 0.0026724778148237358, Avg. Test Loss: 0.0028451671823859215\n",
      "Epoch: 1561, Avg. Train Loss: 0.0027003216633010047, Avg. Test Loss: 0.0028393540997058153\n",
      "Epoch: 1562, Avg. Train Loss: 0.002627340513606404, Avg. Test Loss: 0.002856089733541012\n",
      "Epoch: 1563, Avg. Train Loss: 0.0026313023598388183, Avg. Test Loss: 0.002822086215019226\n",
      "Epoch: 1564, Avg. Train Loss: 0.0026597901149977778, Avg. Test Loss: 0.0028400018345564604\n",
      "Epoch: 1565, Avg. Train Loss: 0.0026780134229379337, Avg. Test Loss: 0.0028221572283655405\n",
      "Epoch: 1566, Avg. Train Loss: 0.002627946192745206, Avg. Test Loss: 0.002829924924299121\n",
      "Epoch: 1567, Avg. Train Loss: 0.002671431181519184, Avg. Test Loss: 0.0028312450740486383\n",
      "Epoch: 1568, Avg. Train Loss: 0.0027313535968058332, Avg. Test Loss: 0.0029382319189608097\n",
      "Epoch: 1569, Avg. Train Loss: 0.0026757069538499035, Avg. Test Loss: 0.0028473336715251207\n",
      "Epoch: 1570, Avg. Train Loss: 0.0026378264694019806, Avg. Test Loss: 0.002966331085190177\n",
      "Epoch: 1571, Avg. Train Loss: 0.0026726287269834862, Avg. Test Loss: 0.002894868841394782\n",
      "Epoch: 1572, Avg. Train Loss: 0.0026362815243733484, Avg. Test Loss: 0.0028333833906799555\n",
      "Epoch: 1573, Avg. Train Loss: 0.0026259777883370946, Avg. Test Loss: 0.0028253139462321997\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1574, Avg. Train Loss: 0.0026503067441977736, Avg. Test Loss: 0.0028776938561350107\n",
      "Epoch: 1575, Avg. Train Loss: 0.002635177203215832, Avg. Test Loss: 0.0028383887838572264\n",
      "Epoch: 1576, Avg. Train Loss: 0.0026737358529380587, Avg. Test Loss: 0.003001396544277668\n",
      "Epoch: 1577, Avg. Train Loss: 0.002674666417459416, Avg. Test Loss: 0.0028986549004912376\n",
      "Epoch: 1578, Avg. Train Loss: 0.002644677646458149, Avg. Test Loss: 0.0028345556929707527\n",
      "Epoch: 1579, Avg. Train Loss: 0.002687739625269937, Avg. Test Loss: 0.0028692714404314756\n",
      "Epoch: 1580, Avg. Train Loss: 0.0026195177613475987, Avg. Test Loss: 0.0028600303921848536\n",
      "Epoch: 1581, Avg. Train Loss: 0.0026897036437984814, Avg. Test Loss: 0.0028694814536720514\n",
      "Epoch: 1582, Avg. Train Loss: 0.0026648978237062693, Avg. Test Loss: 0.0032024981919676065\n",
      "Epoch: 1583, Avg. Train Loss: 0.0026672928117562173, Avg. Test Loss: 0.0028257088270038366\n",
      "Epoch: 1584, Avg. Train Loss: 0.002735131431024435, Avg. Test Loss: 0.0029045387636870146\n",
      "Epoch: 1585, Avg. Train Loss: 0.0026336719476899436, Avg. Test Loss: 0.002863506553694606\n",
      "Epoch: 1586, Avg. Train Loss: 0.002644455720952084, Avg. Test Loss: 0.0029084093403071165\n",
      "Epoch: 1587, Avg. Train Loss: 0.0026718692875705484, Avg. Test Loss: 0.002850231248885393\n",
      "Epoch: 1588, Avg. Train Loss: 0.002628930118801289, Avg. Test Loss: 0.0028192265890538692\n",
      "Epoch: 1589, Avg. Train Loss: 0.0026817111146831235, Avg. Test Loss: 0.0029543235432356596\n",
      "Epoch: 1590, Avg. Train Loss: 0.0026666555921871994, Avg. Test Loss: 0.002848582109436393\n",
      "Epoch: 1591, Avg. Train Loss: 0.0026409146971567428, Avg. Test Loss: 0.002840020228177309\n",
      "Epoch: 1592, Avg. Train Loss: 0.0026293442053936943, Avg. Test Loss: 0.0029333471320569515\n",
      "Epoch: 1593, Avg. Train Loss: 0.002701803733226518, Avg. Test Loss: 0.002916553523391485\n",
      "Epoch: 1594, Avg. Train Loss: 0.0026535253462836492, Avg. Test Loss: 0.0029356293380260468\n",
      "Epoch: 1595, Avg. Train Loss: 0.0026574348922558996, Avg. Test Loss: 0.002818373264744878\n",
      "Epoch: 1596, Avg. Train Loss: 0.002669219474503121, Avg. Test Loss: 0.002863749163225293\n",
      "Epoch: 1597, Avg. Train Loss: 0.002627061295518002, Avg. Test Loss: 0.002834490267559886\n",
      "Epoch: 1598, Avg. Train Loss: 0.0026410602163090264, Avg. Test Loss: 0.002868390642106533\n",
      "Epoch: 1599, Avg. Train Loss: 0.0026769534749693648, Avg. Test Loss: 0.0029895883053541183\n",
      "Epoch: 1600, Avg. Train Loss: 0.0026564210230961096, Avg. Test Loss: 0.0028771015349775553\n",
      "Epoch: 1601, Avg. Train Loss: 0.002652611285664661, Avg. Test Loss: 0.0028140328358858824\n",
      "Epoch: 1602, Avg. Train Loss: 0.0026722312525867724, Avg. Test Loss: 0.002837879816070199\n",
      "Epoch: 1603, Avg. Train Loss: 0.002695749730391558, Avg. Test Loss: 0.0028720346745103598\n",
      "Epoch: 1604, Avg. Train Loss: 0.002644045235112656, Avg. Test Loss: 0.0028576678596436977\n",
      "Epoch: 1605, Avg. Train Loss: 0.00263849341548806, Avg. Test Loss: 0.002828300464898348\n",
      "Epoch: 1606, Avg. Train Loss: 0.002632451563163899, Avg. Test Loss: 0.002841448411345482\n",
      "Epoch: 1607, Avg. Train Loss: 0.002644973763719548, Avg. Test Loss: 0.0028289647307246923\n",
      "Epoch: 1608, Avg. Train Loss: 0.002658662472873233, Avg. Test Loss: 0.0028827365022152662\n",
      "Epoch: 1609, Avg. Train Loss: 0.0026606655311445858, Avg. Test Loss: 0.0029175756499171257\n",
      "Epoch: 1610, Avg. Train Loss: 0.002648729137903036, Avg. Test Loss: 0.002826087176799774\n",
      "Epoch: 1611, Avg. Train Loss: 0.0026428313319419704, Avg. Test Loss: 0.0028588525019586086\n",
      "Epoch: 1612, Avg. Train Loss: 0.0026177165347562974, Avg. Test Loss: 0.0028287468012422323\n",
      "Epoch: 1613, Avg. Train Loss: 0.0026306725908503974, Avg. Test Loss: 0.0028150437865406275\n",
      "Epoch: 1614, Avg. Train Loss: 0.002638155978909412, Avg. Test Loss: 0.002841608365997672\n",
      "Epoch: 1615, Avg. Train Loss: 0.0026877588148467068, Avg. Test Loss: 0.0028489548712968826\n",
      "Epoch: 1616, Avg. Train Loss: 0.0027367065357434195, Avg. Test Loss: 0.002829188946634531\n",
      "Epoch: 1617, Avg. Train Loss: 0.002646537053637033, Avg. Test Loss: 0.0028738894034177065\n",
      "Epoch: 1618, Avg. Train Loss: 0.0026507997549637115, Avg. Test Loss: 0.0028331554494798183\n",
      "Epoch: 1619, Avg. Train Loss: 0.0026974284068443056, Avg. Test Loss: 0.0029713085386902094\n",
      "Epoch: 1620, Avg. Train Loss: 0.002654884508702644, Avg. Test Loss: 0.002827872522175312\n",
      "Epoch: 1621, Avg. Train Loss: 0.002696128876143417, Avg. Test Loss: 0.002832146594300866\n",
      "Epoch: 1622, Avg. Train Loss: 0.0026247765284118266, Avg. Test Loss: 0.0028280839323997498\n",
      "Epoch: 1623, Avg. Train Loss: 0.002626932453537403, Avg. Test Loss: 0.0028552175499498844\n",
      "Epoch: 1624, Avg. Train Loss: 0.002689030687432996, Avg. Test Loss: 0.002878544619306922\n",
      "Epoch: 1625, Avg. Train Loss: 0.0026318731956010643, Avg. Test Loss: 0.0028858971782028675\n",
      "Epoch: 1626, Avg. Train Loss: 0.0026369061602582763, Avg. Test Loss: 0.0028520876076072454\n",
      "Epoch: 1627, Avg. Train Loss: 0.0026378093049103436, Avg. Test Loss: 0.0030468341428786516\n",
      "Epoch: 1628, Avg. Train Loss: 0.002666770464329179, Avg. Test Loss: 0.0029021475929766893\n",
      "Epoch: 1629, Avg. Train Loss: 0.002647220844749448, Avg. Test Loss: 0.0028335980605334044\n",
      "Epoch: 1630, Avg. Train Loss: 0.0026256959495502847, Avg. Test Loss: 0.002840632339939475\n",
      "Epoch: 1631, Avg. Train Loss: 0.002637607023813004, Avg. Test Loss: 0.002868451178073883\n",
      "Epoch: 1632, Avg. Train Loss: 0.0026402267854834017, Avg. Test Loss: 0.002915741875767708\n",
      "Epoch: 1633, Avg. Train Loss: 0.002647952371558478, Avg. Test Loss: 0.002829896518960595\n",
      "Epoch: 1634, Avg. Train Loss: 0.00265515020095505, Avg. Test Loss: 0.0028401254676282406\n",
      "Epoch: 1635, Avg. Train Loss: 0.0026835811670956225, Avg. Test Loss: 0.002967118052765727\n",
      "Epoch: 1636, Avg. Train Loss: 0.002665494563231288, Avg. Test Loss: 0.00285122892819345\n",
      "Epoch: 1637, Avg. Train Loss: 0.002662150384208491, Avg. Test Loss: 0.0029655825346708298\n",
      "Epoch: 1638, Avg. Train Loss: 0.0026391225401312113, Avg. Test Loss: 0.0028966234531253576\n",
      "Epoch: 1639, Avg. Train Loss: 0.002673659516974937, Avg. Test Loss: 0.003071682993322611\n",
      "Epoch: 1640, Avg. Train Loss: 0.00264629764417403, Avg. Test Loss: 0.002857208950445056\n",
      "Epoch: 1641, Avg. Train Loss: 0.0026430250524521566, Avg. Test Loss: 0.0028382549062371254\n",
      "Epoch: 1642, Avg. Train Loss: 0.0027311911026752273, Avg. Test Loss: 0.002841441659256816\n",
      "Epoch: 1643, Avg. Train Loss: 0.002620875006974783, Avg. Test Loss: 0.0028579188510775566\n",
      "Epoch: 1644, Avg. Train Loss: 0.0026414019521325827, Avg. Test Loss: 0.0028221027459949255\n",
      "Epoch: 1645, Avg. Train Loss: 0.002623922045364283, Avg. Test Loss: 0.002827585907652974\n",
      "Epoch: 1646, Avg. Train Loss: 0.0026137585383515026, Avg. Test Loss: 0.00283965771086514\n",
      "Epoch: 1647, Avg. Train Loss: 0.002685980627659795, Avg. Test Loss: 0.0029530697502195835\n",
      "Epoch: 1648, Avg. Train Loss: 0.0026456545334482607, Avg. Test Loss: 0.00282593653537333\n",
      "Epoch: 1649, Avg. Train Loss: 0.002646542896061789, Avg. Test Loss: 0.0028420158196240664\n",
      "Epoch: 1650, Avg. Train Loss: 0.0026285847768100887, Avg. Test Loss: 0.0028388379141688347\n",
      "Epoch: 1651, Avg. Train Loss: 0.002645792975631911, Avg. Test Loss: 0.0028293768409639597\n",
      "Epoch: 1652, Avg. Train Loss: 0.0026534693423918513, Avg. Test Loss: 0.002810393227264285\n",
      "Epoch: 1653, Avg. Train Loss: 0.002632796666909789, Avg. Test Loss: 0.0028341489378362894\n",
      "Epoch: 1654, Avg. Train Loss: 0.0026541936243775974, Avg. Test Loss: 0.0028319775592535734\n",
      "Epoch: 1655, Avg. Train Loss: 0.002652901197718673, Avg. Test Loss: 0.002841487992554903\n",
      "Epoch: 1656, Avg. Train Loss: 0.0026757224073070424, Avg. Test Loss: 0.002821974689140916\n",
      "Epoch: 1657, Avg. Train Loss: 0.0026796638023454783, Avg. Test Loss: 0.0028985529206693172\n",
      "Epoch: 1658, Avg. Train Loss: 0.0026327261950300877, Avg. Test Loss: 0.0028077035676687956\n",
      "Epoch: 1659, Avg. Train Loss: 0.0026365689023636106, Avg. Test Loss: 0.0028193353209644556\n",
      "Epoch: 1660, Avg. Train Loss: 0.002634501593663942, Avg. Test Loss: 0.0028183108661323786\n",
      "Epoch: 1661, Avg. Train Loss: 0.002631788434417442, Avg. Test Loss: 0.002850225195288658\n",
      "Epoch: 1662, Avg. Train Loss: 0.002661603849467843, Avg. Test Loss: 0.002878880128264427\n",
      "Epoch: 1663, Avg. Train Loss: 0.002656035060279591, Avg. Test Loss: 0.0028292995411902666\n",
      "Epoch: 1664, Avg. Train Loss: 0.0026782365017678847, Avg. Test Loss: 0.002856503939256072\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1665, Avg. Train Loss: 0.002686144134332967, Avg. Test Loss: 0.0028348034247756004\n",
      "Epoch: 1666, Avg. Train Loss: 0.002669975351065744, Avg. Test Loss: 0.0028733129147440195\n",
      "Epoch: 1667, Avg. Train Loss: 0.0027017917234970386, Avg. Test Loss: 0.002822723938152194\n",
      "Epoch: 1668, Avg. Train Loss: 0.002659630885910849, Avg. Test Loss: 0.002872936660423875\n",
      "Epoch: 1669, Avg. Train Loss: 0.0026515525018493105, Avg. Test Loss: 0.0028520990163087845\n",
      "Epoch: 1670, Avg. Train Loss: 0.0026095243723153376, Avg. Test Loss: 0.0028408048674464226\n",
      "Epoch: 1671, Avg. Train Loss: 0.0026327178402002467, Avg. Test Loss: 0.002949261339381337\n",
      "Epoch: 1672, Avg. Train Loss: 0.002651809573953235, Avg. Test Loss: 0.0028150391299277544\n",
      "Epoch: 1673, Avg. Train Loss: 0.0026405977821627328, Avg. Test Loss: 0.002975685754790902\n",
      "Epoch: 1674, Avg. Train Loss: 0.0026602999383020538, Avg. Test Loss: 0.0029095523059368134\n",
      "Epoch: 1675, Avg. Train Loss: 0.002666246487087635, Avg. Test Loss: 0.002999489661306143\n",
      "Epoch: 1676, Avg. Train Loss: 0.002636565610246603, Avg. Test Loss: 0.002839084016159177\n",
      "Epoch: 1677, Avg. Train Loss: 0.0026213218306386193, Avg. Test Loss: 0.002820872236043215\n",
      "Epoch: 1678, Avg. Train Loss: 0.0026832534552573466, Avg. Test Loss: 0.002818433102220297\n",
      "Epoch: 1679, Avg. Train Loss: 0.0026196272188234466, Avg. Test Loss: 0.002882992848753929\n",
      "Epoch: 1680, Avg. Train Loss: 0.002631817478686571, Avg. Test Loss: 0.002820100635290146\n",
      "Epoch: 1681, Avg. Train Loss: 0.0026544713859208103, Avg. Test Loss: 0.002837185747921467\n",
      "Epoch: 1682, Avg. Train Loss: 0.0026496605308683114, Avg. Test Loss: 0.0028823064640164375\n",
      "Epoch: 1683, Avg. Train Loss: 0.002630812754897877, Avg. Test Loss: 0.0028380483854562044\n",
      "Epoch: 1684, Avg. Train Loss: 0.0026462605320523645, Avg. Test Loss: 0.002907766029238701\n",
      "Epoch: 1685, Avg. Train Loss: 0.0026369023699919845, Avg. Test Loss: 0.0028259512037038803\n",
      "Epoch: 1686, Avg. Train Loss: 0.0026143036706936223, Avg. Test Loss: 0.0028398490976542234\n",
      "Epoch: 1687, Avg. Train Loss: 0.002619616887640468, Avg. Test Loss: 0.0029058270156383514\n",
      "Epoch: 1688, Avg. Train Loss: 0.002662888890522164, Avg. Test Loss: 0.002997930394485593\n",
      "Epoch: 1689, Avg. Train Loss: 0.002639380283653736, Avg. Test Loss: 0.0028517311438918114\n",
      "Epoch: 1690, Avg. Train Loss: 0.0026983395272995843, Avg. Test Loss: 0.0029452419839799404\n",
      "Epoch: 1691, Avg. Train Loss: 0.0026859837410928207, Avg. Test Loss: 0.0028620727825909853\n",
      "Epoch: 1692, Avg. Train Loss: 0.002614906306790058, Avg. Test Loss: 0.002816366031765938\n",
      "Epoch: 1693, Avg. Train Loss: 0.00262092502224584, Avg. Test Loss: 0.0028401350136846304\n",
      "Epoch: 1694, Avg. Train Loss: 0.0026402854154882736, Avg. Test Loss: 0.0028088109102100134\n",
      "Epoch: 1695, Avg. Train Loss: 0.0026390537738713413, Avg. Test Loss: 0.002893410623073578\n",
      "Epoch: 1696, Avg. Train Loss: 0.0026546261587375125, Avg. Test Loss: 0.0028579949866980314\n",
      "Epoch: 1697, Avg. Train Loss: 0.0026268129626852137, Avg. Test Loss: 0.0028899405151605606\n",
      "Epoch: 1698, Avg. Train Loss: 0.0026520463952058276, Avg. Test Loss: 0.0029261827003210783\n",
      "Epoch: 1699, Avg. Train Loss: 0.0026191470733042373, Avg. Test Loss: 0.0029028034768998623\n",
      "Epoch: 1700, Avg. Train Loss: 0.0026443502432558427, Avg. Test Loss: 0.0029183945152908564\n",
      "Epoch: 1701, Avg. Train Loss: 0.0026651829762687515, Avg. Test Loss: 0.0028594909235835075\n",
      "Epoch: 1702, Avg. Train Loss: 0.002642973661855903, Avg. Test Loss: 0.002956477692350745\n",
      "Epoch: 1703, Avg. Train Loss: 0.002631695318403979, Avg. Test Loss: 0.002855455270037055\n",
      "Epoch: 1704, Avg. Train Loss: 0.002638050799019808, Avg. Test Loss: 0.0028420265298336744\n",
      "Epoch: 1705, Avg. Train Loss: 0.0026203419872407995, Avg. Test Loss: 0.002837063744664192\n",
      "Epoch: 1706, Avg. Train Loss: 0.0026194021582256915, Avg. Test Loss: 0.0028541770298033953\n",
      "Epoch: 1707, Avg. Train Loss: 0.0026912610100712194, Avg. Test Loss: 0.0028167571872472763\n",
      "Epoch: 1708, Avg. Train Loss: 0.0027311868629916465, Avg. Test Loss: 0.0028440996538847685\n",
      "Epoch: 1709, Avg. Train Loss: 0.002626654107210248, Avg. Test Loss: 0.002823682501912117\n",
      "Epoch: 1710, Avg. Train Loss: 0.00261930045996641, Avg. Test Loss: 0.002831951016560197\n",
      "Epoch: 1711, Avg. Train Loss: 0.0026632361168171777, Avg. Test Loss: 0.002834634855389595\n",
      "Epoch: 1712, Avg. Train Loss: 0.0026520766469455043, Avg. Test Loss: 0.002810539910569787\n",
      "Epoch: 1713, Avg. Train Loss: 0.002634274394273065, Avg. Test Loss: 0.0028249481692910194\n",
      "Epoch: 1714, Avg. Train Loss: 0.0026179221079706454, Avg. Test Loss: 0.002816243330016732\n",
      "Epoch: 1715, Avg. Train Loss: 0.002632382363730738, Avg. Test Loss: 0.002816008171066642\n",
      "Epoch: 1716, Avg. Train Loss: 0.0026825439553101395, Avg. Test Loss: 0.0028958236798644066\n",
      "Epoch: 1717, Avg. Train Loss: 0.002673018323040979, Avg. Test Loss: 0.002853468293324113\n",
      "Epoch: 1718, Avg. Train Loss: 0.0026283546914021637, Avg. Test Loss: 0.002842743182554841\n",
      "Epoch: 1719, Avg. Train Loss: 0.0026238911546940026, Avg. Test Loss: 0.002836397150531411\n",
      "Epoch: 1720, Avg. Train Loss: 0.0026163888911088537, Avg. Test Loss: 0.002849763259291649\n",
      "Epoch: 1721, Avg. Train Loss: 0.0026406782386867804, Avg. Test Loss: 0.0031525257509201765\n",
      "Epoch: 1722, Avg. Train Loss: 0.0026416729182698008, Avg. Test Loss: 0.002878997242078185\n",
      "Epoch: 1723, Avg. Train Loss: 0.0026460501181264947, Avg. Test Loss: 0.0028110407292842865\n",
      "Epoch: 1724, Avg. Train Loss: 0.002641821967784402, Avg. Test Loss: 0.0028115513268858194\n",
      "Epoch: 1725, Avg. Train Loss: 0.0026112543364856826, Avg. Test Loss: 0.0028074122965335846\n",
      "Epoch: 1726, Avg. Train Loss: 0.002626766894705767, Avg. Test Loss: 0.0029272036626935005\n",
      "Epoch: 1727, Avg. Train Loss: 0.002625845778776809, Avg. Test Loss: 0.002966033760458231\n",
      "Epoch: 1728, Avg. Train Loss: 0.0027038126501666253, Avg. Test Loss: 0.0029313114937394857\n",
      "Epoch: 1729, Avg. Train Loss: 0.002651492696861888, Avg. Test Loss: 0.0028125527314841747\n",
      "Epoch: 1730, Avg. Train Loss: 0.0026342406554883996, Avg. Test Loss: 0.002916568424552679\n",
      "Epoch: 1731, Avg. Train Loss: 0.0026664937586458617, Avg. Test Loss: 0.002969692461192608\n",
      "Epoch: 1732, Avg. Train Loss: 0.0026386128142909253, Avg. Test Loss: 0.0029101737309247255\n",
      "Epoch: 1733, Avg. Train Loss: 0.002678953295270371, Avg. Test Loss: 0.0028717585373669863\n",
      "Epoch: 1734, Avg. Train Loss: 0.0026594186959744887, Avg. Test Loss: 0.002827876480296254\n",
      "Epoch: 1735, Avg. Train Loss: 0.0026460797471795664, Avg. Test Loss: 0.0029579056426882744\n",
      "Epoch: 1736, Avg. Train Loss: 0.0027106880361950675, Avg. Test Loss: 0.003106862073764205\n",
      "Epoch: 1737, Avg. Train Loss: 0.002649958326676211, Avg. Test Loss: 0.0028059203177690506\n",
      "Epoch: 1738, Avg. Train Loss: 0.002644887177793439, Avg. Test Loss: 0.002811698243021965\n",
      "Epoch: 1739, Avg. Train Loss: 0.002618647093862988, Avg. Test Loss: 0.0028568569105118513\n",
      "Epoch: 1740, Avg. Train Loss: 0.0026235637027597013, Avg. Test Loss: 0.0028263612184673548\n",
      "Epoch: 1741, Avg. Train Loss: 0.002640702750880358, Avg. Test Loss: 0.00281378417275846\n",
      "Epoch: 1742, Avg. Train Loss: 0.002623880211653751, Avg. Test Loss: 0.002837665844708681\n",
      "Epoch: 1743, Avg. Train Loss: 0.002640973890286892, Avg. Test Loss: 0.0028405138291418552\n",
      "Epoch: 1744, Avg. Train Loss: 0.0026245181784466947, Avg. Test Loss: 0.0028261931147426367\n",
      "Epoch: 1745, Avg. Train Loss: 0.002682895340068742, Avg. Test Loss: 0.002831618068739772\n",
      "Epoch: 1746, Avg. Train Loss: 0.002641597410750597, Avg. Test Loss: 0.002890474395826459\n",
      "Epoch: 1747, Avg. Train Loss: 0.0026459966482984465, Avg. Test Loss: 0.0028343144804239273\n",
      "Epoch: 1748, Avg. Train Loss: 0.00263321592450835, Avg. Test Loss: 0.002825295552611351\n",
      "Epoch: 1749, Avg. Train Loss: 0.0026065240787385507, Avg. Test Loss: 0.002808623481541872\n",
      "Epoch: 1750, Avg. Train Loss: 0.002624814777613379, Avg. Test Loss: 0.0028734849765896797\n",
      "Epoch: 1751, Avg. Train Loss: 0.0026367221590737964, Avg. Test Loss: 0.0028081152122467756\n",
      "Epoch: 1752, Avg. Train Loss: 0.002606172358270648, Avg. Test Loss: 0.0028026478830724955\n",
      "Epoch: 1753, Avg. Train Loss: 0.0026293849832443304, Avg. Test Loss: 0.002828495344147086\n",
      "Epoch: 1754, Avg. Train Loss: 0.0026720774489953076, Avg. Test Loss: 0.0028648092411458492\n",
      "Epoch: 1755, Avg. Train Loss: 0.0026155793443755353, Avg. Test Loss: 0.00280598271638155\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1756, Avg. Train Loss: 0.0026284391872671456, Avg. Test Loss: 0.0028143629897385836\n",
      "Epoch: 1757, Avg. Train Loss: 0.0026155679789913256, Avg. Test Loss: 0.0030493331141769886\n",
      "Epoch: 1758, Avg. Train Loss: 0.002646893576913795, Avg. Test Loss: 0.0028511660639196634\n",
      "Epoch: 1759, Avg. Train Loss: 0.002662571055034912, Avg. Test Loss: 0.002984801772981882\n",
      "Epoch: 1760, Avg. Train Loss: 0.0026233347869196602, Avg. Test Loss: 0.0028106102254241705\n",
      "Epoch: 1761, Avg. Train Loss: 0.002623308780278231, Avg. Test Loss: 0.0029587559401988983\n",
      "Epoch: 1762, Avg. Train Loss: 0.0026171392230533584, Avg. Test Loss: 0.0028363761957734823\n",
      "Epoch: 1763, Avg. Train Loss: 0.002705530864511465, Avg. Test Loss: 0.002815415384247899\n",
      "Epoch: 1764, Avg. Train Loss: 0.0026409771769892337, Avg. Test Loss: 0.0028181541711091995\n",
      "Epoch: 1765, Avg. Train Loss: 0.00260335156087612, Avg. Test Loss: 0.00280141644179821\n",
      "Epoch: 1766, Avg. Train Loss: 0.0026368857415522947, Avg. Test Loss: 0.0028542708605527878\n",
      "Epoch: 1767, Avg. Train Loss: 0.0026242657196383144, Avg. Test Loss: 0.0029156224336475134\n",
      "Epoch: 1768, Avg. Train Loss: 0.002646732539328378, Avg. Test Loss: 0.0028807856142520905\n",
      "Epoch: 1769, Avg. Train Loss: 0.002633342855111804, Avg. Test Loss: 0.002832554280757904\n",
      "Epoch: 1770, Avg. Train Loss: 0.0026969323151333387, Avg. Test Loss: 0.002959076315164566\n",
      "Epoch: 1771, Avg. Train Loss: 0.002682317438167195, Avg. Test Loss: 0.0028151036240160465\n",
      "Epoch: 1772, Avg. Train Loss: 0.002617170666019584, Avg. Test Loss: 0.002803446725010872\n",
      "Epoch: 1773, Avg. Train Loss: 0.002636953257024288, Avg. Test Loss: 0.002861529588699341\n",
      "Epoch: 1774, Avg. Train Loss: 0.0026887417933362167, Avg. Test Loss: 0.0028284937143325806\n",
      "Epoch: 1775, Avg. Train Loss: 0.0026655273273760494, Avg. Test Loss: 0.002819646615535021\n",
      "Epoch: 1776, Avg. Train Loss: 0.0026044133010991784, Avg. Test Loss: 0.0028070698026567698\n",
      "Epoch: 1777, Avg. Train Loss: 0.0026116498291145923, Avg. Test Loss: 0.00282765063457191\n",
      "Epoch: 1778, Avg. Train Loss: 0.002630864053444807, Avg. Test Loss: 0.0028152517043054104\n",
      "Epoch: 1779, Avg. Train Loss: 0.002629488121804803, Avg. Test Loss: 0.002840096829459071\n",
      "Epoch: 1780, Avg. Train Loss: 0.002652293217346765, Avg. Test Loss: 0.0028783087618649006\n",
      "Epoch: 1781, Avg. Train Loss: 0.0026578808766464855, Avg. Test Loss: 0.002822770271450281\n",
      "Epoch: 1782, Avg. Train Loss: 0.002621927742608065, Avg. Test Loss: 0.0030859648250043392\n",
      "Epoch: 1783, Avg. Train Loss: 0.0027199392585993505, Avg. Test Loss: 0.0029142750427126884\n",
      "Epoch: 1784, Avg. Train Loss: 0.002679704109120161, Avg. Test Loss: 0.0028103969525545835\n",
      "Epoch: 1785, Avg. Train Loss: 0.0026104683868673653, Avg. Test Loss: 0.0027981181629002094\n",
      "Epoch: 1786, Avg. Train Loss: 0.0026190008827333532, Avg. Test Loss: 0.0028101936914026737\n",
      "Epoch: 1787, Avg. Train Loss: 0.002619616042952551, Avg. Test Loss: 0.0028199160005897284\n",
      "Epoch: 1788, Avg. Train Loss: 0.00261045400551412, Avg. Test Loss: 0.0027983440086245537\n",
      "Epoch: 1789, Avg. Train Loss: 0.0026252315769535167, Avg. Test Loss: 0.0028288390021771193\n",
      "Epoch: 1790, Avg. Train Loss: 0.002621669349325604, Avg. Test Loss: 0.0028990507125854492\n",
      "Epoch: 1791, Avg. Train Loss: 0.0026319395902371684, Avg. Test Loss: 0.0028078423347324133\n",
      "Epoch: 1792, Avg. Train Loss: 0.0026145176691284707, Avg. Test Loss: 0.0028195076156407595\n",
      "Epoch: 1793, Avg. Train Loss: 0.002621246615511387, Avg. Test Loss: 0.002965485444292426\n",
      "Epoch: 1794, Avg. Train Loss: 0.002640731107486888, Avg. Test Loss: 0.002841261913999915\n",
      "Epoch: 1795, Avg. Train Loss: 0.0026735829373518397, Avg. Test Loss: 0.002833958715200424\n",
      "Epoch: 1796, Avg. Train Loss: 0.002633086297401162, Avg. Test Loss: 0.0029840583447366953\n",
      "Epoch: 1797, Avg. Train Loss: 0.0026345172149757315, Avg. Test Loss: 0.002935422118753195\n",
      "Epoch: 1798, Avg. Train Loss: 0.00266570178250414, Avg. Test Loss: 0.0029062514659017324\n",
      "Epoch: 1799, Avg. Train Loss: 0.0026590759855110286, Avg. Test Loss: 0.0028073908761143684\n",
      "Epoch: 1800, Avg. Train Loss: 0.0026309515219614947, Avg. Test Loss: 0.0028223609551787376\n",
      "Epoch: 1801, Avg. Train Loss: 0.0026497615252209956, Avg. Test Loss: 0.0028313437942415476\n",
      "Epoch: 1802, Avg. Train Loss: 0.0026184114854956087, Avg. Test Loss: 0.0028066905215382576\n",
      "Epoch: 1803, Avg. Train Loss: 0.002622811167046081, Avg. Test Loss: 0.0028166244737803936\n",
      "Epoch: 1804, Avg. Train Loss: 0.002619862372358871, Avg. Test Loss: 0.0028710586484521627\n",
      "Epoch: 1805, Avg. Train Loss: 0.0026888223202509243, Avg. Test Loss: 0.002845720387995243\n",
      "Epoch: 1806, Avg. Train Loss: 0.0026525688563408547, Avg. Test Loss: 0.0028567223343998194\n",
      "Epoch: 1807, Avg. Train Loss: 0.0026614692083798174, Avg. Test Loss: 0.0028277477249503136\n",
      "Epoch: 1808, Avg. Train Loss: 0.002644600763613748, Avg. Test Loss: 0.0028088134713470936\n",
      "Epoch: 1809, Avg. Train Loss: 0.0026392000510768836, Avg. Test Loss: 0.0028735913801938295\n",
      "Epoch: 1810, Avg. Train Loss: 0.0026171831251663525, Avg. Test Loss: 0.0028197646606713533\n",
      "Epoch: 1811, Avg. Train Loss: 0.0026395909087515847, Avg. Test Loss: 0.0028199544176459312\n",
      "Epoch: 1812, Avg. Train Loss: 0.00260895527466092, Avg. Test Loss: 0.002843695692718029\n",
      "Epoch: 1813, Avg. Train Loss: 0.0026351194558015397, Avg. Test Loss: 0.0028163439128547907\n",
      "Epoch: 1814, Avg. Train Loss: 0.002655295600984679, Avg. Test Loss: 0.002816535532474518\n",
      "Epoch: 1815, Avg. Train Loss: 0.0026437246760483398, Avg. Test Loss: 0.002806417876854539\n",
      "Epoch: 1816, Avg. Train Loss: 0.002637779453855961, Avg. Test Loss: 0.0028033475391566753\n",
      "Epoch: 1817, Avg. Train Loss: 0.002603508104288647, Avg. Test Loss: 0.002802065806463361\n",
      "Epoch: 1818, Avg. Train Loss: 0.0026236171617584174, Avg. Test Loss: 0.0028301568236202\n",
      "Epoch: 1819, Avg. Train Loss: 0.0026217972653982944, Avg. Test Loss: 0.0028139932546764612\n",
      "Epoch: 1820, Avg. Train Loss: 0.002663264375959718, Avg. Test Loss: 0.0028095797169953585\n",
      "Epoch: 1821, Avg. Train Loss: 0.0026135523262065512, Avg. Test Loss: 0.002804354764521122\n",
      "Epoch: 1822, Avg. Train Loss: 0.0026242723905069883, Avg. Test Loss: 0.0028193756006658077\n",
      "Epoch: 1823, Avg. Train Loss: 0.002616828540340066, Avg. Test Loss: 0.002810037462040782\n",
      "Epoch: 1824, Avg. Train Loss: 0.002621239912154716, Avg. Test Loss: 0.0028160009533166885\n",
      "Epoch: 1825, Avg. Train Loss: 0.0027224960314586413, Avg. Test Loss: 0.0030188788659870625\n",
      "Epoch: 1826, Avg. Train Loss: 0.002667800014362086, Avg. Test Loss: 0.002932765753939748\n",
      "Epoch: 1827, Avg. Train Loss: 0.0026057668755827255, Avg. Test Loss: 0.002873804420232773\n",
      "Epoch: 1828, Avg. Train Loss: 0.00265494323075684, Avg. Test Loss: 0.0029425190296024084\n",
      "Epoch: 1829, Avg. Train Loss: 0.002635617561768307, Avg. Test Loss: 0.0028783034067600965\n",
      "Epoch: 1830, Avg. Train Loss: 0.0026140621549254933, Avg. Test Loss: 0.002812725491821766\n",
      "Epoch: 1831, Avg. Train Loss: 0.0026379335119367337, Avg. Test Loss: 0.0028316807001829147\n",
      "Epoch: 1832, Avg. Train Loss: 0.002641263677803583, Avg. Test Loss: 0.0028031067922711372\n",
      "Epoch: 1833, Avg. Train Loss: 0.0026361387991887886, Avg. Test Loss: 0.0028978888876736164\n",
      "Epoch: 1834, Avg. Train Loss: 0.0026318557387174563, Avg. Test Loss: 0.0028271751943975687\n",
      "Epoch: 1835, Avg. Train Loss: 0.0026239580312353928, Avg. Test Loss: 0.0028528866823762655\n",
      "Epoch: 1836, Avg. Train Loss: 0.0026124309650947188, Avg. Test Loss: 0.0028623344842344522\n",
      "Epoch: 1837, Avg. Train Loss: 0.002649513587658835, Avg. Test Loss: 0.002926688874140382\n",
      "Epoch: 1838, Avg. Train Loss: 0.0026209815730189167, Avg. Test Loss: 0.002843961352482438\n",
      "Epoch: 1839, Avg. Train Loss: 0.002626373015647364, Avg. Test Loss: 0.0028227174188941717\n",
      "Epoch: 1840, Avg. Train Loss: 0.0026326765966883233, Avg. Test Loss: 0.002827312098816037\n",
      "Epoch: 1841, Avg. Train Loss: 0.0026541586456343877, Avg. Test Loss: 0.0027981908060610294\n",
      "Epoch: 1842, Avg. Train Loss: 0.0026172405801886734, Avg. Test Loss: 0.00289197382517159\n",
      "Epoch: 1843, Avg. Train Loss: 0.0026194726517640575, Avg. Test Loss: 0.0028367640916258097\n",
      "Epoch: 1844, Avg. Train Loss: 0.002604897984108606, Avg. Test Loss: 0.002817379077896476\n",
      "Epoch: 1845, Avg. Train Loss: 0.002605634665679793, Avg. Test Loss: 0.0028061880730092525\n",
      "Epoch: 1846, Avg. Train Loss: 0.002676339283975404, Avg. Test Loss: 0.002815837971866131\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1847, Avg. Train Loss: 0.00262735920503389, Avg. Test Loss: 0.002798214089125395\n",
      "Epoch: 1848, Avg. Train Loss: 0.002603803696327431, Avg. Test Loss: 0.0028075375594198704\n",
      "Epoch: 1849, Avg. Train Loss: 0.0026161282453252828, Avg. Test Loss: 0.002800727728754282\n",
      "Epoch: 1850, Avg. Train Loss: 0.002638296570715516, Avg. Test Loss: 0.0028363557066768408\n",
      "Epoch: 1851, Avg. Train Loss: 0.002617824622321614, Avg. Test Loss: 0.0029046207200735807\n",
      "Epoch: 1852, Avg. Train Loss: 0.0026088487627634474, Avg. Test Loss: 0.0028400591108947992\n",
      "Epoch: 1853, Avg. Train Loss: 0.0026321890276618477, Avg. Test Loss: 0.002810039324685931\n",
      "Epoch: 1854, Avg. Train Loss: 0.0026048161306006963, Avg. Test Loss: 0.0028002343606203794\n",
      "Epoch: 1855, Avg. Train Loss: 0.0026512280009080504, Avg. Test Loss: 0.003060021670535207\n",
      "Epoch: 1856, Avg. Train Loss: 0.0026748388637463714, Avg. Test Loss: 0.002812630031257868\n",
      "Epoch: 1857, Avg. Train Loss: 0.002625193538923943, Avg. Test Loss: 0.0030088964849710464\n",
      "Epoch: 1858, Avg. Train Loss: 0.0026375504188932654, Avg. Test Loss: 0.002799511654302478\n",
      "Epoch: 1859, Avg. Train Loss: 0.0026149448971155773, Avg. Test Loss: 0.0030962848104536533\n",
      "Epoch: 1860, Avg. Train Loss: 0.002629156787554885, Avg. Test Loss: 0.002794366329908371\n",
      "Epoch: 1861, Avg. Train Loss: 0.0026766060537463704, Avg. Test Loss: 0.002907950896769762\n",
      "Epoch: 1862, Avg. Train Loss: 0.0026383308130641316, Avg. Test Loss: 0.0027994480915367603\n",
      "Epoch: 1863, Avg. Train Loss: 0.002606717588076758, Avg. Test Loss: 0.0028093382716178894\n",
      "Epoch: 1864, Avg. Train Loss: 0.002630616392030619, Avg. Test Loss: 0.002832697704434395\n",
      "Epoch: 1865, Avg. Train Loss: 0.0026312685993954885, Avg. Test Loss: 0.002806062111631036\n",
      "Epoch: 1866, Avg. Train Loss: 0.0026386687423773977, Avg. Test Loss: 0.0028089028783142567\n",
      "Epoch: 1867, Avg. Train Loss: 0.0026316122465961894, Avg. Test Loss: 0.002862156368792057\n",
      "Epoch: 1868, Avg. Train Loss: 0.002616311439724509, Avg. Test Loss: 0.002804485149681568\n",
      "Epoch: 1869, Avg. Train Loss: 0.0026052732962768437, Avg. Test Loss: 0.002807555953040719\n",
      "Epoch: 1870, Avg. Train Loss: 0.002604965028504646, Avg. Test Loss: 0.002806665375828743\n",
      "Epoch: 1871, Avg. Train Loss: 0.0026867802493100944, Avg. Test Loss: 0.0028349931817501783\n",
      "Epoch: 1872, Avg. Train Loss: 0.002619756120365373, Avg. Test Loss: 0.0028552787844091654\n",
      "Epoch: 1873, Avg. Train Loss: 0.0026245965611536143, Avg. Test Loss: 0.002799992449581623\n",
      "Epoch: 1874, Avg. Train Loss: 0.002625867188366693, Avg. Test Loss: 0.0030430713668465614\n",
      "Epoch: 1875, Avg. Train Loss: 0.0027175618736289963, Avg. Test Loss: 0.0030010994523763657\n",
      "Epoch: 1876, Avg. Train Loss: 0.0026137304254049477, Avg. Test Loss: 0.002795741893351078\n",
      "Epoch: 1877, Avg. Train Loss: 0.0026738275827969922, Avg. Test Loss: 0.0028517090249806643\n",
      "Epoch: 1878, Avg. Train Loss: 0.002639082585309827, Avg. Test Loss: 0.002787716221064329\n",
      "Epoch: 1879, Avg. Train Loss: 0.0026325045565013276, Avg. Test Loss: 0.002834211103618145\n",
      "Epoch: 1880, Avg. Train Loss: 0.002656531915458482, Avg. Test Loss: 0.0029574749059975147\n",
      "Epoch: 1881, Avg. Train Loss: 0.0026474420013729225, Avg. Test Loss: 0.00281321257352829\n",
      "Epoch: 1882, Avg. Train Loss: 0.0026466438416824782, Avg. Test Loss: 0.002823161892592907\n",
      "Epoch: 1883, Avg. Train Loss: 0.002666200153789548, Avg. Test Loss: 0.002814858453348279\n",
      "Epoch: 1884, Avg. Train Loss: 0.0026269636853316495, Avg. Test Loss: 0.0028070088010281324\n",
      "Epoch: 1885, Avg. Train Loss: 0.002631874007800984, Avg. Test Loss: 0.0028271637856960297\n",
      "Epoch: 1886, Avg. Train Loss: 0.0026123222223548, Avg. Test Loss: 0.0028128642588853836\n",
      "Epoch: 1887, Avg. Train Loss: 0.002614018404423151, Avg. Test Loss: 0.002860003150999546\n",
      "Epoch: 1888, Avg. Train Loss: 0.0026123435669686904, Avg. Test Loss: 0.0028320762794464827\n",
      "Epoch: 1889, Avg. Train Loss: 0.0026184485651292774, Avg. Test Loss: 0.0028264096472412348\n",
      "Epoch: 1890, Avg. Train Loss: 0.002623916868943461, Avg. Test Loss: 0.002818711567670107\n",
      "Epoch: 1891, Avg. Train Loss: 0.0026144110056203467, Avg. Test Loss: 0.002789790742099285\n",
      "Epoch: 1892, Avg. Train Loss: 0.0026351307020630946, Avg. Test Loss: 0.0028195844497531652\n",
      "Epoch: 1893, Avg. Train Loss: 0.002641610541315966, Avg. Test Loss: 0.00300647527910769\n",
      "Epoch: 1894, Avg. Train Loss: 0.0026558329578662333, Avg. Test Loss: 0.0029496930073946714\n",
      "Epoch: 1895, Avg. Train Loss: 0.0026249883284922256, Avg. Test Loss: 0.0028667235746979713\n",
      "Epoch: 1896, Avg. Train Loss: 0.0026207117872789156, Avg. Test Loss: 0.0029029420111328363\n",
      "Epoch: 1897, Avg. Train Loss: 0.002611984996948131, Avg. Test Loss: 0.0028013656847178936\n",
      "Epoch: 1898, Avg. Train Loss: 0.002612563575682945, Avg. Test Loss: 0.002809700323268771\n",
      "Epoch: 1899, Avg. Train Loss: 0.0026154988716074893, Avg. Test Loss: 0.0028185914270579815\n",
      "Epoch: 1900, Avg. Train Loss: 0.0025984372694565112, Avg. Test Loss: 0.002893929136916995\n",
      "Epoch: 1901, Avg. Train Loss: 0.0026908221838692595, Avg. Test Loss: 0.0030359120573848486\n",
      "Epoch: 1902, Avg. Train Loss: 0.0026552317566563223, Avg. Test Loss: 0.0028210333548486233\n",
      "Epoch: 1903, Avg. Train Loss: 0.002602481299491469, Avg. Test Loss: 0.002818184206262231\n",
      "Epoch: 1904, Avg. Train Loss: 0.00262929247908814, Avg. Test Loss: 0.002803477458655834\n",
      "Epoch: 1905, Avg. Train Loss: 0.0026245447265547377, Avg. Test Loss: 0.002842966467142105\n",
      "Epoch: 1906, Avg. Train Loss: 0.0026334866307415935, Avg. Test Loss: 0.002813402796164155\n",
      "Epoch: 1907, Avg. Train Loss: 0.0026158522543778947, Avg. Test Loss: 0.002910307375714183\n",
      "Epoch: 1908, Avg. Train Loss: 0.0026245235931128263, Avg. Test Loss: 0.003005714388564229\n",
      "Epoch: 1909, Avg. Train Loss: 0.0026453565372977147, Avg. Test Loss: 0.0027854815125465393\n",
      "Epoch: 1910, Avg. Train Loss: 0.002609238347991608, Avg. Test Loss: 0.0028079587500542402\n",
      "Epoch: 1911, Avg. Train Loss: 0.0026106830621354803, Avg. Test Loss: 0.002796851797029376\n",
      "Epoch: 1912, Avg. Train Loss: 0.0026635294725988494, Avg. Test Loss: 0.0028718162793666124\n",
      "Epoch: 1913, Avg. Train Loss: 0.002604199687105625, Avg. Test Loss: 0.0028052134439349174\n",
      "Epoch: 1914, Avg. Train Loss: 0.0025975982561101054, Avg. Test Loss: 0.002806050004437566\n",
      "Epoch: 1915, Avg. Train Loss: 0.002620017870740835, Avg. Test Loss: 0.002838292857632041\n",
      "Epoch: 1916, Avg. Train Loss: 0.0026157708827752708, Avg. Test Loss: 0.002823831979185343\n",
      "Epoch: 1917, Avg. Train Loss: 0.002630061697388111, Avg. Test Loss: 0.0027964068576693535\n",
      "Epoch: 1918, Avg. Train Loss: 0.002670773277925544, Avg. Test Loss: 0.0029722501058131456\n",
      "Epoch: 1919, Avg. Train Loss: 0.0026629223423295244, Avg. Test Loss: 0.002891119569540024\n",
      "Epoch: 1920, Avg. Train Loss: 0.0026087945998581343, Avg. Test Loss: 0.0027958303689956665\n",
      "Epoch: 1921, Avg. Train Loss: 0.002643859723236325, Avg. Test Loss: 0.0028190510347485542\n",
      "Epoch: 1922, Avg. Train Loss: 0.0026159902417295894, Avg. Test Loss: 0.0028014134149998426\n",
      "Epoch: 1923, Avg. Train Loss: 0.0026056566708829512, Avg. Test Loss: 0.002817927859723568\n",
      "Epoch: 1924, Avg. Train Loss: 0.002610336009109783, Avg. Test Loss: 0.0028351612854748964\n",
      "Epoch: 1925, Avg. Train Loss: 0.002661320673258499, Avg. Test Loss: 0.0029130110051482916\n",
      "Epoch: 1926, Avg. Train Loss: 0.002646002182087233, Avg. Test Loss: 0.002792887855321169\n",
      "Epoch: 1927, Avg. Train Loss: 0.002615795600726161, Avg. Test Loss: 0.0027984739281237125\n",
      "Epoch: 1928, Avg. Train Loss: 0.002606315873996463, Avg. Test Loss: 0.002930345479398966\n",
      "Epoch: 1929, Avg. Train Loss: 0.0026245444395774325, Avg. Test Loss: 0.0027923346497118473\n",
      "Epoch: 1930, Avg. Train Loss: 0.0026256734461978424, Avg. Test Loss: 0.0028132402803748846\n",
      "Epoch: 1931, Avg. Train Loss: 0.0026363665183876143, Avg. Test Loss: 0.002811445388942957\n",
      "Epoch: 1932, Avg. Train Loss: 0.0026295437358406395, Avg. Test Loss: 0.0027984874323010445\n",
      "Epoch: 1933, Avg. Train Loss: 0.0026098805003214715, Avg. Test Loss: 0.0027896997053176165\n",
      "Epoch: 1934, Avg. Train Loss: 0.0026185205964328246, Avg. Test Loss: 0.002791691804304719\n",
      "Epoch: 1935, Avg. Train Loss: 0.0026398696611787, Avg. Test Loss: 0.002856617094948888\n",
      "Epoch: 1936, Avg. Train Loss: 0.002619345342133974, Avg. Test Loss: 0.0028900064062327147\n",
      "Epoch: 1937, Avg. Train Loss: 0.002616653105157406, Avg. Test Loss: 0.003031759522855282\n",
      "Epoch: 1938, Avg. Train Loss: 0.0026341015364714834, Avg. Test Loss: 0.0029047636780887842\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1939, Avg. Train Loss: 0.002600510090286302, Avg. Test Loss: 0.0027893015649169683\n",
      "Epoch: 1940, Avg. Train Loss: 0.0026057384594148675, Avg. Test Loss: 0.002941710175946355\n",
      "Epoch: 1941, Avg. Train Loss: 0.0026236528281642253, Avg. Test Loss: 0.002788853831589222\n",
      "Epoch: 1942, Avg. Train Loss: 0.002600927317385064, Avg. Test Loss: 0.0028342651203274727\n",
      "Epoch: 1943, Avg. Train Loss: 0.0026781306125570176, Avg. Test Loss: 0.0028659370727837086\n",
      "Epoch: 1944, Avg. Train Loss: 0.002645236304636265, Avg. Test Loss: 0.0028591512236744165\n",
      "Epoch: 1945, Avg. Train Loss: 0.002621324938656979, Avg. Test Loss: 0.00283053214661777\n",
      "Epoch: 1946, Avg. Train Loss: 0.0026580646287563234, Avg. Test Loss: 0.002842225134372711\n",
      "Epoch: 1947, Avg. Train Loss: 0.0026055446251966926, Avg. Test Loss: 0.002824191004037857\n",
      "Epoch: 1948, Avg. Train Loss: 0.002595946360596044, Avg. Test Loss: 0.0027949230279773474\n",
      "Epoch: 1949, Avg. Train Loss: 0.00262735401236907, Avg. Test Loss: 0.0028270466718822718\n",
      "Epoch: 1950, Avg. Train Loss: 0.002608521603221117, Avg. Test Loss: 0.0028186843264847994\n",
      "Epoch: 1951, Avg. Train Loss: 0.0026025103816632615, Avg. Test Loss: 0.002846964867785573\n",
      "Epoch: 1952, Avg. Train Loss: 0.002607445254228836, Avg. Test Loss: 0.002921598730608821\n",
      "Epoch: 1953, Avg. Train Loss: 0.0026065179764098207, Avg. Test Loss: 0.0028265011496841908\n",
      "Epoch: 1954, Avg. Train Loss: 0.0026185092256339484, Avg. Test Loss: 0.002784974407404661\n",
      "Epoch: 1955, Avg. Train Loss: 0.002753256116235672, Avg. Test Loss: 0.002808225341141224\n",
      "Epoch: 1956, Avg. Train Loss: 0.0026056084099637215, Avg. Test Loss: 0.0029024917166680098\n",
      "Epoch: 1957, Avg. Train Loss: 0.0026187690592176, Avg. Test Loss: 0.0028031012043356895\n",
      "Epoch: 1958, Avg. Train Loss: 0.0026301619824195322, Avg. Test Loss: 0.002845619572326541\n",
      "Epoch: 1959, Avg. Train Loss: 0.002595902214823074, Avg. Test Loss: 0.002835098886862397\n",
      "Epoch: 1960, Avg. Train Loss: 0.0026093695345226417, Avg. Test Loss: 0.002879065228626132\n",
      "Epoch: 1961, Avg. Train Loss: 0.002621736761918941, Avg. Test Loss: 0.002788804704323411\n",
      "Epoch: 1962, Avg. Train Loss: 0.002643561737915111, Avg. Test Loss: 0.002860664390027523\n",
      "Epoch: 1963, Avg. Train Loss: 0.0026362045169916262, Avg. Test Loss: 0.0027937220875173807\n",
      "Epoch: 1964, Avg. Train Loss: 0.0026172247368755727, Avg. Test Loss: 0.0027918952982872725\n",
      "Epoch: 1965, Avg. Train Loss: 0.002651315334058085, Avg. Test Loss: 0.0029986482113599777\n",
      "Epoch: 1966, Avg. Train Loss: 0.0026669201798477146, Avg. Test Loss: 0.0028819513972848654\n",
      "Epoch: 1967, Avg. Train Loss: 0.002707015019083439, Avg. Test Loss: 0.0027941172011196613\n",
      "Epoch: 1968, Avg. Train Loss: 0.002611200070701713, Avg. Test Loss: 0.002792252926155925\n",
      "Epoch: 1969, Avg. Train Loss: 0.002592771844721811, Avg. Test Loss: 0.002827228279784322\n",
      "Epoch: 1970, Avg. Train Loss: 0.002597826430140886, Avg. Test Loss: 0.0028279682155698538\n",
      "Epoch: 1971, Avg. Train Loss: 0.002612963145555452, Avg. Test Loss: 0.002824043855071068\n",
      "Epoch: 1972, Avg. Train Loss: 0.0026301321909264768, Avg. Test Loss: 0.0027983917389065027\n",
      "Epoch: 1973, Avg. Train Loss: 0.0025999999583460566, Avg. Test Loss: 0.0028468728996813297\n",
      "Epoch: 1974, Avg. Train Loss: 0.0026302120572519166, Avg. Test Loss: 0.002791630569845438\n",
      "Epoch: 1975, Avg. Train Loss: 0.0026081661141455865, Avg. Test Loss: 0.002801507944241166\n",
      "Epoch: 1976, Avg. Train Loss: 0.0026796775285241217, Avg. Test Loss: 0.0028740798588842154\n",
      "Epoch: 1977, Avg. Train Loss: 0.0026165567349295976, Avg. Test Loss: 0.002917225006967783\n",
      "Epoch: 1978, Avg. Train Loss: 0.0026052191062982, Avg. Test Loss: 0.002821441041305661\n",
      "Epoch: 1979, Avg. Train Loss: 0.0026116084935533445, Avg. Test Loss: 0.002791906474158168\n",
      "Epoch: 1980, Avg. Train Loss: 0.002615044223751093, Avg. Test Loss: 0.0030427814926952124\n",
      "Epoch: 1981, Avg. Train Loss: 0.0026610342590788075, Avg. Test Loss: 0.0028063692152500153\n",
      "Epoch: 1982, Avg. Train Loss: 0.002629408076795381, Avg. Test Loss: 0.0028380141593515873\n",
      "Epoch: 1983, Avg. Train Loss: 0.0026442172265676565, Avg. Test Loss: 0.0027960159350186586\n",
      "Epoch: 1984, Avg. Train Loss: 0.002611092178064377, Avg. Test Loss: 0.0027901288121938705\n",
      "Epoch: 1985, Avg. Train Loss: 0.0026231887208860976, Avg. Test Loss: 0.002806700300425291\n",
      "Epoch: 1986, Avg. Train Loss: 0.0026267102843713624, Avg. Test Loss: 0.002941871527582407\n",
      "Epoch: 1987, Avg. Train Loss: 0.0026258494120177836, Avg. Test Loss: 0.0028531590942293406\n",
      "Epoch: 1988, Avg. Train Loss: 0.0026002938772530055, Avg. Test Loss: 0.0028344772290438414\n",
      "Epoch: 1989, Avg. Train Loss: 0.002617251062982304, Avg. Test Loss: 0.0029986693989485502\n",
      "Epoch: 1990, Avg. Train Loss: 0.002612812054711719, Avg. Test Loss: 0.0028528121765702963\n",
      "Epoch: 1991, Avg. Train Loss: 0.00263196955499954, Avg. Test Loss: 0.002913170726969838\n",
      "Epoch: 1992, Avg. Train Loss: 0.0026595374612614167, Avg. Test Loss: 0.002801640424877405\n",
      "Epoch: 1993, Avg. Train Loss: 0.0026091606204592904, Avg. Test Loss: 0.0028051040135324\n",
      "Epoch: 1994, Avg. Train Loss: 0.0026171343227805095, Avg. Test Loss: 0.0028002478647977114\n",
      "Epoch: 1995, Avg. Train Loss: 0.002618100997710297, Avg. Test Loss: 0.0027987791690975428\n",
      "Epoch: 1996, Avg. Train Loss: 0.0025944899453586617, Avg. Test Loss: 0.0028406139463186264\n",
      "Epoch: 1997, Avg. Train Loss: 0.002621599213155203, Avg. Test Loss: 0.002810810925439\n",
      "Epoch: 1998, Avg. Train Loss: 0.0026013637448899273, Avg. Test Loss: 0.0028036970179528\n",
      "Epoch: 1999, Avg. Train Loss: 0.0026160256698900875, Avg. Test Loss: 0.0028084174264222383\n",
      "Epoch: 2000, Avg. Train Loss: 0.0026190718365183404, Avg. Test Loss: 0.0028157932683825493\n",
      "Epoch: 2001, Avg. Train Loss: 0.0026353519561505595, Avg. Test Loss: 0.0028611584566533566\n",
      "Epoch: 2002, Avg. Train Loss: 0.002605129423183064, Avg. Test Loss: 0.0028047047089785337\n",
      "Epoch: 2003, Avg. Train Loss: 0.0026283434397259423, Avg. Test Loss: 0.0028680949471890926\n",
      "Epoch: 2004, Avg. Train Loss: 0.0026085678228112154, Avg. Test Loss: 0.002832694910466671\n",
      "Epoch: 2005, Avg. Train Loss: 0.002619988837301038, Avg. Test Loss: 0.0028071876149624586\n",
      "Epoch: 2006, Avg. Train Loss: 0.002613668384160413, Avg. Test Loss: 0.002796049462631345\n",
      "Epoch: 2007, Avg. Train Loss: 0.0026642941425792698, Avg. Test Loss: 0.002878960222005844\n",
      "Epoch: 2008, Avg. Train Loss: 0.0026129166768907113, Avg. Test Loss: 0.0029914432670921087\n",
      "Epoch: 2009, Avg. Train Loss: 0.002640200692207314, Avg. Test Loss: 0.002805102616548538\n",
      "Epoch: 2010, Avg. Train Loss: 0.002610535631606052, Avg. Test Loss: 0.0028708160389214754\n",
      "Epoch: 2011, Avg. Train Loss: 0.0025968088681787944, Avg. Test Loss: 0.002849534386768937\n",
      "Epoch: 2012, Avg. Train Loss: 0.0026541535666775567, Avg. Test Loss: 0.0030180809553712606\n",
      "Epoch: 2013, Avg. Train Loss: 0.0026844712948903096, Avg. Test Loss: 0.0028089203406125307\n",
      "Epoch: 2014, Avg. Train Loss: 0.002608657657537003, Avg. Test Loss: 0.003023371333256364\n",
      "Epoch: 2015, Avg. Train Loss: 0.002607681636893472, Avg. Test Loss: 0.002866809256374836\n",
      "Epoch: 2016, Avg. Train Loss: 0.0026283091378159996, Avg. Test Loss: 0.0028196077328175306\n",
      "Epoch: 2017, Avg. Train Loss: 0.002606648951768875, Avg. Test Loss: 0.002837562235072255\n",
      "Epoch: 2018, Avg. Train Loss: 0.0026083167772306954, Avg. Test Loss: 0.0028850568924099207\n",
      "Epoch: 2019, Avg. Train Loss: 0.002625521960083482, Avg. Test Loss: 0.0028026271611452103\n",
      "Epoch: 2020, Avg. Train Loss: 0.0026011174100689415, Avg. Test Loss: 0.0028540014754980803\n",
      "Epoch: 2021, Avg. Train Loss: 0.0026860719081014395, Avg. Test Loss: 0.0030406154692173004\n",
      "Epoch: 2022, Avg. Train Loss: 0.0026194262047579816, Avg. Test Loss: 0.0028176922351121902\n",
      "Epoch: 2023, Avg. Train Loss: 0.0026153989710173634, Avg. Test Loss: 0.0028241993859410286\n",
      "Epoch: 2024, Avg. Train Loss: 0.0026114389711861, Avg. Test Loss: 0.002853181678801775\n",
      "Epoch: 2025, Avg. Train Loss: 0.0026094220080521216, Avg. Test Loss: 0.0027866296004503965\n",
      "Epoch: 2026, Avg. Train Loss: 0.002609109489767011, Avg. Test Loss: 0.0028256766963750124\n",
      "Epoch: 2027, Avg. Train Loss: 0.002629148053698415, Avg. Test Loss: 0.0027827925514429808\n",
      "Epoch: 2028, Avg. Train Loss: 0.002589474507975717, Avg. Test Loss: 0.0027877904940396547\n",
      "Epoch: 2029, Avg. Train Loss: 0.0026223030926789655, Avg. Test Loss: 0.0030301520600914955\n",
      "Epoch: 2030, Avg. Train Loss: 0.002607955407827746, Avg. Test Loss: 0.0029216757975518703\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2031, Avg. Train Loss: 0.002607964287880202, Avg. Test Loss: 0.0027816062793135643\n",
      "Epoch: 2032, Avg. Train Loss: 0.0025923444597093863, Avg. Test Loss: 0.002793374704197049\n",
      "Epoch: 2033, Avg. Train Loss: 0.0026092854826602827, Avg. Test Loss: 0.0028584215324372053\n",
      "Epoch: 2034, Avg. Train Loss: 0.002642208195919561, Avg. Test Loss: 0.002839089371263981\n",
      "Epoch: 2035, Avg. Train Loss: 0.002611820759295031, Avg. Test Loss: 0.0028089003171771765\n",
      "Epoch: 2036, Avg. Train Loss: 0.0026783437663039497, Avg. Test Loss: 0.002791961655020714\n",
      "Epoch: 2037, Avg. Train Loss: 0.0025894747841236896, Avg. Test Loss: 0.0028212247416377068\n",
      "Epoch: 2038, Avg. Train Loss: 0.0026455481731614402, Avg. Test Loss: 0.0028575158212333918\n",
      "Epoch: 2039, Avg. Train Loss: 0.002668707723577702, Avg. Test Loss: 0.0027949498035013676\n",
      "Epoch: 2040, Avg. Train Loss: 0.0026341551308368526, Avg. Test Loss: 0.002845936454832554\n",
      "Epoch: 2041, Avg. Train Loss: 0.0026043111588372743, Avg. Test Loss: 0.002791964216157794\n",
      "Epoch: 2042, Avg. Train Loss: 0.0025751322215466304, Avg. Test Loss: 0.0027787787839770317\n",
      "Epoch: 2043, Avg. Train Loss: 0.0026465811236046776, Avg. Test Loss: 0.002780050504952669\n",
      "Epoch: 2044, Avg. Train Loss: 0.0025823895472946554, Avg. Test Loss: 0.002780291484668851\n",
      "Epoch: 2045, Avg. Train Loss: 0.002647764390594391, Avg. Test Loss: 0.00277708750218153\n",
      "Epoch: 2046, Avg. Train Loss: 0.002595795226434982, Avg. Test Loss: 0.0027939709834754467\n",
      "Epoch: 2047, Avg. Train Loss: 0.002622966822453363, Avg. Test Loss: 0.002790267113596201\n",
      "Epoch: 2048, Avg. Train Loss: 0.0026326865705033372, Avg. Test Loss: 0.002840583911165595\n",
      "Epoch: 2049, Avg. Train Loss: 0.0026119294695469528, Avg. Test Loss: 0.0030281126964837313\n",
      "Epoch: 2050, Avg. Train Loss: 0.002640906234033579, Avg. Test Loss: 0.0028545719105750322\n",
      "Epoch: 2051, Avg. Train Loss: 0.0026292643823855838, Avg. Test Loss: 0.0030635716393589973\n",
      "Epoch: 2052, Avg. Train Loss: 0.0026520199445617754, Avg. Test Loss: 0.0027811340987682343\n",
      "Epoch: 2053, Avg. Train Loss: 0.002596103093521886, Avg. Test Loss: 0.002787507139146328\n",
      "Epoch: 2054, Avg. Train Loss: 0.0025889978711601605, Avg. Test Loss: 0.0028367668855935335\n",
      "Epoch: 2055, Avg. Train Loss: 0.0026393994840598384, Avg. Test Loss: 0.0028343303129076958\n",
      "Epoch: 2056, Avg. Train Loss: 0.00260024010961832, Avg. Test Loss: 0.002777219284325838\n",
      "Epoch: 2057, Avg. Train Loss: 0.002591225102024023, Avg. Test Loss: 0.002859380329027772\n",
      "Epoch: 2058, Avg. Train Loss: 0.002595334129711223, Avg. Test Loss: 0.0028382970485836267\n",
      "Epoch: 2059, Avg. Train Loss: 0.0025992954344770244, Avg. Test Loss: 0.0028671734035015106\n",
      "Epoch: 2060, Avg. Train Loss: 0.0025995764935519113, Avg. Test Loss: 0.0028431687969714403\n",
      "Epoch: 2061, Avg. Train Loss: 0.002651951162057907, Avg. Test Loss: 0.002837586449459195\n",
      "Epoch: 2062, Avg. Train Loss: 0.002617451562654487, Avg. Test Loss: 0.002961872611194849\n",
      "Epoch: 2063, Avg. Train Loss: 0.002613738623209471, Avg. Test Loss: 0.0027864265721291304\n",
      "Epoch: 2064, Avg. Train Loss: 0.002605303612992514, Avg. Test Loss: 0.00284460443072021\n",
      "Epoch: 2065, Avg. Train Loss: 0.002619622486405248, Avg. Test Loss: 0.0029333799611777067\n",
      "Epoch: 2066, Avg. Train Loss: 0.0026012000974354357, Avg. Test Loss: 0.002777444664388895\n",
      "Epoch: 2067, Avg. Train Loss: 0.0025977294263971407, Avg. Test Loss: 0.0028008227236568928\n",
      "Epoch: 2068, Avg. Train Loss: 0.0026084207279910873, Avg. Test Loss: 0.0028241032268851995\n",
      "Epoch: 2069, Avg. Train Loss: 0.0026404246048958497, Avg. Test Loss: 0.0028449685778468847\n",
      "Epoch: 2070, Avg. Train Loss: 0.002623356710902827, Avg. Test Loss: 0.0027889434713870287\n",
      "Epoch: 2071, Avg. Train Loss: 0.002595157654912666, Avg. Test Loss: 0.0028009589295834303\n",
      "Epoch: 2072, Avg. Train Loss: 0.002602494099762204, Avg. Test Loss: 0.002901302184909582\n",
      "Epoch: 2073, Avg. Train Loss: 0.0026189436172243466, Avg. Test Loss: 0.0027822349220514297\n",
      "Epoch: 2074, Avg. Train Loss: 0.0026187555171376053, Avg. Test Loss: 0.002782275667414069\n",
      "Epoch: 2075, Avg. Train Loss: 0.002598884022729688, Avg. Test Loss: 0.0029850543942302465\n",
      "Epoch: 2076, Avg. Train Loss: 0.002662625661942848, Avg. Test Loss: 0.0028312334325164557\n",
      "Epoch: 2077, Avg. Train Loss: 0.0026542995298324628, Avg. Test Loss: 0.003061623778194189\n",
      "Epoch: 2078, Avg. Train Loss: 0.0026686927195378515, Avg. Test Loss: 0.0027906750328838825\n",
      "Epoch: 2079, Avg. Train Loss: 0.0026151729574383693, Avg. Test Loss: 0.002798746805638075\n",
      "Epoch: 2080, Avg. Train Loss: 0.0026155709841310286, Avg. Test Loss: 0.0028702905401587486\n",
      "Epoch: 2081, Avg. Train Loss: 0.0026742375055111424, Avg. Test Loss: 0.0027856905944645405\n",
      "Epoch: 2082, Avg. Train Loss: 0.0025910735346896703, Avg. Test Loss: 0.002796968910843134\n",
      "Epoch: 2083, Avg. Train Loss: 0.002582764604973585, Avg. Test Loss: 0.002780366688966751\n",
      "Epoch: 2084, Avg. Train Loss: 0.002628403179737371, Avg. Test Loss: 0.002796290209516883\n",
      "Epoch: 2085, Avg. Train Loss: 0.002603582918730586, Avg. Test Loss: 0.002845969283953309\n",
      "Epoch: 2086, Avg. Train Loss: 0.0026162480827161046, Avg. Test Loss: 0.002852832432836294\n",
      "Epoch: 2087, Avg. Train Loss: 0.0026356061368227697, Avg. Test Loss: 0.0028506710659712553\n",
      "Epoch: 2088, Avg. Train Loss: 0.002600227303932919, Avg. Test Loss: 0.002888648072257638\n",
      "Epoch: 2089, Avg. Train Loss: 0.00262666390234128, Avg. Test Loss: 0.002774896565824747\n",
      "Epoch: 2090, Avg. Train Loss: 0.002613248650071233, Avg. Test Loss: 0.0028043435886502266\n",
      "Epoch: 2091, Avg. Train Loss: 0.002593492065707958, Avg. Test Loss: 0.0028462675400078297\n",
      "Epoch: 2092, Avg. Train Loss: 0.0025956592912417514, Avg. Test Loss: 0.002781630028039217\n",
      "Epoch: 2093, Avg. Train Loss: 0.0025913275312632322, Avg. Test Loss: 0.002793240826576948\n",
      "Epoch: 2094, Avg. Train Loss: 0.002615021032736052, Avg. Test Loss: 0.0027997400611639023\n",
      "Epoch: 2095, Avg. Train Loss: 0.0026688261098380007, Avg. Test Loss: 0.0027967013884335756\n",
      "Epoch: 2096, Avg. Train Loss: 0.002620536693220222, Avg. Test Loss: 0.002798974048346281\n",
      "Epoch: 2097, Avg. Train Loss: 0.002602762629299663, Avg. Test Loss: 0.0029037066269665956\n",
      "Epoch: 2098, Avg. Train Loss: 0.002626168465804915, Avg. Test Loss: 0.0027902922593057156\n",
      "Epoch: 2099, Avg. Train Loss: 0.0026286102582289035, Avg. Test Loss: 0.002846845891326666\n",
      "Epoch: 2100, Avg. Train Loss: 0.0025985914466599394, Avg. Test Loss: 0.002798474859446287\n",
      "Epoch: 2101, Avg. Train Loss: 0.002632286350870895, Avg. Test Loss: 0.002915019867941737\n",
      "Epoch: 2102, Avg. Train Loss: 0.0026379697360531533, Avg. Test Loss: 0.0027932843659073114\n",
      "Epoch: 2103, Avg. Train Loss: 0.002606678705359268, Avg. Test Loss: 0.002801606897264719\n",
      "Epoch: 2104, Avg. Train Loss: 0.00260081754585858, Avg. Test Loss: 0.0028157257474958897\n",
      "Epoch: 2105, Avg. Train Loss: 0.002625107591928438, Avg. Test Loss: 0.002934908028692007\n",
      "Epoch: 2106, Avg. Train Loss: 0.0026220925650451074, Avg. Test Loss: 0.00283569167368114\n",
      "Epoch: 2107, Avg. Train Loss: 0.0026097850072695768, Avg. Test Loss: 0.00277336617000401\n",
      "Epoch: 2108, Avg. Train Loss: 0.0025906156055455986, Avg. Test Loss: 0.002850102260708809\n",
      "Epoch: 2109, Avg. Train Loss: 0.0025947119412553865, Avg. Test Loss: 0.002784604439511895\n",
      "Epoch: 2110, Avg. Train Loss: 0.002582927353593499, Avg. Test Loss: 0.002783997217193246\n",
      "Epoch: 2111, Avg. Train Loss: 0.002620869197038024, Avg. Test Loss: 0.0028609088622033596\n",
      "Epoch: 2112, Avg. Train Loss: 0.0027174333998456943, Avg. Test Loss: 0.0028888185042887926\n",
      "Epoch: 2113, Avg. Train Loss: 0.00265323132991271, Avg. Test Loss: 0.0027964997570961714\n",
      "Epoch: 2114, Avg. Train Loss: 0.002618298730488087, Avg. Test Loss: 0.002838867250829935\n",
      "Epoch: 2115, Avg. Train Loss: 0.002596344127384729, Avg. Test Loss: 0.002801265800371766\n",
      "Epoch: 2116, Avg. Train Loss: 0.0026386932816443056, Avg. Test Loss: 0.002816184191033244\n",
      "Epoch: 2117, Avg. Train Loss: 0.0025759866937648417, Avg. Test Loss: 0.0027851019985973835\n",
      "Epoch: 2118, Avg. Train Loss: 0.002593298356027104, Avg. Test Loss: 0.0027865655720233917\n",
      "Epoch: 2119, Avg. Train Loss: 0.0026204297806374554, Avg. Test Loss: 0.002782133175060153\n",
      "Epoch: 2120, Avg. Train Loss: 0.0026146449516852234, Avg. Test Loss: 0.0028409280348569155\n",
      "Epoch: 2121, Avg. Train Loss: 0.0026081819195560244, Avg. Test Loss: 0.0028384120669215918\n",
      "Epoch: 2122, Avg. Train Loss: 0.0026294860479876745, Avg. Test Loss: 0.00289925723336637\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2123, Avg. Train Loss: 0.002613477544252609, Avg. Test Loss: 0.0028046173974871635\n",
      "Epoch: 2124, Avg. Train Loss: 0.0025993374468715386, Avg. Test Loss: 0.002844924572855234\n",
      "Epoch: 2125, Avg. Train Loss: 0.0026091646164828953, Avg. Test Loss: 0.0028151723090559244\n",
      "Epoch: 2126, Avg. Train Loss: 0.002614317965412209, Avg. Test Loss: 0.002785895485430956\n",
      "Epoch: 2127, Avg. Train Loss: 0.002605885370136347, Avg. Test Loss: 0.0028382577002048492\n",
      "Epoch: 2128, Avg. Train Loss: 0.002618647619085603, Avg. Test Loss: 0.0029707138892263174\n",
      "Epoch: 2129, Avg. Train Loss: 0.0026552356281426062, Avg. Test Loss: 0.002841927343979478\n",
      "Epoch: 2130, Avg. Train Loss: 0.0025951463220164526, Avg. Test Loss: 0.0027858733665198088\n",
      "Epoch: 2131, Avg. Train Loss: 0.0026182553102803785, Avg. Test Loss: 0.0029590697959065437\n",
      "Epoch: 2132, Avg. Train Loss: 0.002621979717988261, Avg. Test Loss: 0.0028500172775238752\n",
      "Epoch: 2133, Avg. Train Loss: 0.0025938044919437448, Avg. Test Loss: 0.0027885499875992537\n",
      "Epoch: 2134, Avg. Train Loss: 0.002619946370074569, Avg. Test Loss: 0.00299231824465096\n",
      "Epoch: 2135, Avg. Train Loss: 0.0026406467848912227, Avg. Test Loss: 0.0027916410472244024\n",
      "Epoch: 2136, Avg. Train Loss: 0.0025932138276741254, Avg. Test Loss: 0.0028067189268767834\n",
      "Epoch: 2137, Avg. Train Loss: 0.0025890940464599883, Avg. Test Loss: 0.0027979938313364983\n",
      "Epoch: 2138, Avg. Train Loss: 0.002663477941221276, Avg. Test Loss: 0.0032246997579932213\n",
      "Epoch: 2139, Avg. Train Loss: 0.002652295881362502, Avg. Test Loss: 0.0027798644732683897\n",
      "Epoch: 2140, Avg. Train Loss: 0.002600429536298264, Avg. Test Loss: 0.002821206348016858\n",
      "Epoch: 2141, Avg. Train Loss: 0.002593392804048436, Avg. Test Loss: 0.0027912212535738945\n",
      "Epoch: 2142, Avg. Train Loss: 0.0026008021194747714, Avg. Test Loss: 0.0027726597618311644\n",
      "Epoch: 2143, Avg. Train Loss: 0.0026344659651607967, Avg. Test Loss: 0.0028169022407382727\n",
      "Epoch: 2144, Avg. Train Loss: 0.00260679691835025, Avg. Test Loss: 0.002803081413730979\n",
      "Epoch: 2145, Avg. Train Loss: 0.002614786458569904, Avg. Test Loss: 0.0028170612640678883\n",
      "Epoch: 2146, Avg. Train Loss: 0.0026073066604345345, Avg. Test Loss: 0.002839235123246908\n",
      "Epoch: 2147, Avg. Train Loss: 0.0026431207512613644, Avg. Test Loss: 0.0027941095177084208\n",
      "Epoch: 2148, Avg. Train Loss: 0.0025968974900193688, Avg. Test Loss: 0.0028161099180579185\n",
      "Epoch: 2149, Avg. Train Loss: 0.0026060326977871183, Avg. Test Loss: 0.0027838044334203005\n",
      "Epoch: 2150, Avg. Train Loss: 0.002620651836095508, Avg. Test Loss: 0.0028055275324732065\n",
      "Epoch: 2151, Avg. Train Loss: 0.0026479109385332397, Avg. Test Loss: 0.0028392428066581488\n",
      "Epoch: 2152, Avg. Train Loss: 0.0026104398624061846, Avg. Test Loss: 0.0027966215275228024\n",
      "Epoch: 2153, Avg. Train Loss: 0.002611999573229357, Avg. Test Loss: 0.0027797268703579903\n",
      "Epoch: 2154, Avg. Train Loss: 0.0026470027582416703, Avg. Test Loss: 0.00292984233237803\n",
      "Epoch: 2155, Avg. Train Loss: 0.0026571356236588122, Avg. Test Loss: 0.002776129636913538\n",
      "Epoch: 2156, Avg. Train Loss: 0.002589277923107147, Avg. Test Loss: 0.002799633191898465\n",
      "Epoch: 2157, Avg. Train Loss: 0.002598824391011582, Avg. Test Loss: 0.0027694704476743937\n",
      "Epoch: 2158, Avg. Train Loss: 0.002650783397257328, Avg. Test Loss: 0.002773955697193742\n",
      "Epoch: 2159, Avg. Train Loss: 0.0025971421083911908, Avg. Test Loss: 0.0028301558922976255\n",
      "Epoch: 2160, Avg. Train Loss: 0.002583483131169233, Avg. Test Loss: 0.0028648788575083017\n",
      "Epoch: 2161, Avg. Train Loss: 0.0026064041384690722, Avg. Test Loss: 0.0028010590467602015\n",
      "Epoch: 2162, Avg. Train Loss: 0.0026068470798172923, Avg. Test Loss: 0.0027833296917378902\n",
      "Epoch: 2163, Avg. Train Loss: 0.002605049020805678, Avg. Test Loss: 0.0027814037166535854\n",
      "Epoch: 2164, Avg. Train Loss: 0.0025991447984652465, Avg. Test Loss: 0.002830339130014181\n",
      "Epoch: 2165, Avg. Train Loss: 0.0025890331585393393, Avg. Test Loss: 0.0028582338709384203\n",
      "Epoch: 2166, Avg. Train Loss: 0.0025960275751733502, Avg. Test Loss: 0.0029708168003708124\n",
      "Epoch: 2167, Avg. Train Loss: 0.0025931590583262057, Avg. Test Loss: 0.002779717091470957\n",
      "Epoch: 2168, Avg. Train Loss: 0.0025893892811308075, Avg. Test Loss: 0.002776622772216797\n",
      "Epoch: 2169, Avg. Train Loss: 0.002656904054632367, Avg. Test Loss: 0.0031033542472869158\n",
      "Epoch: 2170, Avg. Train Loss: 0.002611095383546727, Avg. Test Loss: 0.0027827376034110785\n",
      "Epoch: 2171, Avg. Train Loss: 0.0026099550494447696, Avg. Test Loss: 0.0027711689472198486\n",
      "Epoch: 2172, Avg. Train Loss: 0.002583281451099834, Avg. Test Loss: 0.002962404163554311\n",
      "Epoch: 2173, Avg. Train Loss: 0.002645200930622428, Avg. Test Loss: 0.0030422566924244165\n",
      "Epoch: 2174, Avg. Train Loss: 0.0026953128155667422, Avg. Test Loss: 0.002826313953846693\n",
      "Epoch: 2175, Avg. Train Loss: 0.002602535456982116, Avg. Test Loss: 0.0027776279021054506\n",
      "Epoch: 2176, Avg. Train Loss: 0.0026009039585153724, Avg. Test Loss: 0.0028921475168317556\n",
      "Epoch: 2177, Avg. Train Loss: 0.002609477616673292, Avg. Test Loss: 0.002806925680488348\n",
      "Epoch: 2178, Avg. Train Loss: 0.0025911611602316763, Avg. Test Loss: 0.0027958720456808805\n",
      "Epoch: 2179, Avg. Train Loss: 0.0025855125317913157, Avg. Test Loss: 0.0027670173440128565\n",
      "Epoch: 2180, Avg. Train Loss: 0.0025979196652770042, Avg. Test Loss: 0.0028350302018225193\n",
      "Epoch: 2181, Avg. Train Loss: 0.002614160003357155, Avg. Test Loss: 0.002915238495916128\n",
      "Epoch: 2182, Avg. Train Loss: 0.0026546326184342076, Avg. Test Loss: 0.002788109704852104\n",
      "Epoch: 2183, Avg. Train Loss: 0.002610635938296138, Avg. Test Loss: 0.0027673712465912104\n",
      "Epoch: 2184, Avg. Train Loss: 0.0025815179105848074, Avg. Test Loss: 0.0028613393660634756\n",
      "Epoch: 2185, Avg. Train Loss: 0.0026125177621928067, Avg. Test Loss: 0.0029100484680384398\n",
      "Epoch: 2186, Avg. Train Loss: 0.0026134670235563157, Avg. Test Loss: 0.0028162566013634205\n",
      "Epoch: 2187, Avg. Train Loss: 0.0025784653059185243, Avg. Test Loss: 0.0028265039436519146\n",
      "Epoch: 2188, Avg. Train Loss: 0.0026469868391232436, Avg. Test Loss: 0.0028050951659679413\n",
      "Epoch: 2189, Avg. Train Loss: 0.002589539375675972, Avg. Test Loss: 0.002787692239508033\n",
      "Epoch: 2190, Avg. Train Loss: 0.002719773483181069, Avg. Test Loss: 0.0032736638095229864\n",
      "Epoch: 2191, Avg. Train Loss: 0.0026492013130337, Avg. Test Loss: 0.0027935332618653774\n",
      "Epoch: 2192, Avg. Train Loss: 0.0025813906659307175, Avg. Test Loss: 0.0027705200482159853\n",
      "Epoch: 2193, Avg. Train Loss: 0.002588554745713292, Avg. Test Loss: 0.002803523326292634\n",
      "Epoch: 2194, Avg. Train Loss: 0.002591801547380381, Avg. Test Loss: 0.002835688879713416\n",
      "Epoch: 2195, Avg. Train Loss: 0.002600224661575847, Avg. Test Loss: 0.002778095193207264\n",
      "Epoch: 2196, Avg. Train Loss: 0.002588928081528392, Avg. Test Loss: 0.0027977663557976484\n",
      "Epoch: 2197, Avg. Train Loss: 0.0026167042033616887, Avg. Test Loss: 0.0028607859276235104\n",
      "Epoch: 2198, Avg. Train Loss: 0.0026074597709487344, Avg. Test Loss: 0.002768483478575945\n",
      "Epoch: 2199, Avg. Train Loss: 0.0025862545305646435, Avg. Test Loss: 0.0027992278337478638\n",
      "Epoch: 2200, Avg. Train Loss: 0.0025867240687529017, Avg. Test Loss: 0.0027990839444100857\n",
      "Epoch: 2201, Avg. Train Loss: 0.0025872072464851446, Avg. Test Loss: 0.0027880261186510324\n",
      "Epoch: 2202, Avg. Train Loss: 0.0026047541543321555, Avg. Test Loss: 0.0028483131900429726\n",
      "Epoch: 2203, Avg. Train Loss: 0.0026318434420106716, Avg. Test Loss: 0.0028434668201953173\n",
      "Epoch: 2204, Avg. Train Loss: 0.002644143002324326, Avg. Test Loss: 0.002801964757964015\n",
      "Epoch: 2205, Avg. Train Loss: 0.0026092363445651395, Avg. Test Loss: 0.0027924503665417433\n",
      "Epoch: 2206, Avg. Train Loss: 0.002583109443400835, Avg. Test Loss: 0.0028166871052235365\n",
      "Epoch: 2207, Avg. Train Loss: 0.002593370576843966, Avg. Test Loss: 0.0027633467689156532\n",
      "Epoch: 2208, Avg. Train Loss: 0.002593926933788976, Avg. Test Loss: 0.002825159812346101\n",
      "Epoch: 2209, Avg. Train Loss: 0.0026964099839502987, Avg. Test Loss: 0.0028040544129908085\n",
      "Epoch: 2210, Avg. Train Loss: 0.0026128255209863878, Avg. Test Loss: 0.0027725279796868563\n",
      "Epoch: 2211, Avg. Train Loss: 0.002580493634436713, Avg. Test Loss: 0.002815617946907878\n",
      "Epoch: 2212, Avg. Train Loss: 0.0026205014383290396, Avg. Test Loss: 0.0028888473752886057\n",
      "Epoch: 2213, Avg. Train Loss: 0.002601140525278657, Avg. Test Loss: 0.0027745715342462063\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2214, Avg. Train Loss: 0.0025767496797840955, Avg. Test Loss: 0.0027859217952936888\n",
      "Epoch: 2215, Avg. Train Loss: 0.002596701354568088, Avg. Test Loss: 0.0029113248456269503\n",
      "Epoch: 2216, Avg. Train Loss: 0.0026126758921025104, Avg. Test Loss: 0.0027624936774373055\n",
      "Epoch: 2217, Avg. Train Loss: 0.002585976866485421, Avg. Test Loss: 0.002794199390336871\n",
      "Epoch: 2218, Avg. Train Loss: 0.002590054099253097, Avg. Test Loss: 0.0027687372639775276\n",
      "Epoch: 2219, Avg. Train Loss: 0.0025725830562932546, Avg. Test Loss: 0.0028090428095310926\n",
      "Epoch: 2220, Avg. Train Loss: 0.0025860900925688966, Avg. Test Loss: 0.0028102968353778124\n",
      "Epoch: 2221, Avg. Train Loss: 0.002606794562970483, Avg. Test Loss: 0.0027899278793483973\n",
      "Epoch: 2222, Avg. Train Loss: 0.0026002906392826593, Avg. Test Loss: 0.0027738786302506924\n",
      "Epoch: 2223, Avg. Train Loss: 0.002602393565656141, Avg. Test Loss: 0.0027853616047650576\n",
      "Epoch: 2224, Avg. Train Loss: 0.0025794518851610117, Avg. Test Loss: 0.0027649460826069117\n",
      "Epoch: 2225, Avg. Train Loss: 0.002744648908806402, Avg. Test Loss: 0.002874769037589431\n",
      "Epoch: 2226, Avg. Train Loss: 0.002630892729516639, Avg. Test Loss: 0.002837932901456952\n",
      "Epoch: 2227, Avg. Train Loss: 0.002616688240925933, Avg. Test Loss: 0.002846064977347851\n",
      "Epoch: 2228, Avg. Train Loss: 0.0026403635220472203, Avg. Test Loss: 0.0028716709930449724\n",
      "Epoch: 2229, Avg. Train Loss: 0.002628646763907962, Avg. Test Loss: 0.002798517467454076\n",
      "Epoch: 2230, Avg. Train Loss: 0.0026124418485736433, Avg. Test Loss: 0.0027744898106902838\n",
      "Epoch: 2231, Avg. Train Loss: 0.0025712666318340356, Avg. Test Loss: 0.0027644906658679247\n",
      "Epoch: 2232, Avg. Train Loss: 0.002590112409792667, Avg. Test Loss: 0.002773300278931856\n",
      "Epoch: 2233, Avg. Train Loss: 0.002592499107988768, Avg. Test Loss: 0.0028190903831273317\n",
      "Epoch: 2234, Avg. Train Loss: 0.0026465322508281747, Avg. Test Loss: 0.002881148597225547\n",
      "Epoch: 2235, Avg. Train Loss: 0.00260697390754209, Avg. Test Loss: 0.0027692492585629225\n",
      "Epoch: 2236, Avg. Train Loss: 0.0025905454802045294, Avg. Test Loss: 0.002787899225950241\n",
      "Epoch: 2237, Avg. Train Loss: 0.0025885215592245723, Avg. Test Loss: 0.0027724443934857845\n",
      "Epoch: 2238, Avg. Train Loss: 0.002606026048577109, Avg. Test Loss: 0.002765628742054105\n",
      "Epoch: 2239, Avg. Train Loss: 0.0025734175808814377, Avg. Test Loss: 0.0028316073585301638\n",
      "Epoch: 2240, Avg. Train Loss: 0.0026561592402326506, Avg. Test Loss: 0.002890879986807704\n",
      "Epoch: 2241, Avg. Train Loss: 0.0026529798403295665, Avg. Test Loss: 0.002763936063274741\n",
      "Epoch: 2242, Avg. Train Loss: 0.002595878834294718, Avg. Test Loss: 0.002854088554158807\n",
      "Epoch: 2243, Avg. Train Loss: 0.0026541946260908314, Avg. Test Loss: 0.0027837990783154964\n",
      "Epoch: 2244, Avg. Train Loss: 0.002599968477477168, Avg. Test Loss: 0.002763038035482168\n",
      "Epoch: 2245, Avg. Train Loss: 0.002578132228146112, Avg. Test Loss: 0.0027886631432920694\n",
      "Epoch: 2246, Avg. Train Loss: 0.002608236450658635, Avg. Test Loss: 0.002859067637473345\n",
      "Epoch: 2247, Avg. Train Loss: 0.002620772426124922, Avg. Test Loss: 0.0028627384454011917\n",
      "Epoch: 2248, Avg. Train Loss: 0.0026327300177843766, Avg. Test Loss: 0.0027997647412121296\n",
      "Epoch: 2249, Avg. Train Loss: 0.0025841610581982272, Avg. Test Loss: 0.002810392063111067\n",
      "Epoch: 2250, Avg. Train Loss: 0.0026546707485131053, Avg. Test Loss: 0.0028031375259160995\n",
      "Epoch: 2251, Avg. Train Loss: 0.002598044993139284, Avg. Test Loss: 0.002784355077892542\n",
      "Epoch: 2252, Avg. Train Loss: 0.0026292227598470313, Avg. Test Loss: 0.0027695356402546167\n",
      "Epoch: 2253, Avg. Train Loss: 0.002584197645097278, Avg. Test Loss: 0.002796189859509468\n",
      "Epoch: 2254, Avg. Train Loss: 0.00257572264757094, Avg. Test Loss: 0.002782398136332631\n",
      "Epoch: 2255, Avg. Train Loss: 0.002606496014523991, Avg. Test Loss: 0.0027968736831098795\n",
      "Epoch: 2256, Avg. Train Loss: 0.002580776675279404, Avg. Test Loss: 0.002774637658149004\n",
      "Epoch: 2257, Avg. Train Loss: 0.002678556405657599, Avg. Test Loss: 0.00283735990524292\n",
      "Epoch: 2258, Avg. Train Loss: 0.002612232100651708, Avg. Test Loss: 0.0029276739805936813\n",
      "Epoch: 2259, Avg. Train Loss: 0.0025962304356399665, Avg. Test Loss: 0.0027654580771923065\n",
      "Epoch: 2260, Avg. Train Loss: 0.0026046798434541667, Avg. Test Loss: 0.0027773708570748568\n",
      "Epoch: 2261, Avg. Train Loss: 0.0026604578083077837, Avg. Test Loss: 0.0027862400747835636\n",
      "Epoch: 2262, Avg. Train Loss: 0.002577158552053016, Avg. Test Loss: 0.0027862940914928913\n",
      "Epoch: 2263, Avg. Train Loss: 0.0026006406541307305, Avg. Test Loss: 0.0027645372319966555\n",
      "Epoch: 2264, Avg. Train Loss: 0.0025834796062215817, Avg. Test Loss: 0.0027783806435763836\n",
      "Epoch: 2265, Avg. Train Loss: 0.0025961844434658457, Avg. Test Loss: 0.0027656450401991606\n",
      "Epoch: 2266, Avg. Train Loss: 0.0025767459328351326, Avg. Test Loss: 0.0027939435094594955\n",
      "Epoch: 2267, Avg. Train Loss: 0.0026049595651065193, Avg. Test Loss: 0.0027823925483971834\n",
      "Epoch: 2268, Avg. Train Loss: 0.0025833395342234264, Avg. Test Loss: 0.0027821832336485386\n",
      "Epoch: 2269, Avg. Train Loss: 0.0025772307891138765, Avg. Test Loss: 0.0027663682121783495\n",
      "Epoch: 2270, Avg. Train Loss: 0.0025830596338870912, Avg. Test Loss: 0.0027707740664482117\n",
      "Epoch: 2271, Avg. Train Loss: 0.0026029544655060354, Avg. Test Loss: 0.0028063151985406876\n",
      "Epoch: 2272, Avg. Train Loss: 0.002601687390313939, Avg. Test Loss: 0.002951338654384017\n",
      "Epoch: 2273, Avg. Train Loss: 0.0026211558278043602, Avg. Test Loss: 0.0028071568813174963\n",
      "Epoch: 2274, Avg. Train Loss: 0.002587271713500106, Avg. Test Loss: 0.002870923141017556\n",
      "Epoch: 2275, Avg. Train Loss: 0.002625699284984622, Avg. Test Loss: 0.002800918649882078\n",
      "Epoch: 2276, Avg. Train Loss: 0.0025903258559315705, Avg. Test Loss: 0.0028842343017458916\n",
      "Epoch: 2277, Avg. Train Loss: 0.0026048736181110144, Avg. Test Loss: 0.0028688733000308275\n",
      "Epoch: 2278, Avg. Train Loss: 0.0025975757635869953, Avg. Test Loss: 0.00288762291893363\n",
      "Epoch: 2279, Avg. Train Loss: 0.0026302021538275617, Avg. Test Loss: 0.0027765040285885334\n",
      "Epoch: 2280, Avg. Train Loss: 0.002614115662656205, Avg. Test Loss: 0.0027813310734927654\n",
      "Epoch: 2281, Avg. Train Loss: 0.002587160880699061, Avg. Test Loss: 0.003000051248818636\n",
      "Epoch: 2282, Avg. Train Loss: 0.0025970035687435506, Avg. Test Loss: 0.0027653260622173548\n",
      "Epoch: 2283, Avg. Train Loss: 0.0026339018489992204, Avg. Test Loss: 0.002767663449048996\n",
      "Epoch: 2284, Avg. Train Loss: 0.002583906947916677, Avg. Test Loss: 0.00276552583090961\n",
      "Epoch: 2285, Avg. Train Loss: 0.002595034162622205, Avg. Test Loss: 0.0028881607577204704\n",
      "Epoch: 2286, Avg. Train Loss: 0.0025952083849196516, Avg. Test Loss: 0.0027902249712496996\n",
      "Epoch: 2287, Avg. Train Loss: 0.002587335249192493, Avg. Test Loss: 0.0027606277726590633\n",
      "Epoch: 2288, Avg. Train Loss: 0.0025914947307387063, Avg. Test Loss: 0.0028031435795128345\n",
      "Epoch: 2289, Avg. Train Loss: 0.002607647778986152, Avg. Test Loss: 0.0028290902264416218\n",
      "Epoch: 2290, Avg. Train Loss: 0.0025899688074321942, Avg. Test Loss: 0.002757362322881818\n",
      "Epoch: 2291, Avg. Train Loss: 0.002607399917229317, Avg. Test Loss: 0.002766994759440422\n",
      "Epoch: 2292, Avg. Train Loss: 0.0025928850491466217, Avg. Test Loss: 0.0027682974468916655\n",
      "Epoch: 2293, Avg. Train Loss: 0.002629334924655945, Avg. Test Loss: 0.002787776989862323\n",
      "Epoch: 2294, Avg. Train Loss: 0.002575957281298416, Avg. Test Loss: 0.0027749408036470413\n",
      "Epoch: 2295, Avg. Train Loss: 0.0026104053980562578, Avg. Test Loss: 0.0028781474102288485\n",
      "Epoch: 2296, Avg. Train Loss: 0.0026707920397436896, Avg. Test Loss: 0.0028060281183570623\n",
      "Epoch: 2297, Avg. Train Loss: 0.002610263127703653, Avg. Test Loss: 0.0029598637484014034\n",
      "Epoch: 2298, Avg. Train Loss: 0.0026584628882796264, Avg. Test Loss: 0.0027883946895599365\n",
      "Epoch: 2299, Avg. Train Loss: 0.002606634240120996, Avg. Test Loss: 0.0027988189831376076\n",
      "Epoch: 2300, Avg. Train Loss: 0.002603673143312335, Avg. Test Loss: 0.0028339452110230923\n",
      "Epoch: 2301, Avg. Train Loss: 0.0026158461953664936, Avg. Test Loss: 0.0027910624630749226\n",
      "Epoch: 2302, Avg. Train Loss: 0.0025945095410353915, Avg. Test Loss: 0.0027638906612992287\n",
      "Epoch: 2303, Avg. Train Loss: 0.0026079704443555934, Avg. Test Loss: 0.002815180690959096\n",
      "Epoch: 2304, Avg. Train Loss: 0.0026182551803283914, Avg. Test Loss: 0.0030565650667995214\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2305, Avg. Train Loss: 0.002605669671496333, Avg. Test Loss: 0.0027725996915251017\n",
      "Epoch: 2306, Avg. Train Loss: 0.002573924242020693, Avg. Test Loss: 0.0027551506645977497\n",
      "Epoch: 2307, Avg. Train Loss: 0.0025878441520035267, Avg. Test Loss: 0.002758210292086005\n",
      "Epoch: 2308, Avg. Train Loss: 0.0025957084076782297, Avg. Test Loss: 0.0028306436724960804\n",
      "Epoch: 2309, Avg. Train Loss: 0.0025688221753943103, Avg. Test Loss: 0.002797003136947751\n",
      "Epoch: 2310, Avg. Train Loss: 0.0025892522521750176, Avg. Test Loss: 0.0027547006029635668\n",
      "Epoch: 2311, Avg. Train Loss: 0.0025804461857174025, Avg. Test Loss: 0.0027963242027908564\n",
      "Epoch: 2312, Avg. Train Loss: 0.002625933815833441, Avg. Test Loss: 0.002774997381493449\n",
      "Epoch: 2313, Avg. Train Loss: 0.0026092337617693944, Avg. Test Loss: 0.0027658347971737385\n",
      "Epoch: 2314, Avg. Train Loss: 0.002586826102721483, Avg. Test Loss: 0.0028722414281219244\n",
      "Epoch: 2315, Avg. Train Loss: 0.0025763029860722464, Avg. Test Loss: 0.0029135586228221655\n",
      "Epoch: 2316, Avg. Train Loss: 0.002642926321429915, Avg. Test Loss: 0.0028428789228200912\n",
      "Epoch: 2317, Avg. Train Loss: 0.0026170669643338336, Avg. Test Loss: 0.0027713084127753973\n",
      "Epoch: 2318, Avg. Train Loss: 0.002586168935522437, Avg. Test Loss: 0.002764351898804307\n",
      "Epoch: 2319, Avg. Train Loss: 0.0026052691323985885, Avg. Test Loss: 0.0028066227678209543\n",
      "Epoch: 2320, Avg. Train Loss: 0.0025975925219786722, Avg. Test Loss: 0.0028877188451588154\n",
      "Epoch: 2321, Avg. Train Loss: 0.002608139446914889, Avg. Test Loss: 0.0027723819948732853\n",
      "Epoch: 2322, Avg. Train Loss: 0.002578389549324679, Avg. Test Loss: 0.002860073698684573\n",
      "Epoch: 2323, Avg. Train Loss: 0.002610287753605219, Avg. Test Loss: 0.0028494661673903465\n",
      "Epoch: 2324, Avg. Train Loss: 0.002604867044706331, Avg. Test Loss: 0.002751482417806983\n",
      "Epoch: 2325, Avg. Train Loss: 0.0025859467717710624, Avg. Test Loss: 0.0027652441058307886\n",
      "Epoch: 2326, Avg. Train Loss: 0.002617436656078627, Avg. Test Loss: 0.0028317293617874384\n",
      "Epoch: 2327, Avg. Train Loss: 0.0025868026842904646, Avg. Test Loss: 0.0027757741045206785\n",
      "Epoch: 2328, Avg. Train Loss: 0.0026187205329797295, Avg. Test Loss: 0.002756138565018773\n",
      "Epoch: 2329, Avg. Train Loss: 0.0025951509136533323, Avg. Test Loss: 0.002928238594904542\n",
      "Epoch: 2330, Avg. Train Loss: 0.002600725258289035, Avg. Test Loss: 0.002897004596889019\n",
      "Epoch: 2331, Avg. Train Loss: 0.002613551340737315, Avg. Test Loss: 0.0027765838894993067\n",
      "Epoch: 2332, Avg. Train Loss: 0.0026143166658923376, Avg. Test Loss: 0.002982956590130925\n",
      "Epoch: 2333, Avg. Train Loss: 0.002624907677040197, Avg. Test Loss: 0.0027615551371127367\n",
      "Epoch: 2334, Avg. Train Loss: 0.002652810317962322, Avg. Test Loss: 0.0027879863046109676\n",
      "Epoch: 2335, Avg. Train Loss: 0.002604471384222771, Avg. Test Loss: 0.0028309014160186052\n",
      "Epoch: 2336, Avg. Train Loss: 0.0025979896065194247, Avg. Test Loss: 0.002808780875056982\n",
      "Epoch: 2337, Avg. Train Loss: 0.0025908877358360345, Avg. Test Loss: 0.002783224917948246\n",
      "Epoch: 2338, Avg. Train Loss: 0.0025947116542780813, Avg. Test Loss: 0.00281152012757957\n",
      "Epoch: 2339, Avg. Train Loss: 0.0026157279553021802, Avg. Test Loss: 0.0027740569785237312\n",
      "Epoch: 2340, Avg. Train Loss: 0.002633042682265473, Avg. Test Loss: 0.0027584165800362825\n",
      "Epoch: 2341, Avg. Train Loss: 0.0025737995585036833, Avg. Test Loss: 0.002757119946181774\n",
      "Epoch: 2342, Avg. Train Loss: 0.0026091033820236143, Avg. Test Loss: 0.002768774051219225\n",
      "Epoch: 2343, Avg. Train Loss: 0.0025857605072561393, Avg. Test Loss: 0.0029335101135075092\n",
      "Epoch: 2344, Avg. Train Loss: 0.0026320684051444362, Avg. Test Loss: 0.00299057736992836\n",
      "Epoch: 2345, Avg. Train Loss: 0.002575265952970746, Avg. Test Loss: 0.002793935127556324\n",
      "Epoch: 2346, Avg. Train Loss: 0.0025885221927405095, Avg. Test Loss: 0.002825165865942836\n",
      "Epoch: 2347, Avg. Train Loss: 0.0025864346927508366, Avg. Test Loss: 0.002775175729766488\n",
      "Epoch: 2348, Avg. Train Loss: 0.002586103233963598, Avg. Test Loss: 0.00281949108466506\n",
      "Epoch: 2349, Avg. Train Loss: 0.00269415991943936, Avg. Test Loss: 0.0027699600905179977\n",
      "Epoch: 2350, Avg. Train Loss: 0.0025757289664863152, Avg. Test Loss: 0.0028164158575236797\n",
      "Epoch: 2351, Avg. Train Loss: 0.0025903377627823935, Avg. Test Loss: 0.002793327672407031\n",
      "Epoch: 2352, Avg. Train Loss: 0.0025768479722183806, Avg. Test Loss: 0.0028218694496899843\n",
      "Epoch: 2353, Avg. Train Loss: 0.002583346113042776, Avg. Test Loss: 0.0027741019148379564\n",
      "Epoch: 2354, Avg. Train Loss: 0.00258409773367782, Avg. Test Loss: 0.0029206809122115374\n",
      "Epoch: 2355, Avg. Train Loss: 0.002607383602840263, Avg. Test Loss: 0.002752648899331689\n",
      "Epoch: 2356, Avg. Train Loss: 0.0025842931868811678, Avg. Test Loss: 0.00281911832280457\n",
      "Epoch: 2357, Avg. Train Loss: 0.0026135687326449292, Avg. Test Loss: 0.0027651444543153048\n",
      "Epoch: 2358, Avg. Train Loss: 0.002576978292402833, Avg. Test Loss: 0.002793069463223219\n",
      "Epoch: 2359, Avg. Train Loss: 0.002614578351291806, Avg. Test Loss: 0.0028176498599350452\n",
      "Epoch: 2360, Avg. Train Loss: 0.0026432237327965193, Avg. Test Loss: 0.0027669977862387896\n",
      "Epoch: 2361, Avg. Train Loss: 0.0025725222116899354, Avg. Test Loss: 0.002767405938357115\n",
      "Epoch: 2362, Avg. Train Loss: 0.002565387262811148, Avg. Test Loss: 0.0027911476790905\n",
      "Epoch: 2363, Avg. Train Loss: 0.0025896868224493984, Avg. Test Loss: 0.0028599423822015524\n",
      "Epoch: 2364, Avg. Train Loss: 0.002621812897539416, Avg. Test Loss: 0.002791669685393572\n",
      "Epoch: 2365, Avg. Train Loss: 0.002637322959598414, Avg. Test Loss: 0.002763126278296113\n",
      "Epoch: 2366, Avg. Train Loss: 0.0025758712909855815, Avg. Test Loss: 0.0028306327294558287\n",
      "Epoch: 2367, Avg. Train Loss: 0.002638193193909734, Avg. Test Loss: 0.0027558300644159317\n",
      "Epoch: 2368, Avg. Train Loss: 0.002579880493887982, Avg. Test Loss: 0.0027579187881201506\n",
      "Epoch: 2369, Avg. Train Loss: 0.0025817634277912073, Avg. Test Loss: 0.0028732200153172016\n",
      "Epoch: 2370, Avg. Train Loss: 0.002618190550873446, Avg. Test Loss: 0.0027709200512617826\n",
      "Epoch: 2371, Avg. Train Loss: 0.002581692744739527, Avg. Test Loss: 0.0027862126007676125\n",
      "Epoch: 2372, Avg. Train Loss: 0.002577471140728787, Avg. Test Loss: 0.0027829527389258146\n",
      "Epoch: 2373, Avg. Train Loss: 0.002608280655992932, Avg. Test Loss: 0.0027800959069281816\n",
      "Epoch: 2374, Avg. Train Loss: 0.002592866406451131, Avg. Test Loss: 0.002806468168273568\n",
      "Epoch: 2375, Avg. Train Loss: 0.0025747443040356386, Avg. Test Loss: 0.0027806423604488373\n",
      "Epoch: 2376, Avg. Train Loss: 0.00259367095544761, Avg. Test Loss: 0.00285296980291605\n",
      "Epoch: 2377, Avg. Train Loss: 0.0026690785415730504, Avg. Test Loss: 0.002955813193693757\n",
      "Epoch: 2378, Avg. Train Loss: 0.002578705278506806, Avg. Test Loss: 0.002823234535753727\n",
      "Epoch: 2379, Avg. Train Loss: 0.0025861615011858385, Avg. Test Loss: 0.0029231130611151457\n",
      "Epoch: 2380, Avg. Train Loss: 0.0026122822133867545, Avg. Test Loss: 0.0027867385651916265\n",
      "Epoch: 2381, Avg. Train Loss: 0.0025834345507847016, Avg. Test Loss: 0.002791757695376873\n",
      "Epoch: 2382, Avg. Train Loss: 0.002609366291137629, Avg. Test Loss: 0.002776874229311943\n",
      "Epoch: 2383, Avg. Train Loss: 0.002590844386018986, Avg. Test Loss: 0.002980487421154976\n",
      "Epoch: 2384, Avg. Train Loss: 0.002641775065946371, Avg. Test Loss: 0.0027728420682251453\n",
      "Epoch: 2385, Avg. Train Loss: 0.0025715085266287937, Avg. Test Loss: 0.002769689541310072\n",
      "Epoch: 2386, Avg. Train Loss: 0.0025722525775605854, Avg. Test Loss: 0.002759478520601988\n",
      "Epoch: 2387, Avg. Train Loss: 0.0025791090447455645, Avg. Test Loss: 0.0027741065714508295\n",
      "Epoch: 2388, Avg. Train Loss: 0.0025580320182408012, Avg. Test Loss: 0.0027794428169727325\n",
      "Epoch: 2389, Avg. Train Loss: 0.0026140259687117366, Avg. Test Loss: 0.0027870615012943745\n",
      "Epoch: 2390, Avg. Train Loss: 0.002578378757895079, Avg. Test Loss: 0.002779086586087942\n",
      "Epoch: 2391, Avg. Train Loss: 0.002580402381068399, Avg. Test Loss: 0.002831490011885762\n",
      "Epoch: 2392, Avg. Train Loss: 0.002612919714518411, Avg. Test Loss: 0.0028619146905839443\n",
      "Epoch: 2393, Avg. Train Loss: 0.002603353905426555, Avg. Test Loss: 0.002781093353405595\n",
      "Epoch: 2394, Avg. Train Loss: 0.0025716823590702788, Avg. Test Loss: 0.002791748847812414\n",
      "Epoch: 2395, Avg. Train Loss: 0.0025725257149789224, Avg. Test Loss: 0.0027841622941195965\n",
      "Epoch: 2396, Avg. Train Loss: 0.00260549305050179, Avg. Test Loss: 0.002793907420709729\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2397, Avg. Train Loss: 0.002588595761809238, Avg. Test Loss: 0.00291481357999146\n",
      "Epoch: 2398, Avg. Train Loss: 0.0025979307707572397, Avg. Test Loss: 0.002751895459368825\n",
      "Epoch: 2399, Avg. Train Loss: 0.0025614109973228255, Avg. Test Loss: 0.0027832097839564085\n",
      "Epoch: 2400, Avg. Train Loss: 0.0025743536250449196, Avg. Test Loss: 0.002757501322776079\n",
      "Finished Training\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2af300def9e8>"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Now let's train the initial network \n",
    "\n",
    "model = offCenterLineNet()\n",
    "model = model.to(dev)\n",
    "model.apply(weights_init_uniform)\n",
    "\n",
    "model.train();\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=.01) \n",
    "# scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=500, gamma=0.1)\n",
    "\n",
    "n_epochs = 2400\n",
    "\n",
    "mse_loss = nn.MSELoss()\n",
    "ce_loss = nn.CrossEntropyLoss()\n",
    "\n",
    "for epoch in range(0,n_epochs):  # loop over the dataset multiple times\n",
    "    \n",
    "    if epoch == 0:\n",
    "        train_loss_over_time = [] # to track the loss as the network trains\n",
    "        test_loss_over_time = []\n",
    "        \n",
    "    if epoch == 10:\n",
    "        optimizer = torch.optim.Adam(model.parameters(),lr=.002) \n",
    "        \n",
    "        \n",
    "    running_loss = 0\n",
    "    num_batches = 0\n",
    "    \n",
    "    for batch_i, data in enumerate(train_loader):\n",
    "        \n",
    "        # get the input images and their corresponding labels\n",
    "        num_batches += 1\n",
    "\n",
    "        inputs, output_gt, _, _ = data\n",
    "        inputs, output_gt = inputs.to(dev), output_gt.to(dev)\n",
    "        \n",
    "        # zero the parameter (weight) gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # forward pass to get outputs\n",
    "        output_line_params = model(inputs)\n",
    "        \n",
    "\n",
    "        # make the ground truth\n",
    "        c = -output_gt[:,2]*torch.cos(output_gt[:,0]) + output_gt[:,1]*torch.sin(output_gt[:,0])\n",
    "        gt_line_params = torch.stack((-torch.sin(output_gt[:,0]),torch.cos(output_gt[:,0]),c),dim=1)\n",
    "        \n",
    "        # calculate the loss\n",
    "#         print(output_line_params[:,:,0,50])\n",
    "        \n",
    "        loss = mse_loss(output_line_params,gt_line_params)\n",
    "        \n",
    "        # backward pass to calculate the parameter gradients\n",
    "        loss.backward()\n",
    "\n",
    "        # update the parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        # to convert loss into a scalar and add it to running_loss, we use .item()\n",
    "        running_loss += loss.item()\n",
    "      \n",
    "\n",
    "#     scheduler.step()\n",
    "    \n",
    "    # Calculate test data loss after each epoch\n",
    "    with torch.no_grad():\n",
    "        test_loss = 0\n",
    "        num_batches_test = 0\n",
    "        for batch_i, data in enumerate(test_loader):\n",
    "            num_batches_test += 1\n",
    "\n",
    "            # Add code here\n",
    "            inputs, output_gt, _, _ = data\n",
    "            inputs, output_gt = inputs.to(dev), output_gt.to(dev)\n",
    "\n",
    "\n",
    "            # zero the parameter (weight) gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward pass to get outputs\n",
    "            output_line_params = model(inputs)\n",
    "\n",
    "            # make the ground truth\n",
    "            c = -output_gt[:,2]*torch.cos(output_gt[:,0]) + output_gt[:,1]*torch.sin(output_gt[:,0])\n",
    "            gt_line_params = torch.stack((-torch.sin(output_gt[:,0]),torch.cos(output_gt[:,0]),c),dim=1)\n",
    "    \n",
    "\n",
    "            # calculate the loss\n",
    "    #         print(output_line_params[:,:,0,50])\n",
    "\n",
    "            loss = mse_loss(output_line_params,gt_line_params)\n",
    "            \n",
    "            test_loss += loss\n",
    "                    \n",
    "        test_loss_over_time.append(test_loss/num_batches_test)\n",
    "\n",
    "    # Calculate model loss:\n",
    "    avg_loss = running_loss/num_batches\n",
    "    train_loss_over_time.append(avg_loss)\n",
    "    \n",
    "#     print('Epoch: {}, Avg. Train Loss: {},'.format(epoch + 1, train_loss_over_time[-1]))\n",
    "\n",
    "\n",
    "    print('Epoch: {}, Avg. Train Loss: {}, Avg. Test Loss: {}'.format(epoch + 1, train_loss_over_time[-1], test_loss_over_time[-1]))\n",
    "    \n",
    "print('Finished Training')\n",
    "\n",
    "plt.figure()\n",
    "plt.semilogy(np.arange(0,n_epochs),train_loss_over_time[0:])\n",
    "plt.semilogy(np.arange(0,n_epochs),test_loss_over_time[0:])\n",
    "plt.legend(['Training loss', 'Testing loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "4bc0a2ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor(3.3162), tensor(3.5948), tensor(3.1768), tensor(3.1478), tensor(3.4375), tensor(3.5968), tensor(3.6383), tensor(3.6072), tensor(3.2531), tensor(3.2379), tensor(3.4659), tensor(3.4950), tensor(3.5042), tensor(3.2282), tensor(3.3257)]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA10AAANSCAYAAACeLaSKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4xLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvDW2N/gAAIABJREFUeJzs3Xd4VNXWwOHfmZKe0EJCDSQEQuhVmoogIEpTylVRbNgVyxWxdwWx3avYQP3s4lWKIKiAgApKCCGhidRQEkhCCunT53x/jN1AJmFmzsxkvc/jwzVz5uzFjdmZdfbaayuqqiKEEEIIIYQQwjt0WgcghBBCCCGEEMFMki4hhBBCCCGE8CJJuoQQQgghhBDCiyTpEkIIIYQQQggvkqRLCCGEEEIIIbxIki4hhBBCCCGE8CK3ki5FUe5WFOVnRVF2KYqyUFGUMG8HJoQQtZG5SQjhr2R+EkL8Wa1Jl6IorYE7gH6qqnYD9MBl3g5MCCFOR+YmIYS/kvlJCPF37pYXGoBwRVEMQARw3HshCSGE22RuEkL4K5mfhBC/M9R2gaqqxxRFeQE4CpiA1aqqrv77dYqi3AjcCBAZGdm3c+fOno5V+IrdDtu3Q3w8tGnj1ltKSuDQIejYEWJivByf8JqtW7cWqaraXOs43CFzkxANS7DNTzI3BRdVhcxMaNUKWrbUOpp6yM6Gykro0UPrSAKOu3OToqrq6S9QlCbAYuBSoBT4HFikqupHp3pPv3791IyMjLpFLPzHa6/B7be7Ei83f/jOPReOH4d9+0An7VkClqIoW1VV7ad1HO6QuUmIhiWY5yeZmwJfcTHExsJ//wt33ql1NHXkdELz5jB+PLz7rtbRBBx35yZ3Ph6PAA6pqlqoqqoNWAIMPtMAhR/75BPo1s3thGv3btiwAW68URIu4VMyNwkh/JXMTw1Mebnrz0aNtI2jXrZtc5UsnX++1pEENXc+Ih8FBiqKEqEoigKcD/zi3bCEZg4dgp9+gqlT3X7LggVgNMI113gvLCFqIHOTEMJfyfzUwJSVuf4MyC0Wa9e6/hw+XNs4glytSZeqqpuBRUAmsPPX9yzwclxCKwsXuv68/HK3LjeZ4P33YdIkiIvzYlxC/E295qaKCu8HJoRo8OSzU8PzW9IVkCtda9dCaqprQ5rwGreKwVRVfUxV1c6qqnZTVXWaqqoWbwcmNKCq8PHHMGQItG/v1ls++wxKS+Gmm7wbmhA1qfPctG8fTJ/uKqMQQggvks9ODUvAlhdara49IlJa6HWyA0f8YccO1watK65w+y3z50NKCgwd6sW4hPCUFi1cS7OdO7v2LtbSSEgIIYRwR8CWF6alQXU1jBihdSRBT5Iu8YePPwaDAaZMcevynTth0yZXAw1F8XJsQnhC69awdSskJroeLowe7WqTK4QQQpyBgC0v/PZbVxc0eXrudZJ0CRen07Wf64ILXD1P3TB/PoSGwtVXezk2ITypZ09Xs5h581x/dusGzz8PNpvWkQkhhAhQAVteuHYt9OsHjRtrHUnQk6RLuGzYALm5bnctrKqCDz90LYo1a+bl2ITwNL3edRbd7t0wahTMmgX9+8OWLVpHJoQQIgCVlbk6OYeGah1JHVRUQHq67OfyEUm6hMsnn0BkJEyY4Nbln37qeqojDTREQGvbFr74ApYsgcJCGDDAdaqldDkUQghRB+XlrlWugNpu8cMPYLdL0uUjknQJV+eazz+Hiy92JV5umD8funRxNToUIuBdcolr1evWW11lh126wPLlWkclhBAiQJSVBWATjbVrXUtzg+Xcbl+QpEvAN9/AyZNulxZmZbmqsG66KcCe6AhxOo0awauvwo8/umrbJ0yAyZPh+HGtIxNCCOHnysoCdD/XkCEQHq51JA2CJF3C1bUwNhZGjnTr8vnzISwMpk3zclxCaGHQIMjMhNmzYeVK14GRb7zhajYjhBBC1OC38sKAceKE66ggaRXvM5J0NXQVFa4yqn/9y7UD1I3LP/4YLrsMmjTxQXxCaMFohAcecJ2L0L+/q+zwnHNg1y6tIxNCCOGHAq68cN0615+yn8tnFNULh4PGx8erl156ab3e20ijxwQ9e/bUZNzi4mJNxp0zZw4AEysream4mInx8WSGhdX6voqKqZSUzKZFi0sIDc2q87jnnXdend/jCT/++KMm456v0WT25ptv1ut9iqJsVVW1n4fD8RudO3dWFyxYULc3qSpxq1bRft48Qkwmfr7oInZOmIAjJMQ7Qf7N+PHjfTLO361evVqTcUePHq3JuKtWrdJk3NzcXE3GTUlJ0WTcCy+8sN7vDeb5qW3btupdd91Vr/d269bNw9G4p127dpqM+84772gy7oYNG077elbWUmJisujQ4UmPjtu/f3+P3u83l69bR68DB7j/+utRdf9cgzG68SDeG6KjozUZ94knnqj3e92dmwz1HkEEhQlVVeTo9WS60eNUVaGycipG4y+EhNQ94RIiICkKJ0aPZkebNvT95BO6f/kl7dLT2XztteR36aJ1dEIIIfyAwxGBXl+ldRhu65Sby4HWrWtMuIR3yP/TDVisw8HZZjPLIiPd6ohhtfbAau1GdPTH0kBDNDiW6Gh+uukm1tx3H6gqI599lsELFhAq7eWFEKJBU1VwOCIDJulqVl5ObHk5e9u00TqUBkWSrgZsTFUVenAlXW6orJyKolQTGbnMu4EJ4cfyu3ZlxezZ7Bw3jsRNmxh///0k/vij67euEEKIBsfpDAcM6PWVWofilk45OQDsa9tW40gaFkm6GrCLq6rYbTSy3429KU5nNFVV44mMXIZOJ0/2RcPmCAlh25QprHzySSri4jh7/nxGPPccUQUFWocmhBDCxxwO18PrQFnpSsnNpSwignzpiOZTknQ1UAk2G72tVrdXuaqqLkZVI4iK+sTLkQkROErbtuWbRx5h81VX0ezgQcY9+CBdv/wSxW7XOjQhhBA+4nBEAQTESpeiqnTKzWVv27Zy2KqPSSONBmpCVRVOYLkbSZequroWhoTsJDR0p/eDEyKQ6HTsGzGCnD596P/RR/T5/HMS09JIu/ZaipKTtY5OCCGEl/220mUw+H/S1bK4mGiTiX2yn8vnZKWrIVJVLq6qIj00lDxD7Xm31doHmy1VVrmEOA1T06b8cMcdrL/zTkIqKxn91FP0/+ADjCaT1qEJIYTwIrv9t/LCao0jqV3Kr8dUSBMN35OVrgYoNieHDnY7b7t5il9FxVQUpYLIyOVejkwI7yotNWC3KxgM3mt6kdu3L/ldutBr8WI6r1lD261b2XLVVeT07eu1MYUQQmgnkMoLO+XkcKJRI0o1Og+rIZOVrgYoOT0dK/BVRESt1zocMVRXj/21gUZgbBAV4lQKCsK4+uq+rF3bHKfTe+PYw8PJuPJKvn70USxRUZz38ssMffllIkpKvDeoEEIITfzRSMO/ky6dw0Hy8eOu/VzC5yTpamAUp5PkLVv4PjycMr2+1uurqiahqmFER0tpoQh8rVubCAlx8uSTqdxwQx82bWrq1U7vxR068NUTT7D10ktptXMn4+6/n5Q1a1C8mfEJIYTwqT9Wuvz74XS7EycIs9lkP5dGJOlqYFru20dkWRlfuNlAo7JyKiEh2wgJ2e2D6ITwrqgoB++8k8nDD/+CyaTn/vu7MWNGT7Zvb+S1MVWDgd1jxvDl7NkUJSdz1ocfcsFTT9H46FGvjSmEEMJ3/ljp8u89XZ1yc3EC+1q31jqUBqnWpEtRlBRFUbb96Z9yRVHu8kVwwvOSt2zBGhrK2vDwWq+1WPpjs3UkOvpjH0QmRN3Ud27S6WDkyEI++CCDe+7ZT15eGHfc0ZN77+3Gvn1RXou3Mi6Otffey8abbyb6xAnGPPYYvT/7DL3V6rUxhRDakM9ODYvDEYlOV4Wi+HcVQ0pODrnNm1PtxmdA4Xm1NtJQVXUv0AtAURQ9cAxY6uW4hBfobTaSMjM51Ls35ry8Wq+vrJyKopQTEbHCB9EJUTdnOjcZDCrjx+dxwQUFLF3aio8/bssNN/Rh6NBCpk8/TLt2Xug6qCgcGjyYY9270/fTT+m2YgXt0tPZfM015HXr5vnxhBCakM9ODYvDEeX3pYUhNhuJ+fl817On1qE0WHUtLzwfOKiq6hFvBCO8q+2uXYSaTBzo37/Wax2OJlRVXURU1BJ0Oml5Lfxeveem0FAnl12Wy8KF6Vx11RHS05tyzTX9mDu3EwUFoV4IFazR0Wy64QZW338/qqIw4rnnGDx/PqHl5V4ZTwihKfnsFOTs9ki/P6Mr6fhxDE6ntIrXUF2TrsuAhTW9oCjKjYqiZCiKkmGSc2n8Usf0dKqjoznWuXOt11ZVTQJC5WwuESjcmptKS0tPeYOoKAfTpx9h4cJ0Jk06xrffxnHFFf2ZNy+JkyeNXgm6oEsXvnzmGXZMmED7tDTG338/SRs24NXuHkIIX6txfvrz3FRV5d+rJOL0AmGlKyU3F7tOR3arVlqH0mC5nXQpihICjAc+r+l1VVUXqKraT1XVfuFSK+p3QkwmEnbu5GC/fqi1dC1UVaiouJzQ0AxCQvb5KEIh6qcuc1Pjxo1rvV+TJjZuvz2bjz/ewqhRBSxd2prLLz+LRYt6Ul3t+eTLGRLC9kmTWPnUU5S3bMmQt95ixNy5ROfne3wsIYRvnW5++vPcFOlGcyvhvxyOSL9vF98pN5dDLVpgNXrnIaKoXV1Wui4EMlVVLfBWMMJ7ErOyMNjtHDjrrFqvtVgGYbd3kFUuESi8MjfFxVmYNWs/772XwcCBxSxf3oN77rmElSu7YLHUftxCXZW1acOqhx4i7ZpraHb4MOMeeohuy5eDNNoQIpDJZ6cGwJV0+e9KV4TZTJvCQmkVr7G6JF2Xc4ryHeH/ktPTKWvenBPt29d6bUXFVHS6UiIiVno/MCHOnFfnpoQEE48/vocnn1xBhw5F/O9/fbn33otZu7YTdruHT93Q6dg/fDjLn32WnN696b1oEVFDh6LfvNmz4wghfEU+OzUA/l5e2DE3Fx3Iocgac+sTg6IokcBIYIl3wxHeEFFWRqu9e10NNBTltNc6HM2orr6AyMjF6HQWH0UoRP34cm5q3/4kM2eu46GHVhEXV8H77w/g/vvH8+OPiTidp/+5qitT48ZsuP121t99N0pFBZGjRxN2zz1QVubRcYQQ3iOfnRoOV9Llv+WFKbm5mI1GjsTFaR1Kg+ZW0qWqapWqqs1UVZXf+AGoQ0YGOlV1q7SwsnIKEEJ0tJQWCv+nxdyUknKChx5azT33rCUszMb8+Wfz8MNj2Lq1jcf7X+T27k1FWhrWm28m5N13iR4wAMOyZdJoQ4gAIJ+dGganU4/TGebX3QtTcnI40KoVzlr29Avv8nBtjPBHyenpFCYkUNqixWmvU1WFysrLCQ3djNF40EfRCRF4FAV69jzOk0+u5LbbfsBu1/Hyy8N48snR7N4d79nBoqIwz5lD1dq1qM2bE3n11URMnYqSm+vZcYQQQtSZw+FqguKv5YWNKyqIKytjn5QWak6SriDXqKCAuCNH2O/GKpfZPAS7vR3R0R/7IDIhAp9OBwMGHGHOnC+ZPn0TJ09G8Oyzo5g7dwTZ2c08Opajd28q16/H9NRTGL7/nuiBAwl5801wODw6jhBCCPc5HFGA/yZdKb8+oJPzubQnSVeQS05PR1UUDvbtW+u1lZVT0emKiYj4xgeRCRE89HqVoUMP8NxzXzB16haOHm3C449fxMsvD+XYsUaeG8hgwDpjBhU//YR94EDC77+fyJEj0e3c6bkxhBBCuM3fV7o65eZSER5OXjPPPggUdSdJVzBTVZK3bOF4p05UN2ly2kvt9uZUV48iKmoRiiItqoWoj5AQJ6NH7+GFF5YyceI2du9uwYMPjmX+/MEUFkZ5bBy1fXuqP/+c6nfeQZeTQ9R55xH26KNQXe2xMYQQQtTuj5UuP9zTpaqk5OSwr00b1FoaqQnvk6QriDU/coTGJ064VVpYVfUvwEBUlHS2FeJMhYfbufjinbzwwlJGj/6F9PR2zJo1ng8+6E9paZhnBlEUbJMmUZmejm3qVEJfeYXoQYMwrF3rmfsLIYSo1R8rXf6XdMWfPEmj6mopLfQTknQFseT0dBwGA4d69z7tdaqqo6LicsLCfsRoPOyb4IRoAKKjrVx+eSbPP/8FQ4ceYP36TsyceQmffdabqqoQj4yhNmmCad48KleuRA0JIXLSJMJvuAGlsNAj9xdCCHFq/rynKyUnB0CaaPgJSbqClOJ00iEjg6PdumGNiDjttWbzuTgcbYiKkjbxQnhD06YmrrkmnWefXU7fvjmsXNmVe+65hOXLu2GxGDwyhmPIECo3bsR8330Yv/iCqP79MX70kbSXF0IIL7LbXStdBoMfJl25uRTFxFAcE6N1KAJJuoJWq717iSwvd6u0sKLiCnS6QiIiVvsgMiEarvj4Cm65ZSNPPbWClJQCFi3qzcyZF7N6dQo2mwem49BQLA88QOXGjThTU4m4/XYix41Dd+DAmd9bCCHEP/hreaHO6ST52DH2SWmh35CkK0h1TE/HEhbG0e7dT3ud3d4Ck2k4UVGfoyg2H0UnRMOWkFDK3Xd/xyOPfE2rVmV89NFZ3HffBDZsSMLpPPPNzs6UFKpWrqT65ZfR79xJ1JAhhD73HFilSY4QQniSwxGFotj8rglZ28JCIqxW2c/lRzxT1/I34eHh9K5lH9GptGrVysPRuCckxDP7K+rq8OHDHr+nwWajfWYm+3r0oNRsBrP5H9eMHDkSgMzMcRw7pmf06BxiYkZ6PJa/++GHH7w+Rk1KS0s1GXffvn2ajCtqVlFRUe//Bm+55RYPR+Nyxx3w/fflPP10BG+9NYTvvx/Agw+aGDPGiqLASy+9dEb3j5o+ndGrVtF99mzK33qL5WPGkJOQUOv7Jk+efEbj1tfixYs1GXfMmDGajJuZmanJuMePH9dkXFGzsLAwunTpUq/3Hjx40MPRuKdjx46ajDtz5kxNxq2qqrl8sKKiPSdPmunbt49Xxv3mm/od43NTSQkAb+7bR0l2dp3fb7fb6zXumbrssss0GdcXZKUrCCX98guhFgu/9Op12uucTh17955N69Y/ExNT5KPohBB/pihw3nk21qwp4733KgC45ppoRoxoxPr1xjPeklUZFcWiSZP46PLLMVqtXP/ee4xduZKwGh7GCCGEqBubLYyQEJPWYfzDIJOJX0JCKDF4ZX1F1IMkXUGoc1YWldHR5CQnn/a6nJxuVFU1JTX1ex9FJoQ4FUWBsWOtbNhQxquvVlJSojBlSgwffHANOTlnXh6yv2NHXrvlFn4cOJC+mZnc/vrrdNm9WxptCCHEGbBawwkJ8a+HWKFOJ/3MZjaFh2sdivgTSbqCTGh1NUm//MKeXr1Qdaf/9u7ZM5SIiFISEnb4KDohRG30erjsMgtpaaU8+2wVRUWxvPvuDXz66eUUFMSd0b1tISGsHjWKBddfT0V0NJcuWsTUTz+lUVmZh6IXQoiGxWoN87ukq4/ZTKiqsqmW7tXCtyTpCjIdd+3C4HDwSy176ioqmpKT041OnTai0zl8FJ0Qwl2hoXD99WZmzHiZ4cO/5ejRdsyffwtLlkyipKTpGd07r2VL3po+nW9GjiTx8GFue/11BqaloTidHopeCCEaBtdKl3+VFw4ymbABW2Sly69IoWeQ6ZKZSUlsLAW1dKvZu/ccAFJSNvgiLCFEPYWE2Dj77A307buFn34aQnr6QHbv7krv3pmcc873xMRU1Ou+Tp2OTYMGsTs1lTFff82Fq1fTY+dOlo8dS37Llh7+WwghRHDyx/LCwdXV7AgLo6qWiifhW/LdCCJRZWW0zc52rXIpp2477XDo2LfvbNq23UV0dIkPIxRC1Fd4uJnzz1/LjBkv07dvBllZvXn11TtZs2YU1dX1f5pZ1rgxn1x2GZ9NmkRMeTk3vv02o1avRqmu9mD0QggRnFzlhf6z0hXtcNDNYpH9XH5Ikq4g0nnbNhRVrbW0cPfuJKqrG9O5szTQECLQREVVcuGFX3HbbfPo2nUXaWmDeOWVu/j++6FYLPU8+kJR+LlrV1699VayevdmSFoanSZOJGqDrIQLIcSpqKr/7ek6y2RCD7Kfyw9J0hVEOmdlkde2LaXNm5/2urS0nkRGltC27S4fRSaE8LQmTUqZMOELbr75dZKSsvn+++HMm3cXaWmDsNvrVzluDg/ny7Fjeeeaa3CGhZF42220nTULQ3Gxh6MXQojAZ7eHoqp6v1rpGmwyUa0obAsL0zoU8TeSdAWJpidO0OLYsVpXuYqLG7FvXyIpKRvR6WTTvBCBrnnzQv71r/8xffp8WrTIY/Xq0bz66h1kZvbB6azfFH80IYEDn31Gwa23ErN2LZ3Gj6fJ4sUgjTaEEOJ3VqsrsfGnpGuQyURGeDjW02wzEdqQpCtIpGZm4lQU9vbsedrrNm/ugaI4SUnZ6KPIhBC+0Lr1ca688kOmTXuX6OhyVqyYwOuv38bPP3dFVev+y1cNCeHEzTezf9EiTCkptHniCRKnTyf00CEvRC+EEIHHanXtm/KX8sI4u52OVqvs5/JTknQFA1UlNSuLo8nJVMXEnPIyu13Hli3dSE3NJjLypA8DFEL4SmLiYa677m0uvfQTDAYHixf/i7feuon9+zvW6xxka2Iih955h9wnniBs/36SJ08m7vXXUaxWzwcvhBABxGLxr5WugSZXHD9J0uWX3Eq6FEVprCjKIkVR9iiK8ouiKIO8HZhwX8ujR2lcUlJraeHPPydTWRnJoEHbfRSZEN4lc1PNFAVSUvZy441vcMkli7BYQlm48Eree+86jhxJqNcNT15yCfuXLaN8xAji33yT5ClTiMjI8HzwQgQJmZ+Cn83mXytdg6urOanT8UtoqNahiBq4u9L1MvCNqqqdgZ7AL94LSdRValYWdoOB/d26nfa6tLSeNGlSRqdOh30TmBDeJ3PTaeh0Kt277+TWW1/loou+5OTJJrz//nQ++eQK8vJa1Pl+9mbNyJk7l0Ovv47OYqHDddfR+vHH0ZWXeyF6IQKezE9Bzq/2dKkqg0wmNoeHo8p+Lr9Ua9KlKEoj4FzgHQBVVa2qqpZ6OzDhHsXhIGX7dg526YL1NMvJhYWNOXCgHQMG7ECnq0eNkRB+RuYm9+n1Dvr1y2DGjFcYMWI1x4614a23bmHRoikUFTWr8/0qzz6bfUuWUHjNNTRZtoxOEybQ6OuvqVf9ohBBSOanhuGPPV3aJ13tbDZa2e38JK3i/ZY7K12JQCHwrqIoWYqivK0oSuTfL1IU5UZFUTIURcmorKz0eKCiZu0OHCCyspJfevU67XWbN/dEp3PSv7+0iRdBo85zU1VVle+j9CNGo43Bg39kxoz/cs4537F/f0feeOM2vvxyPGVljep0LzUigvx//5sDCxdia9GChPvuo/1tt2E8dsxL0QsRUGqdn/48N5XLanFA+mOlS/vywsGyn8vvuZN0GYA+wBuqqvYGqoD7/36RqqoLVFXtp6pqv6ioKA+HKU4lNTMTc1gYh1JTT3mN3a4nI6MrXbocICamYX/oFEGlznNTZOQ/crIGKSzMwrBh67njjpc566x0duzoyauv3sGqVaOpqqrb/0fmzp05+NFHHJ81i4itW+l0ySXEvv8+2O1eil6IgFDr/PTnuSnmNE2whP+yWFwJjtGofdI1qLqa4wYDR4xGrUMRp+BO0pUL5KqquvnXf1+EayIRGjNYrXT8+Wf29eiBw3Dqw1B37uxIVVWENNAQwUbmpjMUGVnFBRd8w+23v0KPHttJTx/AvHl3sn79MCoq6tDcVq+n+Mor2f/FF1SedRYtX3yR5KlTCdu923vBC+HfZH5qAGy2MIxGk+bbNhRVZaDJ5GoVL/u5/Fatv1VVVc0HchRFSfn1S+cD8pvUD3TYvZsQi6XWroVpaT1p2rSU5OQjPopMCO+TuclzGjUqY9y45dxyy6skJ+9nw4bzuOiiFN59Nxaz2f1f4LaWLTkybx5HXngBQ3ExyVOn0vL559FVV3sxeiH8j8xPDYPVGu4XpYWpFgtNnE7Zz+Xn3H2UOQP4WFGUHUAvYLb3QhLuSs3KoiImhtykpFNeU1DQlOzstgwcuAOdnMomgo/MTR4UG1vM5Mmfc8MNb9Ktm4n//KclY8em8NlnTbHZ3LyJolA+ahT7li6lZNIkYj/8kI6XXEL0Dz94NXYh/JDMT0HOYgn3iyYav+3nSpP9XH7NrY/hqqpu+7XuuIeqqherqion62osrLqaxL172dOrF+ppsqnNm3ug1zukgYYISjI3eUfLlnm88cZh/u//DtK6tZWnn27NhAmdWLmyMQ6He/dwxsRw/JFHOPj++zgjImh/++20nTkTQ2Ghd4MXwk/I/BT8bLYwv1jpGmQyccBo5MRptpoI7cnaR4DqtGMHeofjtKWFNpuBjIyudOu2n6goKe8RQtRNv37VvPdeNq+9dpjISCcPPNCWKVM6sn59tNvd4at79+bAZ5+Rf/vtxHz3HZ0uvpgmixaB0+nd4IUQwstc5YXarnQZVZV+JpOUFgYASboCVGpWFsVxcZxo3fqU1+zY0QmTKZyBA6WBhhCifhQFzjmngv/97wDPPXcUm03hzjvbM21aB9LT3et0qBqNFN54I/sXLcLUuTNtnnySpGuvJfTgQS9HL4QQ3uMqL9R2pauX2UyEqkqr+AAgSVcAii4tpW12tutsrtN0qdm0qSfNm5fQoUOOD6MTQgQjnQ5Gjy5jyZJ9PPZYLgUFBq6/PombbmrPrl3u/bK3tm/PobffJueppwjNziZ5yhTiXnsNxWLxcvRCCOF5rvJCbVe6BldX4wDSJenye5J0BaDOWVkApy0tzM+P5ciR1gwYsEO6hwohPMZohEmTTrJixT7uvfc4e/aEM3VqMnffncDBg6G130BRKJ0wgX3LllE2ejTx8+fTcfJkIrds8X7wQgjhQf7QvXCQycSu0FAq9HpN4xC1k6QrAKVmZXE8IYGy2NhTXpOW1gO93k6/fj/7MDIhREMRGqoybVoxK1fu5dZbC0hLi2LSpI48/HAbjh2r/XBOR9Om5M6ezaE33wSHg6Tp02n92GOU6uRgAAAgAElEQVSEVFb6IHohhDgzDocOuz1E05WuSKeTHmaz7OcKEJJ0BZhm+fnE5eWddpXLajWwdWsXevTYR2Sk9q1MhRDBKyrKyc03n+Crr/Zy5ZVFfPNNI8aN68ScOS0pKqq9k1bl4MHsX7yYE9ddR5Ply7nkwQdJ3LQJtzt1CCGEBmw2Vzmflitd/U0mjOA6FFn4PUm6AkxqVhZOnY69PXue8prt2ztjNodJAw0hhM80aeJg5sx8VqzYy8UXn+Szz5px0UUpvPxyPOXlp/9Vo4aHU3DXXRz49FMqmzdn6IIFjHzxRaJOnPBR9EIIUTdWaxiApitdg6qrsSgKmWFhmsUg3CdJVyBRVVKzsjiSnEx1dPQpL9u0qSdxccUkJh7zYXBCCAEtWth59NHjLFu2j2HDynnnnTguvLAzb7/dnOrq028wNaek8NVDD5F2xRXEHTzIxY88Qtevv0ax230UvRBCuMdq/W2lS8Oky2QiIywMy2nOaxX+Q75LAaTVkSM0OnnytKWFx441JyenJQMHbpcGGkIIzSQkWJk7N4fPP99P795VvPJKC8aMSWHhwmbYbKeenFSdjj0jRrD06ac53rUr/T/7jHFPPkmz7GwfRi+EEKf3R9KlTXlhU7udVKtVSgsDiFeOrjaZTGzfXr/StpSUFA9H456NGzdqMu7y5cvdvvbfBw9i0en4z+HDmHJza7zm4MF70OksFBQ8zxdfVJzyXvX9/pypyy67TJNxV61apcm48fHxmowramaz2Th+/Hi93jtixAgPR+OekpISTcbt2LGjx+51ww0wdGgsn3/emzlzWvHWWzFMnLiDIUMOodPVvHerulkz1t1xBwlbtzLgo48Y+/TT/HL++WROnIjdCx8yGjVq5PF7usNms2kybmJioibjipqpqorVaq3Xe/Py8jwcjXu0+r1aXFysybj5+fl/+feCgrYAVFTk/uM1T7Kc4kiNftXVAHxvMJzymjMxefJkj9/THYsWLdJk3Dlz5nh9DK8kXcLz9E4nw4qK2NikCSZDzd82hyOcwsJRxMauxWA4dcIlhBC+1qlTEQ8+uIZdu1ry+ee9WLBgMCtWdGHy5O3065dzypX5o337kpeaSp/Fi0ldu5Z2W7eSNm0aOadZ8RdCCG/7rZGGwVCtyfhnm82UKQo7Q0I0GV/UnSRdAaJ/aSlN7HZWN29+ymsKC0fgcEQSH7/Mh5EJIYR7FAW6d8+jW7c8MjLasmhRL155ZSiJicVMmZJFt241Py22RUSwedo0sgcNYvB773H+K69wuF8/Nk+diqlJEx//LYQQAux2V5t2o1GbpGuI2UxaWBhO2UsSMCTpChAji4ooNxjYfJoPGPn5FxMRcYDoaDmbSwjhvxQF+vfPoU+fXH78MZElS3rw3HMjSE3NZ9KkrXToUFjj+wqTk1n++ON0++Ybei1bRquff2br5MnsPe88kI3kQggfstm0S7ra2u0kOBy8HerGgfTCb8hvqQAQ5nBwTnEx65s1w36KDxYVFSlUVaXQosVyaaAhhAgIer3Kuedm8/zzy7nyyi0cO9aIp58ew8svDycnp3GN71ENBnaOHcsXTz9NUWIigz78kAvnzKHxKfa5CiGEN9hsESiKDZ3O9/syh5hdzTs2Sqv4gCJJVwA4u6SECKfztKWFBQUT0OlMNG+uzcZWIYSoL6PRyQUX7OXFF5cxcWIme/e24LHHJjB//jmcOFHz8RgV8fGsnjmTDddfT6P8fMY//ji9Fy9GX89mBEIIURd2ewRGY7UmD7qHWCwU6HQcOMUef+Gf5LsVAEYWFlIQEsKOmJgaX7fbIyksHEFs7LcYDFU+jk4IITwjLMzOuHE7GDZsD19/3Z1vv01ly5ZEzj13H+PG7aBJk7+V8SgKB4cMIbdHD/p/+ik9V6wgMT2dn66+mvwuXbT5SwghGgSbLUKT0kJFVRliNvNDWBhS2hRYZKXLzzWy2RhQWsq3zZujnuKHq7BwFE5nBC1aSAMNIUTgi4qyMmXKVubOXczQoXv54YdO3HffRP73v35UVv5zD4MlOpqNN9zAqpkzARj9/POc/fbbhFZIF1chhHfYbBEYDL4/GDnFZiPW6ZTSwgAkSZefG1ZUhEFVWXOK0kJVhfz8CURG7iUqao+PoxNCCO9p3NjEtGmbmT17Cf37H2bVqq7MmjWJ5ct7YDL9s1Ajr2tXlj31FNvHjiUpLY1LHnyQpJ9+ck2UQgjhQa7yQt9XFw359UyuH6WJRsCRpMvPjSwqIjsiggMRETW+XlnZlerqZGmgIYQIWnFxldxww0aeemoZqal5LF3ah/vum8Tq1V2w2fR/udYREkLWpEksf+wxyuPjOfettxj1wgtEnzihUfRCiGCkVXnh2WYz2QYDebKfK+BI0uXH4s1mepaXsyY29pR1u/n549HpqomNXe3j6IQQwrdaty5lxoz1PPLICtq2PcnChWdx//2X8MMPHXE4/jpHlrZty9cPPsimadOIzc5mwsMP033lShS7XaPohRDBxG73fXmhQVUZYLHIKleAkqTLj40sKgLg21OUFtrt0RQVnU/z5qs1qSsWQggtJCUVce+9q7n33lU0bmzi3XeH8PDDF5Oe3h6n84/rVJ2OvcOH88Xs2eT26EHfRYsY98QTND94ULvghRBBQYuVrp5WK1GqKvu5ApRba5OKohwGKgAHYFdVtZ83gxIuIwsL2REdTd4pfrhOnLgApzNMGmiIBkvmpoatS5c8UlNXkpXVliVL+vDGG+eRkFDMpEmZdO9+7PcCgeomTfju9ttpm5nJwI8+4qJnnmHP8OFkTpqELTxc27+ECFoyPwUvVQWbLRyDwbdJ1xCzGSfwk6x0BaS6FIQOU1W1yGuRiL9IqqqiQ3U1LyYl1fj6bw00oqJ2ExW138fRCeFXZG5qwBQF+vTJoVevXNLSEvnii9785z8j6dixgMmTt9Kp0x97uXL69CE/NZXeS5aQunYtCZmZbL7ySo726aPh30AEOZmfgpDDEQbofb7SNcRi4WejkTK9vvaLhd+R8kI/NaqwEDuwPja2xtcrKnpgMiXKKpcQQgA6ncrgwdnMnr2UadM2ceJENHPmXMRLL43gyJGmv19nCw8n/YorWPnQQ1iiohg+bx7D5s2D3FwNoxdCBBKbzbVC7sukK9zppK/Fwo9SWhiw3E26VGC1oihbFUW5saYLFEW5UVGUDEVRMkwm2V90JhRVZURREelNmlBqNNZ4TX7+ePT6SmJj1/o4OiH8isxN4i8MBifDh+9l7tzFTJ6cQXZ2cx5/fDxvvDGU/Pw/Dpgv6tCBLx99lIwpU2i9cyfGXr3QvfEGOBwaRi+CzGnnpz/PTeXl5RqEJ+rLZnN1lPZleWF/i4UQYKOUFgYsd8sLz1ZV9ZiiKHHAGkVR9qiq+sOfL1BVdQGwACA+Pl4ORTkD3cvLaWGxMD8hocbXbbYYioqGER+/Ar3e7OPohPArdZqb4uLiZG5qIEJDHYwZs4thw/bx9dddWbOmCxkZ7Tj77AOMH7+NZs2qUQ0Gdl10EUf69eOS1asx3HUXzk8+wfH666jdu2v9VxCB77Tz05/npuTkZJmbAojdHgn4dqXrbIsFK7BFkq6A5dZKl6qqx3798wSwFDjLm0E1dCOLijDpdGxs1qzG10+cuBBVDZXSQtHgydwkahMRYWXSpCzmzl3M8OF7+OmnDtx//yQWLuxPebnrw0tFXBz2lSuxv/suSnY2hoED0T/8MMjKqDgDMj8FLy3KC4eYzWwNDcWkk51BgarW75yiKJGKokT/9r+BUcAubwfWUBmcToYXFbGxaVNMNWyUVFUoKBhPdPROIiOzNYhQCP8gc5Ooi0aNzFxxRTpz5ixh4MBs1qxJ5b77JrN0aS+qq42gKDinTsW2YwfOK65A//zzGPv0QVkrJdyi7mR+Cm52u2/LCxs5HHS12eR8rgDnTrocD2xUFGU7kA6sVFX1G++G1XCdVVpKI7ud1ac4m6u8vDcmUztZ5RJC5iZRD7GxVUyf/iPPPLOMbt2OsXx5L2bNmsRLL+lcC1vNmuFYsADbN9+ATofxoovQX3cdFBZqHboILDI/BTGbzbflhYMtFnQgTTQCXK17ulRVzQZ6+iAWgatrYanBQHrjxjW+np8/Ab2+gmbN1vk4MiH8i8xN4ky0bFnGbbd9x+HDzVi8uA8PPNCaefNUHnzQwTXXODEOG4Zt61b0zz6L7oUX0H3zDY65c3FeeSW/HwAmxCnI/BTcfisv9NVK19lmM5WKwvaQEJ+MJ7xDCkP9SLjDwdklJayPjcVRQ82u1dqY4uKhxMV9jV5v1SBCIYQILu3bF3PPPWtYs8ZGu3Yqt99uoEcPI59+qsMZEobj8cexp6ejduqE4frrMYweDfvlbEQhGrLfyguNRt80MxtisbA5NBS7PPAJaJJ0+ZFziosJczpZc4rSwhMnLkJVjVJaKIQQHnbuuSrr19tZutRGZKTK1Vcb6N/fwIoVCs7ULtjXrcM+bx5KZibGvn3RzZ0LVnn4JURDZLNFYDBUoyhOr4/V0m4nyW5no5QWBjxJuvzIyKIi8kJD2Rkd/Y/XVFWhoGA8MTHbiIg4okF0QggR3BQFLrpIJT3dzgcf2DGZFCZNMnLeeQa+36DHeeON2LZvRx0zBsOjj2IYMABl0yatwxZC+Jgr6fJNd9MhFguANNEIApJ0+YnGViv9T57k29hY1BqWj8vK+mI2tyE+Xla5hBDCm3Q6uPRSJ9u323j9dTs5OQqjRhkZM8bA1rzW2BcuxLZ4MUpFBYZhw9DPmAFlZVqHLYTwEbs9AqOxyidjnW02U6jTsddo9Ml4wnsk6fITw4uLMcApuxbm50/AYCglNvZ73wYmhBANlNEI06c7+flnG3Pn2snKUhg82MhllxnY3WEstqwsnLfdhu7ttzH27ImydKnrXA8hRFCz2SJ807lQVRliNvNTWFiND+RFYJGky0+MLCzkQEQEhyIj//Ga1dqUkpJziIv7Gp1O9hAIIYQvhYfDXXc52bPHxsMPO1izRqFPHyPX392YgzNexL5xI2pcHMbLLsMweTLk5GgdshDCi+x235QXtq6oIN7plNLCICFJlx9oZTbTvaLilA00CgrGoKoGWrRY7uPIhBBC/CYmBh55xMHevTZmzHDy2Wc6unUzctdHZ3Fs6U/Y58xBWbsWY69e6F59FRwOrUMWQniBr1a6ev56PqCczxUcJOnyAyN+/aH6Njb2H6+5GmiMo1GjrYSHy9NTIYTQWmwsPPecg927bUyb5mT+fB2du4XzcOm9FH+fhTp4MIZ77sFw7rkoO3ZoHa4QwsNcSZf393R1LyzkqF5PjqHWY3VFAJCkS2uqysjCQrbFxFBQw5OM0tKzsFhaSQMNIYTwM23awBtvONi+3cbYsU7mztXTcVQn5pyzgsq3PkA5ehTDwIHoH3gAqn1ziKoQwvt8UV6oczrpVlQkq1xBxCupc0REBL169arXe0tLSz0cjXuan6K0z9sGRUaSaDLxVmoqrVq1+sfrhw5dSmhoGd2770en++fr9WUy+abV6d+lp6drMm5iYqIm43733XeajCtqZjKZ2LlzZ73eG1nDfktfGDBggCbjLl+uTTnzli1bNBm3vLz8jN4/ZAi0axfLypWDePiRRJ6LmcjE8xrx7/xn6f7SS1S+/z7rp0zhaGrqX95nt9vPaNz6GjNmjCbjippVVlayYcOGer335ptv9nA07lm3bp0m4w4aNEiTcU+cOAGAw6HD4QilWTMDbdq08dp4Cfn5RNpsrAsNpVqDhzZr1qzx+ZgA/fv312RcX5CVLo2dc+QIdkVhUw0/uCZTE/Ly+tK+/Xp0OtkbIIQQ/qxNmyJuuulL7rzzc5o3L+W95eM578DXPD3ieRx6PRe/+SajPviA8IoKrUMVQtST1epaeQoJMXt1nJTcXAA2SKv4oCFJl5acTobk5LC9RQsqa+hMc+jQcFRVT1LSWg2CE0IIUR9JSXnMmLGYm2/+gogIC498O5PeShbLel1Ox23bmDZ7Nl3S0qS9vBAByGoNByA01LsVQ51ycjjWrBlFOvmoHizkO6mhFvv20cxkYkNCwj9eU1WF7OzziY/fTlRUgQbRCSGEqC9FgdTUo9xzz6dce+1XmNUwLt72CaPi1pHbqB0jFi5k4quv0vjXRkpCiMDgi5Uuo91OUl4e+9q29doYwvck6dJQUloaZr2erTXs5crL643JFEtS0rcaRCaEEMITdDro1esA99//MZdf/i2Zpt50ytvFw3HP0iznOFe98AID1qxBp9HeLiFE3fy20uXNpCsxLw+jw8FeL+4ZE74nSZdGdDYb7TMySG/dGksNrUCzs0cSFnaSVq0yNIhOCCGEJ+n1KgMH7uaRRz7gkokbeLl6BomWg6yJuIAh33zDtJdeolV2ttZhCiFqYbH8ttLlvfLCTjk5OHQ6DrZu7bUxhO9J0qWRNrt2EVpdzcYaSgurq5uRl9ebxMR10kBDCCGCiMHgYOjQ7Tz66Pv0G5PNROtixrAC60kdl732GucvWkSoRt1lhRC1+628MDTUeytdnXJzORIfjyUkxGtjCN+TpEsjSZs2YYqOZmd8/D9ey84+H4DERGmgIYQQwSg01MaoURk89NA7mIY1p4vzZ17iLrpt2sxVzz5Hp23bpNGGEH7I2+WF4RYLCSdOsE9KC4OOJF0aMJpMtN2+ncP9++P4W1cap1PHoUPDadFiG5GRRRpFKIQQwhciIsyMHbuROx78jMWDr2agson9lR0Y++GHjFvwHtElJVqHKIT4E2+XFyYfO4ZOVaWJRhCSpEsD7TIzMdhsHBw48B+v5eX1xWxuKg00hBCiAWnUqIpJk9Yx6oGd3NLnPf7Ni7Tal82Vz75Ej3UbUZxOrUMUQuAqL9Tp7Oj13ml+0yknB4vBwOEWLbxyf6EdSbo0kJSWRkVsLIUdOvzjtezsEYSHF9OyZaYGkQkhhNBSs2ZlXHrFt+hnNuOSjitZ5xjGiJVLGff0WzQ9kqd1eEI0eFZrOCEhZhTFO/fvlJtLdqtW2PV67wwgNCNJl4+Fl5XRcvdusgcO5O8/sVVVzcnP7/lrAw15qimEEA1Vy5bFjL45k9UzpnJH/GtElZUx7ZWX6Dj/J3Qmq9bhCdFgWa1hXjsYOaaykpYlJeyV0sKg5HbSpSiKXlGULEVRVngzoGDXPj0dnapycMCAf7yWnT0CkAYaQtSFzE0imLVrX0D7WWaeu2YOn0ZNZdy+xUx89HXUr8qRikP/J/NT8LFaw7zWRKNTbi6ANNEIUnVZ6boT+MVbgTQUHdLSKE5IoOxvZy84nXoOHRpGy5aZRETIxmkh6kDmJhH02nQ/Sf7jvZl94TOYlXDuWfsEHR/dwLHMxtLk0L/J/BRkLJZwryZdVWFhHGve3Cv3F9pyK+lSFKUNMAZ427vhBLfoggKaHzpEdg2rXMeP98NiaUyHDms0iEyIwCRzk2hIFAXCRoSx8unr+bz7lYw2fcXDH99D0bMODmfLpnt/I/NTcHKtdHmhvFBV6ZSTw/7WrVG9tWFMaMrdla7/ArOAUxYzKIpyo6IoGYqiZFRUVHgkuGCTtHkzqqLUmHQdPDiSiIhCWrTYpkFkQgSsOs1NNpvNd5EJ4SVqiJ6ca3rz4T3/5nhsAnOKZjHptfmsfa07x4/Hah2e+MNp56c/z03V1dW+jUzUm7fKC5uXldG0slJaxQexWpMuRVHGAidUVd16uutUVV2gqmo/VVX7RUdHeyzAoKGqJKWlkd+pE9VNm/7lpcrKeE6c6EFi4loURepEhHBHfeYmo9Hoo+iE8L7yVs1Zdd80Vk68jD7GLJZkjyXqxWw+fX8EhYWNtQ6vQXNnfvrz3BQREeHD6MSZsFrDvdJIo1NODoA00Qhi7qx0DQHGK4pyGPgUGK4oykdejSoINTtyhMb5+a6uhX+TnT0CRXGQmLheg8iECFgyNwmh07F3SH8+fuge9vfozuM8wQc7/sWmuUl8/vkISkujtI6woZL5KQipqvdWulJyciiJiqKwUSOP31v4h1qTLlVVH1BVtY2qqu2By4B1qqpe6fXIgkxSWhoOvZ7Dffv+5esOh4FDh4bRqlUG4eEnNYpOiMAjc5MQf6iOjmb11VNZcsMNxDcu4jt1GNM3v8Ibsy9h+fJzqawM1zrEBkXmp+Bks4WgqjqPJ12KqtLx2DFXaaHs5wpack6XDyhOJ0mbN5PbowfWqL8+dTx27Cys1hiSkr7VKDohhBDB4nDnznw46x4yzjuPa3mXPUoqLb/fx+xnrmPVqkGYzSFahyhEwLJaXQ8vPF1e2LqwkEizWVrFB7k6JV2qqn6nqupYbwUTrFrs3UtEWdkpSwsjIwuIj9+hQWRCBAeZm4T4gz00lB/GjeOTu+7E1iKchVzBmtBR7F3dkmeemc533/XFbJan6b4i81PwsFrDADy+0iXnczUMstLlA0mbNmENCyOnZ8+/fD0vrxGFhd1ISvpWGmgIIYTwqMI2bVh4552snzCBAZY09ho680jE03z15RAuuCCR//2vEdLQUwj3/bbS5emkKyUnh/wmTSiPkj2YwUySLi/T22y027qVI3374gj5a1nH9993QlHstG//nTbBCSGECGqqTkfWuefy/qxZ5HbqwP1Fs8mO7cjwRuk89lgLxo5NZMWKaJynPHRBCPGbP1a6PFdeqHc4SDp+XLoWNgCSdHlZmx07CDWZ/nE2l82m58cfk2ndegthYWUaRSeEEKIhqGjShGXXXceXV11FU0sxHx84l23Db6CJsYKZM1txySXtWL8+ElWKLoQ4JYvF8+WF7fPzCbXb5XyuBkCSLi9LSkujOiaGvNTUv3w9I6MdVVVhJCWt0SgyIYQQDYqisL9nT96/7z7K/vUveq57m/SqHiy+7gNMJh233NKGqVMTSE+XTodC1OSPRhqeS7pScnJwKgoHWrf22D2Ff5Kky4uM1dW02b6dw2edharX/+W1775LIT6+jLi4nzWKTgghRENkCQ+n4PHHOfrJJzgjI5j4f1ezI/Vinr9nB8eOGbjqqgSuv74Nu3aFah2qEH7FG+WFnXJzORoXhylUft6CnSRdXtRu61YMdjsH/9a18Nixxuzf34KhQ/dJAw0hhBCaMPXpw+ElSyi8806i16/l7gVnk3Hjs8yamc/OnWFMntyeO+9sRXa2tJkXAv4oLzQaLR65X6jVSruCAula2EBI0uVFHdLSKI+Loygx8S9f/+67FAwGB0OG7NcoMiGEEAIICaHklls4vGwZltRU2j79KI+tG8PGBau59dYiNmyIZOzY9jz4YAuOHTNoHa0QmrJawzEazeh0nnlg3uHYMfROp+znaiAk6fKS8NJSWu7Z41rl+tPp4haLnp9+6kDfvoeJjvbMkxIhhBDiTNgSE8l5/33yZs8m9OBBul45gSd4jLUrf2HatJOsWBHN6NGJPPNMHMXF+tpvKEQQslrDPNpEIyU3F5tez6GWLT12T+G/JOnyksT0dBRV/UfXwi1bEjGZQjnvvL0aRSaEEELUQFEonziRQ199RcXo0cS+/jp9rh3Lk8NXsGrVIS6+uJxPPmnMyJFJ/Pe/sZSXy0cI0bBYrWGEhnpwP1dODtktW2IzyCpyQ+CV77JOpyM8vH7dj7Zt2+bhaNyza9cuj97v3NWryW7alMW7dsGf7r169dnExBzjyJGPOHoUNm7c6NFx3dWhQwdNxm3atKkm427atEmTcTt27KjJuKJmTqcTk6l+vzALCgo8HI17hg0bpsm48fHxmowbpdHhoBkZGZqM279/f03Gre2/5+MzZ9Jk6FCSX3yRhKuvJuSii7jrlluYMCGe//u/drz5ZhwffxzD1Kk5TJx4nLAw9w76SklJ8UT4QSc0NJTk5OR6vXfDhg0ejsY9e/bs0WTcZs2aaTJuu3bt0OmaEB2t0q5duzO+X3hFBa2Li9lw4YWnvd+55557xmPVh8Ph0GRcWxCf2C6PqbygRXk5HUpK+OlvP0QnTyZQXNyRDh3W/rniUAghhPA7J/v3Z+t775Fz+eXEr1pFv6uuos+e5Tz26C+89dZWunYtZ/78JC6/vD9Ll7bEZpNfbCK4mc0hhIV5ZmtIwoEDAByVh7MNhiRdXjDkyBGcwE8JCX/5+oED56PTWUlM1OaplBBCCFEXzrAwDt18M5kLFmBu0YLUp5+m26xZ9Ig+wNy5P/PKK9to3drMf//bkWnT+rFqVRwaPSAXwuvM5lDCwqweuVfCgQOYw8IokM6FDYYkXZ6mqgw5fJjd8fGURkT8/mWbLZTDh4eQkLCZ0NAqDQMUQggh6qYqOZltr73GgTvuIGbnTvpefTVtFi6kZ9cS5s3bzty5O4mKsjN7dmemT+/Lhg3NUOVEFBFkPLrStX8/uR06oOrko3hDId9pD+tQUkKLykp+/Ftp4dGjg7DbI0hOXqtRZEIIIcQZ0Os5PmkSWz/4gJP9+pH05pv0uekmovf8wsCBJ1mwIIvHH9+N3a7w8MNdufXWXmRmNtY6aiE8xlMrXTHFxTQuKZHSwgZGki4PG3z4MDadji1/O3PhwIHzadToKLGx+zSKTAghhDhzlrg4dj/zDD8/9RTG0lJ633orHV55BaO5mmHDinjvvQxmzdpHUVEId9/dg3//uzu//BKtddhCnBGHQ4fNZvTISle7X/dzHaln8xQRmCTp8iCd08mgo0fJatWK6pCQ379eUpJISUkHkpPXSQMNIYQQgU9RKD73XDLef5+88eNptWQJ/a66iqY//ojBAGPG5PPRR1u4/faDHDgQyc039+ahh7rw889aBy5E/ZjNrs91nki6EvbvpzImhhKNusQKbUjS5UFdCgpobDbzY/v2f/n6gQPno9dbaN9em/bwQgghhDc4oqI4cPfdbHv1VexRUXR78EFSH32UkKIiQkNVpkw5xqefbuG66w6TldWY7t3hqqvg0CGtIxeibud2rUAAACAASURBVMzmUIAzLy90OknYv5+jycnIk/iGRZIuDxpy5AjVRiPbWrX6/Ws2WzhHjgwmIWETISHVGkYnhBBCeEdFt25kvvUWh264gWabNtHvqqto+cUX4HQSEeHg6quPsnBhOjNnwuefQ0oK3H475OVpHbkQ7vkj6Tqzla7Y/HwiqqpkP1cDJEmXhxjtdvrn5JDepg02vf73rx8+PBi7PUwaaAghhAhqqtFIzpVXkvHuu1R07kzH//yHnjNmEPHrslajRnaeew4OHoTp02H+fOjQAR54AEpKNA5eiFr8UV54Zitdcj5XwyVJl4f0OX6cCLv9L6WFquoqLWzc+DDNmh3ULjghhBDCR8xt2rDzxRfZ88ADROTk0Of662n/9tsoFtcKQatW8MYbsGcPTJwIc+dCUhI88wxUVmocvBCn4KmVroT9+ymJjaWisXT2bGgk6fKQwUeOcDI8nN1xcb9/raSkA6Wl7UlOXitlu0IIIRoOReHE6NFs+eADCs8/n4QPP6TftdfCunW/X9KhA3z0EWzfDkOHwsMPu772yitg8cxRSEJ4jCcaaegcDtpmZ8sqVwNVa9KlKEqYoijpiqJsVxTlZ0VRnvBFYIEk0mql1/HjbEpI+Mshd/v3n4/BYKZ9+580jE6I4CRzkxD+z964MXsffJAdL77o+sL558O110Jx8e/XdO8Oy5bBpk3QtSvceadrz9d774Hdrk3cZ0rmp+DjiUYaLXJyCLFYXE00RIPjzkqXBRiuqmpPoBcwWlGUgd4NK7D0z8nB6HT+pbTQao3g6NFBtGv3E0ajSbvghAheMjcJESBK+/Vj67vvujZwffQRdO7s+lNVf79m4EBYuxbWrIG4OFdu1r07LF78l8sChcxPQcYTK10J+/ejKgo5knQ1SLUmXarLb1XWxl//Cbzpz4uGHD7M8ehoDjVp8vvXDh8+G4cjVBpoCOElMjcJEVicoaEwezZkZkJyMkybBhdc4Oqs8StFgREjYPNmWLIEdDqYPBn699cw8HqQ+Sn4mM2h6PV2jEZHve+RsH8/J1q1whwZ6cHIRKBwa0+Xoih6RVG2ASeANaqqbq7hmhsVRclQFCWjvLzc03H6rabV1aSeOOFa5fp145argcZwmjY9SNOmchiJEN5S17nJHqi1SkIEk/9n787j467ue/+/zuwz2mzJWmxZsmUbY4zZDSaQsJkASQgJCQlhDQkN7U1I0vb+mpvm9tHeJvfR27T3Nu0jJE0JOJCwhTUJJOxhSdiCAQNeMJYXbZZlWZK1zj7n98fIwotsjeQZfTUz7+fjoQd4vt+Z8x6QP9Jnzvme7wknwB//CD/6Ebz6KqxYkd5NIx4fO8UYuPxyeOcduPPOA1Yj5o2J6tP+tWlIO4jMeJGI76iWFnqiUea1tOh6riKWUdNlrU1aa08G5gNnGGNWjHPOrdbaldbaleXl5dnOOWN9qKUFF/DyggVjj+3Zcwz9/Y2a5RLJscnWJo/HM/0hReRQbjd89auwaRN8/OPw7W/DypXpKa6DTrv++vROh/lmovq0f20qLS11JqRkLBLxH9XSwvodO3Ank7So6Spak9q90Fq7F3gOuCQ3cfLPWS0tNFdV0VVWNvZYc/OFeDwjNDa+4mAykeKh2iSSp+rr0xdtPfJIejrrQx+Cr38dDlox4/c7lC8LVJ8Kw9HOdC3YsoWk203Hftf/S3HJZPfCamPMrNF/DwIfBfLwM6fsm9ffT1Nf3wGzXNFoCa2tq1i48CW8Xu15K5Irqk0iBeTTn4aNG+Hmm9PLDpcvh1/9yulUU6b6VHiOdqarccsWdi5YQCKfP0GQo5LJTNdc4DljzDvA66TXJT+W21j54eyWFlLG8Epj49hj27d/hFTKp6WFIrmn2iRSSMrL0zfpeuUVqKpKX9T1mc9AR4fTyaZC9anApJuuqc10BUZGqNm5U1vFF7kJL3Cw1r4DnDINWfKLtZzV0sL62lr6g8F9D7F162qqqrYwe3arwwFFCptqk0iBWrUK1q6FH/wA/uEf4Ljj4P/8H6dTTYrqU+FJLy+c2kxXQ3MzxlptolHkJnVNl3xgSU8PtUNDvLTf0sLu7mUMDNRrlktERORoeL3wrW/B+vXpG3jdfLPTiaTIHc1MV+OWLcT8fnbttzJKio+arik6e8cOYm43axsaxh5rbl6N1ztMY+OrDiYTEREpEIsXw5NPpm+kLOIQa49upqtxyxbaFi0i5XZnOZnkEzVdU+BOpTiztZU3580j7PUCEI2W0dZ2Bk1Nf8DjmfruNiIiIrIfY+Caa5xOIUUsEnFjrWtKM11le/dSuWePlhaKmq6pOH7XLiqiUV7eb9vPbdvOIZXyammhiIiISAEZGUl/wD6Vma7GLVsAtImGqOmairNbWhj2elk3dy4A1hq2br2A6ur3qKjIy12WRERERGQc4fC+pmvyM12NW7YwUlLCnrq6bMeSPKOma5J8iQSnt7fzWmMjidG1uV1dyxkcnMvixZrlEhERESkkU57pspbG5ub00kKXfuUudvoOmKTTOjoIJBIH7FrY3Lwan2+QxsY/OZhMRERERLJtqk1X5e7dlA4MaGmhAGq6Ju2slhZ6gkHeq6kBIBwup719JU1Nf8DtjjucTkRERESyaWQkfVvbyS4vXDB6PVeLNtEQ1HRNSmk0ykk7d/LKggVYYwDYvv1crPVoAw0RERGRAjTVma7GLVvYW1nJQFVVLmJJnvHk4kW9Xi/19fVTeu7atWuznCYzg4ODE55zdksLHmt5urqawcFBrDVs2XI+VVXvYMz7ZPASh1ixYsUU0h69xYsXOzLu+vXrHRl36dKljoy7YcMGR8aV8c2aNYtPfepTU3ruT37ykyynyczWrVsdGffEE090ZNxTTz3VkXFvueUWR8Ztb293ZFzv6O1Opts555zjyLgzXTweZ9euXVN67qpVq7KcJjPHH3+8I+Pee++90z7mxo1u4DQ2bnwFny+c0XNcqRR/8f77vNrQwOuvvz7lscvLy6f83KOxefNmR8Y95ZRTHBl3OmimaxLO7eigtbSUbaN/Abq7T2ZkpI7GxiccTiYiIiIiuRCNBgHweCIZP6epr4+SeJz1tbW5iiV5Rk1XhqrDYVb09vJCfX36Ro1Aa+sl+Hz91NW94nA6EREREcmFaDSAxzOCy2Uzfs6Kri4ANozuASCipitD53Sk77/1wrx5AEQilXR1raKh4Wnc7oST0UREREQkR2KxAF5vZssK91mxezctFRUMBAI5SiX5Rk1Xhs7t6GDT7Nl0lZQA0NZ2Ida6aWx8yuFkIiIiIpIr6aZrJOPzvYkEx3Z3s0FLC2U/aroy0DgwQNPg4Ngsl7UuWlouYc6ctygp6XQ4nYiIiIjkSjQanNRM17E9PfhSKd5V0yX7UdOVgXN37iRpDH8cbbp27z6VSKRaG2iIiIiIFLhYzD+pma4VXV0kjGFTdXUOU0m+UdM1AWMt53Z0sG7OHPr9fiC9gYbf30dd3WsOpxMRERGRXIrFJjfTtaKri62VlUQcujWDzExquiawrK+P2nCY50fvOxYOz6GrayUNDU/jciUdTiciIiIiuRSNZn5NVygWY1Ffn7aKl0Oo6ZrAeR0dRF0uXqurA6C19aOAobHxSWeDiYiIiEjOTWb3wuO6u3FZq6ZLDqGm6wjcqRQf3rmTV+vqCHs8pFIuWlsvprr6LUKh3U7HExEREZEcSiZdJBK+jGe6VnR1EXW72VJVleNkkm/UdB3BKd3dlMfj6RsiA7t3n040WsWCBdpAQ0RERKTQxWLp+2xl2nSd0NXFe9XVJNzuXMaSPDRh02WMaTDGPGeM2WiM2WCM+eZ0BJsJzuvoYMDr5a3R3WdaWi7B7++hpuZPDicTkWKuTSIys6k+FY5YLAiQ0fLC2eEw8wcGWF9Tk+tYkoc8GZyTAP67tfZNY0wZ8IYx5mlr7cYcZ3NUIJFgVVcXz9XXk3C5GBmpobv7VI455pe4XCmn44lIkdYmEckLqk8FIhrNfKbr+K4uAN2fS8Y14UyXtbbTWvvm6L8PApuA+lwHc9qqXbsIJJNjuxa2tl4EWBobn3I2mIgAxVubRGTmU30qHB8sL5x4pmtFVxeDPh8ts2fnOpbkoUld02WMWQicAhxygypjzE3GmLXGmLV79+7NTjoHnbtzJ92BAJsqK0ml3LS1fZSamjcIBvc4HU1EDpJpbRoeHp7uaCJS5A5Xn/avTSMjmd94V6ZXxjNd1rJi92421tRgjZmGZJJvMm66jDGlwEPAX1prBw4+bq291Vq70lq7ctasWdnMOO3Ko1FO7e7mhfp6rDF0da0iGq3UBhoiM9BkalNJScn0BxSRonWk+rR/bQqFQs4ElAl9cE3XkZuuuqEh5oyMaKt4OayMmi5jjJd00bjbWvtwbiM578OdnbitHdu1sKXlEgKBbmpq3nA4mYjsr9hqk4jkD9WnwhCL+YGJlxeuGL2eS02XHE4muxca4HZgk7X233IfyXnndnSwo6yMHeXlDA/XsWfPKTQ2Pokx2kBDZKYoxtokIvlB9alwRKOZzXSd0NVFTzBIZ2npdMSSPJTJTNfZwHXABcaYdaNfH89xLsfUjoywvK9vbJartfVijEnS2Pi0w8lE5CBFVZtEJK+oPhWIaDSA253A7Y4f9hxjLct3707Pcul6LjmMCbeMt9b+ESia76BzOjoAeHHePFIpD21tF1JT8ycCgV6Hk4nI/oqtNolI/lB9KhyxWACfL3LEcxb09VEWi2mreDmiSe1eWPCs5byODjbOns3uUIhdu84kFpulDTREREREilC66Zrgeq7duwHYoKZLjkBN134WDg7SODQ0dm+ulpZLCAa7qK5+y+FkIiIiIjLdYrEAfv+RZ7pWdHXRXl5OXzA4TakkH6np2s+5HR0kjOGlefMYGqqnp+ckFix4AmOs09FEREREZJpFo8EjLi90J5Ms6+5mfU3NNKaSfKSma5SxlnM7OnirupoBn290A40E8+c/43Q0EREREXHARNd0HdPTQyCZ1FbxMiE1XaOW9/ZSHYnwfH09yaSXtrbV1NW9SiCw1+loIiIiIuKAaPTIywtP6OoiZQwbNdMlE1DTNeq8jg7Cbjev1dbS2XkW8Xg5jY3aQENERESkWE0007Wiq4tts2cz4vNNYyrJR2q6SK/HPbuzk1fr6oh6PLS2XkIotJM5c95xOpqIiIiIOMDafRtpjL97YSAeZ3Fvr5YWSkbUdAHHbt9OWTzOC/PmMTjYSG/vCm2gISIiIlLE4nEf1rrw+aLjHj+uuxuPtWq6JCNquoBTNm2i3+djXXU1LS0X43LFmT//WadjiYiIiIhDYrH0FvCHu0/Xiq4uYi4Xm6uqpjOW5ClPLl40HA6zcePGKT334x//eJbTHJl7ZIQTfvhDHquupn/E0t5+PtXVfyCV6iJ85HvhZUVPT0/uBxlHIpFwZFyPJyffchN68803HRm3oqLCkXFlfNZaksmk0zEmZdOmTY6M+8wzzuzc+ulPf7qoxr3tttscGffCCy90ZFzJvj/84Q+OjLt06VJHxp3O2hSJNAHw/vuvc8klpx1y/PQXX6Rz0SJOXLUqZxlefvnlnL32kaxevdqRcQcHBx0ZdzoU/UzXnD/+EXc0yrN1dezefS6JRBn19b91OpaIiIiIOCiVKgPA7R4+5FhoaIiazk5aliyZ7liSp4q+6ap99lnCdXVsrKigo+NSQqFWZs162+lYIiIiIuKgZLIUAJfr0NmXxuZmAFrVdEmGirrp8vb2UvnGG3StXs3g0CL6+4+nvv63GON0MhERERFxUiqVbrrGm+lqbG4mGgiwq75+umNJnnLmApsZoub55zGpFF0XXEDH81W4XDHmzn3K6VgiIiIi4rAjzXQtaG6mdfFirNs93bEkTxX1TFfts88yuHgxPXWL2bXrQmpqXsDrLdwL+EREREQkMx/MdA0d8HhFby+zent1PZdMStE2XYGODio2bWL36tU891wtyWQJ9fWPOR1LRERERGaAD2a6Rg54vHHLFkDXc8nkFG3TVfv73wPQdcEFPProPEpKtlNRscHhVCIiIiIyE6RSpbhcQxiTOuDxBc3NDJWV0VNT41AyyUfF2XRZS+0zz7D3xBN5d+8iNm8u1wYaIiIiIjImmSzD5TpwaSGpFI3NzelZLv3iKJNQlE1X6ZYtlLS1sevCC3nssXn4/Unq6p52OpaIiIiIzBCpVMkh13NVd3VRMjys67lk0oqy6ap99llSHg+tp5/Ps8/Wct55u/F6D90OVERERESK03gzXfuu51LTJZNVfE1XMknt739Pzxln8MSfjiEc9nDZZTudTiUiIiIiM8h4M10LmpvpnTOHwdmzHUol+WrCpssYs8YYs9sYs346AuXarHfewd/TQ9cFq3n00XksXjzIsmUDTscSkSkotPokIoVBtakwJJOlB8x0uZJJGrZt066FMiWZzHTdAVyS4xzTpvbZZ0kEg7xcdRHNzWVceulOXQcpkr/uoIDqk4gUjDtQbcp7qVTZATNddW1t+GIxLS2UKZmw6bLWvgj0TkOWnDOxGNUvvED3Rz7Cr55aRCCQ4MILu5yOJSJTVEj1SUQKh2pTYUgmS3C7B8f+vKC5GWsMrYsXO5hK8lXWrukyxtxkjFlrjFk7NDQ08RMcUPXaa3iHh2k566M891wtF1ywm5KSpNOxRCSH9q9NIyMjEz9BRGQaqDbNbNZ6sDaIy/XBRmsLtmxh99y5REpKHEwm+SprTZe19lZr7Upr7crS0tJsvWxW1T77LLHZs/nlno8Tibi57LIOpyOJSI7tX5tCoZDTcUREANWmmS6ZTDdW+2a6vLEY81pbtbRQpqxodi90Dw1R9cordJ13Hr/+bSNLlw6wdOnMnJETEREREeekUmUAYzNd9du3404maTnmGCdjSR4rmqar+o9/xB2P80rTp9i+vZRLL9U28SIiIiJyqGQyvWpr30zXguZmkm43HU1NTsaSPJbJlvH3Aq8Axxpj2o0xN+Y+VvbVPvssI/Pmcfu7HyUUSrB69W6nI4nIUSqU+iQihUW1Kf+lUumma9+W8Y3NzexsbCTu8zkZS/KYZ6ITrLVXTUeQXPL19DD7rbd4/4rreP5XtVxyyS6CQW2gIZLvCqE+iUjhUW3Kfx/MdA1RnkhQu3MnL114ocOpJJ8VxfLCmueew6RS3O/5ArGYm09+UhtoiIiIiMj49p/pOmN4GGMtrbqeS45CUTRdtc8+y8Axx3DbHz/Cccf1s3jx8MRPEhEREZGitP9M15nDw8R8PjobGhxOJfms4JuuYHs75Zs3s+64T9DaWqINNERERETkiPY1XS7XEKuGhmhbtIiU2+1wKslnBd901T7zDNYYftRzPSUlcc4/XxtoiIiIiMjhpVKlGBNjbmKIhbEYrbo/lxylwm66rKX2979nz/Gn8MifTuKii7oIBFJOpxIRERGRGSyVKsXlGuTM4fQlKbo/lxytgm66yjZvJtTezuNVVxCPu7j0Um2gISIiIiJHlkyW4XYPs2poiB63m+7aWqcjSZ4r6Kar9tlnSXm9fH/LF1mxYi9NTSNORxIRERGRGS6VKsFlBlk1PMyfSkvBVdC/Mss0KNzvoGSSmueeY+uxH2bjznnaQENEREREMpJMlnK8611qEgleKylxOo4UgIJtumavW4e/t5e7UldTVhbn3HO7nY4kIiIiInkglSrl/NRLALxWWupwGikEnly9cDKZnNLzvv/972dl/L9+912G3F7+dePnqVnwKP/+77ce8XxjTFbGnaxSh/4iL1y40JFxA4GAI+O2tbU5Mm6t1oDPKAMDAzz55JNTem4oFMpymsyMjDizLHrBggWOjPvYY485Mu73vvc9R8Y99dRTHRn39ttvd2Tc73znO46MO9OFQiFOOumkKT3X48nZr3JHVF5e7si40/V+k8kyzuN1Onw+doVCbNu2bVrGPZi11pFxvV6vI+NWV1c7Mu50KMiZLl8yydm7d/Nk6AzClDN//u+cjiQiIiIiecIkA3w48W76ei6RLCjIpuuM7m5KEgnWRG9m9ux3KC1tdzqSiIiIiOQBa+Gk1GYq7AivlZU5HUcKREE2Xed3drLHU8ITsc/R0KBZLhERERHJTCoVZDXPA2imS7Km4Jqu0nic07u7ecj7cdzeQWprX3I6koiIiIjkiVSqlNU8yyZvLX0OXdskhafgmq6zu7rwWcvt4b+mvv4ZXK6405FEREREJE+440HO5iVeDjQ4HUUKSME1Xed3drLdW8vrrGL+/N86HUdERERE8shJwyMEifBKSDsQS/YUVNNVFYlwYm8vd6eupbJyHSUlnU5HEhEREZE8cuZwDwncvFHizLb4UpgKquk6d9cuXMDPkzdpAw0RERERmbSzRjp5jVWEvTGno0gBKaim64KdO3nLs4wWXzU1Na84HUdERERE8khpIsEJsS6eZTVu95DTcaSAFEzT1TA0xJLBQe5MfIX6+idxuRJORxIRERGRPLJyeBg3drTpGnY6jhSQgmm6zu/sJInhl1zJ/PmPOx1HRERERPLMGYODjODlVc7A5VLTJdmTUdNljLnEGLPZGNNsjPl2rkNNmrWc19nJ8+YjxKs6CYW6nE4kItNgxtcmESlaqk/56YyhIV7zLiPhSmCMdTqOFJAJmy5jjBv4EfAxYDlwlTFmea6DTcay/n7mhcPcZW/QBhoiRSIfapOIFCfVp/w0Jx5ncSTCC55TtLRQsi6Tma4zgGZr7TZrbQy4D/hUbmNNzvmdnUTw8VvfeVRXv+Z0HBGZHjO+NolI0VJ9ykOnDw4C8Jx7lTbRkKwz1h556tQYcwVwibX2z0b/fB2wylp780Hn3QTcNPrHFcD67MedseYAe5wOMU2K6b1C8b3fY621ZU6HyIRqU0aK7ftX77ewFVR9Um0qqu9dvd/CllFt8mRrNGvtrcCtAMaYtdbaldl67ZmumN5vMb1XKM7363SGbFNt0vstVMX4fp3OkE2qTXq/haoY328m52WyvLADaNjvz/NHHxMRcZJqk4jMVKpPInKATJqu14FjjDFNxhgf8AXgN7mNJSIyIdUmEZmpVJ9E5AATLi+01iaMMTcDTwJuYI21dsMET7s1G+HySDG932J6r6D3O2OpNmVE77ew6f3OUFOoT3nz3rJE77ew6f2OY8KNNERERERERGTqMro5soiIiIiIiEyNmi4REREREZEcymrTZYy5xBiz2RjTbIz5djZfe6YxxjQYY54zxmw0xmwwxnzT6UzTwRjjNsa8ZYx5zOksuWaMmWWMedAY854xZpMx5kNOZ8olY8xfjX4vrzfG3GuMCTidKVuKqTZBcdYn1abCVci1CYqrPhVjbQLVJ6cz5dJk6lPWmi5jjBv4EfAxYDlwlTFmebZefwZKAP/dWrscOBP4WoG/332+CWxyOsQ0+Q/gCWvtMuAkCvh9G2PqgW8AK621K0hf+P0FZ1NlRxHWJijO+qTaVIAKuTZBUdanYqxNoPpUkCZbn7I503UG0Gyt3WatjQH3AZ/K4uvPKNbaTmvtm6P/Pkj6m6re2VS5ZYyZD3wCuM3pLLlmjKkAzgFuB7DWxqy1e51NlXMeIGiM8QAhYKfDebKlqGoTFF99Um1SbcpjRVWfiq02geqT6tMHstl01QNt+/25nQL/i7SPMWYhcArwmrNJcu7fgW8BKaeDTIMmoBv42eiSgNuMMSVOh8oVa20H8H+BVqAT6LfWPuVsqqwp2toERVOfVJsKVIHXJiji+lQktQlUn1SfRmkjjaNkjCkFHgL+0lo74HSeXDHGXArstta+4XSWaeIBTgX+01p7CjAMFOxae2PMbNKfrjYB84ASY8y1zqaSo1UM9Um1SbVJ8k8x1CZQfUL16QDZbLo6gIb9/jx/9LGCZYzxki4ad1trH3Y6T46dDVxmjNlBevnDBcaYu5yNlFPtQLu1dt8ncA+SLiSF6kJgu7W221obBx4GznI4U7YUXW2CoqpPqk2qTfms6OpTEdUmUH1SfdpPNpuu14FjjDFNxhgf6QvJfpPF159RjDGG9JrVTdbaf3M6T65Za//WWjvfWruQ9P/b31trC/bTRmvtLqDNGHPs6EOrgY0ORsq1VuBMY0xo9Ht7NYVz8WtR1SYorvqk2qTalOeKqj4VU20C1SdUnw7gydao1tqEMeZm4EnSu3essdZuyNbrz0BnA9cB7xpj1o0+9h1r7e8czCTZ9XXg7tEfhNuALzmcJ2esta8ZYx4E3iS9u9RbwK3OpsqOIqxNoPpU6FSbCkQR1ifVpsKn+nQYxlo7XdlERERERESKjjbSEBERERERySE1XSIiIiIiIjmkpktERERERCSH1HSJiIiIiIjkkJouERERERGRHFLTJSIiIiIikkNqukRERERERHJITZeIiIiIiEgOqekSERERERHJITVdIiIiIiIiOaSmS0REREREJIfUdImIiIiIiOSQmi4REREREZEcUtMlIiIiIiKSQ2q6REREREREckhNl4iIiIiISA6p6RIREREREckhNV0iIiIiIiI5pKZLREREREQkh9R0iYiIiIiI5JCaLhERERERkRxS0yUiIiIiIpJDarpERERERERySE2XiIiIiIhIDqnpEhERERERySE1XSIiIiIiIjmkpktERERERCSH1HSJiIiIiIjkUEZNlzHmr4wxG4wx640x9xpjArkOJiIyEdUmEZmpVJ9EZH8TNl3GmHrgG8BKa+0KwA18IdfBRESORLVJRGYq1ScROVimyws9QNAY4wFCwM7cRRIRyZhqk4jMVKpPIjLGM9EJ1toOY8z/BVqBMPCUtfapg88zxtwE3ARQUlJy2rJly7KddebYuDH9z+XL6euDbdtgyRKoqHA2lsjReuONN/ZYa6udzpGJGVWb2tuhqwtOPBG83nFPaWmBnh446SRwu7MfQaTQFVp9Kqrfm0QKWKa1yVhrj3yCMbOBxqMOYgAAIABJREFUh4Argb3AA8CD1tq7DveclStX2rVr104ucT75yU/gv/03eOUVYqeeSX09nHsuPPig08FEjo4x5g1r7Uqnc2RiRtWm5mZYuhT+/u/hf/2vcU/5059g1Sr4r/+Cm27KfgSRQlfI9angf28SKWCZ1qZMlhdeCGy31nZba+PAw8BZRxswr11zDZSVwY9/jM8H110Hv/kNdHc7HUykqMyc2rRkCXzsY+mOKhYb95TTT4cVK+D226c5m4g4YebUJxGZETJpulqBM40xIWOMAVYDm3Iba4YrK4Prr4df/hK6u7nxRojH4Re/cDqYSFGZWbXp5pth1y54+OFxDxsDX/5yesZr/fppziYi021m1ScRcdyETZe19jXgQeBN4N3R59ya41wz31e/mv5Ee80ajj8ezjwTbrsNJlitKSJZMuNq08UXw+LFcMsthz3l2mvTl3z97GfTmEtEpt2Mq08i4riMdi+01v6DtXaZtXaFtfY6a20018FmvOXL4bzz0td3JZPceCNs2gSvvup0MJHiMaNqk8sFX/savPQSvPXWuKdUV8Nll8HPf37YVYgiUiBmVH0SEcdlumW8jOerX4UdO+Dxx7nySigp0fUaIkXthhsgFIIf/eiwp9x4I+zZA489Nn2xRERExFlquo7Gpz8Nc+fCj39MWRlceSXcdx8MDjodTEQcMXt2eg3h3XdDb++4p1x0EdTX6wMaERGRYqKm62h4vem9n594ArZu5cYbYXgY7r/f6WAi4pivfQ0iEVizZtzDbnd6QuyJJ6CjY3qjiYiIiDPUdB2tr3wlfS3HT37Chz4Ey5bpE2yRonbiiXDOOfDjH0MyOe4pX/oSpFJw553TnE1EREQcoabraNXXw+WXw5o1mEiYG2+EV15Jb6ohIkXq5pth+3Z4/PFxDy9enN6HZ80a7XgqIiJSDNR0ZcNXv5q+fuP++7n+evB4NNslUtQ+/WmYN++I28d/+cuwdSu8+OI05hIRERFHqOnKhvPOg+OOgx/9iJqa9JbQd96pLaFFipbXC3/xF/Dkk/D+++Oe8tnPQnn5YS/9EhERkQKipisbjEnPdr3+Orz++tiW0I8+6nQwEXHMV76Sbr5+/ONxD4dCcNVV8MAD0N8/zdlERERkWqnpypbrrkvfqOs//5OLL9aW0CJFr64OPvc5+NnPYGho3FNuvBHCYfjlL6c5m4iIiEwrY3NwFffChQvt3/3d303pufF4PMtpMvPd7373qF/j+/39fC4c5rSaGlqHv83w8Deorj4Dt3vnYZ/j1Pv1+/2OjHv88cc7Mu5bb73lyLinn366I+P+7ne/m9LzjDFvWGtXZjnOjFFbW2uvvPLKKT33vvvum/RzVsbj/G7vXv6mtJQ7g8FDjlsLfX3PY0yY2bM/Nu5rNDU1TXrcbHj/MMsic80Y48i48+bNc2TclpYWR8YtLS11ZNzOzs4pP7eQ61NNTc2Ua5NTP99WrnTmf8WOHTscGXfr1q2OjNt7mHs+5tpNN93kyLhut9uRcafat0DmtUkzXVl0RyhEEPh8OEwweB/gJhyeWhEVkfy31uPhbY+HL4fD425TaAwEAveQSJxGIrHMgYQiIiIyHdR0ZdEmr5fXvF6+ODKC192Cz/cHwuEvYK0zn9yKiMOM4fZgkOOSSc46zKx2IPAgECMSuXp6s4mIiMi0UdOVZXeEQjQlk5wXixEM3ksy2UgsdrbTsUTEIb/y++k1hhvD4XGPu1y9+HxPEIlcgbXeaU4nIiIi00FNV5b9NhCg2+XiiyMjBAK/w5g+wmF9gi1SrCLGcHcgwMdiMeYlk+OeEwjcg7VziMUunuZ0IiIiMh3UdGVZ3BjuDgb5aDRKQ3KYYPBhIpGPkUrNcjqaiDjkjmAQF3B9JDLucZ/veVyunVpiKCIiUqDUdOXAXaEQFrg+HCYYvBcIEA5/xulYIuKQNrebJ30+rguH8Y27oUaKQOA+YrHzSSbnOpBQREREcklNVw50uN085fdz9cgIJZ71eDzvEA5fNd7mZSJSJNYEg1Rby2XR6LjHA4H0jqeRiHY8FRERKTRqunLkjlCIKmu5NBIhFLqHRGIFicSJTscSEYe86PWyxe1Obx8/Drd7B17vH4lErtaOpyIiIgVGTVeO/MHnY6vbzQ0jIwQCjwBhRkaucjqWiDjEGsOaYJCViQQnH3b7+HtIpRYSj39omtOJiIhILqnpyhFrDHeGQpwej3NisodA4LdEIp/B2qDT0UTEIb/0+xky5rCzXX7/YxjTrw01RERECoyarhy6PxgkDNwwMkIweA/WlhOJfMLpWCLikCGXi/v9fi6PRqlKpQ45bkwEv/8RotFLSaXKHEgoIiIiuTBh02WMOdYYs26/rwFjzF9OR7h81+9y8XAwyOWRCHM8L+F2b9cSQ5EsydfatCYYxA9cfZjt4wOBu4EQ0ejl05pLRLInX+uTiOTOhE2XtXaztfZka+3JwGnACPBIzpMViDtDIULWcmUkTDB4H/H4WSQSC52OJZL38rU2ve/x8KLXyw3hMO5xtjT1eN7G7d6oJYYieSxf65OI5M5klxeuBrZaa1tyEaYQvev1stbr5YsjIwQD9wFJwmHNdolkWV7VpjXBIA2pFBfFYoccMyY925VInEoicZwD6UQky/KqPolIbky26foCcO94B4wxNxlj1hpj1g4ODh59sgJyZyjEkmSS85Jt+P3PEg5/HmvdTscSKSQZ1abwYTawmG5P+ny0u1zceJg8gcBDQIxIRB/QiBSAcevTTKxNIpI7GTddxhgfcBnwwHjHrbW3WmtXWmtXlpXpAvD9PRoI0GPM6IYa95JK1RGNXuB0LJGCMJnaFAzOjN1Dk8ZwRzDIOfE4xyQShxx3uXrx+x8nEvkcqZTHgYQikg1Hqk8zsTaJSO5MZqbrY8Cb1tquXIUpVFFjuCcU4uJolIWeJ3C5dhMO63oNkSzJy9p0dyBAFI4w23UP1laxd+850xtMRLIpL+uTiGTfZJquqzjM8h2Z2C+CQQxwfXiQYPB+otELSSarnY4lUgjysjb1uFz8yu/nykiEsnG2j/d6X8Dl6qC7+5MOpBORLMnL+iQi2ZdR02WMKQE+Cjyc2ziFq83j4Rm/n2vCYcoD9wAewuHPOR1LJK/le226PRikBPh8NHrIMWNSBAL30d+/ilisZvrDichRyff6JCLZlVHTZa0dttZWWWv7cx2okN0ZClGTSvHJxEa83tcIh69inB2jRSRD+V6b1nm9vOHxcGM4jBmnGAQC9wFu9uz5+PSHE5Gjku/1SUSya7K7F8pReM7no8Xt5ksjIwSD95BMLiGRONPpWCLioDXBIEuSSc6Jxw855na3UFa2lu7uT2KtcSCdiIiIZIOarmlkjeHOUIgz43FO8TyEMYNEo9c4HUtEHPRrv59uY/jyYTbUqK7+DdHofAYHT5nmZCIiIpItarqm2X3BIBHghnAvgcCviEYvI5UqdTqWiDgkZgy/CAa5OBajIZk85Hhl5fO43YN0d1/mQDoRERHJBjVd06zP5eLXgQBXRCLUBH4OlBCLfcbpWCLioJ8HAqSAG8aZ7XK5olRVPUlv7/kkEiXTH05ERESOmpouB9wRClFqLVclXsPt3kgkcq3TkUTEQTvdbh73+bgmEiEwzoYac+Y8irUBensvciCdiIiIHC01XQ5Y5/OxzuPhhnAYv+8ukslTSSSOczqWiDjo9mCQSmv59Djbx5eUvEcwuEX37BIREclTarocckcoxLGJBBe4fw7EtKGGSJF72etlk9vNn4XDHHwvCWOguvpRhoePZ2RksUMJRUREZKrUdDnkN8EgfcZwY6wbn+93RKOfx1qf07FExCnGsCYY5MREgpWJxCGHq6oex5iYZrtERETykJouh4SN4b5gkE/EYizw/hRrK4nFPuZ0LBFx0IOBAAPGcOM4G2p4vQPMnv0iPT0fI5XyOpBOREREpsqTixeNRqNs27ZtSs9NpVJZTpOZa66Z/uV9e/v68K5Zwz82bOfGlm5Coa9z9tl90zL2q6++Oi3jHKyiosKRcd1utyPjDg8POzKujM8YQzAYnNJzb7zxxiynGd+7zzzDp958k/euvJKh0lIefPDBsWN+/90kEhfS3n4KpaVP5DSH1+tMY1dbW+vIuE7VCL/f78i4Hk9OfvzLFI2MjPDmm29O6blT/X3raL3zzjuOjPu3f/u3jozb09PjyLg7d+50ZNy3337bkXGXLl3qyLjTQTNdDuqZPZu3amq4aMd2Fjc+xe7dJzIyUu10LBFx0KunnoonleKMcX7ghUIv4/HsZGDgCgeSiYiIyFSp6XLY44sWURWJ8PnAHQC0tFzgbCARcdSeykreb2rijLfewnXQzZKNSVFW9jAjIx8hHq9zKKGIiIhMlpouh71ZV0d3MMindr5NTc3btLRcgLX63yJSzF457TQqhoZYvmXLIcfKyx8GXAwO6qbqIiIi+UK/3TssZQxPNjVxYnc359bcQzhcze7dJzgdS0QctHnRInorKvjQG28ccszrbSMYfJmBgSuw1jiQTkRERCZLTdcM8OzChcRdLq4f/hU+3wAtLRc6HUlEHGRdLl499VQWtbVx7Dg3Sy4vf4hEooFw+AwH0omIiMhkqemaAfr9fl6ur+f8th0cW/8kO3eeQTRa5nQsEXHQ2hNPJO7xcG1//yHHSkqexOUaYGDgcw4kExERkclS0zVDPNHUREkiwZd8P8FaL21t5zodSUQcFA4GWbd8OZcNDlJ+0IYaLleU0tJHGR6+mGRSH9CIiIjMdGq6ZojNlZVsq6jg8s61zJ61mZaW1VjrdCoRcdIrp55KyFo+OzBwyLHy8gewNsDQ0CcdSCYiIiKToaZrpjCGJ5qaWDgwwGVzfsrAwAL6+o5xOpWIOKizro61gQDX9vdjDvoUxu/fgM+3iYGBzzqUTkRERDKlpmsG+UNDA8NeL18aeRC3O0JLy2qnI4mIw+6qqKAxkeCckZEDHjcGyssfJBo9kWj0WIfSiYiISCbUdM0gUY+H5xobOauzlZPqHqO9/cMkEn6nY4mIg54qLaXL7R53Q42yst8AMQYGrpj+YCIiIpKxjJouY8wsY8yDxpj3jDGbjDEfynWwYvVEUxNea/lzzy0kEiE6Os5yOpLIjFUMtSluDPdVVHDeyAiNsdgBx9zuvZSWPs3g4Kew1udQQhEZTzHUJxHJXKYzXf8BPGGtXQacBGzKXaTitrOsjLerq7l895+oKGnREkORIyuK2vTL8nLiwDXjzHaVlz9IKjWb4eELpj+YiBxJUdQnEcnMhE2XMaYCOAe4HcBaG7PW7s11sGL2xKJFVIfDXFf5A3p6ljM4WO90JJEZp5hqU7fHw5OlpVwxOEgwlTrgWDD4Mh7PTt2zS2QGKab6JCKZyWSmqwnoBn5mjHnLGHObMabk4JOMMTcZY9YaY9aOHHTBt0zO63V19AQC3BB+AGOStLToE2yRcUy6NoXD4elPmSW/qKigPJXissHBAx43JkVZ2UOMjHyYeLzOoXQicpAJ69P+tSkejzuTUkSmTSZNlwc4FfhPa+0pwDDw7YNPstbeaq1daa1dGQqFshyzuKRcLp5qauK0PTs5a87DtLaeTyrldjqWyEwz6doUDAanO2PWvBkIsNHnS2+ocdD28eXlDwMuBge1fbzIDDFhfdq/Nnm9Xicyisg0yqTpagfarbWvjf75QdKFRHLomYULSRjD19z/QTQ6i127TnM6kshMU1y1yRh+MWsWy2IxTo9EDjjk9bYTDL7EwMBnsdY4FFBE9lNc9UlEJjRh02Wt3QW0GWP23QhmNbAxp6mEvkCAV+fN45M9f2K2v10baogcpBhr02Olpex1ucbdPr68/CESiQbC4VUOJBOR/RVjfRIpBsPD8Mc/wg9+AFdfDccck/lzPRme93XgbmOMD9gGfGnyMWWynli0iA93dPDfav+Jf9r1Q8LhSoLBXqdjicwkRVWbIi4XD5aXc8PevdQmEnR5PijhJSVP4XL1MzBwBaHQqw6mFJFRRVWfRApNLAbvvguvv/7B14YNsG8/q/p6OP10aG7O7PUyarqsteuAlVPMLFO0saqK1rIybhh5gH/iR7S2ns+xxz7kdCyRGaMYa9M9FRV8ee9evtDfz39UVY097nJFKSt7lIGBK0gm/xG3e/AIryIiuVaM9UkkX6VSsHnzgQ3WunUQjaaPV1amG6xPfSr9z9NPh7lz08dMhqv6M53pEicYw+OLFvHnb7/NRRX38lLLBSxd+jDG2ImfKyIFqc3r5flQiC8MDPCflZXE9qv2ZWUP0N9/LUNDn6Si4h4HU4qIiMxM1sLAwCw6Oxvo7JzPrl3z+fGPYd/mwCUlcNppcPPNHzRYTU2ZN1eHo6ZrhnuhoYHrN2zgG+4f8FT/1ezZs5zq6g1OxxIRB/2iooKfdXZy8dAQj5aVjT3u92/E59vEwMAVarpERESA4eESdu2af0CTNTJSCoDLlaCmppNrr003V2ecAcuWgTsHm4ar6ZrhIl4vzzc0cFHLm9R5WmhpWa2mS6TIvRQKsd3r5dr+/gOaLmOgvPwB9uz5e6LRZfj97zmYUkREZHpFo3527ao/oMEaGJg9ejTFnDm7WbToPebObWfu3HaqqzvxeJL88z//c86zqenKA08sWsTHtm/nmxXf5X92/JgTT7wNn083oBYpVtYY7q6o4O/27OH4SIQNgcDYsbKyR9mz59sMDFxBdfX/djCliIhI7iQSHrq65rJrV7rB6uycT2/vHPZtzl5R0cO8ea2cdtrLzJ3bTm1tBz5fzLG8arryQFt5OevnzOGLQw/yP1O30t5+DosWPeF0LBFx0MNlZfxVTw/X9vfzt/s1XW73XkpLn2Jw8DLmzPkXjHHuB4yIiEg2pFIu9uypHWuudu2aT3d3HalUeh1gSckAc+e2s3z5OubObaeurp1QaGZNUKjpyhNPNDXx/73+Op8N3cHTLavVdIkUuUG3m1+XlfHZwUG+P2cOe/dbgF5e/hBDQ5cyNLSasrLHHUwpIiIyOdZCX1/VAddhdXXNI5HwAeD3h6mra+eMM14cbbDaKCsbOOqNLnJNTVeeeG3ePPr8fm52/zsP7L2RvXsXMmvWDqdjiYiD7qqo4OqBAT4/MMCts2ePPR4MvozH08Hg4BVqukREZMayFiKRKvr6ltDXt4Q33zyRXbvmE40GAfB4YtTW7uSkk/40eh1WG7Nn9+blTt5quvJE0uXiqaYmPvfeehab92hpuZBZs25zOpaIOGiL38+rwSBX9/dz26xZpEY/5jMmRVnZw/T1fY14fC5eb6fDSUVERCAaLWXv3mPGmqy+viVEo+kPDY1JUFPTxbJl74xtdDFnThcuV8rh1NmhpiuPPL1wIVds3sx/L/lHvtn2U1as+Dlut67XEClmd1VUcMuuXZw/PMyzpaVjj5eXP0Rf39cZHPwMlZU/cjChiIgUo0QiwN69iw5osEZG6saOl5a2U1PzNrNnNzN7djMVFTs47riFzgXOsZw1XS6Xa0rPi8fjWU6SGa/X68i4u3fvzvxc4MXKSq7a+yv+OrmG9947jurqp6c07uz9liJNp8cfd2ap03nnnefIuG+//bYj48r4jDGYKS76Htx318Rp1t3dfcTj91rLt43hyj17uC8c3v+ZuN3P09d3OYnEP056KUZDQ8MU0h69jo4OR8atr693ZNwlS5Y4Mm5PT48j48r4KioquPjii6f03JKSkiynycwPfvADR8b94Q9/6Mi4VVVVjoz7L//yL46Me8stt0zq/FTKSyRyDCMjx499RSJNQPp6Y6+3k1BoPXPn/pJQaD2h0Cbc7uGx5/f3p7/+5m9uzubbmFE005VnHqmr4/yeDVzj+S8e7PrElJsuESkMSWNY4/Px99EoS5NJ3t9vQw2f7xeEw7eTTH4Ej+dFB1OKiEihsNZFJNJ0UIN1DNamN7rweHoJhTZQUfEModAGQqENeL19Dqd2npquPPNmRQU7gkG+lvwPbu//SyKReQQCO52OJSIO+rnPx/+IRvmzWIxvBYNjj3u9vyUc3kssdq2aLhERmTRrIRarP6DBCoePI5UKAeByDREKbaS6+m5CoY2jDVbnjN9J0AlquvKNMTxSV8dfbd/OabxGV9fHWbBAG2qIFLM9LhePeL1cFYvxvUCAwbENNSL4fPcTi12PtX+DMf0OJxURkZls794gO3ZU09n5VUZGljMyspxkct9GF1GCwc1UVv5mdIngBvz+lrzcSTAr4nHYvDnj09V05aEnamr4i5YW/srzPb68ew2NjWswpjB2dhGRqbnV5+ML8ThXxmLc5vePPe7z3U0sdhOx2BX4/bc7mFBERGaSkREfO3bMYceOOWzfXs2OHdX09e27RjBBILCNiornx5YIBgLNuFwJRzM7prcX3n77wK8NGyCW+YZ2arry0LDHw1PV1Xx295N83Xro6zuDyspXnY4lIg560+PhDbebr8Ri3ObzsW9th9v9Ni7XO8Ri16npEhEpUtGom9bWKnbsqB5ttKrp6qoYO15b28/SpZ0sXLiHhQu7efzxf8LlijiY2CHJJDQ3H9pgtbd/cE5tLZx0Enzzm+l/XnttRi+tpitPPTJ3Lp/q6uJG14/52e5L1XSJCD/1+fhJOMw5ySQvej4o7z7fXUQi/0IyeQJu97sOJhQRkVxLJAw7d1ayffu+Gaw57Nw5m1QqvbP47NnDLFzYzVlnbWHhwm4WLtxDScmBMzZPPln4DZd7ZIRQczMlW7fCz3+ebq7Wr4eRkfQJHg8sWwbnnpturvZ91dYe+EJqugpbc0kJ75SV8dWRW/i3nm8Ri83C59vrdCwRcdAjXi//OxLhpmj0gKbL672fSOR7xGLXEgz+DwcTiohINqVS0NVVwY4d1Wzfnp7BamurJB5P/wwoKYmwcOEeTj65dWwWa9as8ASvWmCsxd/ZSclog1XS3ExJczPBnfttRFdZmW6obrrpg+Zq+XLYb7n+0VLTlccemTuXf3j/fS7kOd7vvoT6+vucjiQiDooaw50+H38ZjdKQStE2er9El2svXu9jxOOfJxD4e4yJOpxUREQmy1ro7S0Zu/5qx445tLTMIRxOb9Xu98dpbOzhvPM20dSUbrCqqweLaidBVyRCaNu2AxusrVvxDKfvCWaNITx/PkPHHkvXJz7B8OLFDB9zDGdcfjm5/g+lpiuPPV9Vxde9Xr5h/5nPdf2MefPuK6q/WCJyqJ+NNl1fisX4biAw9rjX+wvi8c8Sj38cn+8RBxOKiEgmEonZvPPO/LEGa/v2agYH07cFcbuTNDT0smrVVhYu7KapaQ9z5+7F5SqSnQStxdfdPTZrta/BCra3Y1LpzeUSoRDDixez+6KLGF6yhOHFixlZtIjUfrdWGTMNv0Cr6cpjcZeLx2pruab9BaoThsHBFZSXr3c6log4qN3l4nceD1+Mxfi+30909AeJx/MCxrQRj1+rpktEZIZJJksIh5cTDq8Y/TqeeLye994DYyxz5+7lhBPaWLhwD01N3cyf34vXWxw7V5tYjFBLywcN1miT5e3/4DYokblzGV6yhD2rVzO8ZAlDS5YQrauD0RUfM4Garjz369parmlv5y+4hX/vulRNl4jwU7+fTw4P85l4nHt96WUnxlh8vruJRr9FKtWAy9XmcEoRkeKUSvmIRI4da67C4RVEo01AukHwetsJBt+lquperrvuOBYs6CEQiDsbepp4+/oObK6amwm2tOBKJgFI+v2MLFpEz0c+kp69Gp3BSpaWOpx8Yhk1XcaYHcAgkAQS1tqVuQwlmesKBHi5spKv9P2U73Z/h0RTEI+nyC6QlKKl2jS+F91u3nO5uCkW416vd2zZxL6mKxa7ikDgXxxOKVLYVJ8EwFo30ehiRkaOH5vFikaPwVovAB7PHoLB9VRUPEEwuJ5gcD0ezwcbox177F86FT2n3NayIBJhaSTC0nB47Kv6ssvGzolWVzO8eDG9Z5011mCF588Ht9vB5FM3mZmu8621e3KWRKbs4bo6ftC7kct5nNd7LqC29rdORxKZTqpNBzOGn/p8/L9IhNOSSd4Y3cnQ5WrD43mBWOwa/P5/xZgiWfsv4hzVpyJiLcRiDfstEVxBOLwMa0MAuFwDBIMbqaq6c6zB8nq7Cv56/LJEIt1U7ddgLY5E8Nv0z6C4MWzz+3m1rIzjr756rMFKzJrlcPLs0vLCArB21izaAgG+Hvs3Lu66Q02XiPBLn49/iES4KRbjzw/YPv4XJBJrSCY/gsfzooMJRUTyWzxeM7ZEcGRkBZHI8SST6RsOGxMhEHiPysqHCAY3EAyux+drLegPu4y1NMRiB8xcLQ2HmRv/YGlkr8fD+4EAv5wzh/eDQd4PBtnu95MYvfbqh1/4glPxcy7TpssCT5n0d8p/WWtvPfgEY8xNwE0A5eXl2UsoE7LG8Ku6Or6+4w0WDSYYGVlIKLTD6Vgi00G16TCGjOFen48bYjH+LpWi27XvWoHfEon0EYtdp6ZLJLeOWJ/2r00VFRUOxJPJSCTKR6+/OmGs0UokavYdJRDYQnn502MzWIHAVoxJOJo5l0LJJMcctDRwSSRCaN/OgUBLIMC6khLuH22u3g8G2ePxTMtOgTNRpk3Xh621HcaYGuBpY8x71toDflqPFpNbAebOnVu4bfwM9bvaWr7S2spXUz/iH7supanpFqcjiUwH1aYjuM3n489jMa6Pxfh/o9vHGxPF632AWOx6rK3AmP4JXkVEpuiI9Wn/2lRfX19UtWmmS6WCJBInEIudTDx+MvH4SXR2No0d9/m2U1LyGqHQeoLBDQQC7+FyFej9D61lbizGsfs1WMeEwzTGYmOnDLjdvB8I8KvKyrHmalsgQHQG7Rw4E2TUdFlrO0b/udsY8whwBqCPSGeQQY+HZ+bM4Zrdd/Gdrv9JasFPcLkK9xMWEVBtmsgWt5vfezx8ORbj3/01jji+AAAgAElEQVR+kmMbatxFLHYTsdjn8PtvczilSGFSfcoP1nqJx48bba7SDVYisRRIb9bgcnXg861jzpxfj85ibcTtHnQ2dI64YzFm79xJZVsb32pv59jRBqtsdPYqBbT7fLwfDPLYaIO1ORhk134bNsnhTdh0GWNKAJe1dnD03y8CvpvzZDJpj8ydy6W7d3N18jc81fth5sx53ulIIjmj2pSZW30+7hsZ4ROJBL/xpnfLcrvfweV6m1jsWjVdIjmg+jQzWesikVh8QIMVjx8P+AFwuXrwetcRCDyO17sOr3cdbnd6H5SqqioHk2eZtYT6+6lsa0t/tbdT2dZGxa5duEY3txhxudgSCPDE7Nljs1dbAgHCebpz4EyQyUxXLfCISXewHuAea+0TOU0lU7K5tJQNpWV8beiH/GLXz9V0SaFTbcrAUx4PLcZwUzQ61nRBerYrEvlXkskTcLvfdTChSEFSfXKYtZBMNhzUYJ2Iten7ORkzhNf7DiUla/ZrsNoKbsLGlUhQ0dlJVXs7la2tYw1WcGho7JzBqip6GxrYcdpp9DY00DN/Pv98//3YQvuP4bAJmy5r7TbgpGnIIlnwyNw6/m7LFk7tH2IgWoPfv9vpSCI5odqUmZQx3Ob3871IhOXJJBtHP6X0eh8gEvkesdi1BIP/w+GUIoVF9Wn6JZNzDmqwTiaV2jc7FcXr3UAw+MBYg+XxbMWYlKOZs80/OEhleztV+81gzdq5E/fojYUTXi999fW0nnwyvQ0N6a/584mFQoe8lhqu7NOW8QXm93PmcPO2Fr6a/Al/vftjNDTc6XQkEXHYXV4v34lE+LNYjL8OBgFwufbi9T5GPP55AoG/x5gCvQhcRApOKlU21ljF4ycRi51MKlU/ejSJx/M+fv/TeL1v4fOtw+N5D2PiR3zNfGJSKcq7uj5orkYbrJK9H9xUebiigt6GBtqPP36sweqvrcVqeaBj1HQVmJjLxW/rqrmy49d8a9ffYuf/vKDvCSEiE+tzuXjQ6+XKWIx/DAToH9tQ4xfE41cQj38cn+8Rh1OKiBzK2gCx2HLi8ZOJxdINVjK5eOy4270dn+91vN6fjjZY7+JyhR1MnF3ekZH0ksD9ZrBm79yJZ3T3wJTbTd/cuew87jh6588fa7AiZWUOJ5eDqekqQL+uq+Oqjg6+GPsN9/efxqxZa52OJCIOu83v57p4nKtjMf7Tn75o3O1+EWNaicevU9MlIo6z1kM8vnSswUrPZh0LpK9Hdbl24fWuIxh8AJ/vbbzet3G59h75RfOEsZb60a3Z930tjUSY/41vjJ0TLi2lt6GBTeeeO9Zc7Z07l5RHv87nA/1fKkA7AwFenVXJV/be+v+zd99Rclf3+cffd/rMttkmrToSCAkZTBMdA6ZjmmmmN4Nxi0scJ44dJ05ObMeJEyc/J9hEFGNAkgEhioAAokgIsGSJJiRABdVVX6227/T7+2OHtSSEtGVm7+zO8zpHByTNzH3msHx2n7nfucNdW3+n0iUivOv1stDr5fZEgrsCAawxGGMJBKYTj/+ATGYMHs9G1zFFpEhYa0ilDiKZPLq7YCUShwMff6ZgE4HAu5SW/pZA4F0CgXfxereSyQz+92GFMxkm7lasPv5nSfa5pYH1wSDvRSJsOeus7h2sjmhUR7MPYipdQ9TsEcP596YP+NzORtYly/D7h+ZnSohIz90dCHBvZydnplK8lD3JMBCYQTz+AxKJ6wiF/tVxQhEZirpOEhyxxw5WIvFZrK0AwJgO/P73KCl5YLeCtW7w9wtrGZ5Mdu9cTc6Wq7GJBB9/bHCrx8PKUIgno1FWhEKsCIX4KBQilv1g4e9+4Qvu8ktOqXQNUX+qrKQ+UMo3EtO4dccXGTnyMdeRRMSxp/x+tsVifCWR6C5dHs9GfL55JBLXEwz+m94DKiL9lk5X7lWwjiSTGZb92yR+/wdEIk/i93cVLJ9vFcaknWbur0Amw8Hx+B67V5NiMSrSf35eGwIBVoRCPLNbwdqsDxYuGipdQ1TGGJ4aUc031r9K9ZYfYEfo/2mRYpc0hvsDAf46HuegdJp13cfHP0QqdR/p9Gn4fPMdpxSRwSSTKSGZ/OweBSudHvvx3+LzrSYYnN+9g+X3vz/oT0ut3m336uOSNT4e7/6husMYVoVCPF9e3lWuwmFWBYN06OTAoqbSNYQ9M3w4t23YxC2xZ5jWNomyshWuI4mIY78LBPhePM5tiQR/nz0+3u9/hlhsF4nEDSpdIvKpUikvmzfXsnFjHbt2/YpE4khSqYmQvVjO692QLVYPZP/5Hh5P2/4ftID5rOXgVIrPJJMcm0wyqbOTSbEY1bvtXm3x+1kRCvHKxwUrFGJjIEBGr3TLXlS6hrBmv58Xq4dxU8MD/NfWu1S6RIStHg9z/H5uTCT4eShEpzEYE8fvf5RE4iasrcCYZtcxRcSxTMawbVs1GzfWsXHjcDZurGPLllrS6a7dGo9nB37/u4TDT2cL1jt4vY2OU/ddNJNhSjLJlGzJmpJMcmgqRTD793Fj+CgY5NWysu5ytTIUokUnB0oP5eUrxRiD6WPDHzlyZI7T9Exf8/ZXPJ7fLfZHa8q5sGEz5+3YzhujwOvtWi+ddnPt9GGHHeZk3UT28ywG2tixYw98IxkwXq+X6urqPt3X1Yz4Qh7eRP3e9u1c/tJL/NPkycw7uOvzbnbtWstzz4WYOPEfOfTQuaxduzbn6xayZNLNB6du3OjmxMiqqion68qn83g8B77RPtxzzz39XttaSCbHEosdTmfnEcRihxOLTcHaSDZbK6HQMioq5hAKvUc4vIyf/exr2bctjMn+uqjfOXripZde6tf9TSbDsJYWRu/c2fWrsZHRO3dS1d7efZvmcJj6ujrmVVezsbqa+qoqLvze98DnYzQwGjirf0+jx7Zt2zZAK+3phRdecLLuv/zLvzhZ99RTT837GqrnQ9zykhKWBWv4Wvxent11GdU1z7mOJCKOraitZX00yrkrVzJvwgQwhsrK9VRWrmXNmjM49NC5riOKSB4lk7XEYkdkfx1OZ+fhZDJRAIyJEwx+QDT6GKHQe4RC7xEIrP/EITuD4eq5UCLBqMZGxnxcsHbuZOSuXQRTKQDSxrA1GmXViBHU71awWiORTz6YdrSkn/QVNNQZw+y6Uv5h/XIO3fZtdta4DiQizhnDCxMn8pXFi5m0YwcrhnWdKjZhwjzefPNWGhvHAcW10yUyVKXTFcRin9ltB+sIUqnh2b9NEQyuoqxsLuHwe4RCywgGV2FMymnmXrOW6tZWRu9VsGpb//xxOW3BIPXV1SyYPJn66mrqq6vZUllJSodbyABR6SoCL1RV8u0N27m18yV+GhtDKKQPQBUpdm8cdBDXvfMO565a1V26DjroDd5++3rWrDmD6up5bgOKSK9lMmFiscN228E6gmRyXPff+/3riEQWEQoty+5ifYjHE3OYuPf8qRSjspcE7n55YDh7iXAG2F5RwfraWl6fNKl7B6uppGRwbM/JkKXSVQTiXi9PVQ/j2obZ/HzbL2HcdNeRRMSxuM/HvAkTOG/lSqIdHTRFIgQC7YwZs5j160+hsjKAx+PmvZAicmCplIdt24axa9fV3SUrHj8E6Nq58fm2EAq9RzQ6i1BoOaHQMrze1v0/aCGxlnBjI9H164muX09F9p9XbtmCx3Zd6tjp97OpqopFEyd2l6vNlZUksp9DKFJIVLqKxBN1pdzUkOLynVuYM1Zb6SICL06cyAUrVnDWRx/x2BFHADBhwnzWrz+FxsbTqKl50XFCEQHIZKChoZpNm0axadMINm0aydatw0mlun6M83p3EQq9R2npS90HXfh8DY5T95wnmaS8vv4TBSvY9ufj5ttqa2keN45X6+q63ntVXc3OsjKsdq9kkFDpKhIbQyEWhMdxe+dD/KHpSvA97zqSiDi2rayMd0eO5MzVq3liyhTSXi/Dhy+npGQHO3ZcrNIl4oC10NRUwaZNI7sL1ubNI4jHuw4vDwTijBy5lRNOWMyoUZtZsuS3+P2bBs2Vc8Hm5k+Uq/JNm/BkT1VOBQI0jxnDpuOPp2ncOJrGjaN53DiS2cMt+nt6oYgrKl1F5PERAX61Zj1Tt1SzeIzrNCJSCJ6fOJG/nT+f4+vr+eO4cRhjGT9+PsuWXU4sVkcotNV1RJEhLxYL8tJLp3UXrY6OEgC83hR1dds48sj3GDVqM6NHb6amZicez59PEly6dJOr2Ptl0mnKNm/+RMEKNzV136ajqoqmcePYcswx3QWrbcQIbB+PzxcpZCpdReT1ynLqPdXc0jGPP6Zq8fl2uI4kIo69N2IEW0tLOXflSv44rusN9xMmvMqyZZezY8eFjBlzr+OEIkNfY2MV8+efSm1tA5Mnr2LUqM2MGrWF4cO34fNlXMc7IH9bW3e5+rhgVdTX480ebpH2emkZM4atRx5Jc7ZcNY0dS6K83HFykYGj0lVEMsbwWE0d39n+CsN2fp/G4XNcRxIRx2z2+Pib3n6bgxobWVdVRUlJAxUVi9mx40JGj77vE5/PIyK5VVOzk6997ZcEg24+pLunjLWMTSaZFItx+MMPE123jor16ynZubP7NrHycprGjWP1eed17161jhpFRp9zJUVO/wcUmWdH+Pj6dh/XtjTwP8N0eqqIwKsTJvClpUs5Z9Uq7j7hBABqa+ewevVPaW6eSjS62HFCkaEtEEgUXOGKpNMcGo8zOR5nUjzO5FiMifE4JdmTAzNPPEHryJE0TJ7MRx/vXo0bRywa1Q8XIvug0lVkGv1+ni05jJvaZ/M/7edD6buuI4mIYx2BAK+NH89pa9cy86ijaAsGqapagNfbwo4dF6l0iQxl1jIymWTyxwUrFmNSPM645J9LYLPHw4pgkMeiUVYEg3wYCnHtP/8zmUDAYXCRwaXHpcsY4wWWAJustRflL5Lk25MjDV9c1cL5O6t5vtR1GpH+0WzKjbkTJ3L26tWcsWYNTx92GB5Pgtra59i27VJSqXJ8vhbXEUUGnUKbT8FMhkPicQ7LlqvJ8TiHxuOUZ7reN5YBNvr9fBgK8WRFBR9mC9YWn+8Tu1cqXCK905udru8AHwB61+Mgt6zczzLPWL4ce41nUyV4fe2uI4n0h2ZTDmyMRnl/2DDOXrWKZyZNAqC29mm2bv0SDQ3nUlc3y3FCkUHJzXyyltpUao9LAyfF44xPJPj4kzrbjWFlKMSz5eV8GAyyIhRiZTBIh04OFMmLHpUuY8xo4ELgZ8D38ppI8s8YHorW8IvGt5jUeCurh73hOpFIn2g25dYLEyfy3ddf5+gtW1gDlJSsoqTkQ7Zvv1ilS6SXBmo++a1lwm6XBn5ctKqyn3sFsMnn48NQiBfKyroL1ka/Xx8sLDKAerrT9V/A3wBln3YDY8wdwB0A5ToCtOA9X9XKDxtLuaF5G/84zHUakT7r1WyKRqMDFGtwenP0aHaGw5y7ciWPHXQQ0LXbtW7d92lvP5SSkpVuA4oMLvudT7vPpoqKih49YLi9neFbt3b92rKF4Vu38jfbtvHxhX4xY1gVDPJyaWl3uVoRDNLq9e73cUUk/w5YuowxFwHbrbVvGmPO+LTbWWunAdMARo4cqfOFC1yn18Oj4cO5qXMuv2z/PO0l611HEumVvsym0aNHazbtR9rj4aVDDuFL773H2OHD2RAOU1PzAuvXf4vt2y9m/Pj/cB1RZFDoyXzafTaNGjVqj9lkMhmqGhr+XLC2bmXY1q2Ut7Z236a1rIxtdXU8lUzyYbZcrQsESGv3SqQg9WSn6xTgEmPMF4AQUG6Mechae0N+o0m+PVrbwe0bklzaUM6MEtdpRHpNsykPXj74YC5fvpzLt23jvw46CJ+vlaqq+TQ0nMu4cf+Nx5NwHVFkMOjVfAokEkxduLC7YNVu24Y/lQK6Pli4oaaGdRMmsG3ECLbX1bGtro6Okq5v3NOnTx+gpyQi/XHA0mWt/SHwQ4DsqzXf1w81Q8P6cJx53iO5ObaQGekK8KZcRxLpMc2m/GgJh1k4ZgwX1tczbcwYOrxehg2bw86d59LYeDo1NXNdRxQpeL2dT9UNDZz/zDO0RyJsr6vjzeOPZ1u2XDXU1uqDhUWGAP1fXORmVFQzrfFdTtx5NAuH6f0aIgIvHHoop65fz3k7dvB4XR3l5W8SDG5mx46LVLpE8qCxqor/uu022srK9MHCIkNUr84FtdbOK4TPmZDcea16E5sYzvXN21xHEekzzabcWl1dzQclJVy5bRtYizGW2tpnaG4+nlisznU8kUGlJ/MpHgrRVl6uwiUyhOnDGIpcxgMPho/hnMyfGNVR6TqOiBQCY5g1fDgTOjs5pqXrQ5Fra58BMuzYcaHbbCIiIoOQSpfwRG0TSXxcsSPiOoqIFIiXampo8vm6druAYHAbFRV/YseOC7FW3zpERER6Q985haZwI096T+Oa2FsE0we+vYgMfXGPh6eGDeO0xkaGx+NA12d2JRIjaG4+1nE6ERGRwUWlSwCYUVFJFU2cvVOflCwiXR4f1jUPvpjd7aqqehWfr5kdOy52GUtERGTQUekSAJZVfcgyJnN98xaw+vxYEYGtoRCvVVZy6fbtBDIZPJ4kNTXP09h4OqlUuet4IiIig4ZKlwDg8aa4P3wcx2RWM6U94DqOiBSIx+rqqEylOHPnTgBqa+dgbYCGhnMdJxMRERk8VLqk2/O122mllC81qHSJSJfF5eWsC4W4cutWAEpKVlNS8iHbt+sSQxERkZ5S6ZJuyfA6Zngv4IvxZURTKddxRKQQGMOsujo+097OlLY2oGu3q6PjUNrbD3UcTkREZHBQ6ZI9zIxWEiLBJTtLXEcRkQLxf7W1tHu93btdNTVzMSau3S4REZEe8uXlQX0+ampq+nTf6urqHKfpGevo8IjLL7/cybqLFy/e558nk228+vSp3NC2mjfPOBFrTE7X3bVrV04fr6cWLVrkZN3Ro0c7WVf2LZPJ0NHR0af7Dh8+PMdpembkyJFO1n333Xe7/70FeKK8nKt27uTnVVW0+FooK5vLjh3nUFn5czyeuJOMuVRS4uaFpmQy6WTdtuyupRSGsrIyzjjjjD7d94orrshtmB565JFHnKx78cVuXux55ZVXnKwbCLh5y8fJJ5/sZN1LLrnEyboDQTtdsge/v5OHq89gbGorn93spiCJSOGZWVVFwFquyL5wEo3OJpOpoLX1LMfJRERECp9Kl3zCB5MTbKGOMz9scB1FRArE2mCQN0pKuHrXLrzWUlLyJ/z+epqa3OzWi4iIDCYqXfIJFbWr+L3/ak5peZ9h7e2u44hIgZhRVcWIVIrPt7ZijCUafYL29pNIJNxcAikiIjJYqHTJJxgDc8ePI4OHz6/QbpeIdJlfWspmv5/rGhsBiEafADI0NV3mNpiIiEiBU+mSfQoevJQnuYRzNq7Cn067jiMiBSBjDH+orOSEjg4OjsXw+7dQUvJHmpouw1p9OxEREfk0+i4p+xQKNfNw1ZlUZVo5qX6L6zgiUiAei0aJG8N13QdqPEYqNYL29hMdJxMRESlcKl3yqTZObOJDJnHWym2uo4hIgWjy+Xi2vJxLmpooTacpK3sZr7dJB2qIiIjsh0qXfKrhde9wt+9mjmjbwISmJtdxRKRAzKiqImItlzY14fEkqaiYQ2vrWaRSFa6jiYiIFCSVLvlUHk+G+eNG0k6Es1dtch1HRArE++Ew74TDXLtrF8ZaotHHsTZAc/NFrqOJiIgUJJUu2a+qCQuZzvWcvmkdJYmE6zgiUiBmVFUxPpHgpPZ2QqEVhELLaGq6AmtdJxMRESk8Kl2yX6Wl25gZPYewTfD59RtcxxGRAvFCWRkNXu9ux8c/Tjw+iVhsiuNkIiIiheeApcsYEzLG/MkY864xZrkx5p8GIpgUjtaDN/E6J3PO6k0YvYwtBUKzya2kx8OsykpOb2tjVCJBRcUzGBPTgRoiaD6JyCf1ZKcrDpxprT0SOAo43xijs4GLyKhRC5nmvY0xsUY+u2OH6zgiH9NscuyRykoywDW7duH1tlJW9iLNzReSyQRdRxNxTfNJRPZwwNJlu7Rlf+vP/tJ2RxHxehMsGlPDdmo5d/V613FEAM2mQrDN7+elsjKu2LWLUCZDZeVsMplyWlvPdh1NxCnNJxHZW4/e02WM8Rpj3gG2A3OttYv2cZs7jDFLjDFL2traPvkgMqiNHP8q93A7x2/bRE1Hh+s4IkDvZ1OHvnZzbkZVFRWZDBc0NxOJ/Am/fyO7dukSQ5EDzafdZ1OTPpZFZMjrUemy1qattUcBo4HjjTGH7+M206y1U621U0tLS3OdUxyLRtcws+wCDHDOunWu44gAvZ9NkUhk4EMOcUsiEVYGg1y/axeGDNHoE3R0nEgiMcp1NBGnDjSfdp9N0WjUTUgRGTC9Or3QWtsEvAKcn584Usg84z/kaS7irDUb8aXTruOIdNNscsgYZlRVcVgsxlGdnUSjTwIZmpouc51MpCBoPokI9Oz0wlpjTDT772HgHODDfAeTwjNmzKv81txBVbKDEzdvdh1HipxmU+F4uqKCFo+H6xsb8fu3UFLyBk1NX8RafSqJFCfNJxHZW0++I44AXjHGLAUW03Vd8tP5jSWFKBBoZ/nIUlYzgfPWrHMdR0SzqUB0ejw8Ho1yTksLNckk0ehsUqkRtLef5DqaiCuaTyKyB9+BbmCtXQocPQBZZBAYN/5lfrvpG/xH4/cZ19zM+ooK15GkSGk2FZY/VFVxc2MjVzU1cWf1y3i9TTQ1XUZp6euuo4kMOM0nEdmbrv2QXqmpWc7D4S/QSZDz16xxHUdECsSGQIBXS0u5etcugiZBRcUcWlvPIpXSCzMiIiIqXdIrxlgqxr/FTK7jtI31RJJJ15FEpEDMqKykNpXirJYWotHHsTZAc/NFrmOJiIg4p9IlvTZ27Cv8hq8STqc4fcMG13FEpEC8VlrKBr+f6xobCYVWEAoto6npCqw+ElZERIqcSpf0WjjcSP1wH4vNMZy/Zi36iUpEAKwx/KGqimM7O5kcixGNziYen0QsNsV1NBEREadUuqRPxo17kf+x32ZMWyuHNzS4jiMiBeLxaJROY7i2sZGKimcxJkZT0xWuY4mIiDil0iV9MmLEmzzhP49GU64DNUSkW4vXy9MVFVzY3EwVTZSXz6W5+QtkMkHX0URERJxR6ZI+8XhSDBu3kHvtVzhhyxaqOjtdRxKRAjGzqoqwtXyxqYlo9HEymXJaW892HUtERMQZlS7ps4MOeom7+DrGwjnr1rmOIyIFYkUoxJJIhGsaGykNL8Lv38iuXZe7jiUiIuKMSpf0WVnZJpqqksz1nsE569bhzWRcRxKRAjGjspKxySSfa28lGn2Cjo4TSSRGu44lIiLihC8fD5pKpWhqaurTfaurq3OcpmfKysqcrLtx40Yn6y5cuDAnj5NOT+PX6b/imfRFVM6fz9Ph8H5vX1JSkpN1e+uss85ysu68efOcrCv75vF4CAb79t6i9evX5zhNz9TV1TlZt7GxsV/3f9Ra/sbj4apt23is4n7gm2zZch5lZb/c7/2qqqr6tW5fbd++3cm6ff167C9XX1eyb16vl2g02qf7jho1KsdpeqavP+f11zvvvONk3f7OxL766U9/6mTdn/zkJ07WvfzyoXtVhHa6pF9Coad4nlNZZ2q5uaPDdRwRKRApY3ggEuHMRIJD7AYCgfl0dl6Ntfq2IyIixUff/aRfPJ4OAuGnuct+i1MSCSYmk64jiUiBeCgcJgHc0tFBJDKDTGYUicRprmOJiIgMOJUu6bdIZCb38HVieLXbJSLddni9PB0KcXVnJ5X+5zCmkc7Oa13HEhERGXAqXdJvfv9bNPt2Msucx1WdnZToQA0RyfpdJEKFtVwZbyEcfoxY7HwyGTfv2xIREXFFpUv6zRgIh2fyP/bvKbOWy/WZXSKStcTv5z2fj1s7OgiHpgMBOjuH7hulRURE9kWlS3IiHJ7FIo7mbc/YrksMrXUdSUQKgTHcF4lwWCrFabyHz/cOnZ3XakSIiEhRUemSnPB6GwmFXuA39ntMSaU4XgdqiEjWE+EwjcZwa3s7kchMUqkppFJHuo4lIiIyYFS6JGfC4ZlMt1+hyQS4pb3ddRwRKRAxY5gRiXBBPM54/6NAJx0dOlBDRESKh0qX5Eww+Cpxzy5+77mEL8Ri1KbTriOJSIH4fTiMB7gltp1Q6Bliscuwdv8fpi4iIjJUqHRJzhiTIRJ5hDvT/0wAuE7Hx4tIVr3PxwvBIDd0dlIReghry4nFvuA6loiIyIBQ6ZKcCodnsopDeck7kRs7OvDq3fIikvW7SISaTIYrMvPwetfR2XmN60giIiID4oClyxgzxhjzijHmfWPMcmPMdwYimAxOPl89gcBr/I/9ASMzGc6Jx11HkiFKs2nwWRAIsNrr5cudHYTDD5NInEoqNc51LJGc03wSkb31ZKcrBfyVtXYKcCLwTWPMlPzGksEsEpnJnMzN1HsiOlBD8kmzaZCxxvC7SIRjk0lO8t0HZOjsvNp1LJF80HwSkT0csHRZa7dYa9/K/nsr8AEwKt/BZPAKhZ4jY1q523MZpyUSHJxKuY4kQ5Bm0+D0SDhMmzHcFttAIDCPzs4vYa2udJehRfNJRPbWq+90xpiDgKOBRfv4uzuMMUuMMUs6dIBCUTMmTjj8GHelfk4CuFFfD5JnPZ1N7dp5da7N4+HRcJhLYzHGhO4lkxlFInG661giefNp82n32bRr1y4X0URkAPW4dBljSoHHgO9aa1v2/ntr7TRr7VRr7dRIJJLLjDIIRSIz2c5YnvR9hqs7OghnMq4jyRDVm9lUUlIy8AHlE+6PRAgBt2SewZhGfWaXDFn7m0+7z6bKyko3AUVkwPSodBlj/HQNjenW2tn5jSRDgd//AX7/O9xpf0CFtVwWi7mOJEOQZtPgtNLnY1KXiCcAACAASURBVEEgwC0drZSGHiYeP49Mpsp1LJGc0nwSkd315PRCA9wLfGCt/VX+I8lQEQ7PZH76BpZ5y7oO1NDx8ZJDmk2D2+8iEUZnMlzquxMI0Nl5hetIIjmj+SQie+vJTtcpwI3AmcaYd7K/9ImWckDh8BNAjP/1XMHhqRTHJJOuI8nQotk0iL0QDLLJ4+Er8VX4/W/T2XmNXpeRoUTzSUT24DvQDay1rwFmALLIEOPxtBIOz+H+zp/xM/N7buno4Ie6bl1yRLNpcEsbw+8jEX7U1saRJXeypP0eUqkjgdWuo4n0m+aTiOxN5/RKXoXDM2ljJDP9n+Xizk6q0mnXkUSkQMyIRIgDX8vMAjp1oIaIiAxZKl2SV4HAIrzej/iN/VuCwJUtnzhcTkSK1E6PhydDIa6OtVAbfJRY7DIymZDrWCIiIjmn0iV5ZQxEIg+zNHkNC/wVXNvcjEdv3BCRrPtKSii1lls9/4G15bS3n+c6koiISM6pdEnehcOPACnu8lzJ6FSK0/VhySKS9a7fz1t+P7cnluP1rKWl5SrXkURERHJOpUvyzuvdTjD4ErMS/8hWr4/rmptdRxKRAvK7SISJ6TQXBH5GLHYiyeRY15FERERySqVLBkQkMpOEHc2D4SM5raODsTo+XkSy5oRCNHg8fCMzC0jT0qLP7BIRkaFFpUsGRDD4Eh7PNu5K/TVp4FrtdolIVtwYpofDnJtoZnLoUVpbr8BafXsSEZGhQ9/VZEAYkyYcfpQ1sSt4IVLNFS0tBDMZ17FEpEA8EIlggW94fkk6XUdHx6muI4mIiOSMSpcMmEhkJuBjmu9KKjMZLmxrcx1JRArEZq+X54JBboi9Q8RsorVVB2qIiMjQ4cvXA6f7+CG4ixcvznGSnhk+fLiTdcvKypys++1vf9vJun/3d68xp+WveN9M46qGBu5sbx+QdadMmTIg6+wto928guL1eqmoqOjTfTds2JDjND3T5ujFiUsvvXTA11y5eTMXzZnDrZF/4M723wK1+Hy7BmTtHTt2DMg6e/N6vU7W9fv9TtaVffP7/dTV1fXpvj/+8Y9znKZnjj/+eCfrnn/++U7WfeCBB5ys+/777ztZ9xe/+IWTdadPn+5k3ZNOOinva2inSwaUz/d7LBOZ5p3M1EyGY/pYzkVk6Fk5YgQrAwG+lpoF+Glpudh1JBERkZxQ6ZIB5fM9ATTzgP0ebcBXUinXkUSkUBjD9MpKDk+0cHrgIZqbr0SfpS4iIkOBSpcMKGM68flmsSt9HTN9Ea5MpajST1UikjWnvJxWj4dvef6NROJQYrHDXUcSERHpN5UuGXA+3/1AhN/yRcLA9drtEpGsDo+H2RUVXBxbTh1raW6+0nUkERGRflPpkgHn8byNx/Me72a+x+seD7cnkxjtdolI1sxolACWbwb/jtbWC8lkQq4jiYiI9ItKlww4Y8Dne4BM5lj+1zuBg63lLB2oISJZ6wIBFkQi3J56Ak8mRGvrua4jiYiI9ItKlzjh8z0MxJmV+TbbjNGBGiKyh+mVldSlO7nSezfNzVe4jiMiItIvKl3ihDGNeL1P0Zm+nt95g1yQTjNWn2klIlmvlpSw0e/nW+Y/6Ow8gURijOtIIiIifabSJc74/b8HqrjHcxEW+LJ2u0QkK2MMM6NRTk6t4Qjeprn5cteRRERE+kylS5zxeOZjzDrWpr7OM14vtySTBHSghohkPVZRQcwYvuv7CS0tl2GtvmWJiMjgpO9g4owxFp/vITKZM/lf7yhqgMt0oIaIZDV7vcwpL+ea9P9RmgrS3n6q60giIiJ9csDSZYy5zxiz3RizbCACSXHx+R4CMryY+SorjeEryaTrSDKIaD4NfTOiUSI2xZfNb3Sghgwamk0isree7HTdD5yf5xxSpDyeerzeF0mmb+JuX4ATMxk+q90u6bn70Xwa0j4IhXgzHOab5te0t51OKlXpOpJIT9yPZpOI7OaApcta+yrQOABZpEj5fA9g7WgeMGfRATo+XnpM86k4TI9GmZDZznm8QkvLJa7jiByQZpOI7C1n7+kyxtxhjFlijFnS0dGRq4eVIuD1PgM0sDN9Ow/7fFydSlGhAzUkR3afTW1tba7jSB/MLStju9fLtz0/p7n5CjQeZCjYfTbt3LnTdRwRybOclS5r7TRr7VRr7dRIJJKrh5UiYEwSn28m6fSF3O2rJQJcr90uyZHdZ1NpaanrONIHSWN4JBrlvMxrjEl4iMWOcB1JpN92n03V1dWu44hInun0QikIfv8DQIA3Mzex0OPh9mQSo5ezRSTrkWiUNPAN/pvm5itdxxEREekVlS4pCB7PB3g8i0gmb+Zun59DreX0TMZ1LBEpENt9Pl4oK+PL3Eu65QwymZDrSCIiIj3WkyPjZwJ/BCYZY+qNMbflP5YUo64DNQ7jMXM8DcAdOj5eDkDzqbhMj0aJ0s419ilaW89zHUfkU2k2icjefAe6gbX22oEIIuLzPUYi8a+0p2/lfv9C/jKZZFQmwyaPNmRl3zSfistb4TAfBIN8K/4rpjfdT0XFk64jieyTZpOI7E0/zUrBMKYNn282qdSV3OstxwBf1oEaIvIxY5gejfJZPuTYWIJEYqzrRCIiIj2i0iUFxef7PVDGmsxVPOf1cksqhV8HaohI1tPl5TR5fHyLX9PcfLnrOCIiIj2i0iUFxeNZhDErSKVuYprPx3BruTSddh1LRApEzOPhsYoyLmc2pc0nYq3XdSQREZEDUumSgmIM+P2/J5M5iblmCmuM4Ss6UENEdjMzGsVDhtvSs2lvP8V1HBERkQNS6ZKC4/PNBJIk0zdxj9/PKZkMn9Hx8SKSVR8IMK+kjK9yF51Nl7iOIyIickAqXVJwjNmB1/ssyeT1POgN0Qna7RKRPcyorGA4OzivvZFUqtJ1HBERkf1S6ZKC1HWgRi07Mhcyy+fjmlSKMh2oISJZr0cirPWV8BfcRUvLpa7jiIiI7JdKlxQkr/dFjNlEKnUTd/t8lALX6vh4EcmyxjCjqoST+SMTdk1Cr8mIiEghU+mSgmRMBp9vOun0OSwxo1ni8XBHMol+shKRjz1RXk678XNHag6x2GddxxEREflUvnw8aElJCccdd1yf7tvY2JjjND2zefNmJ+tGIhEn67ri9fb8eOdgcDrJ5N+QydzEvYGf89tYjNOB13rxGB+Lx+O9vk8uTJw40cm68uk8nr691hSNRnOcpGcaGhqcrDt2rJsPHt64cWOvbj/D4+PG9Ax+uOlfaQg+0+d1Xf33dfU9wNXzlX1rbGzkD3/4Q5/uO2bMmByn6Zm+ztL++vnPf+5kXZ8vLz8yH1BdXZ2TdRctWuRk3ba2NifrDgTtdEnB8njW4fXOJ5G4kcd8AXYBtycSrmOJSAGZ5reEiHNzuhlri+tFLBERGTxUuqSgBQIPYO1BtGdO46FAgItSKep0fLyIZL3v8TDfVPIN7sOmdHy8iIgUJpUuKWg+39NAE4nEjdwbCOAHbtbx8SKym7v87RzEes5LHeI6ioiIyD6pdElBMyaG3/8IqdQlrDFVzPV6uSWRwKcDNUQk6xmvl42U8w37CpnMwa7jiIiIfIJKlxS8QOABIEQyeSX3BAKMtJYLdXy8iGSljeEen49zmcvByfNcxxEREfkElS4peF7ve3g875BI3MwLPh/rjdGBGiKyh9/7O4nj46vpRqzt/QmnIiIi+aTSJYNCIPAgmcxnSWaO4neBAKel0xyaTruOJSIFYocxzPKM4mYeJZI+3XUcERGRPah0yaDg9z8KdJJI3MgDfj9xdHy8iOxpmr+Bclq5JjnSdRQREZE9qHTJoGBMM37/UySTV9FgIjzu93NtMkmJDtQQkawlngxLGMM37KvYTI3rOCIiIt1UumTQ8PsfAKKkUhdzj99POfAlHR8vIh8zhrv8XqbwIacmT3adRkREpJtKlwwaXu9rGLOGROImFnu9LPV4ui4x1G6XiGTN9m2jgQq+lm7QaBARkYLRo9JljDnfGLPCGLPaGPO3+Q4lsi/GQCDwEOn0aWTsBO4OBDg8k+FEHahRtDSbZG9xY7jPM4FLeZlR6cNdx5EipvkkIrs7YOkyxniBO4ELgCnAtcaYKfkOJrIvfv8MIE0icQOz/H6a0IEaxUqzST7Nvf6NANyW1Pu6xA3NJxHZW092uo4HVltr11hrE8AfgEvzG0tk3zyeLfh8L5BMXkc7PmYEAlyaSlGbybiOJgNPs0n2qd7bwRyO5ja7iEAm7DqOFCfNJxHZg7EHuOjdGHMlcL619vbs728ETrDW/sVet7sDuCP728OBZbmPW7BqgAbXIQZIMT1XKL7nO8laW+Y6RE9oNvVIsX396vkObUNqPmk2FdXXrp7v0Naj2eTL1WrW2mnANABjzBJr7dRcPXahK6bnW0zPFYrz+brOkGuaTXq+Q1UxPl/XGXJJs0nPd6gqxufbk9v15PLCTcCY3X4/OvtnIiIuaTaJSKHSfBKRPfSkdC0GJhpjxhtjAsA1wFP5jSUickCaTSJSqDSfRGQPB7y80FqbMsb8BfA84AXus9YuP8DdpuUi3CBSTM+3mJ4r6PkWLM2mHtHzHdr0fAtUH+bToHluOaLnO7Tp+e7DAQ/SEBERERERkb7r0Ycji4iIiIiISN+odImIiIiIiORRTkuXMeZ8Y8wKY8xqY8zf5vKxC40xZowx5hVjzPvGmOXGmO+4zjQQjDFeY8zbxpinXWfJN2NM1BgzyxjzoTHmA2PMSa4z5ZMx5i+zX8vLjDEzjTEh15lypZhmExTnfNJsGrqG8myC4ppPxTibQPPJdaZ86s18ylnpMsZ4gTuBC4ApwLXGmCm5evwClAL+ylo7BTgR+OYQf74f+w7wgesQA+T/Ac9ZaycDRzKEn7cxZhTwbWCqtfZwut74fY3bVLlRhLMJinM+aTYNQUN5NkFRzqdinE2g+TQk9XY+5XKn63hgtbV2jbU2AfwBuDSHj19QrLVbrLVvZf+9la4vqlFuU+WXMWY0cCFwj+ss+WaMqQBOA+4FsNYmrLVNblPlnQ8IG2N8QATY7DhPrhTVbILim0+aTZpNg1hRzadim02g+aT59Ge5LF2jgI27/b6eIf4/0seMMQcBRwOL3CbJu/8C/gbIuA4yAMYDO4DfZS8JuMcYU+I6VL5YazcB/w5sALYAzdbaF9ymypminU1QNPNJs2mIGuKzCYp4PhXJbALNJ82nLB2k0U/GmFLgMeC71toW13nyxRhzEbDdWvum6ywDxAccA/zWWns00A4M2WvtjTGVdL26Oh4YCZQYY25wm0r6qxjmk2aTZpMMPsUwm0DzCc2nPeSydG0Cxuz2+9HZPxuyjDF+uobGdGvtbNd58uwU4BJjzDq6Ln840xjzkNtIeVUP1FtrP34FbhZdg2SoOhtYa63dYa1NArOBkx1nypWim01QVPNJs0mzaTAruvlURLMJNJ80n3aTy9K1GJhojBlvjAnQ9Uayp3L4+AXFGGPoumb1A2vtr1znyTdr7Q+ttaOttQfR9d/2ZWvtkH210Vq7FdhojJmU/aOzgPcdRsq3DcCJxphI9mv7LIbOm1+LajZBcc0nzSbNpkGuqOZTMc0m0HxC82kPvlytaq1NGWP+AniertM77rPWLs/V4xegU4AbgfeMMe9k/+xH1tpnHWaS3PoWMD37jXANcKvjPHljrV1kjJkFvEXX6VJvA9PcpsqNIpxNoPk01Gk2DRFFOJ80m4Y+zadPYay1A5VNRERERESk6OggDRERERERkTxS6RIREREREckjlS4REREREZE8UukSERERERHJI5UuERERERGRPFLpEhERERERySOVLhERERERkTxS6RIREREREckjlS4REREREZE8UukSERERERHJI5UuERERERGRPFLpEhERERERySOVLhERERERkTxS6RIREREREckjlS4REREREZE8UukSERERERHJI5UuERERERGRPFLpEhERERERySOVLhERERERkTxS6RIREREREckjlS4REREREZE8UukSERERERHJI5UuERERERGRPFLpEhERERERySOVLhERERERkTxS6RIREREREckjlS4REREREZE8UukSERERERHJox6VLmPMXxpjlhtjlhljZhpjQvkOJiJyIJpNIlKoNJ9EZHcHLF3GmFHAt4Gp1trDAS9wTb6DiYjsj2aTiBQqzScR2VtPLy/0AWFjjA+IAJvzF0lEpMc0m0SkUGk+iUg334FuYK3dZIz5d2AD0Am8YK19Ye/bGWPuAO4AKCkpOXby5Mm5zioiefbmm282WGtrXefoCc0mkeIy1OaTZpPI0NDT2WSstfu/gTGVwGPA1UAT8Cgwy1r70KfdZ+rUqXbJkiW9Sywizhlj3rTWTnWdoyc0m0SKy1CeT5pNIoNXT2dTTy4vPBtYa63dYa1NArOBk/sbUESknzSbRKRQaT6JyB56Uro2ACcaYyLGGAOcBXyQ31giIgek2SQihUrzSUT2cMDSZa1dBMwC3gLey95nWp5ziYjsl2aTiBQqzScR2dsBD9IAsNb+BPhJnrOIiPSKZpOIFCrNJxHZXU+PjBcREREREZE+UOkSERERERHJI5UuERERERGRPFLpEhERERERySOVLhERERERkTxS6RIREREREckjlS4REREREZE8UukSERERERHJI5UuERERERGRPPLl40E3b97M3//93/fpvqtXr85xmp5pampysu7xxx/vZN1FixY5WTeRSDhZN5PJOFl34sSJTta9++67naxb6LZu3covf/nLPt23uro6x2l6ZvLkyU7W7ejocLKuqxlx8MEHO1l327ZtTtadN2+ek3X/4R/+wcm6he7tt9+mtLS0T/c1xuQ4Tc9Ya52s6+r5ytDW2tqa9zW00yUiIiIiIpJHKl0iIiIiIiJ5pNIlIiIiIiKSRypdIiIiIiIieaTSJSIiIiIikkcqXSIiIiIiInmk0iUiIiIiIpJHKl0iIiIiIiJ5pNIlIiIiIiKSRypdIiIiIiIieaTSJSIiIiIikkcHLF3GmEnGmHd2+9VijPnuQIQTEfk0mk0iUqg0n0Rkb74D3cBauwI4CsAY4wU2AY/nOZeIyH5pNolIodJ8EpG99fbywrOAj6y16/MRRkSkjzSbRKRQaT6JSK9L1zXAzH39hTHmDmPMEmPMkvb29v4nExHpOc0mESlU+5xPu88ma62DWCIykHpcuowxAeAS4NF9/b21dpq1dqq1dmpJSUmu8omI7Jdmk4gUqv3Np91nkzFm4MOJyIDqzU7XBcBb1tpt+QojItIHmk0iUqg0n0QE6F3pupZPuXxHRMQhzSYRKVSaTyIC9LB0GWNKgHOA2fmNIyLSc5pNIlKoNJ9EZHcHPDIewFrbDlTnOYuISK9oNolIodJ8EpHd9fb0QhEREREREekFlS4REREREZE8UukSERERERHJI5UuERERERGRPFLpEhERERERySOVLhERERERkTxS6RIREREREckjlS4REREREZE8UukSERERERHJI18+HtRai7W2T/d9/fXXc5ymZxKJhJN14/G4k3U3btzoZN2LL77Yybrvv/++k3WbmpqcrCv7VlpaykknndSn+7r6f7W1tdXJuk8++aSTdU899VQn6y5evNjJuqNHj3ayblVVlZN15dMZY1xHEJE80k6XiIiIiIhIHql0iYiIiIiI5JFKl4iIiIiISB6pdImIiEjhammB2293nUJEpF/ycpCGiIiISL+98grccgvU17tOIiLSL9rpEhERkcLS0QHf+Q6ceSYEg/Daa64TiYj0i3a6REREpHAsXAg33wwrV8K3vgW/+AVEIq5TiYj0i3a6RERExL1EAv7u7+CUU6CzE158EX79axUuERkStNMlIiIibi1dCjfe2PXPW2+F//xPqKhwnUpEJGfystNV0tFBtKkpHw8tIiIiQ0UqBf/yLzB1KmzbBk89Bffdp8IlIkNOXna6oi0tfP/OO2morGT1hAl8NH48a8aNIx4K5WM5ERERGWxWrux679bChXDVVfCb30BNjetUIiJ50aPSZYyJAvcAhwMW+LK19o+fdvvtNTU8fcwxHLJmDUcvXcqJb75J2hjqR43io/HjWTVhAptGjiTj0VvKRKTvejubRKQAZDJw553wgx9AKAQzZ8I117hOlXOaTyKyu57udP0/4Dlr7ZXGmACw33e1Jn0+Fh53HAuPOw5vOs2Y+noOWbuWQ9as4YwFCzhzwQJiwSBrxo1j9fjxrJ4wgcbKSjCm309IRIpKr2aTiDi2fj18+cvw8stwwQVwzz0wcqTrVPmi+SQi3Q5YuowxFcBpwC0A1toEkOjpAmmvl3XjxrFu3DhePOMMwh0dTFi/nkPWrOGQtWuZsnIlALsqKlg9YQINHR28HgrRrF0wEdmP/s4mERlA1nLYwoXwox+BtXD33XDbbUP2xVbNJxHZW092usYDO4DfGWOOBN4EvmOtbd/9RsaYO4A7AMrLyz/1wTojEZYfdhjLDzsMrKV61y4OWbOGg9eu5Yjly7krkSANLA0EeDUUYkEwyNvBIMkhOphFpM96PZuGDx8+4CFFil2kpYXPz5zJ+GXL4PTT4f774aCDXMfKtwPOp91nk9HPOCJDXk+2k3zAMcBvrbVHA+3A3+59I2vtNGvtVGvt1EhPP1PDGHZWVbFo6lRmXHUVP//e97h82DD+u7ycNPAXLS3M2rGDdzdt4r4dO7iltZWDk8muV8lEpNj1ejZFo9GBzihS1A556y2u+9nPGLNiBQsuv7zrssKhX7igB/Np99mk0iUy9PVkp6seqLfWLsr+fhb7+MEmFzJeL0uCQZYEg/yqooLyTIaTYjFOi8X4XDzO2dlj6Dd5vSwIhVgQCvFaMMgurzcfcUSksA3YbBKR3gm1t3PaI49w6FtvsXXcOF684Qaa6ur4XPG8dUDzSUT2cMDSZa3daozZaIyZZK1dAZwFvJ//aNDi8fB8JMLz2Z2zsakUn4vF+FwsxgUdHVzT3k4GWOb3syAU4tVQiDeDQRJ6xUhkyHM5m0Tk041bvpwzZ8wg1NbGHy+6iLfOPhvbjxdHW1vhr/86hwEHgOaTiOytp6cXfguYnj19Zw1wa/4ifboNPh/TS0uZXlqK11o+m0jwuexO2B2trXyztZUOY1gYDHbvhK30+YbsG3VFpDBmk4iAv7OTUx9/nM/88Y/sHDGCOV//Og2jR/frMV99FW65Bdaty0nEgab5JCLdelS6rLXvAFPznKVX0sbwdvaQjV9XVFCayXBSPM6p2RJ2ZvZSxK1eLwuCQV4NhXgtFGKnLkUUGTIKcTaJFKNRq1Zx1kMPUbprF2+ecw6LLriAjN/f58fr7IQf/xj+8z9h/Piu8vW5z+Uw8ADQfBKR3fV0p6vgtXk8zA2HmRsOAzAqleouYGfHYlzV0QF0XYr4WvZSxMXBIHHtgomIiPSJN5HgpDlzOGrePJpqa5n93e+ydcKEfj3mkiVw003wwQfw9a/Dv/0blJbmKLCIiCNDpnTtbZPPx8OlpTxcWorHWg5PJrvfD/bl1la+1tpKzBgWBYMsCAZ5yevlA12KKCIi0iPD1q3jnAcfpHL7dpaedhpvXHIJqWCwz4+XTMJPfwo/+xnU1cHzz8O55+YwsIiIQ0O2dO0uYwxLAwGWBgLcWV5OJJPhhHi861TEWIwfx2L8GNju8TA/EODVQID5gQDbdSmiiIjIHjypFMc99xzHzp1Le0UFT3zzm9RPntyvx1y2rGt36+234cYb4de/Bn3Cg4gMJUVRuvbW4fHwSjjMK9lLEetSKU5qb+f0RILPx+NcFYsB8IHPx/xsAVsYCNCpXTARESli1Zs3c/aDD1JbX88HJ5zAgiuuIJH9XtoX6TT86ldd79+qqIDZs+Gyy3IYWESkQBRl6drbVp+Ph8NhHg6HMdbymVSK0xMJTk8kuKWjg691dBAH/pQtYPMDAZb5fFiVMBERKQImk+HoF1/khGefJRaJ8PQdd7DuiCP69ZirV3edTPj6611F6667YNiw3OQVESk0Kl17scawzO9nmd/PnSUlhK3lhGwBOz2R4MdtbfwY2GkM84PB7ksRt+hSRBERGYIqtm/n7IceYsTataw+6ijmXX01sX6cbGFtV8H6/vfB74cHH4Trr9dbqkVkaFPpOoBOY5gXDDIv++bgYek0p2UL2GmJBJdnL0Vc6fUyL1vC3vD76fB4XMYWERHpn0yGIxYs4OQnnyTt9/P8zTez6thj+9WONm6E226DuXO7Dsm4917o50d5iYgMCipdvbTd62VWOMyscBisZXIqxRnZAnZjRwd3dHSQAJb4/d0lbKnPR0Yv4YmIyCBR2tjIWdOnM2blStZNmcIr111He0VFnx/PWvjTnybx4x9DKgW//S189ava3RKR4qHS1R/G8KHfz4d+P3eVlBC0luMSie4S9qO2Nn4ENBrDa4EA8wIBXg0GqdeliCIiUoisZfKiRXzusccw1vLKNdew/OST+9WOWlvD/OEPZ7B06cGceircfz8cfHDuIouIDAZ5KV0tLS383//9X5/uO7mfx8721bvvvtvvx4gBCwIBFgQCANRkMpyWLWCnJxJcEo9Dayurvd7uAznaPB46fAPffS+++OIBXxNgy5YtTtYtdfTJmm+88YaTdWXfOjs7Wbp0aZ/u+4UvfCHHaXqmvr7eybo/+MEPnKzb1NTkZN0nn3zSybquZtOKFSs+8Wdl7e1cM28en127llUjRzL97LPZWV4OK1f2eZ2PPjqSV175EolEiJNPfpx58y5DrzvmlrXWybpG25SSB66+ngeCdrryqMHjYXYoxOxQCKzl0HS6+0COazs7ua2zk/TLL/NBRQVvVVfzVk0NK8vLyej9YCIiMoCOWr2aq+fNI5hMMvvUU5l35JH9OqE3FguzYMGVrFhxPLW1Gzj77Aeprt6K16vz4EWkOKl0DRRjSP/6kQAAIABJREFUWOnzsdLn4+5IhIC1TE0m+VJVFcc2NHDDRx9x00cf0ebz8U5VFW/V1PBWdTVbIxHXyUVEZIiKxGJcNX8+U1etYv2wYTx49tlsq6rq12OuXz+Zl1++jo6Oco477lmmTn0erzeTo8QiIoOTSpcjCWN4IxCgc+JEfj9xImWJBEc1NnJMQwPH7NzJqdu3A7A5HOatmhrerq7mnaoq2v1+x8lFRGQomLJ+Pde99BKlsRhPn3ACc489tl9XWiQSAd5444ssW/Y5qqq2cOGFdzNs2MYcJhYRGbxUugpEayDAgro6FtTVgbWM7ujg6IYGjt25kzM3b+aijRtJAysrKngzW8I+rKggrUsRRUSkF3ydnVzz8suc8v77bK6q4q6LL6a+trZfj7l588G8+OL1tLRUc/TRL3LCCc/g86VylFhEZPBT6SpExlBfUkJ9SQlzxo3Dm8nw/9u78/goy3vv459rluwrWQmEsKOA7IKCCC6ouFTFpdZqa4+tbU9re3qWntbntFqf09P26XP6VK3aqm09banWBaVgVVARKiL7IvuSsGQPCdm3Wa7nj4SQQCAhM2GSzPf9es0rydwz1/27Mf4y37nuue6LqqraZsE+d+gQ9x06RJ3TyY52pyIWxMRo/V0RETmrlJ07mfbUU0SXlbFy2jT+NmsW3gBWtvB6XaxffxNbt15NQkI5ixY9SVbWoSBWLCIyMCh09QM+h4NdycnsSk7mj2PGEOfxMLm8nGmtt8vLygAoiYpqW5Bj66BB1LauoigiIuHN0dTE+MWLGbV8OXUZGfxy0SLyBg8OaMzS0mzee+9+KioGM3Hi35k9+00iIpqDVLGIyMDSK6HL74/E74/E4WjqjeHDXq3bzdrMTNZmZgIwuL6+bRbsypISFhYU4AcOJCS0zYLtSUrCq1MRRUTCTtKBA0x/4gniCwrIXbiQXV/4Anlr1/Z4PJ/PwaZN17Np0/XExFRzyy1Pk5OzN4gVi4gMPL0SuhobR7Jt20dERJQQGXmEyMijREUdJTLy5K0IY3Sud7AUxcTw1rBhvDVsGA6/n3HV1W0h7O68PD6Xm0uD08mnyclsbg1hWKtTEUVEBjDj8XDRq68y5vXXaUxOZu1jj1E2eXJAY1ZUZLJy5f2UlQ1j3LgNzJ37GlFRDUGqWERk4OqV0BURUUBKynM0NubQ1JTNiRML8fni2z3CS2RkQWsYO0Jk5DEiI48QFXUMa70YM3AvjNbb/A4He5KS2JOUxOLRo4nxeJhcUdF2KuLMvS3vRlZu386+nBz2DxvG/mHDqNPS9CIiA0b8kSNMf/JJknJzOXrVVXz64IN4YmN7PJ7fb9i27SrWr7+ZiIhGFi58gVGjtgexYhGRga1XQpfLVc3gwc+3/WwteL1JNDXl0NQ0jMbGYTQ1tdxqai7F2qi2x+7e3URMTMFpt3xiYwtwuys1OXOe6t1u1mVksC4jA4CM+nqmlZczz+PhkoMHmbVrFwD56ensGzaM/Tk55GVl4XXp434iIv2Oz8fov/6Vi//8ZzyxsXzyve9RPGtWQENWVaXy3nv3UVQ0ipEjtzN//svExNQGqWARkfBwQV5ZGwNudyVudyVxcR3fGbPW4PGk0dSUQ2NjNsaMo75+KLW1wykruxxrT5XoctURE5N/RiCLiSnA7a67EIfS75XExPB2TAxHxo/H+P1kl5Yy9sgRxh05wvwtW7hm0yaaXS5yhwxpmQnLyaEoJUWnIoqI9HGxRUVMe/JJUvbupeDyy9n+1a/SnJjY4/GshV275rB27e0Y4+Paa//AuHEb9edARKQHuhW6jDGHgRrAB3ittTOCVYAxloiIUiIiSomP30hKSkrbNr/fQWNjBvX1Q6mvH0J9/RDq6oZSWTme4uL5wKmFIdzuSmJj888IYzExhTidWtCjM9bh4GhmJkczM3lv1iwim5sZlZ/PuCNHGHv0KLeuWQNAdUxMWwDbP2wYNQGcoiISTL3Zm0T6Db+fEe+8w4Q//AG/y8Wm73yH/LlzA3qzrLY2ifffv5djxy4mO3sPV1/9Z+LjK4NY9MCn/iQi7Z3PTNdV1trjvVZJJxwOPzExRcTEFAEbO2zz+dw0NAw+I5AdPz6D5ubrOzw2MrKM2Nh8oqMLiI09Fciio4txOLSgx0lNERHsHjmS3SNHApBUU9M2C3ZxXh6X7tkDQGFqKvtyctiXk0PekCF4dCqihNYF700ifUX08eNM/dWvSN++nZKpU9n6jW/Q2O7Ny/NlLezfP4PVq+/C73cyb94rTJz4d81u9Zz6k4gA/fg6XU6nh7i4o8TFHT1jm9cb3RbE2t9KSq7E601oe5wxPqKiiomJKaC+fjtO5yFcrkM4nXk4HAUY47+Qh9TnVMbHs2HiRDZMnIixliEnT0U8epS527Zx1ebNeJxOcocMYf+wYezLyaEoLQ2rv84iIr3LWrJXrWLSb3+L8fvZ+vWvc2TBgoBmtxoa4li16rPk5k5h8OBDXHPNn0hKUl4QEQmG7oYuC6wwLcsK/sZa+9zpDzDGPAQ8BBAR4ovyulwNJCQcJCHh4BnbmpvjW0PY0A6BrLHxXqxtf9pcI07nYZzOXFyuXJzOXJzOQziduTgcpWH3rp81hvyMDPIzMvhg5kwiPB5G5ucz9uhRxh05wi0ffcQtH31ETXR022mI+3NyqIqLC3XpMrCdV28aNGjQBS5PJPgiKyuZ8uyzDN6wgePjx7Pl4Yepb71uY0/l5k5i1ap7aGqKYvbsN5ky5QMcDq0kHKBz9qf2vcmE24sKkTDU3dB1hbW2wBiTDqw0xuy11q5p/4DWZvIcQGxsbJ/t1BERNURE7CUpqeOFHLdt247fn4HPNxKfbxQ+3wi83lH4fCNpbr4GiGx7rDG1rSHsVBg7GcwcjvA4573Z7WbviBHsHTECgITa2rYANvboUaa3Lk1fPGhQ2+fBDg0dGsqSZWA6r96Uk5PTZ3uTSHdkrVvH5F//GldDA58+8ACHbrkFArjwfVNTNGvW3Mm+fTNJSzvKbbf9kZSU4iBWHNbO2Z/a9yan06neJDLAdSt0WWsLWr+WGmPeAGYCa879rP7FGHA6S3A6S4B1HbZZ68DvH4rXO6I1kI3E5xuJ1zuZpqZbAGe7ccpxOvPaTlM8OTvWEsjqL+xBXUDVcXFsGj+eTePHY6xl8PHjbZ8Hm71jB/O2bsXrcLAvNZVPMzP5NDOTvORknYooAQmH3iQC4K6tZdLzz5O9Zg0nRo1iy7e/TU12dkBjHj06jg8++Dx1dQlceunfmDHjXZzO8D6tPpjUn0SkvS5DlzEmFnBYa2tav78OeLzXK+tDjPHjdB7F6TwKrO6wzVo3Pt+wtjDm9bbMlDU3X4Hf/9kOj3U4ijrMkLlcudTWRhITU4TD4bmAR9S7rDEUpqVRmJbGhzNm4PZ6GVFQwNgjRxh56BD37NjBPTt2UBMRwc6MDHa0hrByrYoo50G9ScJF+pYtTH36aSKrqthzzz3sv+MObAALGDU0OPnww7vZuXMuyclF3Hnn82RkHAtixaL+JCKn607XzgDeaD3f2AX82Vr7Tq9W1Y8Y48HlalmA43TWxuD1Du9wyqLPN4qmpoVYmwrA2rUAPqKjS4mJKWxd9r6w9YLQhURFleBw9O93Hj0uV8vnvHJyKBozhsTGRiYWF3NJcTGTiou5/FjLH/uC+Hh2ZmayIzOT3enpNLrdIa5c+jj1JhnQXA0NTHjxRUasWEF1djafPPIIVaNGBTTm7t2DeOqpaRQXxzBlygdcdtlyXK6B86ZfH6L+JCIddBm6rLW5wOQLUMuAY0w9bvdu3O7dZ2zz+xPw+UYydOjVrcvdtyzoUVh4LV5vbLsxPK3L5p8ZyCIjj/fLBT2qoqJYO3w4a4cPB2sZWl3NJa0hbH5uLtcfOIDXGA6kpvJpRgY7Bg8mNzkZG8DnFmTgUW+SgSxl1y6mPfUUMaWlHLjtNvZ87nP4A1ikqrnZwUsvXczSpaNJT6/n9tufZMiQM98slOBQfxKR0/XbJeP7O4ejGodjG1lZHVOTtdDcnNQhiJ38Wl4+Fb//1IIeTmcj0dGFxMYWnBHI3O6q/hHIjCE/MZH8xETeHjcOl8/H2OPHmdQawu7cuZO7d+6k1u1mV0YGn7bOhJVpVUQRGYAcTU2M//OfGbVsGXUZGfz9xz+m4uKLAxrz0KFEnnhiOseOJXDddXk88MBOPv5YgUtE5EJS6OpjjIHIyEoiIytJTt7VYZu1hsbG1A5BrL5+CDU1IygtvRxrT/3ndLlqWmfHCtqC2MmvLlffXdDD63SyOyOD3RkZvDx5MvFNTUwoKWFSURGTiouZlZ8PQFFcXNupiLvS02kI8WUKREQClXTwINOeeIKE/Hxyb7iBXV/4Ar7o6B6P5/UaXn99LK++Oo7ExCZ+8IOPmTatNIgVi4hIdyl09SPGWKKjy4iOLiMlZVuHbX6/k4aGjDMC2YkTEygqmg+cOjUvIqKCTz+tJDm5jKSkMpKTy1q/L+9z5/bXREbyybBhfDJsGFhLVk1N26mIVxw+zIKDB/EZw8GUlLZTEQ8NGoRfpyKKSD9hvF7GvfoqY197jabkZNY++ihlU6YENOaxY/E8+eQ0Dh5M5sorj/GVr+wgLq5v9XcRkXCi0DVAOBw+YmMLiY0tJC1tY4dtPl8E9fWDqa8fSl1dFvX1Q4Ax5OVdTH39rHaP9BMfX0lS0vF2Qazla0JCReiXEjaGwoQEChMSeHfsWJw+H2PKy9sW5Fi0ezd37tpFvdvNrvT0tlMRS3Qqooj0UfFHjjD9ySdJys3l6Pz5fPrlL+MJYCVXnw+WLx/F4sXjiY728t3vbuDyywuDWLGIiPSEQlcYcDqbiY8/Qnz8kbb7xo8fD0BTUySVlWlUVqZy4kQ6J06kUlmZxr59U2lqiml7vDE+EhPLSU4+3hbEWr4eJz6+EmMu/HUdfU4ne9PT2ZuezquTJhHb1MSE0tK2EHZpQQEApbGxbEtPZ0d6Op+mp1OnUxFFJMSM38/lH3/M/FWr8MbEsP5736No1qyun3gOxcUxPPXUNHbvTmXmzCK+/vVtJCU1BaliEREJhEJXmIuMbCIjI5+MjPwO91sLjY2xnDiR1hbETpxIo7IyjWPHRuH1tl/Qw9M2O3YyiCUllZKcfJyYmJoLtqBHXWQkG7Kz2ZCdDdaSUVvbtiDHnGPHuC4vDx+Qm5zM9owMtqensz8lBZ9ORRSRCyi5vJxb33yTYUePUjhrFtu+9jWak5J6PJ61sGLFcF58cSIOh+Vb39rM/PnH+sdiSiIiYUKhSzplDERH1xEdXUdW1uEO26yFurrEMwJZRUUGubnj8ftP/VpFRDR2mBkz5iDx8UXExxcTEVHXqwdQEh/Pyvh4Vo4Zg6+piTEnTjC5pIRJpaXcvm8fd+7dS4PLxa7U1LYQVhgfj16piEivsJYZGzdy7YoV+J1O3li0CHPffQH1nPLyKJ5+eipbt2YweXIp3/zmVlJTG4JYtIiIBINCl5w3YyAuroq4uCqysw922Ob3O6iuTqKyMr1DICsqymH//ilYe33bYyMjq4mPLyIurrgtiLV8LcHlCu4pMX6Hg30pKexLSeGV8eOJ8XiYWFrKpNJSJpeUMKO4GICy6Gh2tAawT9PTqYmM7GJkEZGuJVRVccvSpYw6dIiDo0ez7DOfoSYxkUk9DFzWwpo1Q3n++Ul4vQ4eemg711+fhybuRUT6JoUuCSqHw09SUgVJSRUMH95xm9fr5OBBPzU1g6mtzaS6uuVrScklHD48r8Njo6PL24WwU19jY0twOn0B11nvdrNhyBA2DBkCQHpdHZNKSphcWsqsggKuOXwYP5CXlNQ2C7YvJQWv0xnwvkUkjFjLpO3bueHtt3H4/bx1881snjEjoNmtqqoIfvObyaxbN4SLLirn4Ye3kJXVi2cOiIhIwHoldMXFxTFv3ryuH9iJK6+8MsjVdM/OnTtDst+FCxeGZL+LFy++4Pt0uXxkZ9cBB1pvp3g8kVRVpVFVlUFVVTpVVRlUV6eTn38ZTU2nVh80xk9cXDlJSSUkJJSSmFjS9n1cXAUOR+cLehS0LqpxNkedTo5mZbE8KwuHtYyurGTq8eNMPX6cz+zfz6J9+2h0Otk5aBBbU1PZmpbG0bi4Ll84NTXpQ+x9icfjoaioqMfPDYVly5aFZL9JAXzGKBCDBw8OyX7dbnfQx4ypreWGN99k3O7dHMvJYfmdd1KZkkL7Pb344ovnNWZR0Uy2b/9HPJ5Yxo//H0aPXsqKFee/smyo/p0l+IxOiR/QrL3wC5WF0kD+fdZMl/QJbncTqan5pKbmn7GtsTGG6up0Kisz2r5WVWVQXDwajyeq7XEOh4eEhDISE1vCWPuv1hZ0+41lvzHsT05mf3Iyfxkzhmivl0vKy5ly/DhTy8r4yp49sGcP5ZGRbE1LY1tqKttSU6nUqYgi0mrszp0sfPNNIpqbeX/hQjbOmYMN4Nw/jyeWTz99kGPHriYx8RCzZ/+QhISjQaxYRER6k0KX9HlRUfVERR0mPf1wh/uthYaGhLbZsZOhrKoqg/z8Cfh8p95Pdjrr265jdupWQGxsARERtefcf4PLxYaMDDZkZACQ1tDAlLIyph4/zqUlJVyb3xIUcxMSWmbBUlPZPWgQzToVUSTsRDU0sGDZMiZu20ZRVhbL77qL4629o6dKSyexdeu3aGpKZuzYvzBu3Ks4HN4gVSwiIheCQpf0W8ZATEw1MTHVDB7c8XRFv99QVzeo7VTFgoJY6uqyqKoaTXHxHKw9FYjc7urTgtipry5X4xn7LYuOZuWwYawcNgxjLSOrq5lWVsaU48f5TF4ed+Tm0uRwsGvQIJY2NPCh280up1OrIooMcCP37+fGJUuIqa3l79dcw8fz5+MP4M0XrzeSXbu+yOHDNxIXd4yZM39KcvLBrp8oIiJ9jkKXDEgOhyU+vpz4+HKGDt1DUtKpz3T5/S7q6zOoqxtCXV1W29fy8ksoKLi6wziRkeWdBrKYmCKcTi/WGA4lJnIoMZFXR48m0utlYkVFy+fBysr4UX09ACXGsMbtZlVEBKvdbkq0xJjIgOFuauLqt99m2oYNlKWn89r991PcukhPT1VUjGPLlm9TV5fJqFFLufjixTidzUGqWERELjSFLgk7DoeXuLgC4uLOXFzD54ukrm5wu0DWcispmUVzc/uFBfxER5d2Gsg2pkawOT0dgMNr1zLP4+Eqj4d5Hg93Nbe8aNrtdLLa7WaV2806t5sGzYKJ9EvZeXnc9NprJFVW8sncuay59lp8ASzK4fO52Lv3Xg4evJWYmOPMmfMDUlN3BbFiEREJBYUukXacziYSEg6TkHD4jG0eT2yHmbGTt4KCq/B6Y9seZ4yHmJhiYmMLqW7czGHnIf4UlYsz+gCX2AKu8jYz3+PhS42NfL2xkSZgvcvFhxERfOh286nTiVUIE+nTnB4P81auZObatVQmJ/OnL3+Z/BEjAhqzsnIEW7b8EzU1OeTkrGDChN/hdp95irOIiPQ/Cl0i3eR215GUdICkpI6fH7MWmpsTW8NYx0DW2PglILrtsWuoY60zj584DxEbtZcr7FoW2J1c5Svgh/X1/BA43noq4oett0ItyCHSp2Tm53PLq6+SWlbGlpkz+WDhQjwBrF7q9zs4cOBO9u27m4iIai677HEyMrYEsWIREQk1hS6RABkDkZFVREZWMWjQ7g7b1q1bj9+fhd8/Ep9vND7fSHy+UXi9Ezjhv5Fl/Dsnr8KUyX4WmFdYYFayoHkri5prANjvcLMqouV0xLVuN3WaBRMJCYfPx5xVq5j94YfUxsXx8gMPkDd2bEBj1tQMZcuWb1FZOZahQ1dzySXPd7miqoiI9D8KXSK9yBiL01mA01mA2/33DtusdeH3Z+PzjcLnG8UJ30he9l/BYt8X8DOECezhOlawwL+S+xtX89XGGppxst4xlA9cyax2Wz6NKMM6dAFmkd6WWlzMLa+9RmZhITunTGHlLbfQGB3d9RPPwu+Hjz++lA8//BdcrkYuvfRnZGWtC2LFIiLSlyh0iYSIMV6czjyczjzgvQ7brI0k3zec532j+I3/Mlzeu5jlreMa/34W+NfyaPNWaIaKumQ+YDbvOS9mlTOdfFcVTuch9u+HESMggM/ziwhg/H5mfvQRV65cSVNUFK/fey/7J04MaMyKikRee+1mDh8eRmbmBiZPfoaoqMogVSwiIn2RQpdIH2RMEy7XPlyufW33bWm9/cwfR7J3Dlc2R3CVt5qrfeu40/cW+GB/8xhWcB3/Nm4paxxXkToygbFjYcwYGDuWtu+zs0Gr1oucW3J5OTe99hrZR46wb/x43rntNurj4no8nrWwceMU/va3azDGzx13LMfjeUGX8BMRCQPdDl3GGCewCSiw1t7ceyWJyLk4HLVURexlWQQtnwezMMaXyHyPh/meAh7w/Jpv8jQ+6+TAictYteU6Xnl/Ab9quhRf6//yUVEwahRnBLL+SL1Jgs5apq5fz9Vvv43f6WTZXXexc8qUgC5wXl0dx5IlN7J//yhGjjzMnXe+RVJSNevXB7Fu6XPUn0TkpPOZ6fo2sAdI6KVaRKQnjOGAy8UBl4vno8FtoyhasgTnihVctHIlF216jK/bR/EnJFI++Wr2Zl/H2pgFrCsdxd69sHw5eDyhPoiAqDdJ0MRXVnLTkiWMOHiQvNGjeWvRImqSkrp+4llYC9u3j2fZsuvwel3ccssKZs3arJnm8KH+JCJAN0OXMWYocBPwY+Cfe7UiEQmIxxiYN6/l9uMfQ3k5fPABjhUrSFuxgrS/v8FcgJEjYcECfI9fR/6Yq9lbnMQNN4S6+vOj3iRBYy0Tt25lwfLlOHw+3vnMZ9g6a1ZAs1u1tdEsXXoDu3ZdRHZ2AXfdtZzU1IogFi19mfqTiLTX3ZmuXwLfBeLP9gBjzEPAQwDx8Wd9mIhcaCkpcNddLTdr4cABWLECVq6ExYtx/uY35Dgc5MycGepKe+K8elNCgt5sljNFVVezaPFixu3eTf6wYSy/6y5OpKQENOaePaNZsuRGGhujuP76Vcydux6HwwapYuknztmf2vcmow/2iQx4XYYuY8zNQKm1drMxZv7ZHmetfQ54DiAjI0N/WUT6ImNOfYDrm99sOa9w/fpTIawf6UlvysrKUm+SDoZt2sTs//kfXA0NfHDDDWy44gpsAOf+NTZGsnz5tWzZMonBg0v4h394icGDy4JYsfQH3elP7XuT0+lUbxIZ4Loz0zUH+Iwx5kYgCkgwxvzJWntf75YmIr3O7YYrrmi5Pf54QKdShYB6k/RYRF0dsxYvZtS6dRzPyeGN227jeEZGQGMePJjD66/fRHV1PPPnr+Xqqz/C5fIHqWLpZ9SfRKSDLkOXtfb7wPcBWt+t+Vc1DREJNfUm6amsTz9lzu9/T3RVFdtuvZXtN9/M8bKez0Y1N7t5552r+OST6aSmlvO1r/2R7OzCIFYs/Y36k4icTtfpEhGRsOBqbGTGK69w0apVVGZl8cHDD1M+YkRAYx45MoTXXruZ8vJBzJ69keuu+5CICG9wChYRkQHjvEKXtfZD4MNeqUREpIfUm6Qr6fv3c8ULLxB//Dg7r7+erYsW4YuI6PF4Xq+T996by9//PovExGoefHAxo0YdDWLFMlCoP4kIaKZLREQGMKfHw9QlS5jw7rvUpqbyzr//OyXjxgU0ZmFhOq++egslJenMmLGNG298n6io5iBVLCIiA5FCl4iIDEgphw9zxfPPk1xYyL7589n42c/ijYrq8Xg+n2H16sv54IMriI1t4AtfeIWLLjoUxIpFRGSgUugSEZEBxXi9TF6+nEnLltGQkMDKf/5nCi65JKAxS0sH8dprt5Cfn8Ull+zm1ltXEBPTEKSKRURkoFPoEhGRASOxoIC5L7xA6uHDHLrsMtbfdx/NsbE9Hs/vh3XrLuXdd+fhdnu55543mTRpTxArFhGRcKDQJSIi/Z7x+xn/7rtMW7IET1QUq77xDY7MmBHQmBUVibz++k3k5eUwbtxBbr/9byQk1AWpYhERCScKXSIi0q/Fl5ZyxQsvkHHgAEenTuXjL36RxsTEHo9nLWzaNJm33roGY2DRoreYPn1HP7t2uIiI9CUKXSIi0j9Zy7gPP2TGX/6CdTj4+5e/zKHZswkkHVVXx/HGGwvZt280I0Yc4c473yI5uSqIRYuISDhS6BIRkX4npqKCOb/7HUN27aJw/Hg++od/oD4lpcfjWQs7doznr3+9Do/Hxc03r+SyyzbhcASxaBERCVsKXSIi0n9Yy8h167jsT3/C+Hysu/9+9l11VUCzWzU1kbz00m3s3HkxQ4cWctddy0hLqwhi0SIiEu56JXRFR0dz8cUX9+i55eXlQa6me4qLi0Oy32PHjoVkv42NjSHZ7wMPPBCS/RYUFIRkv5///OdDsl/pXHx8PPPnz+/Rczdu3BjcYrrpq1/9akj2W1ERmtDx05/+9KzbEpqaeGjLFi4rLGRPSgpPz5hBcX09vPVWj/dXWDidLVu+RnNzHJmZT5Kc/CLvv+/r8XjnKz4+/oLtq71Q/a2Vs/P7/T16ngnRhw2ttSHZrwxsPf3/oD/QTJeIiPR5lxYU8LWtW4nxePjDxIksHzsWfwAvNj2eGLZvf4AjR64mMfEww4Y9RHT0/iBWLCIicopCl4iI9Fkxzc08uH07844eJTcpicfmzuVYACsTApSWTmTz5m9QXz+IceOWcPHFr5Cbq8AlIiK9R6FLRET6pEklJfzj5s0kNzbyysUXs+Sii/AGsLKF1xvBzp33cejQjcTFFTJ//n+QknIgiBWLiIh0TqFLRET6lEivl/s//ZQbcnPJj4/nkfnzOTRoUEBjlpePZdOmb1Jbm8WoUW8xceJiXK7mIFUsIiJybgpdIiLSZ4w7fpxvbtpERl0dfx0zhpcnTKDZ6ezxeD6fiz336fGRAAAekUlEQVR77mbfvluJialg7tzHSE/fGcSKRUREuqbQJSIiIWeamhjym9/wv1evpiwmhkevvJI9aWkBjVlZmcOmTQ9TVTWc4cPfZ9Kk/8Htrg9SxSIiIt2n0CUiIiEVs3cvIx59lOjcXFaMGMEfLrmERre7x+P5/Q7277+N3bvvIiKilssv/wlZWZuDWLGIiMj5UegSEZGQMF4vmb//PYN/+1u8gwax/4kneG7NmoDGrKnJYuPGhzlxYgxDh65lypTniYysDVLFIiIyELRcZs5BSxRyUV0NXm/Lzefr+LWr+7pLoUtERC64qNxcRjz2GLF79lB+ww0c/dd/xZeYCD0MXdYaDh5cyM6dn8flambmzF+Qnf1xkKsWEelfrDWAk5aX/Ce/tnxv7en3n9puraPDY9t/bXmes9PtZ4558nsn1nZ+/6kxz3Zfx/tPbe/8/o7bHWepp2MECvBKJN2i0CUiIheO30/GSy8x5Jln8MXEcOinP+XENdcENGRdXRqbN3+DsrKJZGZuZtq0Z4mOrgxSwSLS150+a3HukNDd4OHs5EX/+QaIsz2v/f2n6u74vI7Hc+p5Z4aIzo+v/fh9ibf15mv3vR9jTr/P1+5ry/cdH9OEMb4Oj+243Xfa9+23+87Y189+9mNcLnA66fC1O/dddVX3jlyhS0RELoiI/HxGPP448Vu3cmLePI58//t4U1J6PJ61cPjw1ezY8QBgmDbtWYYPfx9jglaySJ/SEi5Of2Ht5uwzE+3v7ypstA8GXc1inGsmpLNAcrZg4Txt/NPvP73ms81s9MWXs82c/qIffO2CwpkBoSUUdAwWUA94cTg6hpT2Y3QMEx3Dy6n9+c/Yb8u2M59zaswzn9P5/s42Zmfh6tz/arbll/yC++d//nGv76PL31JjTBSwBohsffxr1tpHe7swEZFzUW/qR6wl9Y03yP7lL7EOB3mPPkr5TTcRSDpqaEhiy5avU1w8nbS0nUyf/jSxsWVBLFqk5863P/n942loWE5XszItt77k9OBwrgBxthkLHy0BpeUF+5nbTn9B3/kL/q6DR3dCwuljnj1AGNNZIDn5vNAEB+nbuvPWQBNwtbW21hjjBj4yxrxtrf2kl2sTETkX9aZ+wF1ayvD//E8S162jeuZM8n7wAzyZmQGNeezYHLZu/TI+XwSTJv2O0aPf1osc6WvOsz/V4XD8nTPDSmczJacHmLMFkM5mNs41e3H6OKfPzHTch7VezSqLnIcuQ5dtmec7ufSTu/Wmv24iElLqTX2ctQx65x2G/fznGI+HI9/9LmV33AGOnn++oKkpnm3bvkx+/hySkw8wY8ZTJCQUBrFokeA43/7kcBwhMvKrPdqXUfIR6Re6dRKsMcYJbAZGA09ba9d38piHgIcABg0aFMwaRUQ6db69KT09/cIWGKZcJ04w7Kc/ZdAHH1A7aRJ5jz5K07BhAY1ZVDSdzZu/RnNzHBMm/JmxY9/E4fAHqWKR4OuqP7XvTQpOIgNft0KXtdYHTDHGJAFvGGMmWmt3nvaY54DnAIYPH653m0Wk151vbxo3bpx6Uy9LWr2anP/6L5w1NeQ//DDFn/98y/JOPeTxRLNjxwMcPnwNCQlHuOKKH5OUdDh4BYv0kq76U/ve5HQ61ZtEBrjzWu7FWltpjFkF3ADs7OrxIiIXgnpT6Dlrasj+7/8m9a23qB87lv1PP03D6NEBjVlaOpHNm79Bff0gxo1bwsUXv4LTeR5XohTpA9SfRAS6t3phGuBpbRrRwALgZ71emYjIOag39R3x69cz4vHHcZeXU/jggxQ9+CDW7e7xeF5vBDt33sehQzcSF1fI/Pk/ICVlfxArFuld6k8icrruzHQNBv6n9dxkB/CKtXZ575YlItIl9aYQczQ0MPSpp0h/9VUahg/n4P/5P9RPmBDQmOXlY9i06ZvU1g5h1Ki/MXHiYlyupiBVLHLBqD+JSAfdWb1wBzD1AtQiItJt6k2hFbt9OyN+9CMi8/MpvvdeCr7+dWxUVI/Ha242vPBCFh9++J9ER1cwd+6PSE//NIgVi1w46k8ifZC1dH4JcaCwEHw+8Hpbbu2/7+rnbuqLl/AWEZE+yjQ3k/Wb35D5pz/RnJnJvmefpXb69IDG3L8/msceG8GBAzHk5HzA5Mkv4nbXB6liEZHwZKztNGA4AWfrtvb3d7XNAbg62dZ2Oe9O9td+vDMe3/qcs9V2xmO72HZy++njtd9+VkOGnN8/bg8odImISLdE79vHiEcfJebQIcpuv51j3/42/tjYHo/n9cIf/5jJc89lkZDg4//+3wOsW/dMECsWkXBh2r3YPiMsnCV8nGtb+4BxrtByesA4PUS0jdVuvNPrdJ627YzQ0MW2zo775HmtfcXpl+Nuu8S3MaddjvvMS4N7Wx/T1Pp9Z9vOdtnvk9vbbzt9uw/45VNPgcvVcnM6T33f1c9OJ8yY0a1/A4UuERE5N6+XwS++yOAXXsCbnMz+X/6S6jlzAhry8OFIfvSjEezcGcc111Twve8dJSnJy7p1QapZZCDr5IV9VyHibDMAnc1qnDNUnD5WZzMV7badfl9nMyKdzWR0GiTOFayC9W8bBKcHi7avrS/wO4QOOr74P7nNAzSe/Nnh6DhOJ8/rbJ9dbes0pNAShDp9DuA/LSR1qOm057U/Rrp5LbqW64pfeL/8as8uTn4+FLpEROSsovLyGPHYY8Tu3k359ddz9N/+DV9iYo/H8/vhlVfS+dWvhhAZafnP/8zluusquvv3WGRAusjv5/WGhjPDUmvI6Cws9RVnm0E42yxGZyHDR8ssRlswafe800PLGeOctu1ssx09CSZnCxEnt50eSE7+rIYmnelL/9+KiEhf4feT8fLLDHnmGXxRURz66U85cc01AQ1ZVBTB448PZ9OmBGbPruI//uMwaWmeIBUs0n81ATtbZzM6vIg/LRCcvs3f2fd0DCKdPfdsMxnnPN3rtJDhsRYfYBUwRLpFoUtERDpwHTvGuO98h/itW6mcO5fDjzyCNzW1x+NZC8uWpfCLXwzDWvhf/+swt956XG8Gi7TKczj4YmRkj55rQvQ/UmhOAhPpvxS6RESkhbXE/+UvpPzXf+EH8n74Q8pvvjmgU2WOH3fz4x/n8NFHSUybVsMPf5jHkCHNwatZRESkH1DoEhERnCUlpH3/+8SsXk397Nkc/P73ac7MDGjMlSuT+dnPcmhocPCd7xzjnntKcPSlT7uLiIhcIApdIiLhzFpily0j9bHHME1NHH/0Uarvu4/mysoeD1lZ6eTnPx/GihUpjB9fx2OP5TFiRGMQixYREelfeiV0xcfHM3/+/B4998SJE8EtppumTJkSkv1u2LAhJPsdOnRoSPa7cePGkOw3VKqrq0NdgrTT0NDAnj17evTc1AA+0xSIp556qtfGjq2v585Vqxh54AB5gwfz59tu43hVFTz9NK+//nqPxmxouIqKip/j9yeQkPBzqquf4V/+xdft58fHx/dov4G6//77Q7LfNWvWhGS/H3/8cUj2K51LSUnhjjvuCHUZcg6hWso8VJ/ZC5WBfLya6RIRCUMTDh3i7vffJ6apiWVz5rBq+nRsAOf++f1xVFb+gLq6z+F27yUt7YtEROwKYsUiIiL9l0KXiEgYiWpq4rbVq5m1ezcFqan8etEiigKcxWtsvIyKiv/G58siPv4ZEhN/gTFaLENEROQkhS4RkTAx5uhRPrdyJQm1tayYOZMVs2bhczp7PJ7fH0lV1feorX0QlyuP9PQ7iYzcHMSKRUREBgaFLhGRAS7C4+Hmjz5i7vbtlCQn8+RnP8vRAFcmbGqaTEXF/8PrHU1c3IskJv4Eh6MhSBWLiIgMLApdIiID2PDCQu5dsYK0ykpWT53KW3Pm4HH1vPVb66a6+ltUV38Dp7OEtLR7iYr6KIgVi4iIDDwKXSIiA5DT62XhJ59w1ebNnIiP51d33MGh7OyAxmxuHkdFxf/D45lITMyrJCc/hsNRE6SKRUREBi6FLhGRAWZIaSn3vvsuWeXlrJs4kaVXXklTRESPx7PWQU3N16iq+mccjipSUx8kOnplECsWEREZ2BS6REQGCIffzzUbN3L9+vXURkfz3K23smfEiIDG9HiGU1HxC5qbZxAd/RbJyY/gdIbmeooiIiL9lUKXiMgAkF5Rwb3vvktOSQmbx41jyVVXUR8V1ePxrDXU1n6BqqpHgGYGDXqYmJilDODrVoqIiPQahS4RkX7MWMvcrVu5ae1amt1uXrzxRraPHRvQmNXVSZSVLaap6QqiolaRnPxdXK6SIFUsIiISfhS6RET6qUFVVXxuxQpGFxSwc+RIXrnmGmpiY3s8nrWwe/elrF59Ox6Pn+Tk7xEb+2fNbomIiASoy9BljMkG/gBkABZ4zlr7RG8XJiJyLmHdm6zlsp07uXXNGqwx/HnBAjaOH08g6aiuLo7337+b3NxLGDLkIH7/A7hcR4NYtEj4COv+JCKd6s5Mlxf4F2vtFmNMPLDZGLPSWru7l2sTETmXsOxNCbW1fPa99xh/+DD7s7N5acECKhMSAhrzwIHJvP/+nXg8kVx55ZtMnbqGJUsUuEQCEJb9SUTOrsvQZa0tAopav68xxuwBhgBqHCISMmHXm6xl6r593LFqFW6fj9fnz2ft5MnYAGa3GhtjWLVqEfv2TScj4yjXX7+YQYNKg1i0SHgKu/4kIl06r890GWOGA1OB9Z1sewh4CCArKysIpYmIdE93e1NycvIFrStYYhsauPODD5hy4ACHMzP58/XXUxbgseTlXcR7732WhoZ4Lr/8b8yY8T5Opz9IFYvISWfrT+17U1xc3AWvS0QurG6HLmNMHPA68E/W2urTt1trnwOeA7jkkkts0CoUETmH8+lNw4YN63e9aUJuLne/9x4xjY0snzOHD6ZPxzocPR6vuTmSNWs+w86ds0lJKeLWW39Lenp+ECsWkZPO1Z/a96b09PR+15tE5Px0K3QZY9y0NI3F1tolvVuSiEj3DOTe5K6vZ+of/sDI1aspSE3l17ffTlFaWkBj5uePZMWKe6muTmb69Pe5/PK3cbl8QapYRNobyP1JRM5fd1YvNMBvgT3W2l/0fkkiIl0byL0pY+dOZv7610RXVLBi5kxWzJqFz+ns8Xher5u1a29k69YrSUws5+67f0VWVl4QKxaR9gZyfxKRnunOTNcc4H7gU2PMttb7HrHW/q33yhIR6dKA603OxkYmv/QSY1esoDori/cef5y3y8sDGrO4OJsVK+6loiKTSZM+Yu7cZbjdzUGqWETOYsD1JxEJTHdWL/wI0KUxRaRPGWi9KWX/fi579lnii4vZt3AhO+65B19EBPQwdPl8TjZsWMCGDdcSG1vN7bc/S07O/iBXLSKdGWj9SUQCd16rF4qISHA5PB4mvvYaFy1bRkNKCh/84AeUjh8f0JjHj2fy7rufp6xsKBdfvJF585YQFdUYpIpFRETkfCl0iYiESNLhw1z2zDMkHTvGoauuYut99+GNienxeH6/YcuWq1i3biGRkQ3cfPNvGT16ZxArFhERkZ5Q6BIRucCMz8fFS5cycckSmuLjWf1v/0bRtGkBjVlZmcq7795LUdEIRo/eztVXv0pMTF2QKhYREZFAKHSJiFxA8QUFXPbss6QcOsSR2bPZ/MADNMfH93g8a2HHjjn8/e+34HT6uOGGPzJu3BaMPk0iIiLSZyh0iYhcCH4/Y995h0kvv4wvMpK13/42xy67LKAha2qSWLnyHo4eHUdOzh4WLPgLcXFVQSpYREREgkWhS0Skl8WWlTHr2WdJ37OHgmnT2PiVr9CYlNTj8ayFPXtm8OGHi7DWwdVXv8Ill6zT7JaIiEgfpdAlItJbrGXkqlVM/eMfwRjWf/Wr5M2bRyDpqL4+jvffv4tDhyYxZMghrrvuJRITA7uWl4iIiPQuhS4RkV4QVVHBzOefJ2vbNkrGj2f9175GfVpaQGMePHgJ779/N83Nkcydu5SpU1fjcNggVSwiIiK9RaFLRCTIhn38MdN/9zucHg+bv/hFDlx3HTgcPR6vsTGaDz9cxN69M0hPP8b11y8mJaUkiBWLiIhIb+qV0OX3+2ls7NmFON97770gV9M9Q4cODcl+TZh9CCM3Nzck+3UE8II3EEkBfG5Hgs/v91NX17Nl1J999tkuH5Pk9fIfxcXMrq5mW3Q0j2Rnc2TjRti4sUf7BJgy5d9Ztuw26upimTfvA+bMWYPT6Qd6vuJhdzz88MO9Ov7ZPPPMMyHZr8fjCcl+4wNYuTIQw4cPD8l+5ezC7fVAf6P/PhIozXSJiATB/JoaflRYSKLPx/9LT+f3KSn4Avgj7ffHUFLyr+ze/VlSU0v57GcXM3hwURArFhERkQtFoUtEJACxPh/fKylhUWUl+yIj+UpODvujogIas65uGoWF/4XHM4TLL/+I+fM/wOXyBqliERERudAUukREemhWXR3/WVhIhsfDb1JTeTYtDU9As1sRlJZ+i4qKL+J25zN8+Be59toRQaxYREREQkGhS0TkPEX5/XyntJT7KirIi4jg88OH82lMTEBjNjRMoKDgJzQ3jyI5+WUyMv4bh6MeUOgSERHp7xS6RETOw6T6en5SWMjw5mb+OGgQv0xPpzGAhVqsdVFW9lWOH38Il+s4w4Z9hbi4j4NYsYiIiISaQpeISDe4/X7+sayMB8vLKXG7+VJODhtiYwMas7FxFIWFP6GxcQKJiUvJzPwJTmdNkCoWERGRvkKhS0SkC2mFhfwlL49xTU28lpTE/8nIoM7p7PF41jooL/8iZWXfwuGoYejQb5GQ8H4QKxYREZG+RKFLROQsjM/HrDVruOK996gwhn/MzmZ1gNdVam7OpqDgxzQ0TCc+fiWDBz+Oy1URpIpFRESkL1LoEhHpxKCyMm565RWyjh1jz6RJPNjYSJWr5y3TWjhx4rOUlPwrxnjJyvp3EhOXo+ttioiIDHwKXSIi7fn9TP/4Y+a98w7eiAiWfu5z7J08mao//KHHQ3o8GRQW/m/q6uYQG7uWrKwf4HaXBLFoERER6csUukREWiWcOMGNr75KTm4uBy+6iHcWLaIuIaHH41kLVVW3UFz8CNa6yMz8EcnJr2h2S0REJMx0GbqMMb8DbgZKrbUTe78kEZHuCVp/spZJmzZx9fLlYC1v33EHO2bMIJB05PUOoqjoh9TULCA6ejNDhvwvIiKO9Xg8Eek/9NpJRE7XnZmuF4FfAT0/t0ZEpHe8SID9Kba6mhuWLGH03r0cGTmSv915J9WDBgVUVHX1NRQVPYrfH096+s9JSfkDxvgDGlNE+pUX0WsnEWmny9BlrV1jjBne+6WIiJyfQPvTRdu3c93Spbiam3nv5pvZPHs2BHChY58vnuLiR6iq+gxRUbvIyvoSUVGHejyeiPRPeu0kIqcL2me6jDEPAQ8BDB48OFjDiogEpH1vSkpKAiCqro7rli7l4h07KMzO5q2776YiLS2g/dTWzqaw8H/j9aaSmvo0aWnPYYw34PpFZGBq35vi4uJCXI2I9LaghS5r7XPAcwATJkywwRpXRCQQ7XvT0KFD7ci9e1n4+utE19ez5rrr+GTePGwAFzr2+2MoKfkXTpy4h8jIg2RnP0x09O5glS8iA1T73pSenq7XTSIDnFYvFJGwkXjiBHe9+CKlmZm8+qUvUZqVFdB49fXTKCj4MR7PUAYN+j3p6U/icDQHqVoREREZKBS6RCRsRNfXs27+fNZeey2+AC507PdHUFb2MOXlD+B2F5CT8wCxsZuDWKmIiIgMJF1+YtwY8xKwDhhnjMk3xjzY+2WJiHTtfPtTeVoaa264IaDA1dAwnry8Vykv/weSk19h1KhFClwi0oFeO4nI6bqzeuHnLkQhIiLn63z7kyciIoB9uTh+/CuUlX0Vl6uCYcMeIi5ubY/HE5GBS6+dROR0Or1QRKQLJSUp5OUtprFxIomJy8jM/C+czupQlyUiIiL9hEKXiMhZ+P2Gjz66lBUr5mJtNUOH/hMJCStDXZaIiIj0MwpdIiKdKC9P5NVXb+Lw4WzGj9+P1/tlXK7yUJclIiIi/ZBCl4hIO9bChg2TeeutqzHGctddy5k2bRd//KMCl4iIiPSMQpeISKuqqjhef30h+/ePZPTow9x5599ISqoJdVkiIiLSzyl0iUjYsxa2bRvP0qUL8Pkc3HrrCi67bCvGhLoyERERGQgUukQkrNXWRvPGG9eza9c4cnLyueuut0hNrQx1WSIiIjKAKHSJSNjatWsMS5ZcT2NjJAsXrmLu3I04HDbUZYmIiMgAo9AlImGnoSGSZcuuYcuWS8jKKuYrX3mZzMzjoS5LREREBqheCV1lZWU8++yzPXrurFmzglxN93zyySch2W9kZGRI9nvzzTeHZL+pqakh2e+bb74Zkv2G6t9ZOtfQ0MA77/jYsOF+GhqSmDBhCRMmvEFJiY+SknM/t7w8NKsXxsfHh2S/S5cuDcl+k5KSQrLfJ554IiT7TU5ODsl+T5w4EZL9ioiEK810iUjYqKtL4cMPHyEhoYAFCx4lJSU31CWJiIhIGFDoEpGw0dSUwLhxbzFp0iu4XJ5QlyMiIiJhQqFLRMJGfHwR06YtDnUZIiIiEmYcoS5ARORCcbsbQ12CiIiIhCGFLhERERERkV6k0CUiIiIiItKLFLpERERERER6kUKXiIiIiIhIL1LoEhERERER6UUKXSIiIiIiIr1IoUtERERERKQXdSt0GWNuMMbsM8YcNMZ8r7eLEhHpDvUmEemr1J9EpL0uQ5cxxgk8DSwExgOfM8aM7+3CRETORb1JRPoq9ScROV13ZrpmAgettbnW2mbgZeDW3i1LRKRL6k0i0lepP4lIB8Zae+4HGHMncIO19sutP98PzLLWfvO0xz0EPNT640RgZ/DL7bNSgeOhLuICCadjhfA73nHW2vhQF9Ed6k3dEm6/vzregW1A9Sf1prD63dXxDmzd6k2uYO3NWvsc8ByAMWaTtXZGsMbu68LpeMPpWCE8jzfUNQSbepOOd6AKx+MNdQ3BpN6k4x2owvF4u/O47pxeWABkt/t5aOt9IiKhpN4kIn2V+pOIdNCd0LURGGOMGWGMiQDuAf7au2WJiHRJvUlE+ir1JxHpoMvTC621XmPMN4F3ASfwO2vtri6e9lwwiutHwul4w+lYQcfbZ6k3dYuOd2DT8fZRPehP/ebYgkTHO7DpeDvR5UIaIiIiIiIi0nPdujiyiIiIiIiI9IxCl4iIiIiISC8KaugyxtxgjNlnjDlojPleMMfua4wx2caYVcaY3caYXcaYb4e6pgvBGOM0xmw1xiwPdS29zRiTZIx5zRiz1xizxxhzeahr6k3GmO+0/i7vNMa8ZIyJCnVNwRJOvQnCsz+pNw1cA7k3QXj1p3DsTaD+FOqaetP59KeghS5jjBN4GlgIjAc+Z4wZH6zx+yAv8C/W2vHAZcA3BvjxnvRtYE+oi7hAngDesdZeBExmAB+3MWYI8C1ghrV2Ii0f/L4ntFUFRxj2JgjP/qTeNAAN5N4EYdmfwrE3gfrTgHS+/SmYM10zgYPW2lxrbTPwMnBrEMfvU6y1RdbaLa3f19DySzUktFX1LmPMUOAm4IVQ19LbjDGJwJXAbwGstc3W2srQVtXrXEC0McYFxACFIa4nWMKqN0H49Sf1JvWmfiys+lO49SZQf1J/OiWYoWsIcKzdz/kM8P+RTjLGDAemAutDW0mv+yXwXcAf6kIugBFAGfD71lMCXjDGxIa6qN5irS0A/i9wFCgCqqy1K0JbVdCEbW+CsOlP6k0D1ADvTRDG/SlMehOoP6k/tdJCGgEyxsQBrwP/ZK2tDnU9vcUYczNQaq3dHOpaLhAXMA141lo7FagDBuy59saYZFreXR0BZAGxxpj7QluVBCoc+pN6k3qT9D/h0JtA/Qn1pw6CGboKgOx2Pw9tvW/AMsa4aWkai621S0JdTy+bA3zGGHOYltMfrjbG/Cm0JfWqfCDfWnvyHbjXaGkkA9W1QJ61tsxa6wGWALNDXFOwhF1vgrDqT+pN6k39Wdj1pzDqTaD+pP7UTjBD10ZgjDFmhDEmgpYPkv01iOP3KcYYQ8s5q3ustb8IdT29zVr7fWvtUGvtcFr+235grR2w7zZaa4uBY8aYca13XQPsDmFJve0ocJkxJqb1d/saBs6HX8OqN0F49Sf1JvWmfi6s+lM49SZQf0L9qQNXsPZqrfUaY74JvEvL6h2/s9buCtb4fdAc4H7gU2PMttb7HrHW/i2ENUlwPQwsbv1DmAt8KcT19Bpr7XpjzGvAFlpWl9oKPBfaqoIjDHsTqD8NdOpNA0QY9if1poFP/eksjLX2QtUmIiIiIiISdrSQhoiIiIiISC9S6BIREREREelFCl0iIiIiIiK9SKFLRERERESkFyl0iYiIiIiI9CKFLhERERERkV6k0CUiIiIiItKL/j8OEXA57vLXYgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 1080x1080 with 9 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the Results\n",
    "\n",
    "plt.figure()\n",
    "plt.semilogy(np.arange(epoch),train_loss_over_time[:])\n",
    "plt.semilogy(np.arange(epoch),test_loss_over_time[:])\n",
    "plt.legend(['Training loss', 'Testing loss'])\n",
    "\n",
    "model.eval();\n",
    "\n",
    "ang_loss_all = []\n",
    "\n",
    "for batch_i, data in enumerate(test_loader):\n",
    "    # get the input images and their corresponding labels\n",
    "    inputs, output_gt, _, _ = data\n",
    "    inputs, output_gt = inputs.to(dev), output_gt.to(dev)\n",
    "    \n",
    "\n",
    "    # forward pass to get outputs\n",
    "    outputs = model(inputs).squeeze().detach().cpu()\n",
    "    \n",
    "    gt = output_gt.cpu().squeeze()\n",
    "    \n",
    "    c = -output_gt[:,2]*torch.cos(output_gt[:,0]) + output_gt[:,1]*torch.sin(output_gt[:,0])\n",
    "    angle_params = torch.stack((-torch.sin(output_gt[:,0]),torch.cos(output_gt[:,0]),c),axis=1).detach().cpu()\n",
    "  \n",
    "    # Calculate angular loss\n",
    "    ang_loss = torch.mean(torch.abs(torch.rad2deg(torch.atan2(-angle_params[:,0]*outputs[:,1] + angle_params[:,1]*outputs[:,0]\n",
    "                                         ,angle_params[:,1]*outputs[:,1]+angle_params[:,0]*outputs[:,0]).cpu())))\n",
    "\n",
    "    ang_loss_all.append(ang_loss)\n",
    "\n",
    "    \n",
    "print(ang_loss_all)\n",
    "\n",
    "plt.figure(figsize=[15, 15])\n",
    "\n",
    "for ii in range(9):\n",
    "    \n",
    "    plt.subplot(3,3,ii+1)\n",
    "    plt.imshow(inputs[ii].cpu().squeeze(),cmap='gray', vmin=0, vmax=1)\n",
    "    \n",
    "    # Plot the ground truth lines\n",
    "    x_sample = torch.linspace(-1,1,inputs.shape[-1])\n",
    "    y_sample = -angle_params[ii,0]/angle_params[ii,1]*x_sample - angle_params[ii,2]/angle_params[ii,1]\n",
    "    \n",
    "    plt.plot(x_sample*W/2+W/2,y_sample*W/2+W/2,'b')\n",
    "    plt.xlim([0,W])\n",
    "    plt.ylim(([0,W]))\n",
    "    \n",
    "    # Plot the estimated lines\n",
    "    y_est = -outputs[ii,0]/outputs[ii,1]*x_sample - outputs[ii,2]/outputs[ii,1]\n",
    "    plt.plot(x_sample*W/2+W/2,y_est*W/2+W/2,'r')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "b398c59d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1            [-1, 128, 6, 6]           1,280\n",
      "              ReLU-2            [-1, 128, 6, 6]               0\n",
      "            Conv2d-3              [-1, 8, 4, 4]           9,224\n",
      "         MaxPool2d-4              [-1, 8, 2, 2]               0\n",
      "         AvgPool2d-5              [-1, 8, 1, 1]               0\n",
      "            Linear-6                    [-1, 3]              27\n",
      "================================================================\n",
      "Total params: 10,531\n",
      "Trainable params: 10,531\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.07\n",
      "Params size (MB): 0.04\n",
      "Estimated Total Size (MB): 0.11\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "class offCenterLineNet(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "                \n",
    "        self.conv1 = nn.Conv2d(1, 128, kernel_size=3) #64 is good\n",
    "#         self.conv2 = nn.Conv2d(32, 32, kernel_size=3)\n",
    "        self.conv3 = nn.Conv2d(128, 8, kernel_size=3)\n",
    "        self.fc = nn.LazyLinear(3)\n",
    "        self.maxpool = nn.MaxPool2d(2)\n",
    "        self.avgpool = nn.AvgPool2d(2)\n",
    "        self.activate = nn.ReLU()\n",
    "#         self.batchnorm = nn.BatchNorm2d(128)\n",
    "    \n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.conv1(x)\n",
    "#         x = F.relu(x)\n",
    "        x = self.activate(x)\n",
    "#         x = self.maxpool(x)\n",
    "#         x = self.batchnorm(x)\n",
    "#         x = self.conv2(x)\n",
    "#         x = self.activate(x)\n",
    "#         x = F.relu(x)\n",
    "#         x = self.batchnorm(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.shape[0],-1)\n",
    "        \n",
    "        x = self.fc(x)\n",
    "         \n",
    "        # We're defining\n",
    "        # a = - sin(theta)\n",
    "        # b = cos(theta)\n",
    "        # c = -cy*cos(theta)+cx*sin(theta)\n",
    "        # Hence, we want to normalize the vector by 1/sqrt(a^2 + b^2)\n",
    "        norm_factor = (torch.norm(x[:,:2],p=2,dim=1)).unsqueeze(1)       \n",
    "        out = x/(norm_factor)#+eps)\n",
    "#         print('Output shape=',x.shape)\n",
    "\n",
    "#         out = x\n",
    "        \n",
    "        return out\n",
    "    \n",
    "model = offCenterLineNet()\n",
    "model = model.to(dev)\n",
    "summary(model, input_size=(1, H, W))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "0cdff0c4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Avg. Train Loss: 0.5021512931169465, Avg. Test Loss: 0.6537421941757202\n",
      "Epoch: 2, Avg. Train Loss: 0.6153085107027099, Avg. Test Loss: 0.5366257429122925\n",
      "Epoch: 3, Avg. Train Loss: 0.467539788678635, Avg. Test Loss: 0.5068877935409546\n",
      "Epoch: 4, Avg. Train Loss: 0.4471310533063356, Avg. Test Loss: 0.6434330940246582\n",
      "Epoch: 5, Avg. Train Loss: 0.528181602788526, Avg. Test Loss: 0.28025883436203003\n",
      "Epoch: 6, Avg. Train Loss: 0.5823874944864318, Avg. Test Loss: 0.6178687810897827\n",
      "Epoch: 7, Avg. Train Loss: 0.523882563030997, Avg. Test Loss: 0.6897341012954712\n",
      "Epoch: 8, Avg. Train Loss: 0.6969623690427735, Avg. Test Loss: 0.6849868297576904\n",
      "Epoch: 9, Avg. Train Loss: 0.6918647109076034, Avg. Test Loss: 0.6804423332214355\n",
      "Epoch: 10, Avg. Train Loss: 0.6879779128141181, Avg. Test Loss: 0.6772291660308838\n",
      "Epoch: 11, Avg. Train Loss: 0.6263589055039162, Avg. Test Loss: 0.3596056401729584\n",
      "Epoch: 12, Avg. Train Loss: 0.10660029310992984, Avg. Test Loss: 0.03681341931223869\n",
      "Epoch: 13, Avg. Train Loss: 0.02537359942703746, Avg. Test Loss: 0.021706871688365936\n",
      "Epoch: 14, Avg. Train Loss: 0.020157628584393236, Avg. Test Loss: 0.019071901217103004\n",
      "Epoch: 15, Avg. Train Loss: 0.017748671302268672, Avg. Test Loss: 0.016806311905384064\n",
      "Epoch: 16, Avg. Train Loss: 0.01575546178880126, Avg. Test Loss: 0.015337607823312283\n",
      "Epoch: 17, Avg. Train Loss: 0.014635594366768073, Avg. Test Loss: 0.014554097317159176\n",
      "Epoch: 18, Avg. Train Loss: 0.013834493061484293, Avg. Test Loss: 0.01375229749828577\n",
      "Epoch: 19, Avg. Train Loss: 0.01292030132094095, Avg. Test Loss: 0.012766372412443161\n",
      "Epoch: 20, Avg. Train Loss: 0.011909786525160768, Avg. Test Loss: 0.01177047286182642\n",
      "Epoch: 21, Avg. Train Loss: 0.01090217154299797, Avg. Test Loss: 0.010771517641842365\n",
      "Epoch: 22, Avg. Train Loss: 0.010019404900281928, Avg. Test Loss: 0.010053486563265324\n",
      "Epoch: 23, Avg. Train Loss: 0.009328465172371198, Avg. Test Loss: 0.009377960115671158\n",
      "Epoch: 24, Avg. Train Loss: 0.008855002585711867, Avg. Test Loss: 0.008991382084786892\n",
      "Epoch: 25, Avg. Train Loss: 0.008514048455846171, Avg. Test Loss: 0.008793016895651817\n",
      "Epoch: 26, Avg. Train Loss: 0.008292809193737285, Avg. Test Loss: 0.008593399077653885\n",
      "Epoch: 27, Avg. Train Loss: 0.008112585551083781, Avg. Test Loss: 0.008360352367162704\n",
      "Epoch: 28, Avg. Train Loss: 0.0079158881116052, Avg. Test Loss: 0.008149094879627228\n",
      "Epoch: 29, Avg. Train Loss: 0.007787604426401992, Avg. Test Loss: 0.008036518469452858\n",
      "Epoch: 30, Avg. Train Loss: 0.007679706764255845, Avg. Test Loss: 0.007907071150839329\n",
      "Epoch: 31, Avg. Train Loss: 0.007541221880548915, Avg. Test Loss: 0.007809324190020561\n",
      "Epoch: 32, Avg. Train Loss: 0.007439399657900943, Avg. Test Loss: 0.0077280448749661446\n",
      "Epoch: 33, Avg. Train Loss: 0.0073141446878570455, Avg. Test Loss: 0.007563959341496229\n",
      "Epoch: 34, Avg. Train Loss: 0.007251974563439225, Avg. Test Loss: 0.007463053334504366\n",
      "Epoch: 35, Avg. Train Loss: 0.007149405474233073, Avg. Test Loss: 0.007467020768672228\n",
      "Epoch: 36, Avg. Train Loss: 0.007055150951410449, Avg. Test Loss: 0.00733276829123497\n",
      "Epoch: 37, Avg. Train Loss: 0.006953929518457762, Avg. Test Loss: 0.007248758338391781\n",
      "Epoch: 38, Avg. Train Loss: 0.006904499085490094, Avg. Test Loss: 0.007127378601580858\n",
      "Epoch: 39, Avg. Train Loss: 0.006810565110902453, Avg. Test Loss: 0.007258865982294083\n",
      "Epoch: 40, Avg. Train Loss: 0.006719916333379441, Avg. Test Loss: 0.007028713822364807\n",
      "Epoch: 41, Avg. Train Loss: 0.006665510049652915, Avg. Test Loss: 0.006929814349859953\n",
      "Epoch: 42, Avg. Train Loss: 0.006577374922588121, Avg. Test Loss: 0.006826993077993393\n",
      "Epoch: 43, Avg. Train Loss: 0.006524638164528581, Avg. Test Loss: 0.0068130469880998135\n",
      "Epoch: 44, Avg. Train Loss: 0.006488878496511038, Avg. Test Loss: 0.006693584378808737\n",
      "Epoch: 45, Avg. Train Loss: 0.006402412342817285, Avg. Test Loss: 0.006746682804077864\n",
      "Epoch: 46, Avg. Train Loss: 0.0063742845059307504, Avg. Test Loss: 0.006576631683856249\n",
      "Epoch: 47, Avg. Train Loss: 0.006272556790865438, Avg. Test Loss: 0.006496976129710674\n",
      "Epoch: 48, Avg. Train Loss: 0.006224310220500758, Avg. Test Loss: 0.006479269824922085\n",
      "Epoch: 49, Avg. Train Loss: 0.006165564525872469, Avg. Test Loss: 0.0063900998793542385\n",
      "Epoch: 50, Avg. Train Loss: 0.006112339917223814, Avg. Test Loss: 0.0064388057217001915\n",
      "Epoch: 51, Avg. Train Loss: 0.006045855755029723, Avg. Test Loss: 0.006395118311047554\n",
      "Epoch: 52, Avg. Train Loss: 0.005976252041237299, Avg. Test Loss: 0.006205563433468342\n",
      "Epoch: 53, Avg. Train Loss: 0.005962673791272696, Avg. Test Loss: 0.0061758593656122684\n",
      "Epoch: 54, Avg. Train Loss: 0.0059030310380770714, Avg. Test Loss: 0.006097312550991774\n",
      "Epoch: 55, Avg. Train Loss: 0.0058257580669813375, Avg. Test Loss: 0.006051565520465374\n",
      "Epoch: 56, Avg. Train Loss: 0.00579185551032424, Avg. Test Loss: 0.006031000521034002\n",
      "Epoch: 57, Avg. Train Loss: 0.005715390656489966, Avg. Test Loss: 0.005930554121732712\n",
      "Epoch: 58, Avg. Train Loss: 0.005692519518265197, Avg. Test Loss: 0.0058943224139511585\n",
      "Epoch: 59, Avg. Train Loss: 0.005592713847236578, Avg. Test Loss: 0.00596247473731637\n",
      "Epoch: 60, Avg. Train Loss: 0.005627874999718611, Avg. Test Loss: 0.005838919896632433\n",
      "Epoch: 61, Avg. Train Loss: 0.005553516299398833, Avg. Test Loss: 0.005750242155045271\n",
      "Epoch: 62, Avg. Train Loss: 0.005511473788511615, Avg. Test Loss: 0.00570202199742198\n",
      "Epoch: 63, Avg. Train Loss: 0.005468507925438327, Avg. Test Loss: 0.006135155446827412\n",
      "Epoch: 64, Avg. Train Loss: 0.005427349445431731, Avg. Test Loss: 0.0055983709171414375\n",
      "Epoch: 65, Avg. Train Loss: 0.0053711530622528045, Avg. Test Loss: 0.0057464526034891605\n",
      "Epoch: 66, Avg. Train Loss: 0.00529488364537788, Avg. Test Loss: 0.005560158286243677\n",
      "Epoch: 67, Avg. Train Loss: 0.005242831322776024, Avg. Test Loss: 0.005467473529279232\n",
      "Epoch: 68, Avg. Train Loss: 0.005245379648756149, Avg. Test Loss: 0.005395588930696249\n",
      "Epoch: 69, Avg. Train Loss: 0.005143238448126372, Avg. Test Loss: 0.005366297904402018\n",
      "Epoch: 70, Avg. Train Loss: 0.005138273849043735, Avg. Test Loss: 0.005315509624779224\n",
      "Epoch: 71, Avg. Train Loss: 0.005080893278381852, Avg. Test Loss: 0.005419366993010044\n",
      "Epoch: 72, Avg. Train Loss: 0.00512858553854532, Avg. Test Loss: 0.005225356202572584\n",
      "Epoch: 73, Avg. Train Loss: 0.004998062910555407, Avg. Test Loss: 0.005303903482854366\n",
      "Epoch: 74, Avg. Train Loss: 0.004963311128491579, Avg. Test Loss: 0.005236257333308458\n",
      "Epoch: 75, Avg. Train Loss: 0.004967028849086789, Avg. Test Loss: 0.0052827708423137665\n",
      "Epoch: 76, Avg. Train Loss: 0.004926560154228017, Avg. Test Loss: 0.005094245076179504\n",
      "Epoch: 77, Avg. Train Loss: 0.004939851719279622, Avg. Test Loss: 0.005066853016614914\n",
      "Epoch: 78, Avg. Train Loss: 0.004840070176003284, Avg. Test Loss: 0.005104999057948589\n",
      "Epoch: 79, Avg. Train Loss: 0.004806739581358987, Avg. Test Loss: 0.005030200816690922\n",
      "Epoch: 80, Avg. Train Loss: 0.004760138603836991, Avg. Test Loss: 0.0049569373950362206\n",
      "Epoch: 81, Avg. Train Loss: 0.0047732935568620995, Avg. Test Loss: 0.005071079824119806\n",
      "Epoch: 82, Avg. Train Loss: 0.004750239738631387, Avg. Test Loss: 0.004981034900993109\n",
      "Epoch: 83, Avg. Train Loss: 0.004751639992951653, Avg. Test Loss: 0.004949037916958332\n",
      "Epoch: 84, Avg. Train Loss: 0.0046622350292150365, Avg. Test Loss: 0.004827807657420635\n",
      "Epoch: 85, Avg. Train Loss: 0.004620241867594941, Avg. Test Loss: 0.004818357992917299\n",
      "Epoch: 86, Avg. Train Loss: 0.004583920482112918, Avg. Test Loss: 0.0048379129730165005\n",
      "Epoch: 87, Avg. Train Loss: 0.00460083672213693, Avg. Test Loss: 0.004742600955069065\n",
      "Epoch: 88, Avg. Train Loss: 0.004582321357934974, Avg. Test Loss: 0.004810829646885395\n",
      "Epoch: 89, Avg. Train Loss: 0.004529675966951736, Avg. Test Loss: 0.004715690389275551\n",
      "Epoch: 90, Avg. Train Loss: 0.004520060050539499, Avg. Test Loss: 0.004764895420521498\n",
      "Epoch: 91, Avg. Train Loss: 0.004456778999071482, Avg. Test Loss: 0.004735713824629784\n",
      "Epoch: 92, Avg. Train Loss: 0.004471043687920237, Avg. Test Loss: 0.004640659317374229\n",
      "Epoch: 93, Avg. Train Loss: 0.004445865279236852, Avg. Test Loss: 0.004628686234354973\n",
      "Epoch: 94, Avg. Train Loss: 0.004379482993986024, Avg. Test Loss: 0.0045903464779257774\n",
      "Epoch: 95, Avg. Train Loss: 0.004355371442385191, Avg. Test Loss: 0.004524128045886755\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 96, Avg. Train Loss: 0.004473570755921131, Avg. Test Loss: 0.004658543039113283\n",
      "Epoch: 97, Avg. Train Loss: 0.004385993323223882, Avg. Test Loss: 0.004578117746859789\n",
      "Epoch: 98, Avg. Train Loss: 0.004313974153943533, Avg. Test Loss: 0.004637339152395725\n",
      "Epoch: 99, Avg. Train Loss: 0.0043017661285608315, Avg. Test Loss: 0.004488243721425533\n",
      "Epoch: 100, Avg. Train Loss: 0.004279314881450561, Avg. Test Loss: 0.004413763526827097\n",
      "Epoch: 101, Avg. Train Loss: 0.004291390144634385, Avg. Test Loss: 0.0043818773701786995\n",
      "Epoch: 102, Avg. Train Loss: 0.004170580837485748, Avg. Test Loss: 0.004385515581816435\n",
      "Epoch: 103, Avg. Train Loss: 0.004169528356341775, Avg. Test Loss: 0.0044441865757107735\n",
      "Epoch: 104, Avg. Train Loss: 0.004169502647506983, Avg. Test Loss: 0.004395027179270983\n",
      "Epoch: 105, Avg. Train Loss: 0.004123431852433917, Avg. Test Loss: 0.0043186466209590435\n",
      "Epoch: 106, Avg. Train Loss: 0.0041048831880352524, Avg. Test Loss: 0.00431891530752182\n",
      "Epoch: 107, Avg. Train Loss: 0.0041013623176272525, Avg. Test Loss: 0.004295253194868565\n",
      "Epoch: 108, Avg. Train Loss: 0.0040735304409768, Avg. Test Loss: 0.004219029098749161\n",
      "Epoch: 109, Avg. Train Loss: 0.004051195939482991, Avg. Test Loss: 0.004188114777207375\n",
      "Epoch: 110, Avg. Train Loss: 0.00402872099779373, Avg. Test Loss: 0.0042027998715639114\n",
      "Epoch: 111, Avg. Train Loss: 0.004043381639518017, Avg. Test Loss: 0.0041409931145608425\n",
      "Epoch: 112, Avg. Train Loss: 0.003987808700997469, Avg. Test Loss: 0.0042035579681396484\n",
      "Epoch: 113, Avg. Train Loss: 0.0040205584156738465, Avg. Test Loss: 0.004144545178860426\n",
      "Epoch: 114, Avg. Train Loss: 0.00395296347804021, Avg. Test Loss: 0.00409771827980876\n",
      "Epoch: 115, Avg. Train Loss: 0.003980143688792406, Avg. Test Loss: 0.004350522067397833\n",
      "Epoch: 116, Avg. Train Loss: 0.003916915847248462, Avg. Test Loss: 0.004077029414474964\n",
      "Epoch: 117, Avg. Train Loss: 0.0039807457130315695, Avg. Test Loss: 0.0041419221088290215\n",
      "Epoch: 118, Avg. Train Loss: 0.003900907002389431, Avg. Test Loss: 0.004193409811705351\n",
      "Epoch: 119, Avg. Train Loss: 0.0038400125895561867, Avg. Test Loss: 0.004079972393810749\n",
      "Epoch: 120, Avg. Train Loss: 0.0038279494877124943, Avg. Test Loss: 0.003996336832642555\n",
      "Epoch: 121, Avg. Train Loss: 0.0038441277791334445, Avg. Test Loss: 0.0039512766525149345\n",
      "Epoch: 122, Avg. Train Loss: 0.0038407529639296755, Avg. Test Loss: 0.00405732961371541\n",
      "Epoch: 123, Avg. Train Loss: 0.003801102890784657, Avg. Test Loss: 0.0039868438616395\n",
      "Epoch: 124, Avg. Train Loss: 0.0037972082351442685, Avg. Test Loss: 0.004174430854618549\n",
      "Epoch: 125, Avg. Train Loss: 0.003792881267145276, Avg. Test Loss: 0.0039818198420107365\n",
      "Epoch: 126, Avg. Train Loss: 0.0037894509028816637, Avg. Test Loss: 0.00395963666960597\n",
      "Epoch: 127, Avg. Train Loss: 0.003755826605917063, Avg. Test Loss: 0.003944754134863615\n",
      "Epoch: 128, Avg. Train Loss: 0.0037449185606525386, Avg. Test Loss: 0.004078402183949947\n",
      "Epoch: 129, Avg. Train Loss: 0.0037456862845046575, Avg. Test Loss: 0.0038787866942584515\n",
      "Epoch: 130, Avg. Train Loss: 0.0036759316747964816, Avg. Test Loss: 0.003954348154366016\n",
      "Epoch: 131, Avg. Train Loss: 0.0036822743226535793, Avg. Test Loss: 0.0038140881806612015\n",
      "Epoch: 132, Avg. Train Loss: 0.0036843342511633107, Avg. Test Loss: 0.003942346200346947\n",
      "Epoch: 133, Avg. Train Loss: 0.003643190412413935, Avg. Test Loss: 0.0038441745564341545\n",
      "Epoch: 134, Avg. Train Loss: 0.003625044008976845, Avg. Test Loss: 0.003893658285960555\n",
      "Epoch: 135, Avg. Train Loss: 0.003590436603570747, Avg. Test Loss: 0.0037726471200585365\n",
      "Epoch: 136, Avg. Train Loss: 0.0036399823905856805, Avg. Test Loss: 0.0038322501350194216\n",
      "Epoch: 137, Avg. Train Loss: 0.0036422220968403097, Avg. Test Loss: 0.0038919930811971426\n",
      "Epoch: 138, Avg. Train Loss: 0.0036276371521485407, Avg. Test Loss: 0.0037130911368876696\n",
      "Epoch: 139, Avg. Train Loss: 0.0035491197662384706, Avg. Test Loss: 0.0037193417083472013\n",
      "Epoch: 140, Avg. Train Loss: 0.0036348040313135053, Avg. Test Loss: 0.0037227217108011246\n",
      "Epoch: 141, Avg. Train Loss: 0.003514714750223035, Avg. Test Loss: 0.00374235981144011\n",
      "Epoch: 142, Avg. Train Loss: 0.0036352049656818773, Avg. Test Loss: 0.0037067951634526253\n",
      "Epoch: 143, Avg. Train Loss: 0.003551934288034952, Avg. Test Loss: 0.003664688440039754\n",
      "Epoch: 144, Avg. Train Loss: 0.0035306173322592364, Avg. Test Loss: 0.003703321097418666\n",
      "Epoch: 145, Avg. Train Loss: 0.0035754011640715044, Avg. Test Loss: 0.003703733906149864\n",
      "Epoch: 146, Avg. Train Loss: 0.003462513437667905, Avg. Test Loss: 0.0036227675154805183\n",
      "Epoch: 147, Avg. Train Loss: 0.003474916807960632, Avg. Test Loss: 0.003675438230857253\n",
      "Epoch: 148, Avg. Train Loss: 0.0034544832657936006, Avg. Test Loss: 0.003750612260773778\n",
      "Epoch: 149, Avg. Train Loss: 0.003435133176660815, Avg. Test Loss: 0.003639769507572055\n",
      "Epoch: 150, Avg. Train Loss: 0.0034935234905068956, Avg. Test Loss: 0.003708449425175786\n",
      "Epoch: 151, Avg. Train Loss: 0.0034627047540663285, Avg. Test Loss: 0.0036802717950195074\n",
      "Epoch: 152, Avg. Train Loss: 0.003400959004106563, Avg. Test Loss: 0.003620307194069028\n",
      "Epoch: 153, Avg. Train Loss: 0.003411936210901585, Avg. Test Loss: 0.003586070379242301\n",
      "Epoch: 154, Avg. Train Loss: 0.0033797247573560062, Avg. Test Loss: 0.0036139413714408875\n",
      "Epoch: 155, Avg. Train Loss: 0.0034041417665173147, Avg. Test Loss: 0.003604117315262556\n",
      "Epoch: 156, Avg. Train Loss: 0.0033737379234544066, Avg. Test Loss: 0.0035367123782634735\n",
      "Epoch: 157, Avg. Train Loss: 0.003366332030097066, Avg. Test Loss: 0.0036000225227326155\n",
      "Epoch: 158, Avg. Train Loss: 0.003430364891713442, Avg. Test Loss: 0.0036390875466167927\n",
      "Epoch: 159, Avg. Train Loss: 0.0033662643467704226, Avg. Test Loss: 0.003563572419807315\n",
      "Epoch: 160, Avg. Train Loss: 0.0033845582836155973, Avg. Test Loss: 0.0037820732686668634\n",
      "Epoch: 161, Avg. Train Loss: 0.003409515286600867, Avg. Test Loss: 0.0035376485902816057\n",
      "Epoch: 162, Avg. Train Loss: 0.0033493891336716887, Avg. Test Loss: 0.0034881022293120623\n",
      "Epoch: 163, Avg. Train Loss: 0.0033220037179024415, Avg. Test Loss: 0.0037013127002865076\n",
      "Epoch: 164, Avg. Train Loss: 0.0033147663289551125, Avg. Test Loss: 0.0036482366267591715\n",
      "Epoch: 165, Avg. Train Loss: 0.003350693597133423, Avg. Test Loss: 0.003502767765894532\n",
      "Epoch: 166, Avg. Train Loss: 0.0033298945325145194, Avg. Test Loss: 0.003502109320834279\n",
      "Epoch: 167, Avg. Train Loss: 0.0032566746556048475, Avg. Test Loss: 0.0034273089841008186\n",
      "Epoch: 168, Avg. Train Loss: 0.003282559699877057, Avg. Test Loss: 0.0035308527294546366\n",
      "Epoch: 169, Avg. Train Loss: 0.0033034387337000566, Avg. Test Loss: 0.003432219848036766\n",
      "Epoch: 170, Avg. Train Loss: 0.003248093043302381, Avg. Test Loss: 0.0034607476554811\n",
      "Epoch: 171, Avg. Train Loss: 0.0032257664039037947, Avg. Test Loss: 0.0034694697242230177\n",
      "Epoch: 172, Avg. Train Loss: 0.0032354135521102784, Avg. Test Loss: 0.003376048058271408\n",
      "Epoch: 173, Avg. Train Loss: 0.003236684298446012, Avg. Test Loss: 0.003510404611006379\n",
      "Epoch: 174, Avg. Train Loss: 0.003281689638835053, Avg. Test Loss: 0.0034331853967159986\n",
      "Epoch: 175, Avg. Train Loss: 0.0032153977730939557, Avg. Test Loss: 0.003527822205796838\n",
      "Epoch: 176, Avg. Train Loss: 0.0032667227111063723, Avg. Test Loss: 0.0034588726703077555\n",
      "Epoch: 177, Avg. Train Loss: 0.0032257642542813407, Avg. Test Loss: 0.003504728199914098\n",
      "Epoch: 178, Avg. Train Loss: 0.003237244559365303, Avg. Test Loss: 0.003391222795471549\n",
      "Epoch: 179, Avg. Train Loss: 0.0031852122818574655, Avg. Test Loss: 0.003382130293175578\n",
      "Epoch: 180, Avg. Train Loss: 0.0032331868193957, Avg. Test Loss: 0.0035382783971726894\n",
      "Epoch: 181, Avg. Train Loss: 0.0032222446833932122, Avg. Test Loss: 0.0033600367605686188\n",
      "Epoch: 182, Avg. Train Loss: 0.003200115944627066, Avg. Test Loss: 0.003403645707294345\n",
      "Epoch: 183, Avg. Train Loss: 0.003130398766505857, Avg. Test Loss: 0.0033048735931515694\n",
      "Epoch: 184, Avg. Train Loss: 0.0031712759654362534, Avg. Test Loss: 0.00346943736076355\n",
      "Epoch: 185, Avg. Train Loss: 0.0031851707405389047, Avg. Test Loss: 0.00345790502615273\n",
      "Epoch: 186, Avg. Train Loss: 0.003148720328977635, Avg. Test Loss: 0.0033489568158984184\n",
      "Epoch: 187, Avg. Train Loss: 0.0031132344914556937, Avg. Test Loss: 0.0034853550605475903\n",
      "Epoch: 188, Avg. Train Loss: 0.003138191911370255, Avg. Test Loss: 0.003303350182250142\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 189, Avg. Train Loss: 0.003120245904726691, Avg. Test Loss: 0.0033577277790755033\n",
      "Epoch: 190, Avg. Train Loss: 0.003124436710116475, Avg. Test Loss: 0.0033319403883069754\n",
      "Epoch: 191, Avg. Train Loss: 0.003106261446508904, Avg. Test Loss: 0.0032991061452776194\n",
      "Epoch: 192, Avg. Train Loss: 0.003092867035288797, Avg. Test Loss: 0.00325771258212626\n",
      "Epoch: 193, Avg. Train Loss: 0.0031437161649295756, Avg. Test Loss: 0.0033496315591037273\n",
      "Epoch: 194, Avg. Train Loss: 0.0031083595105121996, Avg. Test Loss: 0.003392541781067848\n",
      "Epoch: 195, Avg. Train Loss: 0.0031380081376017528, Avg. Test Loss: 0.003246001899242401\n",
      "Epoch: 196, Avg. Train Loss: 0.0030863669668432583, Avg. Test Loss: 0.0032838331535458565\n",
      "Epoch: 197, Avg. Train Loss: 0.003072610715144249, Avg. Test Loss: 0.00330486916936934\n",
      "Epoch: 198, Avg. Train Loss: 0.003062153771129805, Avg. Test Loss: 0.003308178624138236\n",
      "Epoch: 199, Avg. Train Loss: 0.0030568402942789848, Avg. Test Loss: 0.0033343657851219177\n",
      "Epoch: 200, Avg. Train Loss: 0.0030720225416210503, Avg. Test Loss: 0.0032938832882791758\n",
      "Epoch: 201, Avg. Train Loss: 0.003108859549514776, Avg. Test Loss: 0.0032414807938039303\n",
      "Epoch: 202, Avg. Train Loss: 0.0030998757249827303, Avg. Test Loss: 0.003249002853408456\n",
      "Epoch: 203, Avg. Train Loss: 0.0030863899954183156, Avg. Test Loss: 0.0033449556212872267\n",
      "Epoch: 204, Avg. Train Loss: 0.003090868205871693, Avg. Test Loss: 0.003413519589230418\n",
      "Epoch: 205, Avg. Train Loss: 0.003049547118026503, Avg. Test Loss: 0.003199722385033965\n",
      "Epoch: 206, Avg. Train Loss: 0.003017903273102156, Avg. Test Loss: 0.003396430751308799\n",
      "Epoch: 207, Avg. Train Loss: 0.003068218917347664, Avg. Test Loss: 0.003408921416848898\n",
      "Epoch: 208, Avg. Train Loss: 0.003088955410084752, Avg. Test Loss: 0.0033546078484505415\n",
      "Epoch: 209, Avg. Train Loss: 0.0031291016074287336, Avg. Test Loss: 0.0032125168945640326\n",
      "Epoch: 210, Avg. Train Loss: 0.0030365360326805087, Avg. Test Loss: 0.003197639249265194\n",
      "Epoch: 211, Avg. Train Loss: 0.00298505864474316, Avg. Test Loss: 0.0032555479556322098\n",
      "Epoch: 212, Avg. Train Loss: 0.0030246391502577203, Avg. Test Loss: 0.003267585765570402\n",
      "Epoch: 213, Avg. Train Loss: 0.003005562155225942, Avg. Test Loss: 0.003216732060536742\n",
      "Epoch: 214, Avg. Train Loss: 0.0030184171465766985, Avg. Test Loss: 0.0032064032275229692\n",
      "Epoch: 215, Avg. Train Loss: 0.002982265191412596, Avg. Test Loss: 0.0031588426791131496\n",
      "Epoch: 216, Avg. Train Loss: 0.00296645910955619, Avg. Test Loss: 0.003181397682055831\n",
      "Epoch: 217, Avg. Train Loss: 0.002969396219393888, Avg. Test Loss: 0.0032151471823453903\n",
      "Epoch: 218, Avg. Train Loss: 0.0030350967223734355, Avg. Test Loss: 0.0032645086757838726\n",
      "Epoch: 219, Avg. Train Loss: 0.0030262293077485507, Avg. Test Loss: 0.0032316078431904316\n",
      "Epoch: 220, Avg. Train Loss: 0.002989655707118123, Avg. Test Loss: 0.003312827320769429\n",
      "Epoch: 221, Avg. Train Loss: 0.0030092219767962084, Avg. Test Loss: 0.003207775065675378\n",
      "Epoch: 222, Avg. Train Loss: 0.0029907594976383584, Avg. Test Loss: 0.003198094666004181\n",
      "Epoch: 223, Avg. Train Loss: 0.0029558357674368593, Avg. Test Loss: 0.003175256308168173\n",
      "Epoch: 224, Avg. Train Loss: 0.002929258468929072, Avg. Test Loss: 0.0032315689604729414\n",
      "Epoch: 225, Avg. Train Loss: 0.0030014241482456063, Avg. Test Loss: 0.00320724886842072\n",
      "Epoch: 226, Avg. Train Loss: 0.002975870530272639, Avg. Test Loss: 0.003217151155695319\n",
      "Epoch: 227, Avg. Train Loss: 0.0030131582549751497, Avg. Test Loss: 0.003306993516162038\n",
      "Epoch: 228, Avg. Train Loss: 0.0029851400434191145, Avg. Test Loss: 0.0031205392442643642\n",
      "Epoch: 229, Avg. Train Loss: 0.0029218790208011174, Avg. Test Loss: 0.003217455931007862\n",
      "Epoch: 230, Avg. Train Loss: 0.0029755294875263476, Avg. Test Loss: 0.0031877169385552406\n",
      "Epoch: 231, Avg. Train Loss: 0.0029803729551129564, Avg. Test Loss: 0.0031597213819622993\n",
      "Epoch: 232, Avg. Train Loss: 0.002933063750090294, Avg. Test Loss: 0.003170993411913514\n",
      "Epoch: 233, Avg. Train Loss: 0.0029585601350422515, Avg. Test Loss: 0.0033676791936159134\n",
      "Epoch: 234, Avg. Train Loss: 0.0029375351651376763, Avg. Test Loss: 0.0031440507154911757\n",
      "Epoch: 235, Avg. Train Loss: 0.0029265107099659916, Avg. Test Loss: 0.0032130477484315634\n",
      "Epoch: 236, Avg. Train Loss: 0.0029456585450747677, Avg. Test Loss: 0.003123822622001171\n",
      "Epoch: 237, Avg. Train Loss: 0.002893235729357531, Avg. Test Loss: 0.003196538193151355\n",
      "Epoch: 238, Avg. Train Loss: 0.0029660336738235728, Avg. Test Loss: 0.0031032266560941935\n",
      "Epoch: 239, Avg. Train Loss: 0.002942502325357393, Avg. Test Loss: 0.0032031554728746414\n",
      "Epoch: 240, Avg. Train Loss: 0.0028977642312299373, Avg. Test Loss: 0.0031129580456763506\n",
      "Epoch: 241, Avg. Train Loss: 0.0029058172584099824, Avg. Test Loss: 0.0030737046618014574\n",
      "Epoch: 242, Avg. Train Loss: 0.0028842362022937036, Avg. Test Loss: 0.003181662643328309\n",
      "Epoch: 243, Avg. Train Loss: 0.0029203848166088034, Avg. Test Loss: 0.003116580657660961\n",
      "Epoch: 244, Avg. Train Loss: 0.002855256394764712, Avg. Test Loss: 0.0031219127122312784\n",
      "Epoch: 245, Avg. Train Loss: 0.0029398783185887473, Avg. Test Loss: 0.003170933574438095\n",
      "Epoch: 246, Avg. Train Loss: 0.0029493584135157425, Avg. Test Loss: 0.003246515989303589\n",
      "Epoch: 247, Avg. Train Loss: 0.002893457086323652, Avg. Test Loss: 0.003066876670345664\n",
      "Epoch: 248, Avg. Train Loss: 0.0028677097370111665, Avg. Test Loss: 0.0032644288148730993\n",
      "Epoch: 249, Avg. Train Loss: 0.0029435517147270054, Avg. Test Loss: 0.003186536021530628\n",
      "Epoch: 250, Avg. Train Loss: 0.0028948537019882785, Avg. Test Loss: 0.003079109825193882\n",
      "Epoch: 251, Avg. Train Loss: 0.002923235946963, Avg. Test Loss: 0.0030647062230855227\n",
      "Epoch: 252, Avg. Train Loss: 0.002876318054446994, Avg. Test Loss: 0.0032766282092779875\n",
      "Epoch: 253, Avg. Train Loss: 0.002873964050004995, Avg. Test Loss: 0.0030275352764874697\n",
      "Epoch: 254, Avg. Train Loss: 0.002832226309015654, Avg. Test Loss: 0.003166759852319956\n",
      "Epoch: 255, Avg. Train Loss: 0.002838017148247292, Avg. Test Loss: 0.003047333797439933\n",
      "Epoch: 256, Avg. Train Loss: 0.002860916220734632, Avg. Test Loss: 0.0030751239974051714\n",
      "Epoch: 257, Avg. Train Loss: 0.002834102588294204, Avg. Test Loss: 0.0030867233872413635\n",
      "Epoch: 258, Avg. Train Loss: 0.0028360678576106247, Avg. Test Loss: 0.0031402702443301678\n",
      "Epoch: 259, Avg. Train Loss: 0.0028623096200875763, Avg. Test Loss: 0.0031123857479542494\n",
      "Epoch: 260, Avg. Train Loss: 0.0028406093384377483, Avg. Test Loss: 0.0030856316443532705\n",
      "Epoch: 261, Avg. Train Loss: 0.002885493336158783, Avg. Test Loss: 0.003289023647084832\n",
      "Epoch: 262, Avg. Train Loss: 0.0028586109645318152, Avg. Test Loss: 0.003015478141605854\n",
      "Epoch: 263, Avg. Train Loss: 0.0028300333475737376, Avg. Test Loss: 0.003142008790746331\n",
      "Epoch: 264, Avg. Train Loss: 0.0028372275762173324, Avg. Test Loss: 0.0031117815524339676\n",
      "Epoch: 265, Avg. Train Loss: 0.002913437085226178, Avg. Test Loss: 0.0032530580647289753\n",
      "Epoch: 266, Avg. Train Loss: 0.002835672354152383, Avg. Test Loss: 0.0030252188444137573\n",
      "Epoch: 267, Avg. Train Loss: 0.0028329077826509644, Avg. Test Loss: 0.0030460162088274956\n",
      "Epoch: 268, Avg. Train Loss: 0.0028178746822874906, Avg. Test Loss: 0.0032948206644505262\n",
      "Epoch: 269, Avg. Train Loss: 0.0027998076903438846, Avg. Test Loss: 0.0029942796099931\n",
      "Epoch: 270, Avg. Train Loss: 0.0027948483759753927, Avg. Test Loss: 0.0031332476064562798\n",
      "Epoch: 271, Avg. Train Loss: 0.0028081262310923534, Avg. Test Loss: 0.0030036037787795067\n",
      "Epoch: 272, Avg. Train Loss: 0.0028215313687660667, Avg. Test Loss: 0.003053084248676896\n",
      "Epoch: 273, Avg. Train Loss: 0.002774761486148765, Avg. Test Loss: 0.0030454581137746572\n",
      "Epoch: 274, Avg. Train Loss: 0.002791548743410859, Avg. Test Loss: 0.0030465894378721714\n",
      "Epoch: 275, Avg. Train Loss: 0.0027621546327028165, Avg. Test Loss: 0.0031664655543863773\n",
      "Epoch: 276, Avg. Train Loss: 0.002819540780470815, Avg. Test Loss: 0.0031546957325190306\n",
      "Epoch: 277, Avg. Train Loss: 0.0028713590541291373, Avg. Test Loss: 0.0030027052853256464\n",
      "Epoch: 278, Avg. Train Loss: 0.002789162814097349, Avg. Test Loss: 0.0030836814548820257\n",
      "Epoch: 279, Avg. Train Loss: 0.0027770763317253007, Avg. Test Loss: 0.0029954470228403807\n",
      "Epoch: 280, Avg. Train Loss: 0.002813747775372724, Avg. Test Loss: 0.003072990570217371\n",
      "Epoch: 281, Avg. Train Loss: 0.0027494667704368748, Avg. Test Loss: 0.002997158793732524\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 282, Avg. Train Loss: 0.002778278663754463, Avg. Test Loss: 0.00317639228887856\n",
      "Epoch: 283, Avg. Train Loss: 0.00279319683241463, Avg. Test Loss: 0.003049410181120038\n",
      "Epoch: 284, Avg. Train Loss: 0.002787594894640321, Avg. Test Loss: 0.003351095598191023\n",
      "Epoch: 285, Avg. Train Loss: 0.0028401998922142177, Avg. Test Loss: 0.0031096197199076414\n",
      "Epoch: 286, Avg. Train Loss: 0.0027924892384299013, Avg. Test Loss: 0.00305021065287292\n",
      "Epoch: 287, Avg. Train Loss: 0.0027655261774482422, Avg. Test Loss: 0.003008282510563731\n",
      "Epoch: 288, Avg. Train Loss: 0.0027851510879605317, Avg. Test Loss: 0.0030834379140287638\n",
      "Epoch: 289, Avg. Train Loss: 0.002783424892397814, Avg. Test Loss: 0.0031101172789931297\n",
      "Epoch: 290, Avg. Train Loss: 0.002751371487541947, Avg. Test Loss: 0.003041498363018036\n",
      "Epoch: 291, Avg. Train Loss: 0.002754552982920824, Avg. Test Loss: 0.003118375316262245\n",
      "Epoch: 292, Avg. Train Loss: 0.002784825650282031, Avg. Test Loss: 0.003035755129531026\n",
      "Epoch: 293, Avg. Train Loss: 0.002812399258187344, Avg. Test Loss: 0.003146118950098753\n",
      "Epoch: 294, Avg. Train Loss: 0.0027509078080224436, Avg. Test Loss: 0.003038805676624179\n",
      "Epoch: 295, Avg. Train Loss: 0.002748143978330285, Avg. Test Loss: 0.003081289352849126\n",
      "Epoch: 296, Avg. Train Loss: 0.0027627917439785113, Avg. Test Loss: 0.003209801157936454\n",
      "Epoch: 297, Avg. Train Loss: 0.002751698078544334, Avg. Test Loss: 0.00317914760671556\n",
      "Epoch: 298, Avg. Train Loss: 0.002761283846095551, Avg. Test Loss: 0.0029670277144759893\n",
      "Epoch: 299, Avg. Train Loss: 0.0027322754383000522, Avg. Test Loss: 0.002971992827951908\n",
      "Epoch: 300, Avg. Train Loss: 0.0027741274016714374, Avg. Test Loss: 0.002949927933514118\n",
      "Epoch: 301, Avg. Train Loss: 0.002726197924984749, Avg. Test Loss: 0.0031420045997947454\n",
      "Epoch: 302, Avg. Train Loss: 0.002755819570792969, Avg. Test Loss: 0.0030019190162420273\n",
      "Epoch: 303, Avg. Train Loss: 0.002732353544858999, Avg. Test Loss: 0.0030763985123485327\n",
      "Epoch: 304, Avg. Train Loss: 0.002723691243201841, Avg. Test Loss: 0.002971149981021881\n",
      "Epoch: 305, Avg. Train Loss: 0.002771278263914377, Avg. Test Loss: 0.0029940835665911436\n",
      "Epoch: 306, Avg. Train Loss: 0.0027384310635889687, Avg. Test Loss: 0.002969205379486084\n",
      "Epoch: 307, Avg. Train Loss: 0.002787077133435496, Avg. Test Loss: 0.0030203566420823336\n",
      "Epoch: 308, Avg. Train Loss: 0.0027429768923929957, Avg. Test Loss: 0.002923426451161504\n",
      "Epoch: 309, Avg. Train Loss: 0.0027240285931458305, Avg. Test Loss: 0.0031095300801098347\n",
      "Epoch: 310, Avg. Train Loss: 0.0027149216932526163, Avg. Test Loss: 0.003063641954213381\n",
      "Epoch: 311, Avg. Train Loss: 0.00272910121481779, Avg. Test Loss: 0.003032906213775277\n",
      "Epoch: 312, Avg. Train Loss: 0.0027108895863124797, Avg. Test Loss: 0.003287899773567915\n",
      "Epoch: 313, Avg. Train Loss: 0.002721109297559705, Avg. Test Loss: 0.00297907623462379\n",
      "Epoch: 314, Avg. Train Loss: 0.0027179138648302055, Avg. Test Loss: 0.003002331592142582\n",
      "Epoch: 315, Avg. Train Loss: 0.0027011098491764346, Avg. Test Loss: 0.003032284788787365\n",
      "Epoch: 316, Avg. Train Loss: 0.002766730247585233, Avg. Test Loss: 0.0029505162965506315\n",
      "Epoch: 317, Avg. Train Loss: 0.0026916824930975605, Avg. Test Loss: 0.002970410045236349\n",
      "Epoch: 318, Avg. Train Loss: 0.002677249364814786, Avg. Test Loss: 0.002939036814495921\n",
      "Epoch: 319, Avg. Train Loss: 0.002714800291023282, Avg. Test Loss: 0.0029493109323084354\n",
      "Epoch: 320, Avg. Train Loss: 0.002680298433704085, Avg. Test Loss: 0.0029736182186752558\n",
      "Epoch: 321, Avg. Train Loss: 0.0026933268784696974, Avg. Test Loss: 0.003029958810657263\n",
      "Epoch: 322, Avg. Train Loss: 0.002736344370384549, Avg. Test Loss: 0.0029029620345681906\n",
      "Epoch: 323, Avg. Train Loss: 0.0026678699989218352, Avg. Test Loss: 0.0029360135085880756\n",
      "Epoch: 324, Avg. Train Loss: 0.0026798145683092434, Avg. Test Loss: 0.002924035070464015\n",
      "Epoch: 325, Avg. Train Loss: 0.002700588487218632, Avg. Test Loss: 0.003182572778314352\n",
      "Epoch: 326, Avg. Train Loss: 0.0027278618085696256, Avg. Test Loss: 0.002954632043838501\n",
      "Epoch: 327, Avg. Train Loss: 0.00271157055638384, Avg. Test Loss: 0.0030790662858635187\n",
      "Epoch: 328, Avg. Train Loss: 0.002744463613516716, Avg. Test Loss: 0.002884762827306986\n",
      "Epoch: 329, Avg. Train Loss: 0.0027288790185784183, Avg. Test Loss: 0.002902810461819172\n",
      "Epoch: 330, Avg. Train Loss: 0.002687413646124823, Avg. Test Loss: 0.003051705891266465\n",
      "Epoch: 331, Avg. Train Loss: 0.002672870085726297, Avg. Test Loss: 0.0030579660087823868\n",
      "Epoch: 332, Avg. Train Loss: 0.0026642111465768063, Avg. Test Loss: 0.002920163096860051\n",
      "Epoch: 333, Avg. Train Loss: 0.0026520436716287637, Avg. Test Loss: 0.0029027534183114767\n",
      "Epoch: 334, Avg. Train Loss: 0.0026942717485389737, Avg. Test Loss: 0.0028954073786735535\n",
      "Epoch: 335, Avg. Train Loss: 0.0026534641605563637, Avg. Test Loss: 0.0028882562182843685\n",
      "Epoch: 336, Avg. Train Loss: 0.0027132395243402137, Avg. Test Loss: 0.0030639409087598324\n",
      "Epoch: 337, Avg. Train Loss: 0.0026781977435877155, Avg. Test Loss: 0.002967335283756256\n",
      "Epoch: 338, Avg. Train Loss: 0.002677436452358961, Avg. Test Loss: 0.0029074428603053093\n",
      "Epoch: 339, Avg. Train Loss: 0.0027206005301153246, Avg. Test Loss: 0.0030130913946777582\n",
      "Epoch: 340, Avg. Train Loss: 0.002690511490326635, Avg. Test Loss: 0.0029366835951805115\n",
      "Epoch: 341, Avg. Train Loss: 0.00263149349755326, Avg. Test Loss: 0.0029966195579618216\n",
      "Epoch: 342, Avg. Train Loss: 0.002649221282322393, Avg. Test Loss: 0.0031353130470961332\n",
      "Epoch: 343, Avg. Train Loss: 0.0026592580265863692, Avg. Test Loss: 0.0029168291948735714\n",
      "Epoch: 344, Avg. Train Loss: 0.0026431352950545936, Avg. Test Loss: 0.003140255343168974\n",
      "Epoch: 345, Avg. Train Loss: 0.0027100138777737008, Avg. Test Loss: 0.0029949990566819906\n",
      "Epoch: 346, Avg. Train Loss: 0.0026326339128752087, Avg. Test Loss: 0.0029914199840277433\n",
      "Epoch: 347, Avg. Train Loss: 0.002658445361005359, Avg. Test Loss: 0.003027327125892043\n",
      "Epoch: 348, Avg. Train Loss: 0.002668793762622531, Avg. Test Loss: 0.0028928425163030624\n",
      "Epoch: 349, Avg. Train Loss: 0.0026695894748838835, Avg. Test Loss: 0.0030887797474861145\n",
      "Epoch: 350, Avg. Train Loss: 0.0026413784849695686, Avg. Test Loss: 0.0029554637148976326\n",
      "Epoch: 351, Avg. Train Loss: 0.002650206735314325, Avg. Test Loss: 0.002920702798292041\n",
      "Epoch: 352, Avg. Train Loss: 0.002666083982127697, Avg. Test Loss: 0.0029520101379603148\n",
      "Epoch: 353, Avg. Train Loss: 0.0026134166509172944, Avg. Test Loss: 0.0028788105119019747\n",
      "Epoch: 354, Avg. Train Loss: 0.002621530273626017, Avg. Test Loss: 0.002874993486329913\n",
      "Epoch: 355, Avg. Train Loss: 0.0026296818044123263, Avg. Test Loss: 0.002905182773247361\n",
      "Epoch: 356, Avg. Train Loss: 0.002628541925142324, Avg. Test Loss: 0.0029969343449920416\n",
      "Epoch: 357, Avg. Train Loss: 0.002650150899277177, Avg. Test Loss: 0.003064606571570039\n",
      "Epoch: 358, Avg. Train Loss: 0.0026825460182979357, Avg. Test Loss: 0.002850551391020417\n",
      "Epoch: 359, Avg. Train Loss: 0.002594357421405094, Avg. Test Loss: 0.002903636312112212\n",
      "Epoch: 360, Avg. Train Loss: 0.002651788992807269, Avg. Test Loss: 0.0029650689102709293\n",
      "Epoch: 361, Avg. Train Loss: 0.0026488510599403186, Avg. Test Loss: 0.002947144443169236\n",
      "Epoch: 362, Avg. Train Loss: 0.002643560238052593, Avg. Test Loss: 0.00309695559553802\n",
      "Epoch: 363, Avg. Train Loss: 0.002644822223458526, Avg. Test Loss: 0.0029538748785853386\n",
      "Epoch: 364, Avg. Train Loss: 0.0027063571750511263, Avg. Test Loss: 0.002934841439127922\n",
      "Epoch: 365, Avg. Train Loss: 0.0026617965628501286, Avg. Test Loss: 0.002857508137822151\n",
      "Epoch: 366, Avg. Train Loss: 0.0026361873849879863, Avg. Test Loss: 0.002830704441294074\n",
      "Epoch: 367, Avg. Train Loss: 0.0027061936142312925, Avg. Test Loss: 0.0032018402125686407\n",
      "Epoch: 368, Avg. Train Loss: 0.002649646279467053, Avg. Test Loss: 0.002900976687669754\n",
      "Epoch: 369, Avg. Train Loss: 0.002599631831439775, Avg. Test Loss: 0.002918149344623089\n",
      "Epoch: 370, Avg. Train Loss: 0.002647932873345738, Avg. Test Loss: 0.002953441347926855\n",
      "Epoch: 371, Avg. Train Loss: 0.002592982870504953, Avg. Test Loss: 0.00288976589217782\n",
      "Epoch: 372, Avg. Train Loss: 0.0026445104090800117, Avg. Test Loss: 0.00297704990953207\n",
      "Epoch: 373, Avg. Train Loss: 0.002611426165500699, Avg. Test Loss: 0.002915416145697236\n",
      "Epoch: 374, Avg. Train Loss: 0.002631027170262018, Avg. Test Loss: 0.002964718732982874\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 375, Avg. Train Loss: 0.0026060663012051305, Avg. Test Loss: 0.0029884984251111746\n",
      "Epoch: 376, Avg. Train Loss: 0.002615292085507928, Avg. Test Loss: 0.0030441784765571356\n",
      "Epoch: 377, Avg. Train Loss: 0.002595473378680127, Avg. Test Loss: 0.0031842042226344347\n",
      "Epoch: 378, Avg. Train Loss: 0.0026011979694716457, Avg. Test Loss: 0.002863715635612607\n",
      "Epoch: 379, Avg. Train Loss: 0.002624340875204219, Avg. Test Loss: 0.002970449859276414\n",
      "Epoch: 380, Avg. Train Loss: 0.0026054865041704373, Avg. Test Loss: 0.003158376319333911\n",
      "Epoch: 381, Avg. Train Loss: 0.0026567118502286977, Avg. Test Loss: 0.002969474531710148\n",
      "Epoch: 382, Avg. Train Loss: 0.0025880694400172593, Avg. Test Loss: 0.002848069416359067\n",
      "Epoch: 383, Avg. Train Loss: 0.0026174276623181824, Avg. Test Loss: 0.002842949703335762\n",
      "Epoch: 384, Avg. Train Loss: 0.002556341949330513, Avg. Test Loss: 0.002826714888215065\n",
      "Epoch: 385, Avg. Train Loss: 0.0025634167466832454, Avg. Test Loss: 0.002929632319137454\n",
      "Epoch: 386, Avg. Train Loss: 0.0026113329628525777, Avg. Test Loss: 0.002905871020630002\n",
      "Epoch: 387, Avg. Train Loss: 0.0026092609975400358, Avg. Test Loss: 0.0028175704646855593\n",
      "Epoch: 388, Avg. Train Loss: 0.002575229306510368, Avg. Test Loss: 0.0028724137227982283\n",
      "Epoch: 389, Avg. Train Loss: 0.0026348224559495617, Avg. Test Loss: 0.003033238463103771\n",
      "Epoch: 390, Avg. Train Loss: 0.0026447985721968635, Avg. Test Loss: 0.0028711867053061724\n",
      "Epoch: 391, Avg. Train Loss: 0.0025510655304546966, Avg. Test Loss: 0.0028120942879468203\n",
      "Epoch: 392, Avg. Train Loss: 0.002638134590978193, Avg. Test Loss: 0.0030164364725351334\n",
      "Epoch: 393, Avg. Train Loss: 0.0026327834009777667, Avg. Test Loss: 0.003145035123452544\n",
      "Epoch: 394, Avg. Train Loss: 0.0026670596020859343, Avg. Test Loss: 0.003002149285748601\n",
      "Epoch: 395, Avg. Train Loss: 0.0025807099882513285, Avg. Test Loss: 0.0028139923233538866\n",
      "Epoch: 396, Avg. Train Loss: 0.0025386665677002004, Avg. Test Loss: 0.0029129856266081333\n",
      "Epoch: 397, Avg. Train Loss: 0.0025529504569550584, Avg. Test Loss: 0.0028834245167672634\n",
      "Epoch: 398, Avg. Train Loss: 0.002603399090815422, Avg. Test Loss: 0.002875471254810691\n",
      "Epoch: 399, Avg. Train Loss: 0.002576907663497814, Avg. Test Loss: 0.0028346155304461718\n",
      "Epoch: 400, Avg. Train Loss: 0.0025409772710571457, Avg. Test Loss: 0.0028298236429691315\n",
      "Epoch: 401, Avg. Train Loss: 0.002545325323766054, Avg. Test Loss: 0.002868392039090395\n",
      "Epoch: 402, Avg. Train Loss: 0.002580818557721931, Avg. Test Loss: 0.002956434153020382\n",
      "Epoch: 403, Avg. Train Loss: 0.0026935873022519573, Avg. Test Loss: 0.0028745464514940977\n",
      "Epoch: 404, Avg. Train Loss: 0.002568443289546426, Avg. Test Loss: 0.0029872639570385218\n",
      "Epoch: 405, Avg. Train Loss: 0.002578425264462482, Avg. Test Loss: 0.0028254524804651737\n",
      "Epoch: 406, Avg. Train Loss: 0.0025971037346523168, Avg. Test Loss: 0.002819519955664873\n",
      "Epoch: 407, Avg. Train Loss: 0.0025735386203281406, Avg. Test Loss: 0.0029090996831655502\n",
      "Epoch: 408, Avg. Train Loss: 0.0025606439124013104, Avg. Test Loss: 0.0028917286545038223\n",
      "Epoch: 409, Avg. Train Loss: 0.0025797789580686843, Avg. Test Loss: 0.002830198034644127\n",
      "Epoch: 410, Avg. Train Loss: 0.0025763472996998666, Avg. Test Loss: 0.002813986036926508\n",
      "Epoch: 411, Avg. Train Loss: 0.0026111215255548094, Avg. Test Loss: 0.002947538858279586\n",
      "Epoch: 412, Avg. Train Loss: 0.002671262173545222, Avg. Test Loss: 0.002945404266938567\n",
      "Epoch: 413, Avg. Train Loss: 0.0026123210906895786, Avg. Test Loss: 0.0030358501244336367\n",
      "Epoch: 414, Avg. Train Loss: 0.0026342078859289716, Avg. Test Loss: 0.002833298407495022\n",
      "Epoch: 415, Avg. Train Loss: 0.0025724705882630376, Avg. Test Loss: 0.002874863101169467\n",
      "Epoch: 416, Avg. Train Loss: 0.0025431758799958366, Avg. Test Loss: 0.002953797345981002\n",
      "Epoch: 417, Avg. Train Loss: 0.002571925363871594, Avg. Test Loss: 0.002818243345245719\n",
      "Epoch: 418, Avg. Train Loss: 0.0025243566609745804, Avg. Test Loss: 0.0027788393199443817\n",
      "Epoch: 419, Avg. Train Loss: 0.002531866088163021, Avg. Test Loss: 0.0029816878959536552\n",
      "Epoch: 420, Avg. Train Loss: 0.0025785033980947596, Avg. Test Loss: 0.002891922602429986\n",
      "Epoch: 421, Avg. Train Loss: 0.0025891852781696374, Avg. Test Loss: 0.0029804680962115526\n",
      "Epoch: 422, Avg. Train Loss: 0.0025598365802664397, Avg. Test Loss: 0.0028749804478138685\n",
      "Epoch: 423, Avg. Train Loss: 0.002579797205493547, Avg. Test Loss: 0.0028606506530195475\n",
      "Epoch: 424, Avg. Train Loss: 0.0025878913029161997, Avg. Test Loss: 0.002830351470038295\n",
      "Epoch: 425, Avg. Train Loss: 0.002567730697824858, Avg. Test Loss: 0.002856550272554159\n",
      "Epoch: 426, Avg. Train Loss: 0.002511595608666539, Avg. Test Loss: 0.0028396164998412132\n",
      "Epoch: 427, Avg. Train Loss: 0.0025658849518486234, Avg. Test Loss: 0.002858138643205166\n",
      "Epoch: 428, Avg. Train Loss: 0.0025220913595931475, Avg. Test Loss: 0.002844390459358692\n",
      "Epoch: 429, Avg. Train Loss: 0.0025050056675925505, Avg. Test Loss: 0.002789825899526477\n",
      "Epoch: 430, Avg. Train Loss: 0.0025340342450193886, Avg. Test Loss: 0.002924312837421894\n",
      "Epoch: 431, Avg. Train Loss: 0.0025695992287161737, Avg. Test Loss: 0.002820271300151944\n",
      "Epoch: 432, Avg. Train Loss: 0.0025207316502928734, Avg. Test Loss: 0.0028163548558950424\n",
      "Epoch: 433, Avg. Train Loss: 0.0025295931033703476, Avg. Test Loss: 0.003014256013557315\n",
      "Epoch: 434, Avg. Train Loss: 0.002533304813686152, Avg. Test Loss: 0.002766792196780443\n",
      "Epoch: 435, Avg. Train Loss: 0.0024874615158106007, Avg. Test Loss: 0.002829920733347535\n",
      "Epoch: 436, Avg. Train Loss: 0.0025284384149884763, Avg. Test Loss: 0.002977479714900255\n",
      "Epoch: 437, Avg. Train Loss: 0.0025759815173440202, Avg. Test Loss: 0.0028286483138799667\n",
      "Epoch: 438, Avg. Train Loss: 0.0025712405060699514, Avg. Test Loss: 0.0027964632026851177\n",
      "Epoch: 439, Avg. Train Loss: 0.002521479718906935, Avg. Test Loss: 0.0027970068622380495\n",
      "Epoch: 440, Avg. Train Loss: 0.0025175117270284614, Avg. Test Loss: 0.0028425732161849737\n",
      "Epoch: 441, Avg. Train Loss: 0.002540922555855887, Avg. Test Loss: 0.0029141397681087255\n",
      "Epoch: 442, Avg. Train Loss: 0.0025354951544296605, Avg. Test Loss: 0.0027781366370618343\n",
      "Epoch: 443, Avg. Train Loss: 0.0024945153584054044, Avg. Test Loss: 0.002769091632217169\n",
      "Epoch: 444, Avg. Train Loss: 0.0024985220543173856, Avg. Test Loss: 0.002862254623323679\n",
      "Epoch: 445, Avg. Train Loss: 0.0024793295157250275, Avg. Test Loss: 0.0027691926807165146\n",
      "Epoch: 446, Avg. Train Loss: 0.0025346891380586597, Avg. Test Loss: 0.002789535326883197\n",
      "Epoch: 447, Avg. Train Loss: 0.002505441629436127, Avg. Test Loss: 0.0028725378215312958\n",
      "Epoch: 448, Avg. Train Loss: 0.0025042094355232493, Avg. Test Loss: 0.0028335130773484707\n",
      "Epoch: 449, Avg. Train Loss: 0.00249604579754347, Avg. Test Loss: 0.0028145210817456245\n",
      "Epoch: 450, Avg. Train Loss: 0.0025044058741958337, Avg. Test Loss: 0.0029918637592345476\n",
      "Epoch: 451, Avg. Train Loss: 0.002514138915251161, Avg. Test Loss: 0.0028509919065982103\n",
      "Epoch: 452, Avg. Train Loss: 0.002575485690951694, Avg. Test Loss: 0.002864278620108962\n",
      "Epoch: 453, Avg. Train Loss: 0.0025602366482882304, Avg. Test Loss: 0.0028185718692839146\n",
      "Epoch: 454, Avg. Train Loss: 0.002573886777945729, Avg. Test Loss: 0.0027692755684256554\n",
      "Epoch: 455, Avg. Train Loss: 0.0025026941087183566, Avg. Test Loss: 0.0027715610340237617\n",
      "Epoch: 456, Avg. Train Loss: 0.002562089471233099, Avg. Test Loss: 0.002879576524719596\n",
      "Epoch: 457, Avg. Train Loss: 0.002493490302545387, Avg. Test Loss: 0.002796286717057228\n",
      "Epoch: 458, Avg. Train Loss: 0.002472781841534861, Avg. Test Loss: 0.0027521783486008644\n",
      "Epoch: 459, Avg. Train Loss: 0.002466746178174088, Avg. Test Loss: 0.002783458912745118\n",
      "Epoch: 460, Avg. Train Loss: 0.002473351962561178, Avg. Test Loss: 0.0028772614896297455\n",
      "Epoch: 461, Avg. Train Loss: 0.0024952079862529454, Avg. Test Loss: 0.0029676854610443115\n",
      "Epoch: 462, Avg. Train Loss: 0.002537593965656882, Avg. Test Loss: 0.002787065925076604\n",
      "Epoch: 463, Avg. Train Loss: 0.0024635549742988375, Avg. Test Loss: 0.002782755997031927\n",
      "Epoch: 464, Avg. Train Loss: 0.0025318323060610267, Avg. Test Loss: 0.0028106430545449257\n",
      "Epoch: 465, Avg. Train Loss: 0.002483905325535425, Avg. Test Loss: 0.002801920287311077\n",
      "Epoch: 466, Avg. Train Loss: 0.0024787549655018158, Avg. Test Loss: 0.002870667027309537\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 467, Avg. Train Loss: 0.0024845258246154285, Avg. Test Loss: 0.002740598749369383\n",
      "Epoch: 468, Avg. Train Loss: 0.00246106899278455, Avg. Test Loss: 0.002924642525613308\n",
      "Epoch: 469, Avg. Train Loss: 0.0025330452941531357, Avg. Test Loss: 0.0028912958223372698\n",
      "Epoch: 470, Avg. Train Loss: 0.0025029442662936312, Avg. Test Loss: 0.0028306825552135706\n",
      "Epoch: 471, Avg. Train Loss: 0.002520266627936169, Avg. Test Loss: 0.0031936296727508307\n",
      "Epoch: 472, Avg. Train Loss: 0.002519860825782945, Avg. Test Loss: 0.002867866074666381\n",
      "Epoch: 473, Avg. Train Loss: 0.0024748343032199977, Avg. Test Loss: 0.0027367889415472746\n",
      "Epoch: 474, Avg. Train Loss: 0.002490077054041416, Avg. Test Loss: 0.002749781357124448\n",
      "Epoch: 475, Avg. Train Loss: 0.0024817884997139837, Avg. Test Loss: 0.0027534407563507557\n",
      "Epoch: 476, Avg. Train Loss: 0.0024762273668636416, Avg. Test Loss: 0.0029040053486824036\n",
      "Epoch: 477, Avg. Train Loss: 0.0024618819020255363, Avg. Test Loss: 0.0027647505048662424\n",
      "Epoch: 478, Avg. Train Loss: 0.0024859532713890076, Avg. Test Loss: 0.0027482006698846817\n",
      "Epoch: 479, Avg. Train Loss: 0.002473572182447411, Avg. Test Loss: 0.0027564908377826214\n",
      "Epoch: 480, Avg. Train Loss: 0.002494060461474366, Avg. Test Loss: 0.002961603458970785\n",
      "Epoch: 481, Avg. Train Loss: 0.002461442545186295, Avg. Test Loss: 0.0027555362321436405\n",
      "Epoch: 482, Avg. Train Loss: 0.0024461680048600185, Avg. Test Loss: 0.002830382203683257\n",
      "Epoch: 483, Avg. Train Loss: 0.002472653957950168, Avg. Test Loss: 0.0027530500665307045\n",
      "Epoch: 484, Avg. Train Loss: 0.002593592821815333, Avg. Test Loss: 0.002765507437288761\n",
      "Epoch: 485, Avg. Train Loss: 0.0024915961981859316, Avg. Test Loss: 0.002791262697428465\n",
      "Epoch: 486, Avg. Train Loss: 0.0025032633904714225, Avg. Test Loss: 0.002861025044694543\n",
      "Epoch: 487, Avg. Train Loss: 0.002496394258382362, Avg. Test Loss: 0.002825868083164096\n",
      "Epoch: 488, Avg. Train Loss: 0.002503167588783558, Avg. Test Loss: 0.002755555557087064\n",
      "Epoch: 489, Avg. Train Loss: 0.0024727329958316893, Avg. Test Loss: 0.0027160728350281715\n",
      "Epoch: 490, Avg. Train Loss: 0.002444232110107361, Avg. Test Loss: 0.002761423122137785\n",
      "Epoch: 491, Avg. Train Loss: 0.002452471071507695, Avg. Test Loss: 0.0027261993382126093\n",
      "Epoch: 492, Avg. Train Loss: 0.002478132240994032, Avg. Test Loss: 0.0029487917199730873\n",
      "Epoch: 493, Avg. Train Loss: 0.002457094524965383, Avg. Test Loss: 0.00280116219073534\n",
      "Epoch: 494, Avg. Train Loss: 0.002566298513218414, Avg. Test Loss: 0.002820159774273634\n",
      "Epoch: 495, Avg. Train Loss: 0.0024403616796832444, Avg. Test Loss: 0.0027525934856384993\n",
      "Epoch: 496, Avg. Train Loss: 0.0024470701748721822, Avg. Test Loss: 0.0028883712366223335\n",
      "Epoch: 497, Avg. Train Loss: 0.0025449259650655266, Avg. Test Loss: 0.003022396005690098\n",
      "Epoch: 498, Avg. Train Loss: 0.002435876240650582, Avg. Test Loss: 0.002737787552177906\n",
      "Epoch: 499, Avg. Train Loss: 0.002443512441417159, Avg. Test Loss: 0.0027224449440836906\n",
      "Epoch: 500, Avg. Train Loss: 0.0024401196874244964, Avg. Test Loss: 0.0029883983079344034\n",
      "Epoch: 501, Avg. Train Loss: 0.0024586396107753347, Avg. Test Loss: 0.0027510279323905706\n",
      "Epoch: 502, Avg. Train Loss: 0.002451594897307629, Avg. Test Loss: 0.00272179557941854\n",
      "Epoch: 503, Avg. Train Loss: 0.0024594075295554345, Avg. Test Loss: 0.00276578264310956\n",
      "Epoch: 504, Avg. Train Loss: 0.0024404907382504885, Avg. Test Loss: 0.0027572426479309797\n",
      "Epoch: 505, Avg. Train Loss: 0.0024505105075361424, Avg. Test Loss: 0.0028129881247878075\n",
      "Epoch: 506, Avg. Train Loss: 0.0024957920879472135, Avg. Test Loss: 0.0027621735353022814\n",
      "Epoch: 507, Avg. Train Loss: 0.0024352343428100266, Avg. Test Loss: 0.0028817038983106613\n",
      "Epoch: 508, Avg. Train Loss: 0.0024851286339811806, Avg. Test Loss: 0.0028274001087993383\n",
      "Epoch: 509, Avg. Train Loss: 0.002415029110040429, Avg. Test Loss: 0.002865925896912813\n",
      "Epoch: 510, Avg. Train Loss: 0.0024978018333312382, Avg. Test Loss: 0.0028499590698629618\n",
      "Epoch: 511, Avg. Train Loss: 0.00246928273808471, Avg. Test Loss: 0.0027611232362687588\n",
      "Epoch: 512, Avg. Train Loss: 0.00243227259624143, Avg. Test Loss: 0.0027598694432526827\n",
      "Epoch: 513, Avg. Train Loss: 0.002436003745208646, Avg. Test Loss: 0.0027377053629606962\n",
      "Epoch: 514, Avg. Train Loss: 0.0024403794235441575, Avg. Test Loss: 0.002931581111624837\n",
      "Epoch: 515, Avg. Train Loss: 0.002516990700779959, Avg. Test Loss: 0.002723825629800558\n",
      "Epoch: 516, Avg. Train Loss: 0.00245415712815038, Avg. Test Loss: 0.0028037570882588625\n",
      "Epoch: 517, Avg. Train Loss: 0.002446621466904532, Avg. Test Loss: 0.0027769480366259813\n",
      "Epoch: 518, Avg. Train Loss: 0.00243139035220063, Avg. Test Loss: 0.0027658697217702866\n",
      "Epoch: 519, Avg. Train Loss: 0.0024950876128101763, Avg. Test Loss: 0.002752928761765361\n",
      "Epoch: 520, Avg. Train Loss: 0.002426905925710534, Avg. Test Loss: 0.0028055172879248857\n",
      "Epoch: 521, Avg. Train Loss: 0.0024231315298049254, Avg. Test Loss: 0.0027249911800026894\n",
      "Epoch: 522, Avg. Train Loss: 0.002402295742920318, Avg. Test Loss: 0.0027590792160481215\n",
      "Epoch: 523, Avg. Train Loss: 0.002575272710474078, Avg. Test Loss: 0.002734358888119459\n",
      "Epoch: 524, Avg. Train Loss: 0.0024417666447630456, Avg. Test Loss: 0.002858103020116687\n",
      "Epoch: 525, Avg. Train Loss: 0.002431358930893069, Avg. Test Loss: 0.002699666889384389\n",
      "Epoch: 526, Avg. Train Loss: 0.0024070752199825854, Avg. Test Loss: 0.0028065131045877934\n",
      "Epoch: 527, Avg. Train Loss: 0.002406394401521877, Avg. Test Loss: 0.0027073975652456284\n",
      "Epoch: 528, Avg. Train Loss: 0.002398716134214124, Avg. Test Loss: 0.0027448616456240416\n",
      "Epoch: 529, Avg. Train Loss: 0.002390473079326194, Avg. Test Loss: 0.002702689031139016\n",
      "Epoch: 530, Avg. Train Loss: 0.0024391664787693774, Avg. Test Loss: 0.0028670933097600937\n",
      "Epoch: 531, Avg. Train Loss: 0.002415711379631661, Avg. Test Loss: 0.0028438628651201725\n",
      "Epoch: 532, Avg. Train Loss: 0.0024939654503277568, Avg. Test Loss: 0.003123275702819228\n",
      "Epoch: 533, Avg. Train Loss: 0.0024533658234272586, Avg. Test Loss: 0.002702200785279274\n",
      "Epoch: 534, Avg. Train Loss: 0.002425822413114961, Avg. Test Loss: 0.0027766311541199684\n",
      "Epoch: 535, Avg. Train Loss: 0.002400528293016345, Avg. Test Loss: 0.0027869781479239464\n",
      "Epoch: 536, Avg. Train Loss: 0.002434559041894106, Avg. Test Loss: 0.0029115192592144012\n",
      "Epoch: 537, Avg. Train Loss: 0.002471916908181684, Avg. Test Loss: 0.0028762458823621273\n",
      "Epoch: 538, Avg. Train Loss: 0.0024301200661115173, Avg. Test Loss: 0.0027225157245993614\n",
      "Epoch: 539, Avg. Train Loss: 0.0024051004750004342, Avg. Test Loss: 0.0027073195669800043\n",
      "Epoch: 540, Avg. Train Loss: 0.002439043203065562, Avg. Test Loss: 0.0027501073200255632\n",
      "Epoch: 541, Avg. Train Loss: 0.0023862178339947794, Avg. Test Loss: 0.002774458611384034\n",
      "Epoch: 542, Avg. Train Loss: 0.002446636655043031, Avg. Test Loss: 0.00287290895357728\n",
      "Epoch: 543, Avg. Train Loss: 0.002419014656266501, Avg. Test Loss: 0.002706269035115838\n",
      "Epoch: 544, Avg. Train Loss: 0.002420312345980905, Avg. Test Loss: 0.00296951737254858\n",
      "Epoch: 545, Avg. Train Loss: 0.002446695664074532, Avg. Test Loss: 0.0027767308056354523\n",
      "Epoch: 546, Avg. Train Loss: 0.0024250959273600992, Avg. Test Loss: 0.003009757259860635\n",
      "Epoch: 547, Avg. Train Loss: 0.002493794817953955, Avg. Test Loss: 0.0027103135362267494\n",
      "Epoch: 548, Avg. Train Loss: 0.0024018380682655546, Avg. Test Loss: 0.0028033407870680094\n",
      "Epoch: 549, Avg. Train Loss: 0.002429234448733718, Avg. Test Loss: 0.002715958282351494\n",
      "Epoch: 550, Avg. Train Loss: 0.0023773045517330948, Avg. Test Loss: 0.003051134292036295\n",
      "Epoch: 551, Avg. Train Loss: 0.002445322537231584, Avg. Test Loss: 0.002943894127383828\n",
      "Epoch: 552, Avg. Train Loss: 0.0024288866918014233, Avg. Test Loss: 0.002785181161016226\n",
      "Epoch: 553, Avg. Train Loss: 0.0023882309093984752, Avg. Test Loss: 0.00268627074547112\n",
      "Epoch: 554, Avg. Train Loss: 0.0023626347592230453, Avg. Test Loss: 0.002841421402990818\n",
      "Epoch: 555, Avg. Train Loss: 0.0024746978698774826, Avg. Test Loss: 0.0027135030832141638\n",
      "Epoch: 556, Avg. Train Loss: 0.0023993262046471584, Avg. Test Loss: 0.002765919081866741\n",
      "Epoch: 557, Avg. Train Loss: 0.002435918659145056, Avg. Test Loss: 0.002795713022351265\n",
      "Epoch: 558, Avg. Train Loss: 0.002390184298937404, Avg. Test Loss: 0.002822855021804571\n",
      "Epoch: 559, Avg. Train Loss: 0.002411593942967958, Avg. Test Loss: 0.0027656597085297108\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 560, Avg. Train Loss: 0.0023953492190082405, Avg. Test Loss: 0.002730222186073661\n",
      "Epoch: 561, Avg. Train Loss: 0.0023874772474343, Avg. Test Loss: 0.002735669258981943\n",
      "Epoch: 562, Avg. Train Loss: 0.002389219156358131, Avg. Test Loss: 0.00267826858907938\n",
      "Epoch: 563, Avg. Train Loss: 0.0024232155383499556, Avg. Test Loss: 0.002823703456670046\n",
      "Epoch: 564, Avg. Train Loss: 0.002417584984065142, Avg. Test Loss: 0.002828040160238743\n",
      "Epoch: 565, Avg. Train Loss: 0.002415470724795447, Avg. Test Loss: 0.0028430575039237738\n",
      "Epoch: 566, Avg. Train Loss: 0.0023942376638567725, Avg. Test Loss: 0.0026805640663951635\n",
      "Epoch: 567, Avg. Train Loss: 0.002357856083531366, Avg. Test Loss: 0.002697467803955078\n",
      "Epoch: 568, Avg. Train Loss: 0.0023922804299048904, Avg. Test Loss: 0.0027511902153491974\n",
      "Epoch: 569, Avg. Train Loss: 0.0023782245305821645, Avg. Test Loss: 0.0027031011413782835\n",
      "Epoch: 570, Avg. Train Loss: 0.0023884623755462643, Avg. Test Loss: 0.0027170763351023197\n",
      "Epoch: 571, Avg. Train Loss: 0.0024214829859691995, Avg. Test Loss: 0.0026930400636047125\n",
      "Epoch: 572, Avg. Train Loss: 0.0024121044322761684, Avg. Test Loss: 0.0029667660128325224\n",
      "Epoch: 573, Avg. Train Loss: 0.002401929716904496, Avg. Test Loss: 0.002828029217198491\n",
      "Epoch: 574, Avg. Train Loss: 0.0024121342454278883, Avg. Test Loss: 0.0027198721654713154\n",
      "Epoch: 575, Avg. Train Loss: 0.002369945733483101, Avg. Test Loss: 0.002658843295648694\n",
      "Epoch: 576, Avg. Train Loss: 0.002352501141167311, Avg. Test Loss: 0.0026812979485839605\n",
      "Epoch: 577, Avg. Train Loss: 0.0023496806632380845, Avg. Test Loss: 0.002695178147405386\n",
      "Epoch: 578, Avg. Train Loss: 0.002396926115981715, Avg. Test Loss: 0.0027349679730832577\n",
      "Epoch: 579, Avg. Train Loss: 0.0023947924126459415, Avg. Test Loss: 0.002716093324124813\n",
      "Epoch: 580, Avg. Train Loss: 0.002424804921543529, Avg. Test Loss: 0.0026773251593112946\n",
      "Epoch: 581, Avg. Train Loss: 0.0023745412256048863, Avg. Test Loss: 0.002761370036751032\n",
      "Epoch: 582, Avg. Train Loss: 0.0023982983331607526, Avg. Test Loss: 0.0027011565398424864\n",
      "Epoch: 583, Avg. Train Loss: 0.0024247733540399825, Avg. Test Loss: 0.002791971666738391\n",
      "Epoch: 584, Avg. Train Loss: 0.0024435289344901957, Avg. Test Loss: 0.0027396581135690212\n",
      "Epoch: 585, Avg. Train Loss: 0.002335275902391173, Avg. Test Loss: 0.0027148760855197906\n",
      "Epoch: 586, Avg. Train Loss: 0.0023848622019381023, Avg. Test Loss: 0.002952366368845105\n",
      "Epoch: 587, Avg. Train Loss: 0.0023843295341574177, Avg. Test Loss: 0.002702859463170171\n",
      "Epoch: 588, Avg. Train Loss: 0.002349038256418913, Avg. Test Loss: 0.00272648804821074\n",
      "Epoch: 589, Avg. Train Loss: 0.002336929606403722, Avg. Test Loss: 0.0027499976567924023\n",
      "Epoch: 590, Avg. Train Loss: 0.0023905398908915907, Avg. Test Loss: 0.0026635106187313795\n",
      "Epoch: 591, Avg. Train Loss: 0.0023322577729041494, Avg. Test Loss: 0.002657482633367181\n",
      "Epoch: 592, Avg. Train Loss: 0.002382454662692062, Avg. Test Loss: 0.0026864975225180387\n",
      "Epoch: 593, Avg. Train Loss: 0.0023504651887992093, Avg. Test Loss: 0.002648690016940236\n",
      "Epoch: 594, Avg. Train Loss: 0.002360049099119943, Avg. Test Loss: 0.0027484141755849123\n",
      "Epoch: 595, Avg. Train Loss: 0.00236875161550246, Avg. Test Loss: 0.0027437247335910797\n",
      "Epoch: 596, Avg. Train Loss: 0.00236426314967143, Avg. Test Loss: 0.0026925033889710903\n",
      "Epoch: 597, Avg. Train Loss: 0.0023561967645100382, Avg. Test Loss: 0.0026528160087764263\n",
      "Epoch: 598, Avg. Train Loss: 0.0023908012243377607, Avg. Test Loss: 0.002692476147785783\n",
      "Epoch: 599, Avg. Train Loss: 0.002345146383916916, Avg. Test Loss: 0.0027747959829866886\n",
      "Epoch: 600, Avg. Train Loss: 0.0023596916174472766, Avg. Test Loss: 0.0027718315832316875\n",
      "Epoch: 601, Avg. Train Loss: 0.002383624171015135, Avg. Test Loss: 0.0026605406310409307\n",
      "Epoch: 602, Avg. Train Loss: 0.0023801975374564874, Avg. Test Loss: 0.002792922081425786\n",
      "Epoch: 603, Avg. Train Loss: 0.002415350643744649, Avg. Test Loss: 0.0026995709631592035\n",
      "Epoch: 604, Avg. Train Loss: 0.002355708312892983, Avg. Test Loss: 0.0026689365040510893\n",
      "Epoch: 605, Avg. Train Loss: 0.002362749837122338, Avg. Test Loss: 0.003099024062976241\n",
      "Epoch: 606, Avg. Train Loss: 0.0023909256966827912, Avg. Test Loss: 0.0026618370320647955\n",
      "Epoch: 607, Avg. Train Loss: 0.002326179268704944, Avg. Test Loss: 0.002836569445207715\n",
      "Epoch: 608, Avg. Train Loss: 0.0023884131345724645, Avg. Test Loss: 0.0027144269552081823\n",
      "Epoch: 609, Avg. Train Loss: 0.0023251527508850707, Avg. Test Loss: 0.002690371125936508\n",
      "Epoch: 610, Avg. Train Loss: 0.002330157461814409, Avg. Test Loss: 0.002693331800401211\n",
      "Epoch: 611, Avg. Train Loss: 0.0023660618584429804, Avg. Test Loss: 0.002673689741641283\n",
      "Epoch: 612, Avg. Train Loss: 0.002355194033318481, Avg. Test Loss: 0.002663426101207733\n",
      "Epoch: 613, Avg. Train Loss: 0.00233934796956736, Avg. Test Loss: 0.0026984368450939655\n",
      "Epoch: 614, Avg. Train Loss: 0.002387588670433954, Avg. Test Loss: 0.003015215042978525\n",
      "Epoch: 615, Avg. Train Loss: 0.0024944376037997562, Avg. Test Loss: 0.0027566186618059874\n",
      "Epoch: 616, Avg. Train Loss: 0.002428948857583279, Avg. Test Loss: 0.0027343041729182005\n",
      "Epoch: 617, Avg. Train Loss: 0.0023945654298417095, Avg. Test Loss: 0.002657050732523203\n",
      "Epoch: 618, Avg. Train Loss: 0.002354873739572805, Avg. Test Loss: 0.002682419028133154\n",
      "Epoch: 619, Avg. Train Loss: 0.0023416743375534233, Avg. Test Loss: 0.0026726326905190945\n",
      "Epoch: 620, Avg. Train Loss: 0.002347261807339829, Avg. Test Loss: 0.0027210749685764313\n",
      "Epoch: 621, Avg. Train Loss: 0.002391029864029829, Avg. Test Loss: 0.0027916263788938522\n",
      "Epoch: 622, Avg. Train Loss: 0.002390856453932302, Avg. Test Loss: 0.0027456600219011307\n",
      "Epoch: 623, Avg. Train Loss: 0.0023492247483498136, Avg. Test Loss: 0.0026309452950954437\n",
      "Epoch: 624, Avg. Train Loss: 0.0023276181566680588, Avg. Test Loss: 0.0030692650470882654\n",
      "Epoch: 625, Avg. Train Loss: 0.0024045772828854796, Avg. Test Loss: 0.002726580249145627\n",
      "Epoch: 626, Avg. Train Loss: 0.0023352102441496626, Avg. Test Loss: 0.00267624668776989\n",
      "Epoch: 627, Avg. Train Loss: 0.0023497982752011264, Avg. Test Loss: 0.0026946906000375748\n",
      "Epoch: 628, Avg. Train Loss: 0.0023955593730301357, Avg. Test Loss: 0.0028189592994749546\n",
      "Epoch: 629, Avg. Train Loss: 0.002370419603404264, Avg. Test Loss: 0.0027187755331397057\n",
      "Epoch: 630, Avg. Train Loss: 0.0023681108601564583, Avg. Test Loss: 0.0026268246583640575\n",
      "Epoch: 631, Avg. Train Loss: 0.0023654191592318375, Avg. Test Loss: 0.0026894379407167435\n",
      "Epoch: 632, Avg. Train Loss: 0.0023286896703634844, Avg. Test Loss: 0.0027006608434021473\n",
      "Epoch: 633, Avg. Train Loss: 0.0024442136894131817, Avg. Test Loss: 0.0027432276401668787\n",
      "Epoch: 634, Avg. Train Loss: 0.0023477593285226544, Avg. Test Loss: 0.002818438457325101\n",
      "Epoch: 635, Avg. Train Loss: 0.002315700092071364, Avg. Test Loss: 0.0026543245185166597\n",
      "Epoch: 636, Avg. Train Loss: 0.0023508850853283737, Avg. Test Loss: 0.0027780700474977493\n",
      "Epoch: 637, Avg. Train Loss: 0.0023622689443792023, Avg. Test Loss: 0.002937940414994955\n",
      "Epoch: 638, Avg. Train Loss: 0.002374251578869515, Avg. Test Loss: 0.0026372806169092655\n",
      "Epoch: 639, Avg. Train Loss: 0.0023587644479215837, Avg. Test Loss: 0.0027543525211513042\n",
      "Epoch: 640, Avg. Train Loss: 0.002320073317563118, Avg. Test Loss: 0.0026918225921690464\n",
      "Epoch: 641, Avg. Train Loss: 0.002356825179831926, Avg. Test Loss: 0.002836820902302861\n",
      "Epoch: 642, Avg. Train Loss: 0.0023203753151519353, Avg. Test Loss: 0.0026992138009518385\n",
      "Epoch: 643, Avg. Train Loss: 0.0023106730131562366, Avg. Test Loss: 0.0026628936175256968\n",
      "Epoch: 644, Avg. Train Loss: 0.0023115557607609866, Avg. Test Loss: 0.002714148722589016\n",
      "Epoch: 645, Avg. Train Loss: 0.002355982202949912, Avg. Test Loss: 0.0028474368155002594\n",
      "Epoch: 646, Avg. Train Loss: 0.0023410659023495608, Avg. Test Loss: 0.002633559750393033\n",
      "Epoch: 647, Avg. Train Loss: 0.0023349177547145722, Avg. Test Loss: 0.002731876913458109\n",
      "Epoch: 648, Avg. Train Loss: 0.002288045036758101, Avg. Test Loss: 0.0027197045274078846\n",
      "Epoch: 649, Avg. Train Loss: 0.002319246243555532, Avg. Test Loss: 0.0027388310991227627\n",
      "Epoch: 650, Avg. Train Loss: 0.0023209338487927304, Avg. Test Loss: 0.0026293392293155193\n",
      "Epoch: 651, Avg. Train Loss: 0.0023850665081205755, Avg. Test Loss: 0.0027311642188578844\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 652, Avg. Train Loss: 0.0023676048162891423, Avg. Test Loss: 0.0026537366211414337\n",
      "Epoch: 653, Avg. Train Loss: 0.0023509800694016523, Avg. Test Loss: 0.002802627393975854\n",
      "Epoch: 654, Avg. Train Loss: 0.002329153517737638, Avg. Test Loss: 0.002753129694610834\n",
      "Epoch: 655, Avg. Train Loss: 0.0024474148292007833, Avg. Test Loss: 0.0028548918198794127\n",
      "Epoch: 656, Avg. Train Loss: 0.002316783886229576, Avg. Test Loss: 0.0026955129578709602\n",
      "Epoch: 657, Avg. Train Loss: 0.0023018126375973225, Avg. Test Loss: 0.0028107124380767345\n",
      "Epoch: 658, Avg. Train Loss: 0.002404724496828262, Avg. Test Loss: 0.0029464280232787132\n",
      "Epoch: 659, Avg. Train Loss: 0.0023135138177421202, Avg. Test Loss: 0.0026872698217630386\n",
      "Epoch: 660, Avg. Train Loss: 0.0023369341763819374, Avg. Test Loss: 0.002645554719492793\n",
      "Epoch: 661, Avg. Train Loss: 0.00232880191639239, Avg. Test Loss: 0.002716179471462965\n",
      "Epoch: 662, Avg. Train Loss: 0.0023618557836947054, Avg. Test Loss: 0.0027044874150305986\n",
      "Epoch: 663, Avg. Train Loss: 0.002320158392797376, Avg. Test Loss: 0.002665203530341387\n",
      "Epoch: 664, Avg. Train Loss: 0.0022864595467094765, Avg. Test Loss: 0.0026747051160782576\n",
      "Epoch: 665, Avg. Train Loss: 0.002333346337383223, Avg. Test Loss: 0.0026288507506251335\n",
      "Epoch: 666, Avg. Train Loss: 0.002314494316314542, Avg. Test Loss: 0.0026505552232265472\n",
      "Epoch: 667, Avg. Train Loss: 0.002307902561327399, Avg. Test Loss: 0.002707286272197962\n",
      "Epoch: 668, Avg. Train Loss: 0.002311147836058639, Avg. Test Loss: 0.002714082831516862\n",
      "Epoch: 669, Avg. Train Loss: 0.0023219400670292764, Avg. Test Loss: 0.002624256070703268\n",
      "Epoch: 670, Avg. Train Loss: 0.0022982468362897635, Avg. Test Loss: 0.002680023666471243\n",
      "Epoch: 671, Avg. Train Loss: 0.002280410655319344, Avg. Test Loss: 0.0026432375889271498\n",
      "Epoch: 672, Avg. Train Loss: 0.002292124814418859, Avg. Test Loss: 0.002658906625583768\n",
      "Epoch: 673, Avg. Train Loss: 0.0023968964652699787, Avg. Test Loss: 0.002651883289217949\n",
      "Epoch: 674, Avg. Train Loss: 0.0023108971911634125, Avg. Test Loss: 0.002723047509789467\n",
      "Epoch: 675, Avg. Train Loss: 0.002336949045055134, Avg. Test Loss: 0.002715703332796693\n",
      "Epoch: 676, Avg. Train Loss: 0.0023292072745429914, Avg. Test Loss: 0.002778471214696765\n",
      "Epoch: 677, Avg. Train Loss: 0.00232067521726496, Avg. Test Loss: 0.0026457549538463354\n",
      "Epoch: 678, Avg. Train Loss: 0.002334741334062676, Avg. Test Loss: 0.002646033652126789\n",
      "Epoch: 679, Avg. Train Loss: 0.002374571471929897, Avg. Test Loss: 0.0028109243139624596\n",
      "Epoch: 680, Avg. Train Loss: 0.0023314876124522713, Avg. Test Loss: 0.0028809148352593184\n",
      "Epoch: 681, Avg. Train Loss: 0.00231214641961594, Avg. Test Loss: 0.0027395656798034906\n",
      "Epoch: 682, Avg. Train Loss: 0.002295463573360859, Avg. Test Loss: 0.002662401180714369\n",
      "Epoch: 683, Avg. Train Loss: 0.0023199700977826533, Avg. Test Loss: 0.002878874307498336\n",
      "Epoch: 684, Avg. Train Loss: 0.002365749979088473, Avg. Test Loss: 0.0027610408142209053\n",
      "Epoch: 685, Avg. Train Loss: 0.002372843700699335, Avg. Test Loss: 0.002808359917253256\n",
      "Epoch: 686, Avg. Train Loss: 0.0023015606065475663, Avg. Test Loss: 0.0025958705227822065\n",
      "Epoch: 687, Avg. Train Loss: 0.00230721314979154, Avg. Test Loss: 0.0027632208075374365\n",
      "Epoch: 688, Avg. Train Loss: 0.002387318581472649, Avg. Test Loss: 0.0027107205241918564\n",
      "Epoch: 689, Avg. Train Loss: 0.0023005659432085448, Avg. Test Loss: 0.0027124593034386635\n",
      "Epoch: 690, Avg. Train Loss: 0.002309903773197601, Avg. Test Loss: 0.0026901564560830593\n",
      "Epoch: 691, Avg. Train Loss: 0.0022663417553832363, Avg. Test Loss: 0.002645261585712433\n",
      "Epoch: 692, Avg. Train Loss: 0.0022997446791377177, Avg. Test Loss: 0.0026376897003501654\n",
      "Epoch: 693, Avg. Train Loss: 0.0022993284510448575, Avg. Test Loss: 0.00265804142691195\n",
      "Epoch: 694, Avg. Train Loss: 0.002359625466471148, Avg. Test Loss: 0.00260175671428442\n",
      "Epoch: 695, Avg. Train Loss: 0.0022705907846779323, Avg. Test Loss: 0.0026588058099150658\n",
      "Epoch: 696, Avg. Train Loss: 0.002295384508406007, Avg. Test Loss: 0.002656292635947466\n",
      "Epoch: 697, Avg. Train Loss: 0.0022969561098360046, Avg. Test Loss: 0.0026336817536503077\n",
      "Epoch: 698, Avg. Train Loss: 0.0023534517020506913, Avg. Test Loss: 0.0026227745693176985\n",
      "Epoch: 699, Avg. Train Loss: 0.0023254149777511527, Avg. Test Loss: 0.0027222188655287027\n",
      "Epoch: 700, Avg. Train Loss: 0.0022766633544030576, Avg. Test Loss: 0.0026809261180460453\n",
      "Epoch: 701, Avg. Train Loss: 0.0023028484199109464, Avg. Test Loss: 0.0026538169477134943\n",
      "Epoch: 702, Avg. Train Loss: 0.002292664981512136, Avg. Test Loss: 0.0026565156877040863\n",
      "Epoch: 703, Avg. Train Loss: 0.002323254244402051, Avg. Test Loss: 0.002726132981479168\n",
      "Epoch: 704, Avg. Train Loss: 0.0022555015937880027, Avg. Test Loss: 0.0026384470984339714\n",
      "Epoch: 705, Avg. Train Loss: 0.002263583746457169, Avg. Test Loss: 0.0027311407029628754\n",
      "Epoch: 706, Avg. Train Loss: 0.0023261701233338477, Avg. Test Loss: 0.00278040231205523\n",
      "Epoch: 707, Avg. Train Loss: 0.0022675063905067917, Avg. Test Loss: 0.0026255722623318434\n",
      "Epoch: 708, Avg. Train Loss: 0.002283898458361279, Avg. Test Loss: 0.002712444867938757\n",
      "Epoch: 709, Avg. Train Loss: 0.002314430975550136, Avg. Test Loss: 0.002585330046713352\n",
      "Epoch: 710, Avg. Train Loss: 0.0023043720636430173, Avg. Test Loss: 0.002706313505768776\n",
      "Epoch: 711, Avg. Train Loss: 0.002324014701772221, Avg. Test Loss: 0.0027479706332087517\n",
      "Epoch: 712, Avg. Train Loss: 0.002312565742190494, Avg. Test Loss: 0.002634284319356084\n",
      "Epoch: 713, Avg. Train Loss: 0.0022715236504323956, Avg. Test Loss: 0.0026523424312472343\n",
      "Epoch: 714, Avg. Train Loss: 0.0022796775203544734, Avg. Test Loss: 0.002642995910719037\n",
      "Epoch: 715, Avg. Train Loss: 0.0022626694963248663, Avg. Test Loss: 0.0026184269227087498\n",
      "Epoch: 716, Avg. Train Loss: 0.002245838618512417, Avg. Test Loss: 0.0027483301237225533\n",
      "Epoch: 717, Avg. Train Loss: 0.0022532090782945934, Avg. Test Loss: 0.0026806220412254333\n",
      "Epoch: 718, Avg. Train Loss: 0.0022752193008484536, Avg. Test Loss: 0.002590061165392399\n",
      "Epoch: 719, Avg. Train Loss: 0.0022618063931288414, Avg. Test Loss: 0.0026569173205643892\n",
      "Epoch: 720, Avg. Train Loss: 0.0023315491338888575, Avg. Test Loss: 0.0026606665924191475\n",
      "Epoch: 721, Avg. Train Loss: 0.0022758482901249514, Avg. Test Loss: 0.0025942728389054537\n",
      "Epoch: 722, Avg. Train Loss: 0.002256567768622623, Avg. Test Loss: 0.0027206209488213062\n",
      "Epoch: 723, Avg. Train Loss: 0.0022454339642684128, Avg. Test Loss: 0.0027127861976623535\n",
      "Epoch: 724, Avg. Train Loss: 0.0022605471746173014, Avg. Test Loss: 0.002647535642609\n",
      "Epoch: 725, Avg. Train Loss: 0.0022636409469901824, Avg. Test Loss: 0.0026469575241208076\n",
      "Epoch: 726, Avg. Train Loss: 0.002252836094432792, Avg. Test Loss: 0.0026242323219776154\n",
      "Epoch: 727, Avg. Train Loss: 0.002289152005687356, Avg. Test Loss: 0.002964787883684039\n",
      "Epoch: 728, Avg. Train Loss: 0.002317601316716782, Avg. Test Loss: 0.00266276765614748\n",
      "Epoch: 729, Avg. Train Loss: 0.0022381224431270775, Avg. Test Loss: 0.0026526174042373896\n",
      "Epoch: 730, Avg. Train Loss: 0.002263457075757689, Avg. Test Loss: 0.0027964350301772356\n",
      "Epoch: 731, Avg. Train Loss: 0.002421452853352178, Avg. Test Loss: 0.002815874759107828\n",
      "Epoch: 732, Avg. Train Loss: 0.0022863298329676308, Avg. Test Loss: 0.0026087346486747265\n",
      "Epoch: 733, Avg. Train Loss: 0.002315434962944236, Avg. Test Loss: 0.0026410550344735384\n",
      "Epoch: 734, Avg. Train Loss: 0.0022786770416640266, Avg. Test Loss: 0.0026944372802972794\n",
      "Epoch: 735, Avg. Train Loss: 0.002238080252048581, Avg. Test Loss: 0.0027292377781122923\n",
      "Epoch: 736, Avg. Train Loss: 0.002271635809826643, Avg. Test Loss: 0.00265128118917346\n",
      "Epoch: 737, Avg. Train Loss: 0.002293615190442218, Avg. Test Loss: 0.0027903099544346333\n",
      "Epoch: 738, Avg. Train Loss: 0.002282166555740459, Avg. Test Loss: 0.00270430208183825\n",
      "Epoch: 739, Avg. Train Loss: 0.0023501821154685216, Avg. Test Loss: 0.0029260425362735987\n",
      "Epoch: 740, Avg. Train Loss: 0.002441184903863211, Avg. Test Loss: 0.0027484125457704067\n",
      "Epoch: 741, Avg. Train Loss: 0.0023037289529172487, Avg. Test Loss: 0.002659082878381014\n",
      "Epoch: 742, Avg. Train Loss: 0.0022594014799958745, Avg. Test Loss: 0.002679242054000497\n",
      "Epoch: 743, Avg. Train Loss: 0.0022361843879226337, Avg. Test Loss: 0.002665020991116762\n",
      "Epoch: 744, Avg. Train Loss: 0.002254304936328946, Avg. Test Loss: 0.0028042267076671124\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 745, Avg. Train Loss: 0.0023456078867406345, Avg. Test Loss: 0.0025880206376314163\n",
      "Epoch: 746, Avg. Train Loss: 0.0022610313296967813, Avg. Test Loss: 0.0026938177179545164\n",
      "Epoch: 747, Avg. Train Loss: 0.002300818055478293, Avg. Test Loss: 0.0028377212584018707\n",
      "Epoch: 748, Avg. Train Loss: 0.0022625207608609004, Avg. Test Loss: 0.0026994701474905014\n",
      "Epoch: 749, Avg. Train Loss: 0.002255132865853781, Avg. Test Loss: 0.0026220607105642557\n",
      "Epoch: 750, Avg. Train Loss: 0.0023251463236763728, Avg. Test Loss: 0.0026624384336173534\n",
      "Epoch: 751, Avg. Train Loss: 0.00229516982230856, Avg. Test Loss: 0.0027510777581483126\n",
      "Epoch: 752, Avg. Train Loss: 0.0022735992056685823, Avg. Test Loss: 0.0026033129543066025\n",
      "Epoch: 753, Avg. Train Loss: 0.0022224854775379564, Avg. Test Loss: 0.0026667010970413685\n",
      "Epoch: 754, Avg. Train Loss: 0.0022880678704051776, Avg. Test Loss: 0.002716405550017953\n",
      "Epoch: 755, Avg. Train Loss: 0.002293687118867109, Avg. Test Loss: 0.0029075820930302143\n",
      "Epoch: 756, Avg. Train Loss: 0.0022323740007312493, Avg. Test Loss: 0.002580967964604497\n",
      "Epoch: 757, Avg. Train Loss: 0.0022696334121445586, Avg. Test Loss: 0.0025763141456991434\n",
      "Epoch: 758, Avg. Train Loss: 0.002244857651571375, Avg. Test Loss: 0.0027222896460443735\n",
      "Epoch: 759, Avg. Train Loss: 0.0022727478360540644, Avg. Test Loss: 0.0026085060089826584\n",
      "Epoch: 760, Avg. Train Loss: 0.0022211067438082295, Avg. Test Loss: 0.0026293499395251274\n",
      "Epoch: 761, Avg. Train Loss: 0.0022149935884531154, Avg. Test Loss: 0.0025613135658204556\n",
      "Epoch: 762, Avg. Train Loss: 0.0022499844442706468, Avg. Test Loss: 0.0025929929688572884\n",
      "Epoch: 763, Avg. Train Loss: 0.0022391172364180866, Avg. Test Loss: 0.002752311062067747\n",
      "Epoch: 764, Avg. Train Loss: 0.0022981654051258123, Avg. Test Loss: 0.002757508307695389\n",
      "Epoch: 765, Avg. Train Loss: 0.002304200001797357, Avg. Test Loss: 0.0026191435754299164\n",
      "Epoch: 766, Avg. Train Loss: 0.0022589303688471053, Avg. Test Loss: 0.002758362330496311\n",
      "Epoch: 767, Avg. Train Loss: 0.0022371192895915618, Avg. Test Loss: 0.002638254314661026\n",
      "Epoch: 768, Avg. Train Loss: 0.0022332671174216407, Avg. Test Loss: 0.0025961617939174175\n",
      "Epoch: 769, Avg. Train Loss: 0.0022569084973182788, Avg. Test Loss: 0.00276863481849432\n",
      "Epoch: 770, Avg. Train Loss: 0.002248678605483715, Avg. Test Loss: 0.002585169393569231\n",
      "Epoch: 771, Avg. Train Loss: 0.0023267547556653965, Avg. Test Loss: 0.0025666088331490755\n",
      "Epoch: 772, Avg. Train Loss: 0.0022910060956640994, Avg. Test Loss: 0.0027323386166244745\n",
      "Epoch: 773, Avg. Train Loss: 0.0022829880905445923, Avg. Test Loss: 0.002571083838120103\n",
      "Epoch: 774, Avg. Train Loss: 0.0022297243988358005, Avg. Test Loss: 0.002813867758959532\n",
      "Epoch: 775, Avg. Train Loss: 0.002310687069629514, Avg. Test Loss: 0.002765101846307516\n",
      "Epoch: 776, Avg. Train Loss: 0.002255391367429564, Avg. Test Loss: 0.0025662733241915703\n",
      "Epoch: 777, Avg. Train Loss: 0.002272087536470661, Avg. Test Loss: 0.002746684942394495\n",
      "Epoch: 778, Avg. Train Loss: 0.0022551638485733853, Avg. Test Loss: 0.0027242845389992\n",
      "Epoch: 779, Avg. Train Loss: 0.002223703181804266, Avg. Test Loss: 0.002636416582390666\n",
      "Epoch: 780, Avg. Train Loss: 0.002233959046777251, Avg. Test Loss: 0.00258782971650362\n",
      "Epoch: 781, Avg. Train Loss: 0.0022035001798771147, Avg. Test Loss: 0.0026893578469753265\n",
      "Epoch: 782, Avg. Train Loss: 0.002225763987489911, Avg. Test Loss: 0.002650221809744835\n",
      "Epoch: 783, Avg. Train Loss: 0.0022382772430171107, Avg. Test Loss: 0.0025837859138846397\n",
      "Epoch: 784, Avg. Train Loss: 0.0022256671624301476, Avg. Test Loss: 0.002571289660409093\n",
      "Epoch: 785, Avg. Train Loss: 0.0022257899562286776, Avg. Test Loss: 0.0025902355555444956\n",
      "Epoch: 786, Avg. Train Loss: 0.002275447076901274, Avg. Test Loss: 0.0025823633186519146\n",
      "Epoch: 787, Avg. Train Loss: 0.0022025620348231738, Avg. Test Loss: 0.0027028017211705446\n",
      "Epoch: 788, Avg. Train Loss: 0.0022546793225892755, Avg. Test Loss: 0.002768435515463352\n",
      "Epoch: 789, Avg. Train Loss: 0.002243203289676891, Avg. Test Loss: 0.0025649480521678925\n",
      "Epoch: 790, Avg. Train Loss: 0.002185653223721094, Avg. Test Loss: 0.002554371953010559\n",
      "Epoch: 791, Avg. Train Loss: 0.0022339950488923592, Avg. Test Loss: 0.002620039042085409\n",
      "Epoch: 792, Avg. Train Loss: 0.0022363967619576427, Avg. Test Loss: 0.0026589203625917435\n",
      "Epoch: 793, Avg. Train Loss: 0.0023167138529378312, Avg. Test Loss: 0.002643297426402569\n",
      "Epoch: 794, Avg. Train Loss: 0.0022291670293482237, Avg. Test Loss: 0.0025684961583465338\n",
      "Epoch: 795, Avg. Train Loss: 0.00227117593681743, Avg. Test Loss: 0.002596555044874549\n",
      "Epoch: 796, Avg. Train Loss: 0.002275716865348608, Avg. Test Loss: 0.002661046339198947\n",
      "Epoch: 797, Avg. Train Loss: 0.0022264930776991817, Avg. Test Loss: 0.0028025684878230095\n",
      "Epoch: 798, Avg. Train Loss: 0.002248277511382692, Avg. Test Loss: 0.002699989825487137\n",
      "Epoch: 799, Avg. Train Loss: 0.002206179519118958, Avg. Test Loss: 0.002600202802568674\n",
      "Epoch: 800, Avg. Train Loss: 0.0022495083814097006, Avg. Test Loss: 0.0025610330048948526\n",
      "Epoch: 801, Avg. Train Loss: 0.0022036140557205263, Avg. Test Loss: 0.0026938256341964006\n",
      "Epoch: 802, Avg. Train Loss: 0.0022489394299512687, Avg. Test Loss: 0.0026595345698297024\n",
      "Epoch: 803, Avg. Train Loss: 0.0023368183945760477, Avg. Test Loss: 0.002685748739168048\n",
      "Epoch: 804, Avg. Train Loss: 0.002230698914202147, Avg. Test Loss: 0.0026251249946653843\n",
      "Epoch: 805, Avg. Train Loss: 0.002230398957942461, Avg. Test Loss: 0.002853787736967206\n",
      "Epoch: 806, Avg. Train Loss: 0.0022536551601491693, Avg. Test Loss: 0.0026688138023018837\n",
      "Epoch: 807, Avg. Train Loss: 0.0022032486632206413, Avg. Test Loss: 0.0027274969033896923\n",
      "Epoch: 808, Avg. Train Loss: 0.0022404715093935646, Avg. Test Loss: 0.0025626833084970713\n",
      "Epoch: 809, Avg. Train Loss: 0.0022141660271255774, Avg. Test Loss: 0.002559853717684746\n",
      "Epoch: 810, Avg. Train Loss: 0.0022097413108662462, Avg. Test Loss: 0.0026298421435058117\n",
      "Epoch: 811, Avg. Train Loss: 0.002223816992671684, Avg. Test Loss: 0.002878304570913315\n",
      "Epoch: 812, Avg. Train Loss: 0.002256097282867792, Avg. Test Loss: 0.0026688033249229193\n",
      "Epoch: 813, Avg. Train Loss: 0.002268207974212114, Avg. Test Loss: 0.0026817272882908583\n",
      "Epoch: 814, Avg. Train Loss: 0.002251712155939881, Avg. Test Loss: 0.0026175272651016712\n",
      "Epoch: 815, Avg. Train Loss: 0.00226770322174267, Avg. Test Loss: 0.0028244187124073505\n",
      "Epoch: 816, Avg. Train Loss: 0.0023353805516434963, Avg. Test Loss: 0.002705387771129608\n",
      "Epoch: 817, Avg. Train Loss: 0.0022029730242265518, Avg. Test Loss: 0.0025741965509951115\n",
      "Epoch: 818, Avg. Train Loss: 0.0022148382958284644, Avg. Test Loss: 0.0025868117809295654\n",
      "Epoch: 819, Avg. Train Loss: 0.00221926711369739, Avg. Test Loss: 0.0026165544986724854\n",
      "Epoch: 820, Avg. Train Loss: 0.00222744406904852, Avg. Test Loss: 0.002588374074548483\n",
      "Epoch: 821, Avg. Train Loss: 0.0022604145965170724, Avg. Test Loss: 0.0026264172047376633\n",
      "Epoch: 822, Avg. Train Loss: 0.002203574896855063, Avg. Test Loss: 0.0025815297849476337\n",
      "Epoch: 823, Avg. Train Loss: 0.002204981118137407, Avg. Test Loss: 0.002619283739477396\n",
      "Epoch: 824, Avg. Train Loss: 0.002239583425635342, Avg. Test Loss: 0.002639906480908394\n",
      "Epoch: 825, Avg. Train Loss: 0.0022444857019108047, Avg. Test Loss: 0.0027287364937365055\n",
      "Epoch: 826, Avg. Train Loss: 0.0022155963978188675, Avg. Test Loss: 0.002734298584982753\n",
      "Epoch: 827, Avg. Train Loss: 0.0022107962475613105, Avg. Test Loss: 0.0025946253444999456\n",
      "Epoch: 828, Avg. Train Loss: 0.0022367876439983417, Avg. Test Loss: 0.0026108722668141127\n",
      "Epoch: 829, Avg. Train Loss: 0.002225158500571757, Avg. Test Loss: 0.0029166326858103275\n",
      "Epoch: 830, Avg. Train Loss: 0.0023116196023820097, Avg. Test Loss: 0.002619438571855426\n",
      "Epoch: 831, Avg. Train Loss: 0.002181275222493812, Avg. Test Loss: 0.002592424862086773\n",
      "Epoch: 832, Avg. Train Loss: 0.002253985081171227, Avg. Test Loss: 0.002748070750385523\n",
      "Epoch: 833, Avg. Train Loss: 0.002218037740825567, Avg. Test Loss: 0.0025626502465456724\n",
      "Epoch: 834, Avg. Train Loss: 0.00223724135782483, Avg. Test Loss: 0.0027720483485609293\n",
      "Epoch: 835, Avg. Train Loss: 0.0022155071072670262, Avg. Test Loss: 0.0027730183210223913\n",
      "Epoch: 836, Avg. Train Loss: 0.0022210766842892, Avg. Test Loss: 0.002619088627398014\n",
      "Epoch: 837, Avg. Train Loss: 0.002230173087852119, Avg. Test Loss: 0.0027124816551804543\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 838, Avg. Train Loss: 0.0022582453702641434, Avg. Test Loss: 0.002600220264866948\n",
      "Epoch: 839, Avg. Train Loss: 0.002284304834469113, Avg. Test Loss: 0.002850667806342244\n",
      "Epoch: 840, Avg. Train Loss: 0.002219583942056742, Avg. Test Loss: 0.002679085126146674\n",
      "Epoch: 841, Avg. Train Loss: 0.0021861501736566424, Avg. Test Loss: 0.00255255913361907\n",
      "Epoch: 842, Avg. Train Loss: 0.0021735311913585595, Avg. Test Loss: 0.0026423046365380287\n",
      "Epoch: 843, Avg. Train Loss: 0.002186108686484743, Avg. Test Loss: 0.0026918291114270687\n",
      "Epoch: 844, Avg. Train Loss: 0.0021883353542233278, Avg. Test Loss: 0.0026198667474091053\n",
      "Epoch: 845, Avg. Train Loss: 0.0022084449206717137, Avg. Test Loss: 0.0026221114676445723\n",
      "Epoch: 846, Avg. Train Loss: 0.002234196571936441, Avg. Test Loss: 0.0028197825886309147\n",
      "Epoch: 847, Avg. Train Loss: 0.00228228330135692, Avg. Test Loss: 0.0025444719940423965\n",
      "Epoch: 848, Avg. Train Loss: 0.0021536472838285356, Avg. Test Loss: 0.0025833388790488243\n",
      "Epoch: 849, Avg. Train Loss: 0.002234846364360216, Avg. Test Loss: 0.0025787565391510725\n",
      "Epoch: 850, Avg. Train Loss: 0.0021910942159593105, Avg. Test Loss: 0.0026474320329725742\n",
      "Epoch: 851, Avg. Train Loss: 0.002225946754130513, Avg. Test Loss: 0.002574455225840211\n",
      "Epoch: 852, Avg. Train Loss: 0.0022459969271061034, Avg. Test Loss: 0.002681742189452052\n",
      "Epoch: 853, Avg. Train Loss: 0.0022474430869658325, Avg. Test Loss: 0.0026309313252568245\n",
      "Epoch: 854, Avg. Train Loss: 0.0021780324141429954, Avg. Test Loss: 0.0025999629870057106\n",
      "Epoch: 855, Avg. Train Loss: 0.0021851442207387367, Avg. Test Loss: 0.00259230169467628\n",
      "Epoch: 856, Avg. Train Loss: 0.002209035127402045, Avg. Test Loss: 0.002598368562757969\n",
      "Epoch: 857, Avg. Train Loss: 0.0021752345234935366, Avg. Test Loss: 0.002560599707067013\n",
      "Epoch: 858, Avg. Train Loss: 0.0022374531254172325, Avg. Test Loss: 0.0026498965453356504\n",
      "Epoch: 859, Avg. Train Loss: 0.0022348811860781075, Avg. Test Loss: 0.0026024484541267157\n",
      "Epoch: 860, Avg. Train Loss: 0.002274952801810794, Avg. Test Loss: 0.002759138587862253\n",
      "Epoch: 861, Avg. Train Loss: 0.0022732463210474612, Avg. Test Loss: 0.0026599583216011524\n",
      "Epoch: 862, Avg. Train Loss: 0.002165911897886978, Avg. Test Loss: 0.002610913012176752\n",
      "Epoch: 863, Avg. Train Loss: 0.00219458352427843, Avg. Test Loss: 0.002703289268538356\n",
      "Epoch: 864, Avg. Train Loss: 0.002204932689363527, Avg. Test Loss: 0.0025462035555392504\n",
      "Epoch: 865, Avg. Train Loss: 0.0021578157916231906, Avg. Test Loss: 0.0026106112636625767\n",
      "Epoch: 866, Avg. Train Loss: 0.0022250099871091024, Avg. Test Loss: 0.00267214747145772\n",
      "Epoch: 867, Avg. Train Loss: 0.00219623091479027, Avg. Test Loss: 0.0025744657032191753\n",
      "Epoch: 868, Avg. Train Loss: 0.002154998765543623, Avg. Test Loss: 0.0026076168287545443\n",
      "Epoch: 869, Avg. Train Loss: 0.0021744814002886415, Avg. Test Loss: 0.0025798261631280184\n",
      "Epoch: 870, Avg. Train Loss: 0.0021638941604557424, Avg. Test Loss: 0.0027702231891453266\n",
      "Epoch: 871, Avg. Train Loss: 0.0022794536563979333, Avg. Test Loss: 0.0026295208372175694\n",
      "Epoch: 872, Avg. Train Loss: 0.002187755803555943, Avg. Test Loss: 0.002551996149122715\n",
      "Epoch: 873, Avg. Train Loss: 0.002212058249211242, Avg. Test Loss: 0.002600317355245352\n",
      "Epoch: 874, Avg. Train Loss: 0.0021673758665836135, Avg. Test Loss: 0.002582782646641135\n",
      "Epoch: 875, Avg. Train Loss: 0.002241862899905374, Avg. Test Loss: 0.002602504100650549\n",
      "Epoch: 876, Avg. Train Loss: 0.0021705641140511564, Avg. Test Loss: 0.002575547667220235\n",
      "Epoch: 877, Avg. Train Loss: 0.0021772444177808803, Avg. Test Loss: 0.0027060569263994694\n",
      "Epoch: 878, Avg. Train Loss: 0.0022933114872335696, Avg. Test Loss: 0.0025862667243927717\n",
      "Epoch: 879, Avg. Train Loss: 0.0022041079003450484, Avg. Test Loss: 0.002757948124781251\n",
      "Epoch: 880, Avg. Train Loss: 0.002153973403754969, Avg. Test Loss: 0.0026809179689735174\n",
      "Epoch: 881, Avg. Train Loss: 0.002198323593908098, Avg. Test Loss: 0.002573952544480562\n",
      "Epoch: 882, Avg. Train Loss: 0.002215042255472305, Avg. Test Loss: 0.0025556625332683325\n",
      "Epoch: 883, Avg. Train Loss: 0.002220904698248866, Avg. Test Loss: 0.002549621509388089\n",
      "Epoch: 884, Avg. Train Loss: 0.0021998133770255155, Avg. Test Loss: 0.0029472215101122856\n",
      "Epoch: 885, Avg. Train Loss: 0.002229519415820061, Avg. Test Loss: 0.0025328216142952442\n",
      "Epoch: 886, Avg. Train Loss: 0.0021861705652892935, Avg. Test Loss: 0.0025379417929798365\n",
      "Epoch: 887, Avg. Train Loss: 0.0021929943955741648, Avg. Test Loss: 0.002613946795463562\n",
      "Epoch: 888, Avg. Train Loss: 0.002174910404286239, Avg. Test Loss: 0.002647045999765396\n",
      "Epoch: 889, Avg. Train Loss: 0.002171267181374999, Avg. Test Loss: 0.0025688582099974155\n",
      "Epoch: 890, Avg. Train Loss: 0.002200081887611643, Avg. Test Loss: 0.0026235722471028566\n",
      "Epoch: 891, Avg. Train Loss: 0.0021803880835948295, Avg. Test Loss: 0.002532191574573517\n",
      "Epoch: 892, Avg. Train Loss: 0.002187127756431352, Avg. Test Loss: 0.002600245177745819\n",
      "Epoch: 893, Avg. Train Loss: 0.0021694363663406217, Avg. Test Loss: 0.0025330178905278444\n",
      "Epoch: 894, Avg. Train Loss: 0.002185905246648851, Avg. Test Loss: 0.002543309237807989\n",
      "Epoch: 895, Avg. Train Loss: 0.002190420136050603, Avg. Test Loss: 0.0026001620572060347\n",
      "Epoch: 896, Avg. Train Loss: 0.0021795863339807405, Avg. Test Loss: 0.002556087449193001\n",
      "Epoch: 897, Avg. Train Loss: 0.002164362198781482, Avg. Test Loss: 0.0027360597159713507\n",
      "Epoch: 898, Avg. Train Loss: 0.0022098530506238687, Avg. Test Loss: 0.0026988491881638765\n",
      "Epoch: 899, Avg. Train Loss: 0.0021762789990536348, Avg. Test Loss: 0.0027858628891408443\n",
      "Epoch: 900, Avg. Train Loss: 0.0022146989575175698, Avg. Test Loss: 0.002598862163722515\n",
      "Epoch: 901, Avg. Train Loss: 0.002157726002922065, Avg. Test Loss: 0.0025224783457815647\n",
      "Epoch: 902, Avg. Train Loss: 0.0022152103808556877, Avg. Test Loss: 0.002677490934729576\n",
      "Epoch: 903, Avg. Train Loss: 0.00229303847976722, Avg. Test Loss: 0.0027188698295503855\n",
      "Epoch: 904, Avg. Train Loss: 0.002183104580983, Avg. Test Loss: 0.0025221353862434626\n",
      "Epoch: 905, Avg. Train Loss: 0.0021448157873914337, Avg. Test Loss: 0.0026261708699166775\n",
      "Epoch: 906, Avg. Train Loss: 0.00215659188756416, Avg. Test Loss: 0.0025816806592047215\n",
      "Epoch: 907, Avg. Train Loss: 0.0021569250248979, Avg. Test Loss: 0.0027213329449295998\n",
      "Epoch: 908, Avg. Train Loss: 0.0021840700078322446, Avg. Test Loss: 0.002533211139962077\n",
      "Epoch: 909, Avg. Train Loss: 0.0021441540854095025, Avg. Test Loss: 0.0026235715486109257\n",
      "Epoch: 910, Avg. Train Loss: 0.0022089113670856106, Avg. Test Loss: 0.002625732682645321\n",
      "Epoch: 911, Avg. Train Loss: 0.0022743874944226687, Avg. Test Loss: 0.0026261787861585617\n",
      "Epoch: 912, Avg. Train Loss: 0.0022710557285219777, Avg. Test Loss: 0.002814781852066517\n",
      "Epoch: 913, Avg. Train Loss: 0.00219439618495228, Avg. Test Loss: 0.002524965675547719\n",
      "Epoch: 914, Avg. Train Loss: 0.0021841707314516224, Avg. Test Loss: 0.0025953829754143953\n",
      "Epoch: 915, Avg. Train Loss: 0.002186028584621327, Avg. Test Loss: 0.0025862629991024733\n",
      "Epoch: 916, Avg. Train Loss: 0.002180498992201201, Avg. Test Loss: 0.0026936670765280724\n",
      "Epoch: 917, Avg. Train Loss: 0.0021964145315334547, Avg. Test Loss: 0.002585173584520817\n",
      "Epoch: 918, Avg. Train Loss: 0.002231611529105278, Avg. Test Loss: 0.0027214111760258675\n",
      "Epoch: 919, Avg. Train Loss: 0.0021762924544989717, Avg. Test Loss: 0.0026192530058324337\n",
      "Epoch: 920, Avg. Train Loss: 0.0021866875494895286, Avg. Test Loss: 0.0025183516554534435\n",
      "Epoch: 921, Avg. Train Loss: 0.0021803759655720273, Avg. Test Loss: 0.002639959566295147\n",
      "Epoch: 922, Avg. Train Loss: 0.002214203355833888, Avg. Test Loss: 0.002660447033122182\n",
      "Epoch: 923, Avg. Train Loss: 0.0021912623088546964, Avg. Test Loss: 0.0026566858869045973\n",
      "Epoch: 924, Avg. Train Loss: 0.0021765450297226738, Avg. Test Loss: 0.0025718356482684612\n",
      "Epoch: 925, Avg. Train Loss: 0.0022280177799984813, Avg. Test Loss: 0.002551776124164462\n",
      "Epoch: 926, Avg. Train Loss: 0.0021978204008624995, Avg. Test Loss: 0.0027029700577259064\n",
      "Epoch: 927, Avg. Train Loss: 0.0021551839714913173, Avg. Test Loss: 0.0026447810232639313\n",
      "Epoch: 928, Avg. Train Loss: 0.0021531784847422047, Avg. Test Loss: 0.002570486394688487\n",
      "Epoch: 929, Avg. Train Loss: 0.0022153018183226503, Avg. Test Loss: 0.0028809283394366503\n",
      "Epoch: 930, Avg. Train Loss: 0.0021959433635306913, Avg. Test Loss: 0.002592869335785508\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 931, Avg. Train Loss: 0.002170796866182151, Avg. Test Loss: 0.0025786336045712233\n",
      "Epoch: 932, Avg. Train Loss: 0.002155030517145818, Avg. Test Loss: 0.00258832098916173\n",
      "Epoch: 933, Avg. Train Loss: 0.0021366467374528565, Avg. Test Loss: 0.002636638004332781\n",
      "Epoch: 934, Avg. Train Loss: 0.0021654289746440426, Avg. Test Loss: 0.002587339375168085\n",
      "Epoch: 935, Avg. Train Loss: 0.002153046927306541, Avg. Test Loss: 0.0025659622624516487\n",
      "Epoch: 936, Avg. Train Loss: 0.002161615392799641, Avg. Test Loss: 0.002627284498885274\n",
      "Epoch: 937, Avg. Train Loss: 0.0021296484439178955, Avg. Test Loss: 0.0026309718377888203\n",
      "Epoch: 938, Avg. Train Loss: 0.0021874523061046073, Avg. Test Loss: 0.0025902236811816692\n",
      "Epoch: 939, Avg. Train Loss: 0.0021808304482811066, Avg. Test Loss: 0.0026008673012256622\n",
      "Epoch: 940, Avg. Train Loss: 0.0022238878110900175, Avg. Test Loss: 0.002510880818590522\n",
      "Epoch: 941, Avg. Train Loss: 0.002192911905842985, Avg. Test Loss: 0.0026957171503454447\n",
      "Epoch: 942, Avg. Train Loss: 0.002144736730558581, Avg. Test Loss: 0.0025834711268544197\n",
      "Epoch: 943, Avg. Train Loss: 0.0021707481666749648, Avg. Test Loss: 0.002646175678819418\n",
      "Epoch: 944, Avg. Train Loss: 0.0021615826909235397, Avg. Test Loss: 0.002591553144156933\n",
      "Epoch: 945, Avg. Train Loss: 0.0021266465800879306, Avg. Test Loss: 0.0025638798251748085\n",
      "Epoch: 946, Avg. Train Loss: 0.002144872963558449, Avg. Test Loss: 0.0025207558646798134\n",
      "Epoch: 947, Avg. Train Loss: 0.0022765981564081684, Avg. Test Loss: 0.0026150846388190985\n",
      "Epoch: 948, Avg. Train Loss: 0.002206217668149187, Avg. Test Loss: 0.0026050424203276634\n",
      "Epoch: 949, Avg. Train Loss: 0.0021358507950681935, Avg. Test Loss: 0.0025183078832924366\n",
      "Epoch: 950, Avg. Train Loss: 0.0021304923602444834, Avg. Test Loss: 0.002519690664485097\n",
      "Epoch: 951, Avg. Train Loss: 0.00212138929393489, Avg. Test Loss: 0.00256447889842093\n",
      "Epoch: 952, Avg. Train Loss: 0.0021408141108749563, Avg. Test Loss: 0.0025950532872229815\n",
      "Epoch: 953, Avg. Train Loss: 0.0022017835439074526, Avg. Test Loss: 0.002622750122100115\n",
      "Epoch: 954, Avg. Train Loss: 0.0021746812529082216, Avg. Test Loss: 0.002709281165152788\n",
      "Epoch: 955, Avg. Train Loss: 0.002164203253964525, Avg. Test Loss: 0.0027483112644404173\n",
      "Epoch: 956, Avg. Train Loss: 0.0021718496640840937, Avg. Test Loss: 0.002594773191958666\n",
      "Epoch: 957, Avg. Train Loss: 0.0022051585405025373, Avg. Test Loss: 0.003005013335496187\n",
      "Epoch: 958, Avg. Train Loss: 0.0022015400869815154, Avg. Test Loss: 0.002680992940440774\n",
      "Epoch: 959, Avg. Train Loss: 0.0021797737464048835, Avg. Test Loss: 0.0025231209583580494\n",
      "Epoch: 960, Avg. Train Loss: 0.002178644682930479, Avg. Test Loss: 0.0025132012087851763\n",
      "Epoch: 961, Avg. Train Loss: 0.002241478003778083, Avg. Test Loss: 0.0026355753652751446\n",
      "Epoch: 962, Avg. Train Loss: 0.002148302326108827, Avg. Test Loss: 0.0025137062184512615\n",
      "Epoch: 963, Avg. Train Loss: 0.002137326857421634, Avg. Test Loss: 0.00257050315849483\n",
      "Epoch: 964, Avg. Train Loss: 0.0021585941498795916, Avg. Test Loss: 0.0025945939123630524\n",
      "Epoch: 965, Avg. Train Loss: 0.0021307347667251907, Avg. Test Loss: 0.002495776629075408\n",
      "Epoch: 966, Avg. Train Loss: 0.0021029188741691586, Avg. Test Loss: 0.002561773406341672\n",
      "Epoch: 967, Avg. Train Loss: 0.0021130252239662545, Avg. Test Loss: 0.002536060521379113\n",
      "Epoch: 968, Avg. Train Loss: 0.0021337057263482104, Avg. Test Loss: 0.002668243832886219\n",
      "Epoch: 969, Avg. Train Loss: 0.0021424007569548, Avg. Test Loss: 0.002602623775601387\n",
      "Epoch: 970, Avg. Train Loss: 0.00226574118498193, Avg. Test Loss: 0.0025230885948985815\n",
      "Epoch: 971, Avg. Train Loss: 0.002146840653230631, Avg. Test Loss: 0.0026613848749548197\n",
      "Epoch: 972, Avg. Train Loss: 0.002139015981472682, Avg. Test Loss: 0.002502369461581111\n",
      "Epoch: 973, Avg. Train Loss: 0.002150073466107769, Avg. Test Loss: 0.0027019991539418697\n",
      "Epoch: 974, Avg. Train Loss: 0.00219489753430406, Avg. Test Loss: 0.0025218448136001825\n",
      "Epoch: 975, Avg. Train Loss: 0.0021141915403436436, Avg. Test Loss: 0.002603017259389162\n",
      "Epoch: 976, Avg. Train Loss: 0.0021879455307498574, Avg. Test Loss: 0.002557555679231882\n",
      "Epoch: 977, Avg. Train Loss: 0.002116319317327336, Avg. Test Loss: 0.00258239614777267\n",
      "Epoch: 978, Avg. Train Loss: 0.0021373849973992205, Avg. Test Loss: 0.002585670445114374\n",
      "Epoch: 979, Avg. Train Loss: 0.002197910349296276, Avg. Test Loss: 0.002538051689043641\n",
      "Epoch: 980, Avg. Train Loss: 0.002164095767427149, Avg. Test Loss: 0.002591897500678897\n",
      "Epoch: 981, Avg. Train Loss: 0.0021607041721730387, Avg. Test Loss: 0.0026197077240794897\n",
      "Epoch: 982, Avg. Train Loss: 0.0021601986454063376, Avg. Test Loss: 0.0025982826482504606\n",
      "Epoch: 983, Avg. Train Loss: 0.0021532823380386065, Avg. Test Loss: 0.0026833771262317896\n",
      "Epoch: 984, Avg. Train Loss: 0.0021312022256816544, Avg. Test Loss: 0.0025099117774516344\n",
      "Epoch: 985, Avg. Train Loss: 0.0021446445512823585, Avg. Test Loss: 0.0025142687372863293\n",
      "Epoch: 986, Avg. Train Loss: 0.0021149673401702975, Avg. Test Loss: 0.0025423746556043625\n",
      "Epoch: 987, Avg. Train Loss: 0.0021682180556317054, Avg. Test Loss: 0.002632301300764084\n",
      "Epoch: 988, Avg. Train Loss: 0.002137066763934008, Avg. Test Loss: 0.002528735902160406\n",
      "Epoch: 989, Avg. Train Loss: 0.002132638479409696, Avg. Test Loss: 0.0025332183577120304\n",
      "Epoch: 990, Avg. Train Loss: 0.002142379217412929, Avg. Test Loss: 0.002695033559575677\n",
      "Epoch: 991, Avg. Train Loss: 0.0021615714094666547, Avg. Test Loss: 0.0024950371589511633\n",
      "Epoch: 992, Avg. Train Loss: 0.00215600720108595, Avg. Test Loss: 0.002707189181819558\n",
      "Epoch: 993, Avg. Train Loss: 0.002145348081560156, Avg. Test Loss: 0.0026050808373838663\n",
      "Epoch: 994, Avg. Train Loss: 0.0021629106865242815, Avg. Test Loss: 0.0026616055984050035\n",
      "Epoch: 995, Avg. Train Loss: 0.0021777899914182898, Avg. Test Loss: 0.0025780904106795788\n",
      "Epoch: 996, Avg. Train Loss: 0.0021330707782316344, Avg. Test Loss: 0.0025266227312386036\n",
      "Epoch: 997, Avg. Train Loss: 0.0021266724026307118, Avg. Test Loss: 0.002575555117800832\n",
      "Epoch: 998, Avg. Train Loss: 0.0021927153615844113, Avg. Test Loss: 0.0026545338332653046\n",
      "Epoch: 999, Avg. Train Loss: 0.0021271968211675455, Avg. Test Loss: 0.0025532483123242855\n",
      "Epoch: 1000, Avg. Train Loss: 0.0020920427131661495, Avg. Test Loss: 0.002537531079724431\n",
      "Epoch: 1001, Avg. Train Loss: 0.0021319374507076517, Avg. Test Loss: 0.0025277535896748304\n",
      "Epoch: 1002, Avg. Train Loss: 0.0021579630732493, Avg. Test Loss: 0.0026116869412362576\n",
      "Epoch: 1003, Avg. Train Loss: 0.0021337695029932397, Avg. Test Loss: 0.0027181871701031923\n",
      "Epoch: 1004, Avg. Train Loss: 0.0022392504155462566, Avg. Test Loss: 0.0025085678789764643\n",
      "Epoch: 1005, Avg. Train Loss: 0.0021679606451111477, Avg. Test Loss: 0.002505822805687785\n",
      "Epoch: 1006, Avg. Train Loss: 0.0021658269174093772, Avg. Test Loss: 0.002584032714366913\n",
      "Epoch: 1007, Avg. Train Loss: 0.002147611850591073, Avg. Test Loss: 0.002573183039203286\n",
      "Epoch: 1008, Avg. Train Loss: 0.0021456344957398467, Avg. Test Loss: 0.0025574546307325363\n",
      "Epoch: 1009, Avg. Train Loss: 0.0021222390364422357, Avg. Test Loss: 0.002768290229141712\n",
      "Epoch: 1010, Avg. Train Loss: 0.0021880067787458037, Avg. Test Loss: 0.002553041558712721\n",
      "Epoch: 1011, Avg. Train Loss: 0.0021238034363662782, Avg. Test Loss: 0.002644236432388425\n",
      "Epoch: 1012, Avg. Train Loss: 0.0021682297377738843, Avg. Test Loss: 0.0026466890703886747\n",
      "Epoch: 1013, Avg. Train Loss: 0.00214504363924958, Avg. Test Loss: 0.002502553863450885\n",
      "Epoch: 1014, Avg. Train Loss: 0.0021266857497827256, Avg. Test Loss: 0.0026536055374890566\n",
      "Epoch: 1015, Avg. Train Loss: 0.0021443676290123963, Avg. Test Loss: 0.002639951417222619\n",
      "Epoch: 1016, Avg. Train Loss: 0.0022037565913917713, Avg. Test Loss: 0.0026544667780399323\n",
      "Epoch: 1017, Avg. Train Loss: 0.002195824184021804, Avg. Test Loss: 0.002518549095839262\n",
      "Epoch: 1018, Avg. Train Loss: 0.002089292149406013, Avg. Test Loss: 0.0025669168680906296\n",
      "Epoch: 1019, Avg. Train Loss: 0.0021805013665322994, Avg. Test Loss: 0.002496039494872093\n",
      "Epoch: 1020, Avg. Train Loss: 0.0021209097548582872, Avg. Test Loss: 0.002545150462538004\n",
      "Epoch: 1021, Avg. Train Loss: 0.0021372419554566923, Avg. Test Loss: 0.0026127565652132034\n",
      "Epoch: 1022, Avg. Train Loss: 0.002138684712198758, Avg. Test Loss: 0.002627476118505001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1023, Avg. Train Loss: 0.002129837237081902, Avg. Test Loss: 0.0025877859443426132\n",
      "Epoch: 1024, Avg. Train Loss: 0.002125507529261847, Avg. Test Loss: 0.0025054169818758965\n",
      "Epoch: 1025, Avg. Train Loss: 0.002110693181410085, Avg. Test Loss: 0.002498846035450697\n",
      "Epoch: 1026, Avg. Train Loss: 0.0021387351931311015, Avg. Test Loss: 0.0025948877446353436\n",
      "Epoch: 1027, Avg. Train Loss: 0.002100621666867546, Avg. Test Loss: 0.0025757811963558197\n",
      "Epoch: 1028, Avg. Train Loss: 0.0021337011347113306, Avg. Test Loss: 0.0027037805411964655\n",
      "Epoch: 1029, Avg. Train Loss: 0.0022102681091488445, Avg. Test Loss: 0.0025311510544270277\n",
      "Epoch: 1030, Avg. Train Loss: 0.002097434940921186, Avg. Test Loss: 0.0025027901865541935\n",
      "Epoch: 1031, Avg. Train Loss: 0.002159072765755619, Avg. Test Loss: 0.002559244865551591\n",
      "Epoch: 1032, Avg. Train Loss: 0.0021291906555551427, Avg. Test Loss: 0.0025573873426765203\n",
      "Epoch: 1033, Avg. Train Loss: 0.0021170936172914714, Avg. Test Loss: 0.0025875091087073088\n",
      "Epoch: 1034, Avg. Train Loss: 0.002137573620001244, Avg. Test Loss: 0.0026302190963178873\n",
      "Epoch: 1035, Avg. Train Loss: 0.0021995394517732567, Avg. Test Loss: 0.0025148624554276466\n",
      "Epoch: 1036, Avg. Train Loss: 0.0021404615754998008, Avg. Test Loss: 0.00265562254935503\n",
      "Epoch: 1037, Avg. Train Loss: 0.0021226763763183424, Avg. Test Loss: 0.0024966683704406023\n",
      "Epoch: 1038, Avg. Train Loss: 0.002062740267341047, Avg. Test Loss: 0.002525910036638379\n",
      "Epoch: 1039, Avg. Train Loss: 0.0021164117077755373, Avg. Test Loss: 0.0025905745569616556\n",
      "Epoch: 1040, Avg. Train Loss: 0.002115951499057024, Avg. Test Loss: 0.002550488105043769\n",
      "Epoch: 1041, Avg. Train Loss: 0.0021000622073188424, Avg. Test Loss: 0.0026243424508720636\n",
      "Epoch: 1042, Avg. Train Loss: 0.0021125682315594235, Avg. Test Loss: 0.0026613164227455854\n",
      "Epoch: 1043, Avg. Train Loss: 0.0021331349663912904, Avg. Test Loss: 0.0025134780444204807\n",
      "Epoch: 1044, Avg. Train Loss: 0.0020937860759278368, Avg. Test Loss: 0.002520476235076785\n",
      "Epoch: 1045, Avg. Train Loss: 0.002134703887561553, Avg. Test Loss: 0.002580859698355198\n",
      "Epoch: 1046, Avg. Train Loss: 0.0021185977925914663, Avg. Test Loss: 0.0025171535089612007\n",
      "Epoch: 1047, Avg. Train Loss: 0.002093261679049668, Avg. Test Loss: 0.0026098552625626326\n",
      "Epoch: 1048, Avg. Train Loss: 0.0021747851116192896, Avg. Test Loss: 0.00253100972622633\n",
      "Epoch: 1049, Avg. Train Loss: 0.002105083248881233, Avg. Test Loss: 0.0025789763312786818\n",
      "Epoch: 1050, Avg. Train Loss: 0.0021013357665736316, Avg. Test Loss: 0.0025720596313476562\n",
      "Epoch: 1051, Avg. Train Loss: 0.002196248044086577, Avg. Test Loss: 0.0027127570938318968\n",
      "Epoch: 1052, Avg. Train Loss: 0.0021102365382492196, Avg. Test Loss: 0.002593147801235318\n",
      "Epoch: 1053, Avg. Train Loss: 0.002121063553035086, Avg. Test Loss: 0.002846206072717905\n",
      "Epoch: 1054, Avg. Train Loss: 0.002120323008099614, Avg. Test Loss: 0.002567250980064273\n",
      "Epoch: 1055, Avg. Train Loss: 0.002123287640685259, Avg. Test Loss: 0.0025177360512316227\n",
      "Epoch: 1056, Avg. Train Loss: 0.0021107425279698745, Avg. Test Loss: 0.0025694044306874275\n",
      "Epoch: 1057, Avg. Train Loss: 0.002208024301284621, Avg. Test Loss: 0.002733422676101327\n",
      "Epoch: 1058, Avg. Train Loss: 0.002151631295334461, Avg. Test Loss: 0.002505954122170806\n",
      "Epoch: 1059, Avg. Train Loss: 0.0020823176452067008, Avg. Test Loss: 0.0025631992612034082\n",
      "Epoch: 1060, Avg. Train Loss: 0.002122122626535075, Avg. Test Loss: 0.002872563898563385\n",
      "Epoch: 1061, Avg. Train Loss: 0.0021190757262195613, Avg. Test Loss: 0.002491181716322899\n",
      "Epoch: 1062, Avg. Train Loss: 0.0021389747352534255, Avg. Test Loss: 0.002855829894542694\n",
      "Epoch: 1063, Avg. Train Loss: 0.002133666627044075, Avg. Test Loss: 0.0026217205449938774\n",
      "Epoch: 1064, Avg. Train Loss: 0.002156219564291627, Avg. Test Loss: 0.0025444836355745792\n",
      "Epoch: 1065, Avg. Train Loss: 0.0021643848293785785, Avg. Test Loss: 0.0026614274829626083\n",
      "Epoch: 1066, Avg. Train Loss: 0.0021279951730786366, Avg. Test Loss: 0.0025679185055196285\n",
      "Epoch: 1067, Avg. Train Loss: 0.002133271296855149, Avg. Test Loss: 0.002586331916972995\n",
      "Epoch: 1068, Avg. Train Loss: 0.002111014406478336, Avg. Test Loss: 0.002504876349121332\n",
      "Epoch: 1069, Avg. Train Loss: 0.002088416976919181, Avg. Test Loss: 0.0024850124027580023\n",
      "Epoch: 1070, Avg. Train Loss: 0.0021107035965203893, Avg. Test Loss: 0.0029142347630113363\n",
      "Epoch: 1071, Avg. Train Loss: 0.002165341438444028, Avg. Test Loss: 0.002750517101958394\n",
      "Epoch: 1072, Avg. Train Loss: 0.0021152998385734335, Avg. Test Loss: 0.002708211774006486\n",
      "Epoch: 1073, Avg. Train Loss: 0.002098775582474678, Avg. Test Loss: 0.002558900974690914\n",
      "Epoch: 1074, Avg. Train Loss: 0.0020908780699205954, Avg. Test Loss: 0.0026629874482750893\n",
      "Epoch: 1075, Avg. Train Loss: 0.00211688197423639, Avg. Test Loss: 0.0025912083219736814\n",
      "Epoch: 1076, Avg. Train Loss: 0.0020641898628064367, Avg. Test Loss: 0.0025624313857406378\n",
      "Epoch: 1077, Avg. Train Loss: 0.0021409824582596503, Avg. Test Loss: 0.002496168250218034\n",
      "Epoch: 1078, Avg. Train Loss: 0.002085291802190071, Avg. Test Loss: 0.0025420808233320713\n",
      "Epoch: 1079, Avg. Train Loss: 0.002118934831192154, Avg. Test Loss: 0.002526613185182214\n",
      "Epoch: 1080, Avg. Train Loss: 0.002078446321362673, Avg. Test Loss: 0.0026568376924842596\n",
      "Epoch: 1081, Avg. Train Loss: 0.002165125233532731, Avg. Test Loss: 0.0027015116065740585\n",
      "Epoch: 1082, Avg. Train Loss: 0.0021793165238747415, Avg. Test Loss: 0.0025044598150998354\n",
      "Epoch: 1083, Avg. Train Loss: 0.002114136532750414, Avg. Test Loss: 0.0025814715772867203\n",
      "Epoch: 1084, Avg. Train Loss: 0.002164399909223755, Avg. Test Loss: 0.002565711969509721\n",
      "Epoch: 1085, Avg. Train Loss: 0.002112371202688231, Avg. Test Loss: 0.0025460785254836082\n",
      "Epoch: 1086, Avg. Train Loss: 0.0020769002230101546, Avg. Test Loss: 0.002517375396564603\n",
      "Epoch: 1087, Avg. Train Loss: 0.00209423519270278, Avg. Test Loss: 0.0025411094538867474\n",
      "Epoch: 1088, Avg. Train Loss: 0.0021478953273143878, Avg. Test Loss: 0.0027146218344569206\n",
      "Epoch: 1089, Avg. Train Loss: 0.0021874496475035366, Avg. Test Loss: 0.00254379422403872\n",
      "Epoch: 1090, Avg. Train Loss: 0.0020990571505281816, Avg. Test Loss: 0.002513354877009988\n",
      "Epoch: 1091, Avg. Train Loss: 0.0020897094793834313, Avg. Test Loss: 0.002523773582652211\n",
      "Epoch: 1092, Avg. Train Loss: 0.00209652159774546, Avg. Test Loss: 0.0025261251721531153\n",
      "Epoch: 1093, Avg. Train Loss: 0.002064243976979755, Avg. Test Loss: 0.0026978454552590847\n",
      "Epoch: 1094, Avg. Train Loss: 0.002114635572747089, Avg. Test Loss: 0.002501598559319973\n",
      "Epoch: 1095, Avg. Train Loss: 0.0021218353324721374, Avg. Test Loss: 0.002527500269934535\n",
      "Epoch: 1096, Avg. Train Loss: 0.0021101873893247442, Avg. Test Loss: 0.002595878206193447\n",
      "Epoch: 1097, Avg. Train Loss: 0.0021908030125074264, Avg. Test Loss: 0.002771313302218914\n",
      "Epoch: 1098, Avg. Train Loss: 0.0021406327114375525, Avg. Test Loss: 0.0024882168509066105\n",
      "Epoch: 1099, Avg. Train Loss: 0.002117853305779051, Avg. Test Loss: 0.0027327819261699915\n",
      "Epoch: 1100, Avg. Train Loss: 0.002173273469494699, Avg. Test Loss: 0.0026472306344658136\n",
      "Epoch: 1101, Avg. Train Loss: 0.0021147096589164333, Avg. Test Loss: 0.0025709576439112425\n",
      "Epoch: 1102, Avg. Train Loss: 0.002091179387968813, Avg. Test Loss: 0.002536294749006629\n",
      "Epoch: 1103, Avg. Train Loss: 0.0020971235949112928, Avg. Test Loss: 0.0025117930490523577\n",
      "Epoch: 1104, Avg. Train Loss: 0.002127984016159073, Avg. Test Loss: 0.0025638097431510687\n",
      "Epoch: 1105, Avg. Train Loss: 0.002062940114545961, Avg. Test Loss: 0.002543428912758827\n",
      "Epoch: 1106, Avg. Train Loss: 0.0021205505702731223, Avg. Test Loss: 0.0025522548239678144\n",
      "Epoch: 1107, Avg. Train Loss: 0.0020932513370373568, Avg. Test Loss: 0.0027414478827267885\n",
      "Epoch: 1108, Avg. Train Loss: 0.002135322472557079, Avg. Test Loss: 0.0028304574079811573\n",
      "Epoch: 1109, Avg. Train Loss: 0.002131891409801536, Avg. Test Loss: 0.0025865170173346996\n",
      "Epoch: 1110, Avg. Train Loss: 0.002095125772622089, Avg. Test Loss: 0.0025790943764150143\n",
      "Epoch: 1111, Avg. Train Loss: 0.0020554293797156492, Avg. Test Loss: 0.0025041087064892054\n",
      "Epoch: 1112, Avg. Train Loss: 0.002075515893222981, Avg. Test Loss: 0.0026509626768529415\n",
      "Epoch: 1113, Avg. Train Loss: 0.002102799927490915, Avg. Test Loss: 0.0025729984045028687\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1114, Avg. Train Loss: 0.002121161398759415, Avg. Test Loss: 0.002537979045882821\n",
      "Epoch: 1115, Avg. Train Loss: 0.0020909682268190175, Avg. Test Loss: 0.002563444199040532\n",
      "Epoch: 1116, Avg. Train Loss: 0.0021395595733422874, Avg. Test Loss: 0.0026207994669675827\n",
      "Epoch: 1117, Avg. Train Loss: 0.002126246030160854, Avg. Test Loss: 0.002616701414808631\n",
      "Epoch: 1118, Avg. Train Loss: 0.002108953156790068, Avg. Test Loss: 0.002552629681304097\n",
      "Epoch: 1119, Avg. Train Loss: 0.002068400902803554, Avg. Test Loss: 0.0025887121446430683\n",
      "Epoch: 1120, Avg. Train Loss: 0.002077106586765758, Avg. Test Loss: 0.0025770924985408783\n",
      "Epoch: 1121, Avg. Train Loss: 0.0020716714559036284, Avg. Test Loss: 0.002811301499605179\n",
      "Epoch: 1122, Avg. Train Loss: 0.002138982548616653, Avg. Test Loss: 0.0026633974630385637\n",
      "Epoch: 1123, Avg. Train Loss: 0.0020672910586865836, Avg. Test Loss: 0.002533819992095232\n",
      "Epoch: 1124, Avg. Train Loss: 0.0021434337480080337, Avg. Test Loss: 0.002548622665926814\n",
      "Epoch: 1125, Avg. Train Loss: 0.0021300110126693927, Avg. Test Loss: 0.00255423691123724\n",
      "Epoch: 1126, Avg. Train Loss: 0.002129358586010545, Avg. Test Loss: 0.0025759125128388405\n",
      "Epoch: 1127, Avg. Train Loss: 0.0020889225361738787, Avg. Test Loss: 0.002526467200368643\n",
      "Epoch: 1128, Avg. Train Loss: 0.0021060412468085457, Avg. Test Loss: 0.0025352737866342068\n",
      "Epoch: 1129, Avg. Train Loss: 0.0020627240585379823, Avg. Test Loss: 0.00264564692042768\n",
      "Epoch: 1130, Avg. Train Loss: 0.002080337065921793, Avg. Test Loss: 0.002508837031200528\n",
      "Epoch: 1131, Avg. Train Loss: 0.002084481941406117, Avg. Test Loss: 0.002588082104921341\n",
      "Epoch: 1132, Avg. Train Loss: 0.0021060970395283644, Avg. Test Loss: 0.00255020335316658\n",
      "Epoch: 1133, Avg. Train Loss: 0.0021067699904791836, Avg. Test Loss: 0.002582013141363859\n",
      "Epoch: 1134, Avg. Train Loss: 0.0021227511339062866, Avg. Test Loss: 0.002580326981842518\n",
      "Epoch: 1135, Avg. Train Loss: 0.002114588335199758, Avg. Test Loss: 0.002586345188319683\n",
      "Epoch: 1136, Avg. Train Loss: 0.0020896050494250864, Avg. Test Loss: 0.0026163191068917513\n",
      "Epoch: 1137, Avg. Train Loss: 0.002080740807794554, Avg. Test Loss: 0.002907924819737673\n",
      "Epoch: 1138, Avg. Train Loss: 0.0021275454715197514, Avg. Test Loss: 0.0025141360238194466\n",
      "Epoch: 1139, Avg. Train Loss: 0.0020916694423270435, Avg. Test Loss: 0.0025389629881829023\n",
      "Epoch: 1140, Avg. Train Loss: 0.0020818923664994017, Avg. Test Loss: 0.002735147485509515\n",
      "Epoch: 1141, Avg. Train Loss: 0.0020927957713950513, Avg. Test Loss: 0.0025259791873395443\n",
      "Epoch: 1142, Avg. Train Loss: 0.0020894529785267834, Avg. Test Loss: 0.0026503789704293013\n",
      "Epoch: 1143, Avg. Train Loss: 0.002105151817505789, Avg. Test Loss: 0.0025235230568796396\n",
      "Epoch: 1144, Avg. Train Loss: 0.002050112553893827, Avg. Test Loss: 0.002534743631258607\n",
      "Epoch: 1145, Avg. Train Loss: 0.002137494343874413, Avg. Test Loss: 0.0028252205811440945\n",
      "Epoch: 1146, Avg. Train Loss: 0.0021244520104901736, Avg. Test Loss: 0.0025283005088567734\n",
      "Epoch: 1147, Avg. Train Loss: 0.0020878050411336645, Avg. Test Loss: 0.002608442446216941\n",
      "Epoch: 1148, Avg. Train Loss: 0.00211918497252343, Avg. Test Loss: 0.002489677630364895\n",
      "Epoch: 1149, Avg. Train Loss: 0.0020763453794643283, Avg. Test Loss: 0.0025781181175261736\n",
      "Epoch: 1150, Avg. Train Loss: 0.002064803257844476, Avg. Test Loss: 0.0025720139965415\n",
      "Epoch: 1151, Avg. Train Loss: 0.002030504634603858, Avg. Test Loss: 0.0024724723771214485\n",
      "Epoch: 1152, Avg. Train Loss: 0.0020881451254840507, Avg. Test Loss: 0.0028626087587326765\n",
      "Epoch: 1153, Avg. Train Loss: 0.0021432155288409354, Avg. Test Loss: 0.0024966641794890165\n",
      "Epoch: 1154, Avg. Train Loss: 0.0021162928964639474, Avg. Test Loss: 0.0029224155005067587\n",
      "Epoch: 1155, Avg. Train Loss: 0.0021201303948886517, Avg. Test Loss: 0.002558700740337372\n",
      "Epoch: 1156, Avg. Train Loss: 0.002056593511275254, Avg. Test Loss: 0.0025362917222082615\n",
      "Epoch: 1157, Avg. Train Loss: 0.002167905748518574, Avg. Test Loss: 0.0028731871861964464\n",
      "Epoch: 1158, Avg. Train Loss: 0.002132655189069378, Avg. Test Loss: 0.00260543473996222\n",
      "Epoch: 1159, Avg. Train Loss: 0.0020979255069653656, Avg. Test Loss: 0.002549075521528721\n",
      "Epoch: 1160, Avg. Train Loss: 0.002092935819027209, Avg. Test Loss: 0.0025094954762607813\n",
      "Epoch: 1161, Avg. Train Loss: 0.0020719285280075533, Avg. Test Loss: 0.0024963782634586096\n",
      "Epoch: 1162, Avg. Train Loss: 0.0020578614501065985, Avg. Test Loss: 0.00254588364623487\n",
      "Epoch: 1163, Avg. Train Loss: 0.002075208193990727, Avg. Test Loss: 0.002599825616925955\n",
      "Epoch: 1164, Avg. Train Loss: 0.0020955072466803844, Avg. Test Loss: 0.002615483244881034\n",
      "Epoch: 1165, Avg. Train Loss: 0.002065993149678201, Avg. Test Loss: 0.002467998769134283\n",
      "Epoch: 1166, Avg. Train Loss: 0.002123223942552888, Avg. Test Loss: 0.0025107567198574543\n",
      "Epoch: 1167, Avg. Train Loss: 0.0021117627187523733, Avg. Test Loss: 0.0025842441245913506\n",
      "Epoch: 1168, Avg. Train Loss: 0.002067745795884971, Avg. Test Loss: 0.0024909533094614744\n",
      "Epoch: 1169, Avg. Train Loss: 0.0020587146959029313, Avg. Test Loss: 0.002683755476027727\n",
      "Epoch: 1170, Avg. Train Loss: 0.0021312896725396778, Avg. Test Loss: 0.0024836070369929075\n",
      "Epoch: 1171, Avg. Train Loss: 0.0020570148047882805, Avg. Test Loss: 0.002465626923367381\n",
      "Epoch: 1172, Avg. Train Loss: 0.0020848527485721334, Avg. Test Loss: 0.0025398433208465576\n",
      "Epoch: 1173, Avg. Train Loss: 0.0020981790135116423, Avg. Test Loss: 0.0024880189448595047\n",
      "Epoch: 1174, Avg. Train Loss: 0.002056295783150681, Avg. Test Loss: 0.0024750935845077038\n",
      "Epoch: 1175, Avg. Train Loss: 0.0021139879326531013, Avg. Test Loss: 0.0025120575446635485\n",
      "Epoch: 1176, Avg. Train Loss: 0.002077204080536788, Avg. Test Loss: 0.00253741885535419\n",
      "Epoch: 1177, Avg. Train Loss: 0.0020688926465376174, Avg. Test Loss: 0.0025141432415694\n",
      "Epoch: 1178, Avg. Train Loss: 0.002074485891065452, Avg. Test Loss: 0.0025110410060733557\n",
      "Epoch: 1179, Avg. Train Loss: 0.0020621931667677883, Avg. Test Loss: 0.002513977000489831\n",
      "Epoch: 1180, Avg. Train Loss: 0.0020989641563447063, Avg. Test Loss: 0.002475127810612321\n",
      "Epoch: 1181, Avg. Train Loss: 0.0020792840974578676, Avg. Test Loss: 0.002520544920116663\n",
      "Epoch: 1182, Avg. Train Loss: 0.0021089465969220495, Avg. Test Loss: 0.002523748204112053\n",
      "Epoch: 1183, Avg. Train Loss: 0.0020872246539003626, Avg. Test Loss: 0.002511417493224144\n",
      "Epoch: 1184, Avg. Train Loss: 0.0020623662574000136, Avg. Test Loss: 0.002475620713084936\n",
      "Epoch: 1185, Avg. Train Loss: 0.0020929954805259787, Avg. Test Loss: 0.0025145793333649635\n",
      "Epoch: 1186, Avg. Train Loss: 0.002101225375067876, Avg. Test Loss: 0.0025595668703317642\n",
      "Epoch: 1187, Avg. Train Loss: 0.0020668681353590516, Avg. Test Loss: 0.0025075168814510107\n",
      "Epoch: 1188, Avg. Train Loss: 0.002062514941424651, Avg. Test Loss: 0.002552722580730915\n",
      "Epoch: 1189, Avg. Train Loss: 0.002105521796227888, Avg. Test Loss: 0.002525563584640622\n",
      "Epoch: 1190, Avg. Train Loss: 0.002035503235082467, Avg. Test Loss: 0.002603445202112198\n",
      "Epoch: 1191, Avg. Train Loss: 0.002098555021464478, Avg. Test Loss: 0.0026223864406347275\n",
      "Epoch: 1192, Avg. Train Loss: 0.002073741883450989, Avg. Test Loss: 0.0026554421056061983\n",
      "Epoch: 1193, Avg. Train Loss: 0.002087290100969894, Avg. Test Loss: 0.0024839001707732677\n",
      "Epoch: 1194, Avg. Train Loss: 0.002067705892502915, Avg. Test Loss: 0.002486285287886858\n",
      "Epoch: 1195, Avg. Train Loss: 0.00207707847111187, Avg. Test Loss: 0.0025083806831389666\n",
      "Epoch: 1196, Avg. Train Loss: 0.002094711277222391, Avg. Test Loss: 0.0026833550073206425\n",
      "Epoch: 1197, Avg. Train Loss: 0.002100872087054128, Avg. Test Loss: 0.0024830831680446863\n",
      "Epoch: 1198, Avg. Train Loss: 0.002062335258436411, Avg. Test Loss: 0.002576148835942149\n",
      "Epoch: 1199, Avg. Train Loss: 0.0020760508189194425, Avg. Test Loss: 0.00271917344070971\n",
      "Epoch: 1200, Avg. Train Loss: 0.002050246122877958, Avg. Test Loss: 0.0025314013473689556\n",
      "Epoch: 1201, Avg. Train Loss: 0.002055926841337147, Avg. Test Loss: 0.0025568625424057245\n",
      "Epoch: 1202, Avg. Train Loss: 0.002041781034190641, Avg. Test Loss: 0.0024788922164589167\n",
      "Epoch: 1203, Avg. Train Loss: 0.0020598106893039373, Avg. Test Loss: 0.0026098350062966347\n",
      "Epoch: 1204, Avg. Train Loss: 0.002058353364402645, Avg. Test Loss: 0.0024524000473320484\n",
      "Epoch: 1205, Avg. Train Loss: 0.0020731669677378135, Avg. Test Loss: 0.0025989420246332884\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1206, Avg. Train Loss: 0.0020808889990845737, Avg. Test Loss: 0.002574136247858405\n",
      "Epoch: 1207, Avg. Train Loss: 0.0020905328199787195, Avg. Test Loss: 0.0025976209435611963\n",
      "Epoch: 1208, Avg. Train Loss: 0.0020867445679424806, Avg. Test Loss: 0.002610632451251149\n",
      "Epoch: 1209, Avg. Train Loss: 0.0020695934776043478, Avg. Test Loss: 0.002538612112402916\n",
      "Epoch: 1210, Avg. Train Loss: 0.0020940783677276136, Avg. Test Loss: 0.002599954605102539\n",
      "Epoch: 1211, Avg. Train Loss: 0.00204037933686185, Avg. Test Loss: 0.002591413911432028\n",
      "Epoch: 1212, Avg. Train Loss: 0.0020904520656480348, Avg. Test Loss: 0.002546547446399927\n",
      "Epoch: 1213, Avg. Train Loss: 0.002050689592156126, Avg. Test Loss: 0.0025117872282862663\n",
      "Epoch: 1214, Avg. Train Loss: 0.002023071123741914, Avg. Test Loss: 0.0024794305209070444\n",
      "Epoch: 1215, Avg. Train Loss: 0.002046267315203887, Avg. Test Loss: 0.002630633534863591\n",
      "Epoch: 1216, Avg. Train Loss: 0.0020889306365144116, Avg. Test Loss: 0.0024575325660407543\n",
      "Epoch: 1217, Avg. Train Loss: 0.0020865900062977576, Avg. Test Loss: 0.0024704106617718935\n",
      "Epoch: 1218, Avg. Train Loss: 0.0020949715602233314, Avg. Test Loss: 0.0026734366547316313\n",
      "Epoch: 1219, Avg. Train Loss: 0.0020592650100805386, Avg. Test Loss: 0.002471472369506955\n",
      "Epoch: 1220, Avg. Train Loss: 0.002121336825820076, Avg. Test Loss: 0.002516478765755892\n",
      "Epoch: 1221, Avg. Train Loss: 0.0020552325484797704, Avg. Test Loss: 0.0026418904308229685\n",
      "Epoch: 1222, Avg. Train Loss: 0.00211035581792943, Avg. Test Loss: 0.0027510011568665504\n",
      "Epoch: 1223, Avg. Train Loss: 0.002066200111754412, Avg. Test Loss: 0.0025938109029084444\n",
      "Epoch: 1224, Avg. Train Loss: 0.0020452435751077396, Avg. Test Loss: 0.0026782327331602573\n",
      "Epoch: 1225, Avg. Train Loss: 0.0021435500090118756, Avg. Test Loss: 0.0024843125138431787\n",
      "Epoch: 1226, Avg. Train Loss: 0.0020634180860767183, Avg. Test Loss: 0.0024928057100623846\n",
      "Epoch: 1227, Avg. Train Loss: 0.0020604183529178764, Avg. Test Loss: 0.00253274361602962\n",
      "Epoch: 1228, Avg. Train Loss: 0.0021383095543485047, Avg. Test Loss: 0.0026525394059717655\n",
      "Epoch: 1229, Avg. Train Loss: 0.0020806241731787492, Avg. Test Loss: 0.002579646883532405\n",
      "Epoch: 1230, Avg. Train Loss: 0.0020588908349921885, Avg. Test Loss: 0.0027605388313531876\n",
      "Epoch: 1231, Avg. Train Loss: 0.00210387647411851, Avg. Test Loss: 0.002705854829400778\n",
      "Epoch: 1232, Avg. Train Loss: 0.002131685525243885, Avg. Test Loss: 0.0024845085572451353\n",
      "Epoch: 1233, Avg. Train Loss: 0.002047301099505709, Avg. Test Loss: 0.002472229767590761\n",
      "Epoch: 1234, Avg. Train Loss: 0.0020322935888543725, Avg. Test Loss: 0.0024605521466583014\n",
      "Epoch: 1235, Avg. Train Loss: 0.002072173427942014, Avg. Test Loss: 0.0025008604861795902\n",
      "Epoch: 1236, Avg. Train Loss: 0.002045216260824439, Avg. Test Loss: 0.0024959289003163576\n",
      "Epoch: 1237, Avg. Train Loss: 0.0020918004907840904, Avg. Test Loss: 0.002562140114605427\n",
      "Epoch: 1238, Avg. Train Loss: 0.0020514008572844918, Avg. Test Loss: 0.002586654620245099\n",
      "Epoch: 1239, Avg. Train Loss: 0.0020619896592485695, Avg. Test Loss: 0.002764658536761999\n",
      "Epoch: 1240, Avg. Train Loss: 0.0021239438305370685, Avg. Test Loss: 0.00246371584944427\n",
      "Epoch: 1241, Avg. Train Loss: 0.0020732597859446393, Avg. Test Loss: 0.0027723039966076612\n",
      "Epoch: 1242, Avg. Train Loss: 0.0020772213181264178, Avg. Test Loss: 0.0024454728700220585\n",
      "Epoch: 1243, Avg. Train Loss: 0.0020145398624198036, Avg. Test Loss: 0.0025617422070354223\n",
      "Epoch: 1244, Avg. Train Loss: 0.0020643583753384475, Avg. Test Loss: 0.0025579289067536592\n",
      "Epoch: 1245, Avg. Train Loss: 0.0020740695763379335, Avg. Test Loss: 0.0025898769963532686\n",
      "Epoch: 1246, Avg. Train Loss: 0.0020887127936666094, Avg. Test Loss: 0.0024728691205382347\n",
      "Epoch: 1247, Avg. Train Loss: 0.002059919724435827, Avg. Test Loss: 0.0025007205549627542\n",
      "Epoch: 1248, Avg. Train Loss: 0.002073550669931222, Avg. Test Loss: 0.002472455380484462\n",
      "Epoch: 1249, Avg. Train Loss: 0.002012194968153571, Avg. Test Loss: 0.0025128100533038378\n",
      "Epoch: 1250, Avg. Train Loss: 0.0021063851376692225, Avg. Test Loss: 0.002791963517665863\n",
      "Epoch: 1251, Avg. Train Loss: 0.0021444376514748085, Avg. Test Loss: 0.0025921748019754887\n",
      "Epoch: 1252, Avg. Train Loss: 0.0020450149922696657, Avg. Test Loss: 0.0025068442337214947\n",
      "Epoch: 1253, Avg. Train Loss: 0.0020591293293766156, Avg. Test Loss: 0.002492721891030669\n",
      "Epoch: 1254, Avg. Train Loss: 0.0020246414283593725, Avg. Test Loss: 0.0024713235907256603\n",
      "Epoch: 1255, Avg. Train Loss: 0.0020814612210013493, Avg. Test Loss: 0.0025734850205481052\n",
      "Epoch: 1256, Avg. Train Loss: 0.002059466116195328, Avg. Test Loss: 0.0025603282265365124\n",
      "Epoch: 1257, Avg. Train Loss: 0.0020315410423114204, Avg. Test Loss: 0.002499509137123823\n",
      "Epoch: 1258, Avg. Train Loss: 0.002018350542003159, Avg. Test Loss: 0.0025241335388273\n",
      "Epoch: 1259, Avg. Train Loss: 0.0020698180292234862, Avg. Test Loss: 0.002654790412634611\n",
      "Epoch: 1260, Avg. Train Loss: 0.0021379774241426655, Avg. Test Loss: 0.002472842112183571\n",
      "Epoch: 1261, Avg. Train Loss: 0.0021943357193755894, Avg. Test Loss: 0.0025345180183649063\n",
      "Epoch: 1262, Avg. Train Loss: 0.0021227198533800454, Avg. Test Loss: 0.002508454490453005\n",
      "Epoch: 1263, Avg. Train Loss: 0.002072851306239013, Avg. Test Loss: 0.0024572762195020914\n",
      "Epoch: 1264, Avg. Train Loss: 0.002024628720137962, Avg. Test Loss: 0.0024961326271295547\n",
      "Epoch: 1265, Avg. Train Loss: 0.0020418097968971315, Avg. Test Loss: 0.002515693660825491\n",
      "Epoch: 1266, Avg. Train Loss: 0.00203120659733581, Avg. Test Loss: 0.0024958562571555376\n",
      "Epoch: 1267, Avg. Train Loss: 0.0020848021024924726, Avg. Test Loss: 0.0024623749777674675\n",
      "Epoch: 1268, Avg. Train Loss: 0.0020423789595275426, Avg. Test Loss: 0.002631522947922349\n",
      "Epoch: 1269, Avg. Train Loss: 0.0020754342156917203, Avg. Test Loss: 0.002536046551540494\n",
      "Epoch: 1270, Avg. Train Loss: 0.0020316456915637437, Avg. Test Loss: 0.002531923819333315\n",
      "Epoch: 1271, Avg. Train Loss: 0.002059908989860221, Avg. Test Loss: 0.002446852857246995\n",
      "Epoch: 1272, Avg. Train Loss: 0.0020388479934745404, Avg. Test Loss: 0.002589224837720394\n",
      "Epoch: 1273, Avg. Train Loss: 0.0021133109748493447, Avg. Test Loss: 0.002537182532250881\n",
      "Epoch: 1274, Avg. Train Loss: 0.002007074840908307, Avg. Test Loss: 0.0024518489371985197\n",
      "Epoch: 1275, Avg. Train Loss: 0.0020416732985786227, Avg. Test Loss: 0.002604808658361435\n",
      "Epoch: 1276, Avg. Train Loss: 0.002070881929898331, Avg. Test Loss: 0.002484616357833147\n",
      "Epoch: 1277, Avg. Train Loss: 0.0020144805718256636, Avg. Test Loss: 0.002478056587278843\n",
      "Epoch: 1278, Avg. Train Loss: 0.002017046054175427, Avg. Test Loss: 0.002608490874990821\n",
      "Epoch: 1279, Avg. Train Loss: 0.002041779296082813, Avg. Test Loss: 0.002442860510200262\n",
      "Epoch: 1280, Avg. Train Loss: 0.0020153823682258643, Avg. Test Loss: 0.0025122861843556166\n",
      "Epoch: 1281, Avg. Train Loss: 0.002098293479553662, Avg. Test Loss: 0.0026045488193631172\n",
      "Epoch: 1282, Avg. Train Loss: 0.0021921615793131467, Avg. Test Loss: 0.002968488959595561\n",
      "Epoch: 1283, Avg. Train Loss: 0.0021199724111749334, Avg. Test Loss: 0.0024747783318161964\n",
      "Epoch: 1284, Avg. Train Loss: 0.00202213587282702, Avg. Test Loss: 0.002547859214246273\n",
      "Epoch: 1285, Avg. Train Loss: 0.0020504313938016464, Avg. Test Loss: 0.0026065821293741465\n",
      "Epoch: 1286, Avg. Train Loss: 0.0020455331514524513, Avg. Test Loss: 0.0025235870853066444\n",
      "Epoch: 1287, Avg. Train Loss: 0.002064491202513319, Avg. Test Loss: 0.0024872315116226673\n",
      "Epoch: 1288, Avg. Train Loss: 0.002042159733232544, Avg. Test Loss: 0.002673756331205368\n",
      "Epoch: 1289, Avg. Train Loss: 0.0020495561698754858, Avg. Test Loss: 0.0026278153527528048\n",
      "Epoch: 1290, Avg. Train Loss: 0.002008265590966614, Avg. Test Loss: 0.002464201068505645\n",
      "Epoch: 1291, Avg. Train Loss: 0.0020437758892428042, Avg. Test Loss: 0.0025161386001855135\n",
      "Epoch: 1292, Avg. Train Loss: 0.0020122196265431338, Avg. Test Loss: 0.0026859657373279333\n",
      "Epoch: 1293, Avg. Train Loss: 0.0020331122917881194, Avg. Test Loss: 0.002561332192271948\n",
      "Epoch: 1294, Avg. Train Loss: 0.002053309175142542, Avg. Test Loss: 0.0024975338019430637\n",
      "Epoch: 1295, Avg. Train Loss: 0.002004809371672224, Avg. Test Loss: 0.0025063278153538704\n",
      "Epoch: 1296, Avg. Train Loss: 0.0020186438571748347, Avg. Test Loss: 0.0024814438074827194\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1297, Avg. Train Loss: 0.002019557300521884, Avg. Test Loss: 0.0025003012269735336\n",
      "Epoch: 1298, Avg. Train Loss: 0.002117087149472777, Avg. Test Loss: 0.0025241889525204897\n",
      "Epoch: 1299, Avg. Train Loss: 0.002046890954790247, Avg. Test Loss: 0.0024501595180481672\n",
      "Epoch: 1300, Avg. Train Loss: 0.002059568859485173, Avg. Test Loss: 0.002622544299811125\n",
      "Epoch: 1301, Avg. Train Loss: 0.00207764568987714, Avg. Test Loss: 0.00260182935744524\n",
      "Epoch: 1302, Avg. Train Loss: 0.002068720757961273, Avg. Test Loss: 0.002964072860777378\n",
      "Epoch: 1303, Avg. Train Loss: 0.002038472711086966, Avg. Test Loss: 0.002498095156624913\n",
      "Epoch: 1304, Avg. Train Loss: 0.0020378261051942096, Avg. Test Loss: 0.002619905397295952\n",
      "Epoch: 1305, Avg. Train Loss: 0.002033945478953768, Avg. Test Loss: 0.002563594840466976\n",
      "Epoch: 1306, Avg. Train Loss: 0.0020567732836054855, Avg. Test Loss: 0.0025619883090257645\n",
      "Epoch: 1307, Avg. Train Loss: 0.002083341729134148, Avg. Test Loss: 0.002663802821189165\n",
      "Epoch: 1308, Avg. Train Loss: 0.0020528088464553274, Avg. Test Loss: 0.0024654283188283443\n",
      "Epoch: 1309, Avg. Train Loss: 0.0020789390532733047, Avg. Test Loss: 0.0025540378410369158\n",
      "Epoch: 1310, Avg. Train Loss: 0.001999397883949758, Avg. Test Loss: 0.002477639354765415\n",
      "Epoch: 1311, Avg. Train Loss: 0.0020818032817048735, Avg. Test Loss: 0.002587316557765007\n",
      "Epoch: 1312, Avg. Train Loss: 0.0021072231736683914, Avg. Test Loss: 0.0028390660881996155\n",
      "Epoch: 1313, Avg. Train Loss: 0.00217804602661365, Avg. Test Loss: 0.0025027168449014425\n",
      "Epoch: 1314, Avg. Train Loss: 0.0020394349486978595, Avg. Test Loss: 0.002618080237880349\n",
      "Epoch: 1315, Avg. Train Loss: 0.002085978081341573, Avg. Test Loss: 0.002440629294142127\n",
      "Epoch: 1316, Avg. Train Loss: 0.0020173381266812254, Avg. Test Loss: 0.00252957153134048\n",
      "Epoch: 1317, Avg. Train Loss: 0.0020838574977418366, Avg. Test Loss: 0.0024975796695798635\n",
      "Epoch: 1318, Avg. Train Loss: 0.00203679823912247, Avg. Test Loss: 0.002526496071368456\n",
      "Epoch: 1319, Avg. Train Loss: 0.0020941521154803247, Avg. Test Loss: 0.0029588048346340656\n",
      "Epoch: 1320, Avg. Train Loss: 0.002087885611365701, Avg. Test Loss: 0.002554738661274314\n",
      "Epoch: 1321, Avg. Train Loss: 0.002031860586125837, Avg. Test Loss: 0.002498094690963626\n",
      "Epoch: 1322, Avg. Train Loss: 0.0020202178058626, Avg. Test Loss: 0.0024689268320798874\n",
      "Epoch: 1323, Avg. Train Loss: 0.0019819235976049026, Avg. Test Loss: 0.0024951216764748096\n",
      "Epoch: 1324, Avg. Train Loss: 0.002123918118994943, Avg. Test Loss: 0.002837998792529106\n",
      "Epoch: 1325, Avg. Train Loss: 0.002132390901922833, Avg. Test Loss: 0.002442887518554926\n",
      "Epoch: 1326, Avg. Train Loss: 0.0020247014742994377, Avg. Test Loss: 0.00254270457662642\n",
      "Epoch: 1327, Avg. Train Loss: 0.0020295595452406033, Avg. Test Loss: 0.002476736670359969\n",
      "Epoch: 1328, Avg. Train Loss: 0.00199978411479225, Avg. Test Loss: 0.0025278227403759956\n",
      "Epoch: 1329, Avg. Train Loss: 0.0020300187982705445, Avg. Test Loss: 0.002491390099748969\n",
      "Epoch: 1330, Avg. Train Loss: 0.002092030960633311, Avg. Test Loss: 0.002506749704480171\n",
      "Epoch: 1331, Avg. Train Loss: 0.002054905719232074, Avg. Test Loss: 0.0025174329057335854\n",
      "Epoch: 1332, Avg. Train Loss: 0.0019993401717307954, Avg. Test Loss: 0.002478791167959571\n",
      "Epoch: 1333, Avg. Train Loss: 0.0020095748382858757, Avg. Test Loss: 0.0026695537380874157\n",
      "Epoch: 1334, Avg. Train Loss: 0.0020547960695355785, Avg. Test Loss: 0.002484213327988982\n",
      "Epoch: 1335, Avg. Train Loss: 0.002049136278760988, Avg. Test Loss: 0.0024767951108515263\n",
      "Epoch: 1336, Avg. Train Loss: 0.00202513639923445, Avg. Test Loss: 0.002527461154386401\n",
      "Epoch: 1337, Avg. Train Loss: 0.002006791805480282, Avg. Test Loss: 0.002498367102816701\n",
      "Epoch: 1338, Avg. Train Loss: 0.0020479674499785136, Avg. Test Loss: 0.002564770868048072\n",
      "Epoch: 1339, Avg. Train Loss: 0.002006478499361249, Avg. Test Loss: 0.0025724663864821196\n",
      "Epoch: 1340, Avg. Train Loss: 0.002072466678137696, Avg. Test Loss: 0.0024619046598672867\n",
      "Epoch: 1341, Avg. Train Loss: 0.0020160925558356697, Avg. Test Loss: 0.0024539874866604805\n",
      "Epoch: 1342, Avg. Train Loss: 0.002066421628453184, Avg. Test Loss: 0.002488766796886921\n",
      "Epoch: 1343, Avg. Train Loss: 0.0020815777067138357, Avg. Test Loss: 0.0024855127558112144\n",
      "Epoch: 1344, Avg. Train Loss: 0.0020107022042624477, Avg. Test Loss: 0.0025122705847024918\n",
      "Epoch: 1345, Avg. Train Loss: 0.0020473687503443556, Avg. Test Loss: 0.0026132750790566206\n",
      "Epoch: 1346, Avg. Train Loss: 0.002071373909170371, Avg. Test Loss: 0.0025210909079760313\n",
      "Epoch: 1347, Avg. Train Loss: 0.001998119140152148, Avg. Test Loss: 0.002489283215254545\n",
      "Epoch: 1348, Avg. Train Loss: 0.0020077427399756258, Avg. Test Loss: 0.002445472404360771\n",
      "Epoch: 1349, Avg. Train Loss: 0.0020679772863987575, Avg. Test Loss: 0.002533756196498871\n",
      "Epoch: 1350, Avg. Train Loss: 0.002046450655799099, Avg. Test Loss: 0.0026046596467494965\n",
      "Epoch: 1351, Avg. Train Loss: 0.0020289593565732587, Avg. Test Loss: 0.0024475250393152237\n",
      "Epoch: 1352, Avg. Train Loss: 0.002061415366221999, Avg. Test Loss: 0.002466582227498293\n",
      "Epoch: 1353, Avg. Train Loss: 0.0020653603782574107, Avg. Test Loss: 0.0026160941924899817\n",
      "Epoch: 1354, Avg. Train Loss: 0.00203010922319494, Avg. Test Loss: 0.0024975729174911976\n",
      "Epoch: 1355, Avg. Train Loss: 0.001999210030230325, Avg. Test Loss: 0.0025450331158936024\n",
      "Epoch: 1356, Avg. Train Loss: 0.0020552779721139474, Avg. Test Loss: 0.002637529978528619\n",
      "Epoch: 1357, Avg. Train Loss: 0.0020388211692185247, Avg. Test Loss: 0.0024497690610587597\n",
      "Epoch: 1358, Avg. Train Loss: 0.0020260691215002605, Avg. Test Loss: 0.002507529454305768\n",
      "Epoch: 1359, Avg. Train Loss: 0.001998308120122136, Avg. Test Loss: 0.0024936096742749214\n",
      "Epoch: 1360, Avg. Train Loss: 0.0020210690157444673, Avg. Test Loss: 0.002519013127312064\n",
      "Epoch: 1361, Avg. Train Loss: 0.002044010966972903, Avg. Test Loss: 0.002603936241939664\n",
      "Epoch: 1362, Avg. Train Loss: 0.0020516184375209863, Avg. Test Loss: 0.002478425158187747\n",
      "Epoch: 1363, Avg. Train Loss: 0.0020925368014506475, Avg. Test Loss: 0.0025170384906232357\n",
      "Epoch: 1364, Avg. Train Loss: 0.0020190723007544875, Avg. Test Loss: 0.0024889169726520777\n",
      "Epoch: 1365, Avg. Train Loss: 0.002012709033848761, Avg. Test Loss: 0.002495415974408388\n",
      "Epoch: 1366, Avg. Train Loss: 0.0020258908354958824, Avg. Test Loss: 0.002485599834471941\n",
      "Epoch: 1367, Avg. Train Loss: 0.001984383212402463, Avg. Test Loss: 0.0025147395208477974\n",
      "Epoch: 1368, Avg. Train Loss: 0.0021347910853449343, Avg. Test Loss: 0.002589993877336383\n",
      "Epoch: 1369, Avg. Train Loss: 0.002039936384684298, Avg. Test Loss: 0.002505865413695574\n",
      "Epoch: 1370, Avg. Train Loss: 0.0020406384963195683, Avg. Test Loss: 0.0027358720544725657\n",
      "Epoch: 1371, Avg. Train Loss: 0.002057130104688884, Avg. Test Loss: 0.002468281425535679\n",
      "Epoch: 1372, Avg. Train Loss: 0.0020746359422932877, Avg. Test Loss: 0.002429025014862418\n",
      "Epoch: 1373, Avg. Train Loss: 0.0019893929616786364, Avg. Test Loss: 0.0026064098346978426\n",
      "Epoch: 1374, Avg. Train Loss: 0.0020671660367529406, Avg. Test Loss: 0.002419824944809079\n",
      "Epoch: 1375, Avg. Train Loss: 0.001990072218008166, Avg. Test Loss: 0.002572158584371209\n",
      "Epoch: 1376, Avg. Train Loss: 0.0020154572449364635, Avg. Test Loss: 0.00255591981112957\n",
      "Epoch: 1377, Avg. Train Loss: 0.0019937074624088616, Avg. Test Loss: 0.002513132756575942\n",
      "Epoch: 1378, Avg. Train Loss: 0.0019943709674746144, Avg. Test Loss: 0.0025008018128573895\n",
      "Epoch: 1379, Avg. Train Loss: 0.002003236056500396, Avg. Test Loss: 0.0025257435627281666\n",
      "Epoch: 1380, Avg. Train Loss: 0.002043563138888499, Avg. Test Loss: 0.0024689030833542347\n",
      "Epoch: 1381, Avg. Train Loss: 0.0020199847992422968, Avg. Test Loss: 0.0025234364438802004\n",
      "Epoch: 1382, Avg. Train Loss: 0.00199531456509735, Avg. Test Loss: 0.002443431643769145\n",
      "Epoch: 1383, Avg. Train Loss: 0.0020138234696026112, Avg. Test Loss: 0.002574774669483304\n",
      "Epoch: 1384, Avg. Train Loss: 0.002032028351433922, Avg. Test Loss: 0.0026600006967782974\n",
      "Epoch: 1385, Avg. Train Loss: 0.002008951526286817, Avg. Test Loss: 0.002477821195498109\n",
      "Epoch: 1386, Avg. Train Loss: 0.0019818477706203975, Avg. Test Loss: 0.0024764621630311012\n",
      "Epoch: 1387, Avg. Train Loss: 0.002021181768044656, Avg. Test Loss: 0.00260535953566432\n",
      "Epoch: 1388, Avg. Train Loss: 0.0020393375578054854, Avg. Test Loss: 0.0024569490924477577\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1389, Avg. Train Loss: 0.002048858154435144, Avg. Test Loss: 0.002511922037228942\n",
      "Epoch: 1390, Avg. Train Loss: 0.002039294086158449, Avg. Test Loss: 0.0026665974874049425\n",
      "Epoch: 1391, Avg. Train Loss: 0.0020494917840805163, Avg. Test Loss: 0.002778721274808049\n",
      "Epoch: 1392, Avg. Train Loss: 0.002118647767252527, Avg. Test Loss: 0.0025062905624508858\n",
      "Epoch: 1393, Avg. Train Loss: 0.0021261297231323496, Avg. Test Loss: 0.0025679150130599737\n",
      "Epoch: 1394, Avg. Train Loss: 0.00203813633578288, Avg. Test Loss: 0.0025190706364810467\n",
      "Epoch: 1395, Avg. Train Loss: 0.002018719651671343, Avg. Test Loss: 0.00250721862539649\n",
      "Epoch: 1396, Avg. Train Loss: 0.002029235488301966, Avg. Test Loss: 0.002426676219329238\n",
      "Epoch: 1397, Avg. Train Loss: 0.002031365263297461, Avg. Test Loss: 0.0026820513885468245\n",
      "Epoch: 1398, Avg. Train Loss: 0.0020389294896144853, Avg. Test Loss: 0.002498065587133169\n",
      "Epoch: 1399, Avg. Train Loss: 0.0020399742088345594, Avg. Test Loss: 0.0025536445900797844\n",
      "Epoch: 1400, Avg. Train Loss: 0.0019897083199561334, Avg. Test Loss: 0.0025966132525354624\n",
      "Epoch: 1401, Avg. Train Loss: 0.00212071749901529, Avg. Test Loss: 0.0024738300126045942\n",
      "Epoch: 1402, Avg. Train Loss: 0.002004827521633097, Avg. Test Loss: 0.002524429000914097\n",
      "Epoch: 1403, Avg. Train Loss: 0.0019829664568871606, Avg. Test Loss: 0.002435291651636362\n",
      "Epoch: 1404, Avg. Train Loss: 0.0020271873096177396, Avg. Test Loss: 0.0025142792146652937\n",
      "Epoch: 1405, Avg. Train Loss: 0.0020596451873262952, Avg. Test Loss: 0.0027508812490850687\n",
      "Epoch: 1406, Avg. Train Loss: 0.002071207494821486, Avg. Test Loss: 0.0024766135029494762\n",
      "Epoch: 1407, Avg. Train Loss: 0.0020076248843526076, Avg. Test Loss: 0.002679546596482396\n",
      "Epoch: 1408, Avg. Train Loss: 0.0020338085582913006, Avg. Test Loss: 0.0024356974754482508\n",
      "Epoch: 1409, Avg. Train Loss: 0.001997741681068789, Avg. Test Loss: 0.002590661169961095\n",
      "Epoch: 1410, Avg. Train Loss: 0.0020363755134302514, Avg. Test Loss: 0.0025061212945729494\n",
      "Epoch: 1411, Avg. Train Loss: 0.0019896825299013494, Avg. Test Loss: 0.0024835821241140366\n",
      "Epoch: 1412, Avg. Train Loss: 0.002024542518653149, Avg. Test Loss: 0.0024413445498794317\n",
      "Epoch: 1413, Avg. Train Loss: 0.001997068613702648, Avg. Test Loss: 0.0024326203856617212\n",
      "Epoch: 1414, Avg. Train Loss: 0.002035109223364744, Avg. Test Loss: 0.002478130394592881\n",
      "Epoch: 1415, Avg. Train Loss: 0.00203755225845461, Avg. Test Loss: 0.0024834848009049892\n",
      "Epoch: 1416, Avg. Train Loss: 0.001978300972083627, Avg. Test Loss: 0.00245887553319335\n",
      "Epoch: 1417, Avg. Train Loss: 0.0019869671750077328, Avg. Test Loss: 0.0026264814659953117\n",
      "Epoch: 1418, Avg. Train Loss: 0.0020486138067966285, Avg. Test Loss: 0.002523013623431325\n",
      "Epoch: 1419, Avg. Train Loss: 0.0020076046578672738, Avg. Test Loss: 0.0024293428286910057\n",
      "Epoch: 1420, Avg. Train Loss: 0.002056030903098195, Avg. Test Loss: 0.002526631345972419\n",
      "Epoch: 1421, Avg. Train Loss: 0.0020956245824954537, Avg. Test Loss: 0.00259982468560338\n",
      "Epoch: 1422, Avg. Train Loss: 0.002024492454650097, Avg. Test Loss: 0.0024968436919152737\n",
      "Epoch: 1423, Avg. Train Loss: 0.002032183373325266, Avg. Test Loss: 0.0026741980109363794\n",
      "Epoch: 1424, Avg. Train Loss: 0.002055187541774886, Avg. Test Loss: 0.002605768386274576\n",
      "Epoch: 1425, Avg. Train Loss: 0.0019989545419162444, Avg. Test Loss: 0.0025807509664446115\n",
      "Epoch: 1426, Avg. Train Loss: 0.0020836090945183885, Avg. Test Loss: 0.002458181930705905\n",
      "Epoch: 1427, Avg. Train Loss: 0.0020092351600354496, Avg. Test Loss: 0.002567106392234564\n",
      "Epoch: 1428, Avg. Train Loss: 0.0020209214390190535, Avg. Test Loss: 0.002648944966495037\n",
      "Epoch: 1429, Avg. Train Loss: 0.0020255563038856137, Avg. Test Loss: 0.002465906087309122\n",
      "Epoch: 1430, Avg. Train Loss: 0.002009677394769739, Avg. Test Loss: 0.0024743094108998775\n",
      "Epoch: 1431, Avg. Train Loss: 0.0019826634819511066, Avg. Test Loss: 0.0024347943253815174\n",
      "Epoch: 1432, Avg. Train Loss: 0.002096120866427068, Avg. Test Loss: 0.002563327783718705\n",
      "Epoch: 1433, Avg. Train Loss: 0.001999418427193061, Avg. Test Loss: 0.0025886516086757183\n",
      "Epoch: 1434, Avg. Train Loss: 0.002004123782890654, Avg. Test Loss: 0.0024451797362416983\n",
      "Epoch: 1435, Avg. Train Loss: 0.0019969588394688313, Avg. Test Loss: 0.0024541544262319803\n",
      "Epoch: 1436, Avg. Train Loss: 0.0020444158675842162, Avg. Test Loss: 0.0026399637572467327\n",
      "Epoch: 1437, Avg. Train Loss: 0.0019935737580580766, Avg. Test Loss: 0.00244908663444221\n",
      "Epoch: 1438, Avg. Train Loss: 0.0019892601778210943, Avg. Test Loss: 0.002533962018787861\n",
      "Epoch: 1439, Avg. Train Loss: 0.002040628923189848, Avg. Test Loss: 0.0024984267074614763\n",
      "Epoch: 1440, Avg. Train Loss: 0.001984147771889734, Avg. Test Loss: 0.002589569194242358\n",
      "Epoch: 1441, Avg. Train Loss: 0.00201426574765423, Avg. Test Loss: 0.00241735833697021\n",
      "Epoch: 1442, Avg. Train Loss: 0.0019814463462247407, Avg. Test Loss: 0.002519024768844247\n",
      "Epoch: 1443, Avg. Train Loss: 0.002040076841123749, Avg. Test Loss: 0.002579587511718273\n",
      "Epoch: 1444, Avg. Train Loss: 0.0020345117528597976, Avg. Test Loss: 0.0024762845132499933\n",
      "Epoch: 1445, Avg. Train Loss: 0.002009236632824637, Avg. Test Loss: 0.002513440791517496\n",
      "Epoch: 1446, Avg. Train Loss: 0.0020241364241079533, Avg. Test Loss: 0.0025906285736709833\n",
      "Epoch: 1447, Avg. Train Loss: 0.0020020550393044603, Avg. Test Loss: 0.002436387352645397\n",
      "Epoch: 1448, Avg. Train Loss: 0.002013435132454994, Avg. Test Loss: 0.002489726524800062\n",
      "Epoch: 1449, Avg. Train Loss: 0.002001696258111922, Avg. Test Loss: 0.002483188174664974\n",
      "Epoch: 1450, Avg. Train Loss: 0.002104889346979732, Avg. Test Loss: 0.002571888966485858\n",
      "Epoch: 1451, Avg. Train Loss: 0.0020506693765001242, Avg. Test Loss: 0.002671989146620035\n",
      "Epoch: 1452, Avg. Train Loss: 0.0019700999864442057, Avg. Test Loss: 0.002458360744640231\n",
      "Epoch: 1453, Avg. Train Loss: 0.0019906057954527613, Avg. Test Loss: 0.002499717054888606\n",
      "Epoch: 1454, Avg. Train Loss: 0.0020202757536195394, Avg. Test Loss: 0.002514017978683114\n",
      "Epoch: 1455, Avg. Train Loss: 0.001999874842937949, Avg. Test Loss: 0.0028236093930900097\n",
      "Epoch: 1456, Avg. Train Loss: 0.0020424784648470405, Avg. Test Loss: 0.0024252114817500114\n",
      "Epoch: 1457, Avg. Train Loss: 0.00196142045802675, Avg. Test Loss: 0.0024892494548112154\n",
      "Epoch: 1458, Avg. Train Loss: 0.002019992588239527, Avg. Test Loss: 0.002506774151697755\n",
      "Epoch: 1459, Avg. Train Loss: 0.0020506147425188577, Avg. Test Loss: 0.0025011661928147078\n",
      "Epoch: 1460, Avg. Train Loss: 0.0020229712908351144, Avg. Test Loss: 0.0024983605835586786\n",
      "Epoch: 1461, Avg. Train Loss: 0.0020117919491387383, Avg. Test Loss: 0.002442840952426195\n",
      "Epoch: 1462, Avg. Train Loss: 0.002048476945695489, Avg. Test Loss: 0.002869904041290283\n",
      "Epoch: 1463, Avg. Train Loss: 0.0021422279695438784, Avg. Test Loss: 0.0025942421052604914\n",
      "Epoch: 1464, Avg. Train Loss: 0.0019790456294580257, Avg. Test Loss: 0.002468981547281146\n",
      "Epoch: 1465, Avg. Train Loss: 0.001996525576836321, Avg. Test Loss: 0.0025186631828546524\n",
      "Epoch: 1466, Avg. Train Loss: 0.00204090821166891, Avg. Test Loss: 0.0024915446992963552\n",
      "Epoch: 1467, Avg. Train Loss: 0.0020054128578712426, Avg. Test Loss: 0.0025094328448176384\n",
      "Epoch: 1468, Avg. Train Loss: 0.001971725523363539, Avg. Test Loss: 0.0025070321280509233\n",
      "Epoch: 1469, Avg. Train Loss: 0.001988292043638784, Avg. Test Loss: 0.0025205533020198345\n",
      "Epoch: 1470, Avg. Train Loss: 0.002001581191041962, Avg. Test Loss: 0.002530557569116354\n",
      "Epoch: 1471, Avg. Train Loss: 0.0020157040481260696, Avg. Test Loss: 0.0025806480553001165\n",
      "Epoch: 1472, Avg. Train Loss: 0.0020093377896173055, Avg. Test Loss: 0.002465230179950595\n",
      "Epoch: 1473, Avg. Train Loss: 0.001990459759199862, Avg. Test Loss: 0.0026529598981142044\n",
      "Epoch: 1474, Avg. Train Loss: 0.00198973806813186, Avg. Test Loss: 0.00249957712367177\n",
      "Epoch: 1475, Avg. Train Loss: 0.002002944758291854, Avg. Test Loss: 0.002440900541841984\n",
      "Epoch: 1476, Avg. Train Loss: 0.001971366346900373, Avg. Test Loss: 0.0024871190544217825\n",
      "Epoch: 1477, Avg. Train Loss: 0.0020410669155332237, Avg. Test Loss: 0.002587849972769618\n",
      "Epoch: 1478, Avg. Train Loss: 0.0019791007399299117, Avg. Test Loss: 0.0026839105412364006\n",
      "Epoch: 1479, Avg. Train Loss: 0.0020554151499730558, Avg. Test Loss: 0.0026692026294767857\n",
      "Epoch: 1480, Avg. Train Loss: 0.0020358667541078702, Avg. Test Loss: 0.0024632068816572428\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1481, Avg. Train Loss: 0.0020077880228284834, Avg. Test Loss: 0.002467360580340028\n",
      "Epoch: 1482, Avg. Train Loss: 0.001983952126465738, Avg. Test Loss: 0.0025507137179374695\n",
      "Epoch: 1483, Avg. Train Loss: 0.0020322496921560446, Avg. Test Loss: 0.0025133800227195024\n",
      "Epoch: 1484, Avg. Train Loss: 0.0020354609357106476, Avg. Test Loss: 0.0025802392046898603\n",
      "Epoch: 1485, Avg. Train Loss: 0.0020092955037821518, Avg. Test Loss: 0.002551443176344037\n",
      "Epoch: 1486, Avg. Train Loss: 0.001970856905330059, Avg. Test Loss: 0.0024739326909184456\n",
      "Epoch: 1487, Avg. Train Loss: 0.0019697722529472654, Avg. Test Loss: 0.002486520679667592\n",
      "Epoch: 1488, Avg. Train Loss: 0.0019954945025748984, Avg. Test Loss: 0.0030298030469566584\n",
      "Epoch: 1489, Avg. Train Loss: 0.002048106912826729, Avg. Test Loss: 0.0027883267030119896\n",
      "Epoch: 1490, Avg. Train Loss: 0.002045127685008527, Avg. Test Loss: 0.0024710323195904493\n",
      "Epoch: 1491, Avg. Train Loss: 0.0019839645937345055, Avg. Test Loss: 0.002467530779540539\n",
      "Epoch: 1492, Avg. Train Loss: 0.0020204432184136537, Avg. Test Loss: 0.002547917887568474\n",
      "Epoch: 1493, Avg. Train Loss: 0.001996244590859427, Avg. Test Loss: 0.0024893679656088352\n",
      "Epoch: 1494, Avg. Train Loss: 0.001973599412066992, Avg. Test Loss: 0.0026171491481363773\n",
      "Epoch: 1495, Avg. Train Loss: 0.0020076462885278254, Avg. Test Loss: 0.002781270071864128\n",
      "Epoch: 1496, Avg. Train Loss: 0.00209427225609245, Avg. Test Loss: 0.002554087433964014\n",
      "Epoch: 1497, Avg. Train Loss: 0.0020429897853065024, Avg. Test Loss: 0.0025564872194081545\n",
      "Epoch: 1498, Avg. Train Loss: 0.0020008798699479463, Avg. Test Loss: 0.002447009552270174\n",
      "Epoch: 1499, Avg. Train Loss: 0.001958945584700031, Avg. Test Loss: 0.002538523869588971\n",
      "Epoch: 1500, Avg. Train Loss: 0.002016690045291948, Avg. Test Loss: 0.002550611039623618\n",
      "Epoch: 1501, Avg. Train Loss: 0.0019856166489812177, Avg. Test Loss: 0.002588397590443492\n",
      "Epoch: 1502, Avg. Train Loss: 0.0020702697125501756, Avg. Test Loss: 0.002500078873708844\n",
      "Epoch: 1503, Avg. Train Loss: 0.0019616805596363754, Avg. Test Loss: 0.0024363354314118624\n",
      "Epoch: 1504, Avg. Train Loss: 0.001997018633626921, Avg. Test Loss: 0.002453623339533806\n",
      "Epoch: 1505, Avg. Train Loss: 0.002010112752878042, Avg. Test Loss: 0.00245911767706275\n",
      "Epoch: 1506, Avg. Train Loss: 0.001994176009713217, Avg. Test Loss: 0.002603350905701518\n",
      "Epoch: 1507, Avg. Train Loss: 0.0019672555107146847, Avg. Test Loss: 0.0024857998359948397\n",
      "Epoch: 1508, Avg. Train Loss: 0.00197294031453947, Avg. Test Loss: 0.002547056879848242\n",
      "Epoch: 1509, Avg. Train Loss: 0.0020088590140086276, Avg. Test Loss: 0.0024890578351914883\n",
      "Epoch: 1510, Avg. Train Loss: 0.0020172089462839934, Avg. Test Loss: 0.003066191915422678\n",
      "Epoch: 1511, Avg. Train Loss: 0.0021271259648465487, Avg. Test Loss: 0.0024335409980267286\n",
      "Epoch: 1512, Avg. Train Loss: 0.0019945950398958007, Avg. Test Loss: 0.0024442067369818687\n",
      "Epoch: 1513, Avg. Train Loss: 0.001985015718504613, Avg. Test Loss: 0.0026386345271021128\n",
      "Epoch: 1514, Avg. Train Loss: 0.002036604770394259, Avg. Test Loss: 0.0024820712860673666\n",
      "Epoch: 1515, Avg. Train Loss: 0.0019783038797593394, Avg. Test Loss: 0.0024698511697351933\n",
      "Epoch: 1516, Avg. Train Loss: 0.0020232110089340874, Avg. Test Loss: 0.0025310534983873367\n",
      "Epoch: 1517, Avg. Train Loss: 0.002019735732722248, Avg. Test Loss: 0.002624215092509985\n",
      "Epoch: 1518, Avg. Train Loss: 0.002015322639043768, Avg. Test Loss: 0.0025102486833930016\n",
      "Epoch: 1519, Avg. Train Loss: 0.0020056449927302986, Avg. Test Loss: 0.002692098030820489\n",
      "Epoch: 1520, Avg. Train Loss: 0.002005072256420241, Avg. Test Loss: 0.0024768018629401922\n",
      "Epoch: 1521, Avg. Train Loss: 0.0019776667468249798, Avg. Test Loss: 0.002464245306327939\n",
      "Epoch: 1522, Avg. Train Loss: 0.001999514426516239, Avg. Test Loss: 0.002531822770833969\n",
      "Epoch: 1523, Avg. Train Loss: 0.0019801741731244812, Avg. Test Loss: 0.0025209938175976276\n",
      "Epoch: 1524, Avg. Train Loss: 0.0020030348339702846, Avg. Test Loss: 0.0024259379133582115\n",
      "Epoch: 1525, Avg. Train Loss: 0.0019718312934517515, Avg. Test Loss: 0.0024496151600033045\n",
      "Epoch: 1526, Avg. Train Loss: 0.0019811074449789037, Avg. Test Loss: 0.0025512517895549536\n",
      "Epoch: 1527, Avg. Train Loss: 0.00194720147437481, Avg. Test Loss: 0.002479549730196595\n",
      "Epoch: 1528, Avg. Train Loss: 0.001970957379874795, Avg. Test Loss: 0.0024648886173963547\n",
      "Epoch: 1529, Avg. Train Loss: 0.0019393601498111737, Avg. Test Loss: 0.0026529510505497456\n",
      "Epoch: 1530, Avg. Train Loss: 0.0020530172650767274, Avg. Test Loss: 0.00258456589654088\n",
      "Epoch: 1531, Avg. Train Loss: 0.0019919196127502377, Avg. Test Loss: 0.0028951321728527546\n",
      "Epoch: 1532, Avg. Train Loss: 0.0020292864944569246, Avg. Test Loss: 0.0025114708114415407\n",
      "Epoch: 1533, Avg. Train Loss: 0.00203498171880668, Avg. Test Loss: 0.0025003550108522177\n",
      "Epoch: 1534, Avg. Train Loss: 0.002004029107453345, Avg. Test Loss: 0.0025098780170083046\n",
      "Epoch: 1535, Avg. Train Loss: 0.001983647150810548, Avg. Test Loss: 0.002556371735408902\n",
      "Epoch: 1536, Avg. Train Loss: 0.0019893323444912948, Avg. Test Loss: 0.0024531702511012554\n",
      "Epoch: 1537, Avg. Train Loss: 0.0019642733156594425, Avg. Test Loss: 0.0024774784687906504\n",
      "Epoch: 1538, Avg. Train Loss: 0.0019757921650442618, Avg. Test Loss: 0.0024480039719492197\n",
      "Epoch: 1539, Avg. Train Loss: 0.0020898600585412147, Avg. Test Loss: 0.0024920350406318903\n",
      "Epoch: 1540, Avg. Train Loss: 0.0019688102400450165, Avg. Test Loss: 0.0024273903109133244\n",
      "Epoch: 1541, Avg. Train Loss: 0.002030692093052663, Avg. Test Loss: 0.0029076095670461655\n",
      "Epoch: 1542, Avg. Train Loss: 0.0020615391563190972, Avg. Test Loss: 0.0024343987461179495\n",
      "Epoch: 1543, Avg. Train Loss: 0.002040447488557114, Avg. Test Loss: 0.0025601389352232218\n",
      "Epoch: 1544, Avg. Train Loss: 0.0019609667035902657, Avg. Test Loss: 0.0024588024243712425\n",
      "Epoch: 1545, Avg. Train Loss: 0.002042456643742531, Avg. Test Loss: 0.0025374304968863726\n",
      "Epoch: 1546, Avg. Train Loss: 0.002026856267759793, Avg. Test Loss: 0.0025119383353739977\n",
      "Epoch: 1547, Avg. Train Loss: 0.001985383414944937, Avg. Test Loss: 0.0025388305075466633\n",
      "Epoch: 1548, Avg. Train Loss: 0.002020705426328404, Avg. Test Loss: 0.0024631149135529995\n",
      "Epoch: 1549, Avg. Train Loss: 0.001973161500943608, Avg. Test Loss: 0.0025879002641886473\n",
      "Epoch: 1550, Avg. Train Loss: 0.00198880689175323, Avg. Test Loss: 0.0024655042216181755\n",
      "Epoch: 1551, Avg. Train Loss: 0.0019945030257668955, Avg. Test Loss: 0.0024555600248277187\n",
      "Epoch: 1552, Avg. Train Loss: 0.001995580503717065, Avg. Test Loss: 0.0024706486146897078\n",
      "Epoch: 1553, Avg. Train Loss: 0.0020130676228206517, Avg. Test Loss: 0.002515261061489582\n",
      "Epoch: 1554, Avg. Train Loss: 0.0019718767576959242, Avg. Test Loss: 0.002446624217554927\n",
      "Epoch: 1555, Avg. Train Loss: 0.0019956257459599266, Avg. Test Loss: 0.002432712819427252\n",
      "Epoch: 1556, Avg. Train Loss: 0.001944761271155331, Avg. Test Loss: 0.002464664401486516\n",
      "Epoch: 1557, Avg. Train Loss: 0.0019862736374962817, Avg. Test Loss: 0.0025085050147026777\n",
      "Epoch: 1558, Avg. Train Loss: 0.002014664166910184, Avg. Test Loss: 0.0024556906428188086\n",
      "Epoch: 1559, Avg. Train Loss: 0.001944566199685945, Avg. Test Loss: 0.0025609335862100124\n",
      "Epoch: 1560, Avg. Train Loss: 0.00194008503282486, Avg. Test Loss: 0.002508627949282527\n",
      "Epoch: 1561, Avg. Train Loss: 0.0020239391190887885, Avg. Test Loss: 0.002411905210465193\n",
      "Epoch: 1562, Avg. Train Loss: 0.002066595504211998, Avg. Test Loss: 0.0030292170122265816\n",
      "Epoch: 1563, Avg. Train Loss: 0.001998993186388425, Avg. Test Loss: 0.0026118264067918062\n",
      "Epoch: 1564, Avg. Train Loss: 0.002083734795992631, Avg. Test Loss: 0.002633319701999426\n",
      "Epoch: 1565, Avg. Train Loss: 0.0020120783308304325, Avg. Test Loss: 0.002473982283845544\n",
      "Epoch: 1566, Avg. Train Loss: 0.001970775983144724, Avg. Test Loss: 0.002475579734891653\n",
      "Epoch: 1567, Avg. Train Loss: 0.0019824359928755915, Avg. Test Loss: 0.0027196924202144146\n",
      "Epoch: 1568, Avg. Train Loss: 0.0019980159663963454, Avg. Test Loss: 0.0024291088338941336\n",
      "Epoch: 1569, Avg. Train Loss: 0.0020064573280166747, Avg. Test Loss: 0.0025215030182152987\n",
      "Epoch: 1570, Avg. Train Loss: 0.002014808502957918, Avg. Test Loss: 0.0026173111982643604\n",
      "Epoch: 1571, Avg. Train Loss: 0.002079368246784217, Avg. Test Loss: 0.002510471735149622\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1572, Avg. Train Loss: 0.001972415005290058, Avg. Test Loss: 0.002489234786480665\n",
      "Epoch: 1573, Avg. Train Loss: 0.0019929560529457968, Avg. Test Loss: 0.002520419890061021\n",
      "Epoch: 1574, Avg. Train Loss: 0.0020665052877522484, Avg. Test Loss: 0.002550660166889429\n",
      "Epoch: 1575, Avg. Train Loss: 0.002017841227677499, Avg. Test Loss: 0.0025299442932009697\n",
      "Epoch: 1576, Avg. Train Loss: 0.001975972592549095, Avg. Test Loss: 0.002492055529728532\n",
      "Epoch: 1577, Avg. Train Loss: 0.0019696112478498457, Avg. Test Loss: 0.0025148249696940184\n",
      "Epoch: 1578, Avg. Train Loss: 0.0019567002065826295, Avg. Test Loss: 0.0025779895950108767\n",
      "Epoch: 1579, Avg. Train Loss: 0.001996282106373719, Avg. Test Loss: 0.00245621707290411\n",
      "Epoch: 1580, Avg. Train Loss: 0.0020430387907423254, Avg. Test Loss: 0.002572915982455015\n",
      "Epoch: 1581, Avg. Train Loss: 0.0020843996899202466, Avg. Test Loss: 0.0024570715613663197\n",
      "Epoch: 1582, Avg. Train Loss: 0.002015952711253492, Avg. Test Loss: 0.0024964690674096346\n",
      "Epoch: 1583, Avg. Train Loss: 0.001980781988349072, Avg. Test Loss: 0.0026865063700824976\n",
      "Epoch: 1584, Avg. Train Loss: 0.002051652509307619, Avg. Test Loss: 0.0024376939982175827\n",
      "Epoch: 1585, Avg. Train Loss: 0.0019168321173204932, Avg. Test Loss: 0.0024197082966566086\n",
      "Epoch: 1586, Avg. Train Loss: 0.001947052359884215, Avg. Test Loss: 0.002431556349620223\n",
      "Epoch: 1587, Avg. Train Loss: 0.0020170572841929834, Avg. Test Loss: 0.0025798354763537645\n",
      "Epoch: 1588, Avg. Train Loss: 0.0019857635407513658, Avg. Test Loss: 0.002506921999156475\n",
      "Epoch: 1589, Avg. Train Loss: 0.001975917801542511, Avg. Test Loss: 0.0025489144027233124\n",
      "Epoch: 1590, Avg. Train Loss: 0.0020137100269324902, Avg. Test Loss: 0.0024688998237252235\n",
      "Epoch: 1591, Avg. Train Loss: 0.0019983032306786193, Avg. Test Loss: 0.0024218508042395115\n",
      "Epoch: 1592, Avg. Train Loss: 0.00198998054771056, Avg. Test Loss: 0.0024325165431946516\n",
      "Epoch: 1593, Avg. Train Loss: 0.0019655765987239603, Avg. Test Loss: 0.0025012812111526728\n",
      "Epoch: 1594, Avg. Train Loss: 0.0020547271895677197, Avg. Test Loss: 0.0026030715089291334\n",
      "Epoch: 1595, Avg. Train Loss: 0.001954006272108229, Avg. Test Loss: 0.002480886410921812\n",
      "Epoch: 1596, Avg. Train Loss: 0.0019760287697102095, Avg. Test Loss: 0.0025422738399356604\n",
      "Epoch: 1597, Avg. Train Loss: 0.0019743033728107464, Avg. Test Loss: 0.002427932806313038\n",
      "Epoch: 1598, Avg. Train Loss: 0.001950665978108381, Avg. Test Loss: 0.002587473951280117\n",
      "Epoch: 1599, Avg. Train Loss: 0.0020719910646940388, Avg. Test Loss: 0.002481807256117463\n",
      "Epoch: 1600, Avg. Train Loss: 0.0019838894029732706, Avg. Test Loss: 0.002601802349090576\n",
      "Epoch: 1601, Avg. Train Loss: 0.0020285469512346874, Avg. Test Loss: 0.0024474365636706352\n",
      "Epoch: 1602, Avg. Train Loss: 0.0019819279076791433, Avg. Test Loss: 0.0024350122548639774\n",
      "Epoch: 1603, Avg. Train Loss: 0.001969176639672802, Avg. Test Loss: 0.0025052682030946016\n",
      "Epoch: 1604, Avg. Train Loss: 0.0019408581713431102, Avg. Test Loss: 0.002632184186950326\n",
      "Epoch: 1605, Avg. Train Loss: 0.001970480669961246, Avg. Test Loss: 0.002490895800292492\n",
      "Epoch: 1606, Avg. Train Loss: 0.001983253250093481, Avg. Test Loss: 0.002466051373630762\n",
      "Epoch: 1607, Avg. Train Loss: 0.0019220954543629357, Avg. Test Loss: 0.0024158447049558163\n",
      "Epoch: 1608, Avg. Train Loss: 0.001971186144104184, Avg. Test Loss: 0.0024672753643244505\n",
      "Epoch: 1609, Avg. Train Loss: 0.0019480832256809917, Avg. Test Loss: 0.0024327789433300495\n",
      "Epoch: 1610, Avg. Train Loss: 0.0019678524559970166, Avg. Test Loss: 0.002618295606225729\n",
      "Epoch: 1611, Avg. Train Loss: 0.001997375660467633, Avg. Test Loss: 0.0025191595777869225\n",
      "Epoch: 1612, Avg. Train Loss: 0.0019963871265306723, Avg. Test Loss: 0.0024890126660466194\n",
      "Epoch: 1613, Avg. Train Loss: 0.001972413039766252, Avg. Test Loss: 0.002472175983712077\n",
      "Epoch: 1614, Avg. Train Loss: 0.0019495635358400124, Avg. Test Loss: 0.0024837476667016745\n",
      "Epoch: 1615, Avg. Train Loss: 0.002030370702837096, Avg. Test Loss: 0.0029320726171135902\n",
      "Epoch: 1616, Avg. Train Loss: 0.002030773475484619, Avg. Test Loss: 0.002489978214725852\n",
      "Epoch: 1617, Avg. Train Loss: 0.0019842675145238984, Avg. Test Loss: 0.0025351892691105604\n",
      "Epoch: 1618, Avg. Train Loss: 0.002013869339946744, Avg. Test Loss: 0.002538323635235429\n",
      "Epoch: 1619, Avg. Train Loss: 0.001941015340149576, Avg. Test Loss: 0.0024391883052885532\n",
      "Epoch: 1620, Avg. Train Loss: 0.0019602329296947913, Avg. Test Loss: 0.0024853378999978304\n",
      "Epoch: 1621, Avg. Train Loss: 0.0019670162745209973, Avg. Test Loss: 0.0024252552539110184\n",
      "Epoch: 1622, Avg. Train Loss: 0.0019863282416968846, Avg. Test Loss: 0.0025098484475165606\n",
      "Epoch: 1623, Avg. Train Loss: 0.0019373843841644567, Avg. Test Loss: 0.0024371882900595665\n",
      "Epoch: 1624, Avg. Train Loss: 0.0019881179160979945, Avg. Test Loss: 0.0026600512210279703\n",
      "Epoch: 1625, Avg. Train Loss: 0.0020212405009281845, Avg. Test Loss: 0.002498036017641425\n",
      "Epoch: 1626, Avg. Train Loss: 0.0020731019078169106, Avg. Test Loss: 0.0025345913600176573\n",
      "Epoch: 1627, Avg. Train Loss: 0.0019608099923230883, Avg. Test Loss: 0.0024178822059184313\n",
      "Epoch: 1628, Avg. Train Loss: 0.001996509887841205, Avg. Test Loss: 0.0024482286535203457\n",
      "Epoch: 1629, Avg. Train Loss: 0.00194817450070797, Avg. Test Loss: 0.0024482018779963255\n",
      "Epoch: 1630, Avg. Train Loss: 0.001961468846190634, Avg. Test Loss: 0.002446533180773258\n",
      "Epoch: 1631, Avg. Train Loss: 0.0019996232558908158, Avg. Test Loss: 0.002423335565254092\n",
      "Epoch: 1632, Avg. Train Loss: 0.0019701872383742487, Avg. Test Loss: 0.0026421353686600924\n",
      "Epoch: 1633, Avg. Train Loss: 0.0019807897177849744, Avg. Test Loss: 0.00255511119030416\n",
      "Epoch: 1634, Avg. Train Loss: 0.001946680209880998, Avg. Test Loss: 0.002490471815690398\n",
      "Epoch: 1635, Avg. Train Loss: 0.001981741640456887, Avg. Test Loss: 0.0024933794047683477\n",
      "Epoch: 1636, Avg. Train Loss: 0.00198251434850918, Avg. Test Loss: 0.0025555177126079798\n",
      "Epoch: 1637, Avg. Train Loss: 0.0019958077247666066, Avg. Test Loss: 0.002449280582368374\n",
      "Epoch: 1638, Avg. Train Loss: 0.001971031303604155, Avg. Test Loss: 0.0025098242331296206\n",
      "Epoch: 1639, Avg. Train Loss: 0.001965389132153156, Avg. Test Loss: 0.002448068233206868\n",
      "Epoch: 1640, Avg. Train Loss: 0.001991612327739943, Avg. Test Loss: 0.0024918881244957447\n",
      "Epoch: 1641, Avg. Train Loss: 0.002026751956924103, Avg. Test Loss: 0.0026685120537877083\n",
      "Epoch: 1642, Avg. Train Loss: 0.0019574248621803386, Avg. Test Loss: 0.0024866850581020117\n",
      "Epoch: 1643, Avg. Train Loss: 0.0019342873711138964, Avg. Test Loss: 0.0025024269707500935\n",
      "Epoch: 1644, Avg. Train Loss: 0.001951051586264268, Avg. Test Loss: 0.0025495891459286213\n",
      "Epoch: 1645, Avg. Train Loss: 0.0019849619644065927, Avg. Test Loss: 0.0026400366332381964\n",
      "Epoch: 1646, Avg. Train Loss: 0.00202651783758991, Avg. Test Loss: 0.0032297337893396616\n",
      "Epoch: 1647, Avg. Train Loss: 0.0020378666881168653, Avg. Test Loss: 0.002439063275232911\n",
      "Epoch: 1648, Avg. Train Loss: 0.0020429107717909786, Avg. Test Loss: 0.00244048866443336\n",
      "Epoch: 1649, Avg. Train Loss: 0.0019450567738521238, Avg. Test Loss: 0.0025050495751202106\n",
      "Epoch: 1650, Avg. Train Loss: 0.0019393204576010968, Avg. Test Loss: 0.0023936086799949408\n",
      "Epoch: 1651, Avg. Train Loss: 0.00199084188031076, Avg. Test Loss: 0.0024827413726598024\n",
      "Epoch: 1652, Avg. Train Loss: 0.001989241107366979, Avg. Test Loss: 0.002559148008003831\n",
      "Epoch: 1653, Avg. Train Loss: 0.0019763200516747527, Avg. Test Loss: 0.0024292070884257555\n",
      "Epoch: 1654, Avg. Train Loss: 0.0019289836217107814, Avg. Test Loss: 0.002428491832688451\n",
      "Epoch: 1655, Avg. Train Loss: 0.001974454282263164, Avg. Test Loss: 0.0024999326560646296\n",
      "Epoch: 1656, Avg. Train Loss: 0.001966211132618577, Avg. Test Loss: 0.002500679576769471\n",
      "Epoch: 1657, Avg. Train Loss: 0.0019473066542644141, Avg. Test Loss: 0.0025819242000579834\n",
      "Epoch: 1658, Avg. Train Loss: 0.001985174208489615, Avg. Test Loss: 0.0024233481381088495\n",
      "Epoch: 1659, Avg. Train Loss: 0.0020058643462699515, Avg. Test Loss: 0.0025673049967736006\n",
      "Epoch: 1660, Avg. Train Loss: 0.001978055203095252, Avg. Test Loss: 0.0024248294066637754\n",
      "Epoch: 1661, Avg. Train Loss: 0.0020009103112009377, Avg. Test Loss: 0.002585895359516144\n",
      "Epoch: 1662, Avg. Train Loss: 0.00196914381325938, Avg. Test Loss: 0.002433012705296278\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1663, Avg. Train Loss: 0.0019929555845771764, Avg. Test Loss: 0.0024524061009287834\n",
      "Epoch: 1664, Avg. Train Loss: 0.0020005949908261035, Avg. Test Loss: 0.0024338376242667437\n",
      "Epoch: 1665, Avg. Train Loss: 0.0019619525626821573, Avg. Test Loss: 0.002502832096070051\n",
      "Epoch: 1666, Avg. Train Loss: 0.001982582624741765, Avg. Test Loss: 0.002552869962528348\n",
      "Epoch: 1667, Avg. Train Loss: 0.0019716289257197535, Avg. Test Loss: 0.0024321950040757656\n",
      "Epoch: 1668, Avg. Train Loss: 0.0019348388711033866, Avg. Test Loss: 0.0024998141452670097\n",
      "Epoch: 1669, Avg. Train Loss: 0.0019312917449793151, Avg. Test Loss: 0.0025074253790080547\n",
      "Epoch: 1670, Avg. Train Loss: 0.0019762378056035483, Avg. Test Loss: 0.0025302108842879534\n",
      "Epoch: 1671, Avg. Train Loss: 0.0019479504012134532, Avg. Test Loss: 0.0025583042297512293\n",
      "Epoch: 1672, Avg. Train Loss: 0.00199723040663399, Avg. Test Loss: 0.002449021441861987\n",
      "Epoch: 1673, Avg. Train Loss: 0.0019395263205000826, Avg. Test Loss: 0.002421033103018999\n",
      "Epoch: 1674, Avg. Train Loss: 0.001988726218642537, Avg. Test Loss: 0.002537983004003763\n",
      "Epoch: 1675, Avg. Train Loss: 0.0020088714839847283, Avg. Test Loss: 0.0025768838822841644\n",
      "Epoch: 1676, Avg. Train Loss: 0.0020489336565396813, Avg. Test Loss: 0.0024901730939745903\n",
      "Epoch: 1677, Avg. Train Loss: 0.0019323753008922172, Avg. Test Loss: 0.002451102016493678\n",
      "Epoch: 1678, Avg. Train Loss: 0.0019449835269560302, Avg. Test Loss: 0.0027371584437787533\n",
      "Epoch: 1679, Avg. Train Loss: 0.0020223671602908264, Avg. Test Loss: 0.002443150617182255\n",
      "Epoch: 1680, Avg. Train Loss: 0.0019455548716968921, Avg. Test Loss: 0.0024635163135826588\n",
      "Epoch: 1681, Avg. Train Loss: 0.0019875939686371143, Avg. Test Loss: 0.002465756144374609\n",
      "Epoch: 1682, Avg. Train Loss: 0.001963729179615891, Avg. Test Loss: 0.0024556091520935297\n",
      "Epoch: 1683, Avg. Train Loss: 0.0019439955453150147, Avg. Test Loss: 0.002585924696177244\n",
      "Epoch: 1684, Avg. Train Loss: 0.001993685446376371, Avg. Test Loss: 0.003238585079088807\n",
      "Epoch: 1685, Avg. Train Loss: 0.0020651161389122178, Avg. Test Loss: 0.002448428189381957\n",
      "Epoch: 1686, Avg. Train Loss: 0.0019434588354860628, Avg. Test Loss: 0.0024892177898436785\n",
      "Epoch: 1687, Avg. Train Loss: 0.0019353818457010527, Avg. Test Loss: 0.0025973066221922636\n",
      "Epoch: 1688, Avg. Train Loss: 0.001960106545972616, Avg. Test Loss: 0.002590636722743511\n",
      "Epoch: 1689, Avg. Train Loss: 0.0019504667129800763, Avg. Test Loss: 0.0024573225528001785\n",
      "Epoch: 1690, Avg. Train Loss: 0.0019250857957833728, Avg. Test Loss: 0.002439742209389806\n",
      "Epoch: 1691, Avg. Train Loss: 0.001972897573872361, Avg. Test Loss: 0.002463229699060321\n",
      "Epoch: 1692, Avg. Train Loss: 0.0019610946521509526, Avg. Test Loss: 0.0024328851141035557\n",
      "Epoch: 1693, Avg. Train Loss: 0.0019823036882160015, Avg. Test Loss: 0.002582384506240487\n",
      "Epoch: 1694, Avg. Train Loss: 0.0019888361119990085, Avg. Test Loss: 0.0026686685159802437\n",
      "Epoch: 1695, Avg. Train Loss: 0.0019877165918736612, Avg. Test Loss: 0.0025276553351432085\n",
      "Epoch: 1696, Avg. Train Loss: 0.0019588364223234876, Avg. Test Loss: 0.0025472294073551893\n",
      "Epoch: 1697, Avg. Train Loss: 0.0019774375494223, Avg. Test Loss: 0.0025038791354745626\n",
      "Epoch: 1698, Avg. Train Loss: 0.001958493728104026, Avg. Test Loss: 0.002588071161881089\n",
      "Epoch: 1699, Avg. Train Loss: 0.001958580841960082, Avg. Test Loss: 0.0026845710817724466\n",
      "Epoch: 1700, Avg. Train Loss: 0.0020054849541507836, Avg. Test Loss: 0.002541339723393321\n",
      "Epoch: 1701, Avg. Train Loss: 0.0019305784655951482, Avg. Test Loss: 0.0024585009086877108\n",
      "Epoch: 1702, Avg. Train Loss: 0.002022087741859777, Avg. Test Loss: 0.0028846815694123507\n",
      "Epoch: 1703, Avg. Train Loss: 0.0020178634981992977, Avg. Test Loss: 0.002570674056187272\n",
      "Epoch: 1704, Avg. Train Loss: 0.0020220526331645805, Avg. Test Loss: 0.002427770523354411\n",
      "Epoch: 1705, Avg. Train Loss: 0.0019510931925588223, Avg. Test Loss: 0.0025814936961978674\n",
      "Epoch: 1706, Avg. Train Loss: 0.0019703137818290746, Avg. Test Loss: 0.0026373581495136023\n",
      "Epoch: 1707, Avg. Train Loss: 0.0020195990882077536, Avg. Test Loss: 0.0025883493945002556\n",
      "Epoch: 1708, Avg. Train Loss: 0.0019086016027993241, Avg. Test Loss: 0.0024258510675281286\n",
      "Epoch: 1709, Avg. Train Loss: 0.0019201187276129807, Avg. Test Loss: 0.0024220130871981382\n",
      "Epoch: 1710, Avg. Train Loss: 0.0020581423332048363, Avg. Test Loss: 0.0024916192051023245\n",
      "Epoch: 1711, Avg. Train Loss: 0.0019619554053818765, Avg. Test Loss: 0.0025543475057929754\n",
      "Epoch: 1712, Avg. Train Loss: 0.0019507739086483801, Avg. Test Loss: 0.002404703525826335\n",
      "Epoch: 1713, Avg. Train Loss: 0.0019223963500671955, Avg. Test Loss: 0.002528830198571086\n",
      "Epoch: 1714, Avg. Train Loss: 0.001946318274645438, Avg. Test Loss: 0.0025592343881726265\n",
      "Epoch: 1715, Avg. Train Loss: 0.0019620210961113836, Avg. Test Loss: 0.0028687010053545237\n",
      "Epoch: 1716, Avg. Train Loss: 0.0019742327087103975, Avg. Test Loss: 0.0025706179440021515\n",
      "Epoch: 1717, Avg. Train Loss: 0.002002068584091788, Avg. Test Loss: 0.002519289031624794\n",
      "Epoch: 1718, Avg. Train Loss: 0.001955696324774519, Avg. Test Loss: 0.002454261528328061\n",
      "Epoch: 1719, Avg. Train Loss: 0.0019260035708633272, Avg. Test Loss: 0.002444223966449499\n",
      "Epoch: 1720, Avg. Train Loss: 0.0019224431788072336, Avg. Test Loss: 0.002563793445006013\n",
      "Epoch: 1721, Avg. Train Loss: 0.0019761784310820835, Avg. Test Loss: 0.003351874416694045\n",
      "Epoch: 1722, Avg. Train Loss: 0.0020261917988834686, Avg. Test Loss: 0.002505167154595256\n",
      "Epoch: 1723, Avg. Train Loss: 0.0019705332355400506, Avg. Test Loss: 0.0024897661060094833\n",
      "Epoch: 1724, Avg. Train Loss: 0.001988291843296137, Avg. Test Loss: 0.0026602442376315594\n",
      "Epoch: 1725, Avg. Train Loss: 0.001945111269759404, Avg. Test Loss: 0.002420609351247549\n",
      "Epoch: 1726, Avg. Train Loss: 0.0019152333207298504, Avg. Test Loss: 0.0025807740166783333\n",
      "Epoch: 1727, Avg. Train Loss: 0.0019635418213384097, Avg. Test Loss: 0.0026870097499340773\n",
      "Epoch: 1728, Avg. Train Loss: 0.0019723328323168463, Avg. Test Loss: 0.002431157510727644\n",
      "Epoch: 1729, Avg. Train Loss: 0.001906153074530668, Avg. Test Loss: 0.002408361528068781\n",
      "Epoch: 1730, Avg. Train Loss: 0.0019211764609831017, Avg. Test Loss: 0.002450240310281515\n",
      "Epoch: 1731, Avg. Train Loss: 0.0019516033975970606, Avg. Test Loss: 0.0025660237297415733\n",
      "Epoch: 1732, Avg. Train Loss: 0.0019642936423161002, Avg. Test Loss: 0.0025119453202933073\n",
      "Epoch: 1733, Avg. Train Loss: 0.0019882310041074835, Avg. Test Loss: 0.0026817477773875\n",
      "Epoch: 1734, Avg. Train Loss: 0.001971453138583795, Avg. Test Loss: 0.0026492998003959656\n",
      "Epoch: 1735, Avg. Train Loss: 0.0019900189376934325, Avg. Test Loss: 0.0025438342709094286\n",
      "Epoch: 1736, Avg. Train Loss: 0.0019432256312304458, Avg. Test Loss: 0.0026259906589984894\n",
      "Epoch: 1737, Avg. Train Loss: 0.0019894247782568254, Avg. Test Loss: 0.002498603891581297\n",
      "Epoch: 1738, Avg. Train Loss: 0.002022445104409789, Avg. Test Loss: 0.002424655482172966\n",
      "Epoch: 1739, Avg. Train Loss: 0.0019441377696429575, Avg. Test Loss: 0.0026650046929717064\n",
      "Epoch: 1740, Avg. Train Loss: 0.0019208210666642287, Avg. Test Loss: 0.0024686953984200954\n",
      "Epoch: 1741, Avg. Train Loss: 0.0019631728307928802, Avg. Test Loss: 0.002445925259962678\n",
      "Epoch: 1742, Avg. Train Loss: 0.001935084030941822, Avg. Test Loss: 0.0024423173163086176\n",
      "Epoch: 1743, Avg. Train Loss: 0.0019634045541373104, Avg. Test Loss: 0.0025308548938483\n",
      "Epoch: 1744, Avg. Train Loss: 0.001959383861313379, Avg. Test Loss: 0.0024712185841053724\n",
      "Epoch: 1745, Avg. Train Loss: 0.002015832792642678, Avg. Test Loss: 0.002525568474084139\n",
      "Epoch: 1746, Avg. Train Loss: 0.0019977379747298223, Avg. Test Loss: 0.002409624867141247\n",
      "Epoch: 1747, Avg. Train Loss: 0.0019672601402542273, Avg. Test Loss: 0.0024708150885999203\n",
      "Epoch: 1748, Avg. Train Loss: 0.0019090482179985144, Avg. Test Loss: 0.0024941647425293922\n",
      "Epoch: 1749, Avg. Train Loss: 0.001953693981239096, Avg. Test Loss: 0.0025425227358937263\n",
      "Epoch: 1750, Avg. Train Loss: 0.001967708539585908, Avg. Test Loss: 0.0026271517854183912\n",
      "Epoch: 1751, Avg. Train Loss: 0.0019665680105559703, Avg. Test Loss: 0.002474327804520726\n",
      "Epoch: 1752, Avg. Train Loss: 0.0019572945798985485, Avg. Test Loss: 0.002511574188247323\n",
      "Epoch: 1753, Avg. Train Loss: 0.0019525024785421962, Avg. Test Loss: 0.0024137527216225863\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1754, Avg. Train Loss: 0.0020733173655042817, Avg. Test Loss: 0.0026306449435651302\n",
      "Epoch: 1755, Avg. Train Loss: 0.0021023149547968493, Avg. Test Loss: 0.002437436953186989\n",
      "Epoch: 1756, Avg. Train Loss: 0.0019498316782288426, Avg. Test Loss: 0.0025382856838405132\n",
      "Epoch: 1757, Avg. Train Loss: 0.0019506434206092774, Avg. Test Loss: 0.0024428588803857565\n",
      "Epoch: 1758, Avg. Train Loss: 0.001975531576114685, Avg. Test Loss: 0.0024657053872942924\n",
      "Epoch: 1759, Avg. Train Loss: 0.0019314945377626044, Avg. Test Loss: 0.002462065080180764\n",
      "Epoch: 1760, Avg. Train Loss: 0.001981009528863915, Avg. Test Loss: 0.0024861637502908707\n",
      "Epoch: 1761, Avg. Train Loss: 0.0019897330649803545, Avg. Test Loss: 0.002494944492354989\n",
      "Epoch: 1762, Avg. Train Loss: 0.0020120773372391976, Avg. Test Loss: 0.002438418800011277\n",
      "Epoch: 1763, Avg. Train Loss: 0.0019195415593986941, Avg. Test Loss: 0.002433956367895007\n",
      "Epoch: 1764, Avg. Train Loss: 0.001934980061230098, Avg. Test Loss: 0.002595535945147276\n",
      "Epoch: 1765, Avg. Train Loss: 0.002015604277487931, Avg. Test Loss: 0.002411552472040057\n",
      "Epoch: 1766, Avg. Train Loss: 0.0019757261656787855, Avg. Test Loss: 0.0025875328574329615\n",
      "Epoch: 1767, Avg. Train Loss: 0.0019701320250237056, Avg. Test Loss: 0.0024594778660684824\n",
      "Epoch: 1768, Avg. Train Loss: 0.002017224096519829, Avg. Test Loss: 0.0024731289595365524\n",
      "Epoch: 1769, Avg. Train Loss: 0.001980780894586513, Avg. Test Loss: 0.002570680109784007\n",
      "Epoch: 1770, Avg. Train Loss: 0.0019599656861405386, Avg. Test Loss: 0.002530571771785617\n",
      "Epoch: 1771, Avg. Train Loss: 0.001953292776137417, Avg. Test Loss: 0.002514882246032357\n",
      "Epoch: 1772, Avg. Train Loss: 0.0019490009357849526, Avg. Test Loss: 0.0024589677341282368\n",
      "Epoch: 1773, Avg. Train Loss: 0.0019814474616459635, Avg. Test Loss: 0.0024201874621212482\n",
      "Epoch: 1774, Avg. Train Loss: 0.0019378218810658814, Avg. Test Loss: 0.002418039832264185\n",
      "Epoch: 1775, Avg. Train Loss: 0.0019699983937709136, Avg. Test Loss: 0.0024604694917798042\n",
      "Epoch: 1776, Avg. Train Loss: 0.0019499850675983484, Avg. Test Loss: 0.002615285338833928\n",
      "Epoch: 1777, Avg. Train Loss: 0.0019662906415760517, Avg. Test Loss: 0.0026703174225986004\n",
      "Epoch: 1778, Avg. Train Loss: 0.0019833778984151606, Avg. Test Loss: 0.0025014267303049564\n",
      "Epoch: 1779, Avg. Train Loss: 0.0019396139297980903, Avg. Test Loss: 0.00258058775216341\n",
      "Epoch: 1780, Avg. Train Loss: 0.0020473472080951515, Avg. Test Loss: 0.0024268690031021833\n",
      "Epoch: 1781, Avg. Train Loss: 0.0019127929469483884, Avg. Test Loss: 0.002565258415415883\n",
      "Epoch: 1782, Avg. Train Loss: 0.0019446241528575505, Avg. Test Loss: 0.002412868198007345\n",
      "Epoch: 1783, Avg. Train Loss: 0.001962138193681143, Avg. Test Loss: 0.002555243903771043\n",
      "Epoch: 1784, Avg. Train Loss: 0.0019887511558874054, Avg. Test Loss: 0.0024221690837293863\n",
      "Epoch: 1785, Avg. Train Loss: 0.0019470728435661904, Avg. Test Loss: 0.002632836112752557\n",
      "Epoch: 1786, Avg. Train Loss: 0.001947760877069519, Avg. Test Loss: 0.002433500252664089\n",
      "Epoch: 1787, Avg. Train Loss: 0.0019126135671814514, Avg. Test Loss: 0.0024617037270218134\n",
      "Epoch: 1788, Avg. Train Loss: 0.001991233146792754, Avg. Test Loss: 0.002443891717121005\n",
      "Epoch: 1789, Avg. Train Loss: 0.001942417505846987, Avg. Test Loss: 0.0025046938098967075\n",
      "Epoch: 1790, Avg. Train Loss: 0.001921835201142659, Avg. Test Loss: 0.002461681142449379\n",
      "Epoch: 1791, Avg. Train Loss: 0.001907365675474149, Avg. Test Loss: 0.0025619915686547756\n",
      "Epoch: 1792, Avg. Train Loss: 0.001984823275855634, Avg. Test Loss: 0.0024763192050158978\n",
      "Epoch: 1793, Avg. Train Loss: 0.001913126541821416, Avg. Test Loss: 0.0024584822822362185\n",
      "Epoch: 1794, Avg. Train Loss: 0.001898696440337009, Avg. Test Loss: 0.002459642942994833\n",
      "Epoch: 1795, Avg. Train Loss: 0.0019021929961867458, Avg. Test Loss: 0.002395923947915435\n",
      "Epoch: 1796, Avg. Train Loss: 0.0019268040074208795, Avg. Test Loss: 0.002541043795645237\n",
      "Epoch: 1797, Avg. Train Loss: 0.001978750873985159, Avg. Test Loss: 0.0024247474502772093\n",
      "Epoch: 1798, Avg. Train Loss: 0.001961424445928356, Avg. Test Loss: 0.00258001615293324\n",
      "Epoch: 1799, Avg. Train Loss: 0.0019107847041342147, Avg. Test Loss: 0.0024054483510553837\n",
      "Epoch: 1800, Avg. Train Loss: 0.0019475858940114809, Avg. Test Loss: 0.002520082052797079\n",
      "Epoch: 1801, Avg. Train Loss: 0.002044796946371884, Avg. Test Loss: 0.0025071913842111826\n",
      "Epoch: 1802, Avg. Train Loss: 0.0019522736195561497, Avg. Test Loss: 0.002499219961464405\n",
      "Epoch: 1803, Avg. Train Loss: 0.001992769390452913, Avg. Test Loss: 0.0024720553774386644\n",
      "Epoch: 1804, Avg. Train Loss: 0.0019433196190051562, Avg. Test Loss: 0.002436502603814006\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-155-80409003b1e0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0;31m# backward pass to calculate the parameter gradients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0;31m# update the parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/torch_cuda9/lib/python3.6/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    305\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 307\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/torch_cuda9/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    154\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    155\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Now let's train the initial network \n",
    "\n",
    "model = offCenterLineNet()\n",
    "model = model.to(dev)\n",
    "model.apply(weights_init_uniform)\n",
    "\n",
    "model.train();\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=.01) \n",
    "# scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=500, gamma=0.1)\n",
    "\n",
    "n_epochs = 2400\n",
    "\n",
    "mse_loss = nn.MSELoss()\n",
    "ce_loss = nn.CrossEntropyLoss()\n",
    "\n",
    "for epoch in range(0,n_epochs):  # loop over the dataset multiple times\n",
    "    \n",
    "    if epoch == 0:\n",
    "        train_loss_over_time = [] # to track the loss as the network trains\n",
    "        test_loss_over_time = []\n",
    "        \n",
    "    if epoch == 10:\n",
    "        optimizer = torch.optim.Adam(model.parameters(),lr=.005) \n",
    "        \n",
    "        \n",
    "    running_loss = 0\n",
    "    num_batches = 0\n",
    "    \n",
    "    for batch_i, data in enumerate(train_loader):\n",
    "        \n",
    "        # get the input images and their corresponding labels\n",
    "        num_batches += 1\n",
    "\n",
    "        inputs, output_gt, _, _ = data\n",
    "        inputs, output_gt = inputs.to(dev), output_gt.to(dev)\n",
    "        \n",
    "        # zero the parameter (weight) gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # forward pass to get outputs\n",
    "        output_line_params = model(inputs)\n",
    "        \n",
    "\n",
    "        # make the ground truth\n",
    "        c = -output_gt[:,2]*torch.cos(output_gt[:,0]) + output_gt[:,1]*torch.sin(output_gt[:,0])\n",
    "        gt_line_params = torch.stack((-torch.sin(output_gt[:,0]),torch.cos(output_gt[:,0]),c),dim=1)\n",
    "        \n",
    "        # calculate the loss\n",
    "#         print(output_line_params[:,:,0,50])\n",
    "        \n",
    "        loss = mse_loss(output_line_params,gt_line_params)\n",
    "        \n",
    "        # backward pass to calculate the parameter gradients\n",
    "        loss.backward()\n",
    "\n",
    "        # update the parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        # to convert loss into a scalar and add it to running_loss, we use .item()\n",
    "        running_loss += loss.item()\n",
    "      \n",
    "\n",
    "#     scheduler.step()\n",
    "    \n",
    "    # Calculate test data loss after each epoch\n",
    "    with torch.no_grad():\n",
    "        test_loss = 0\n",
    "        num_batches_test = 0\n",
    "        for batch_i, data in enumerate(test_loader):\n",
    "            num_batches_test += 1\n",
    "\n",
    "            # Add code here\n",
    "            inputs, output_gt, _, _ = data\n",
    "            inputs, output_gt = inputs.to(dev), output_gt.to(dev)\n",
    "\n",
    "\n",
    "            # zero the parameter (weight) gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward pass to get outputs\n",
    "            output_line_params = model(inputs)\n",
    "\n",
    "            # make the ground truth\n",
    "            c = -output_gt[:,2]*torch.cos(output_gt[:,0]) + output_gt[:,1]*torch.sin(output_gt[:,0])\n",
    "            gt_line_params = torch.stack((-torch.sin(output_gt[:,0]),torch.cos(output_gt[:,0]),c),dim=1)\n",
    "    \n",
    "\n",
    "            # calculate the loss\n",
    "    #         print(output_line_params[:,:,0,50])\n",
    "\n",
    "            loss = mse_loss(output_line_params,gt_line_params)\n",
    "            \n",
    "            test_loss += loss\n",
    "                    \n",
    "        test_loss_over_time.append(test_loss/num_batches_test)\n",
    "\n",
    "    # Calculate model loss:\n",
    "    avg_loss = running_loss/num_batches\n",
    "    train_loss_over_time.append(avg_loss)\n",
    "    \n",
    "#     print('Epoch: {}, Avg. Train Loss: {},'.format(epoch + 1, train_loss_over_time[-1]))\n",
    "\n",
    "\n",
    "    print('Epoch: {}, Avg. Train Loss: {}, Avg. Test Loss: {}'.format(epoch + 1, train_loss_over_time[-1], test_loss_over_time[-1]))\n",
    "    \n",
    "print('Finished Training')\n",
    "\n",
    "plt.figure()\n",
    "plt.semilogy(np.arange(0,n_epochs),train_loss_over_time[0:])\n",
    "plt.semilogy(np.arange(0,n_epochs),test_loss_over_time[0:])\n",
    "plt.legend(['Training loss', 'Testing loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "df61a258",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor(2.8954), tensor(3.1278), tensor(2.9318), tensor(2.7288), tensor(2.9849), tensor(3.1614), tensor(3.1129), tensor(3.2746), tensor(2.9380), tensor(2.8767), tensor(3.2177), tensor(2.9134), tensor(2.7144), tensor(2.7509), tensor(2.6870)]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA10AAANSCAYAAACeLaSKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4xLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvDW2N/gAAIABJREFUeJzs3Xd8VHX2//HXnZJegER6Cy3Se+9SpINiwc6KjV0V97f2srbdBV3X/dpWscuquEoTQZqAdKVKEektlAABQtok0+7vj4AVIQmZuZnJ+/l4+EDD3Ps5MXqYM+fcz8cwTRMREREREREJDJvVAYiIiIiIiIQzFV0iIiIiIiIBpKJLREREREQkgFR0iYiIiIiIBJCKLhERERERkQBS0SUiIiIiIhJARSq6DMP4s2EY3xuGscUwjMmGYUQFOjARkQtRbhKRskr5SUR+7oJFl2EYNYB7gXamaTYD7MCoQAcmInI+yk0iUlYpP4nIrxV1vNABRBuG4QBigMOBC0lEpMiUm0SkrFJ+EpEfOS70AtM0DxmG8QJwAHAB803TnP/r1xmGcQdwB0BsbGzbSy+9tLRjlbLm9GnYtQsaNOCkL5G9e6FhQ0hIsDowKal169ZlmKZ5idVxFIVyk0j5Em75SbkpvJgmrF8P1atDtWpBWtTvhw0boEYNqFo1SIvKrxU1NxmmaZ7/BYZREZgKXAtkAp8BU0zT/PD3rmnXrp25du3a4kUsoeemm2D2bEhPp0ffCA4fhh07wKbtWUKWYRjrTNNsZ3UcRaHcJFK+hHN+Um4KfSdOQHIy/N//wbhxQVp03z5ISYF334U//CFIi8qvFTU3FeXtcV9gr2max03T9ADTgC4XG6CEuLw8mDEDRo5k664Ili2DO+5QwSVBpdwkImWV8lM5k5VV+GtiYhAXPXas8NfKlYO4qJRUUd4iHwA6GYYRYxiGAfQBfghsWFLmzZ4NOTlw3XW8+SY4nTB6tNVBSTmj3CQiZZXyUzlz+nThr0F9xEJFV0i5YNFlmua3wBRgPbD5zDVvBjguKesmT4Zq1XB16MkHH8DIkfp/XoJLuUlEyirlp/LnbNFlSafrkpB41LHcu+BGGgCmaT4JPBngWCRUnD4NX34Jd93Fp1PtZGbCnXdaHZSUR8pNIlJWKT+VL5aMFx4/Xviriq6QoCdwpPimT4eCArjuOiZOhNRU6NnT6qBERERErGHZeGFsbOFfUuap6JLimzwZ6tVjc3QHVq0q3EDDMKwOSkRERMQalo0X6tmOkKGiS4rn2DFYuBBGjWLimwaRkXDLLVYHJSIiImIdy3Yv1GhhyCjSM10iP/rsM/D5yBt+Hf/tB1dfDUlJVgclUkSZmYUnWKo1KyIipej06cKdnCMjg7jo8eOFByNLSFCnS4rnk0+gaVMmb25GVpY20JAQs3s3DBwI27dbHYmIiISRrKzCLldQP9PTeGFIUdElRXfgACxf/uMGGk2aQNeuVgclUgw1a8KqVdCsGTzwwE/zICIiIhfh9Okgb6Jhmiq6QoyKLim6//0PgO+bj2LNmsIul6a0JKRUqQI7dsBNN8ELLxRuvTlpEvj9VkcmIiIh7PTpID/Pdfo0eDx6piuEqOiSops8GTp04JUv6xMVVfi+VSTkVKkC774L334LtWsX7gTTrRusW2d1ZCIiEqLOjhcGzdkzutTpChkquqRotm+HDRvIv+I6PvoIRo2CihWtDkrkInToUDhq+O67hc96tW9feP7B2T/IREREiijo44XHjhX+qqIrZBimaZb6TatUqWJee+21Jbo2MagfE/ykZcuWlqx74sQJS9YdP358sV5/X2Ym954+TfMKd7M18xWqVr2CyMgNxV63V69exb6mNKxYscKSdfv06WPJum+88UaJrjMMY51pmu1KOZwy49JLLzXffPPN33zdnpNDnfffp/q0afiio9l/660cHj4cHD9t8Lp///5ghvqjYcOGWbLu/PnzLVl3wIABlqw7b948S9Y9ePCgJeumpqZasu7AgQNLfG0456datWqZ9913X4mubdasWSlHUzR16tSxZN133nnHknWXLVt23t/fsGE6CQkbqF//mVJdt3379uf8eovdu7l9zhwmXHsthwIwYuh0Okv9nkURHx9vybpPP/10ia8tam5Sp0suzDQZmpvLN5GR7Mq7E6fzByIiil9wiZRVvrg49tx9N+vffZec1FQavPwybW+7jcT1660OTUREQoDPF4Pdnhu09eJdLgByoqODtqZcHBVdckFN3W7qe71Mi0zF7W5GfPxH2kBDwlJe3bps/te/+P7ZZ7G7XLT8859p/OSTRB49anVoIiJSRpkm+HyxQS264lR0hRwdjiwXNCwvDw/wqe8eDCOP2NjPrQ5JJHAMgxM9enCqY0dqTp5MrY8+otKqVUQOHsz3gwbhj4iwOkIRESlD/P5owIHdnhO0NeNcLvIiI/HZ7UFbUy6OOl1yXsaZ0cKlUfEczLue2NjPsdmyrQ5LJOD8kZEcGD2atf/9Lyc7daLVtGkMe+QRaq1bV/ixpoiICIVdLiDo44XZ6nKFFBVdcl5tCwqo7vPxqf0yTDOGuLiPrQ5JJKgKqlblh2eeYcFDD+GLiKDXSy/R55//JOHwYatDExGRMsDniwMIaqcrPi9Po4UhRkWXnNew3FxchsGnBY8TEbGZyMjNVockYon0pk2Z9eyzrLnhBpL37GHoY4/RZvJknGfm6kVEpHw62+lyOII7XqiiK7So6JLfZTdNBuXlMT+yOpnedupySblnOhxsu/xyPn/+eXZ360aTuXMZ/uCD1Fu2DPx+q8MTERELeL1nxwvzgrZmnMYLQ46KLvldXfPzSfb7mWxej2FkExs70+qQRC5KZqYDr/fit97MT0jgmzFjmPPkk+QkJ9P1rbcY8OyzVNqzpxSiFBGRUBLs8ULD7ycuP5/smJigrCelQ0WX/K5hubmcNmzMKHjszAYawXtAVCQQjh6N4pZb2rJw4SWl0pg6Ua8ec594ghW3305cRgaDnn6aTu+8Q1RW1sXfXEREQsJPG2kEp+iKLSjAZprkREUFZT0pHSq65JwiTZP+eXnMcraggETi4zVaKKGvRg0XERF+nnmmMbff3oZVqypd/EaENht7unfn8+eeY+uAAdRfvpzhDz7IpfPnY3i9pRK3iIiUXT91uoLz4fSPZ3Sp0xVSVHTJOfVyuUgwTT70jSMi4jsiIrZaHZLIRYuL8/HOO+t5/PEfcLnsPPxwM+65pyUbNyZe9L09MTGsv+46vvjb38ioV4/2H37IkCeeoOpW/b8jIhLOfup0BeeZrri8wnX0TFdouWDRZRhGqmEY3/3sryzDMO4LRnBinWG5uRy3RbLAdyPx8R9ZHY7Ib5Q0N9ls0K/fcSZNWstf/rKTI0eiuPfeljzwQDN27Ii76LiyatRg4QMP8PW4cTgKCug3YQI9XnmFmIyMi763iIQGvXcqX3y+WGy2XAwjOBsqxZ/pdKnoCi2OC73ANM3tQCsAwzDswCFgeoDjEgvF+f30cbn4wD4Av5lHTMwsq0MS+Y2LzU0Oh8mwYUe4/PKjTJ9enY8+qsXtt7ehZ8/jjBmzjzp1LmIreMMgrW1bDjdvTpMvv6TZrFnU2LiRLUOGsHXQIHwRESW/t4iUeXrvVL74fHFBPxgZ0JbxIaa444V9gN2mae4PRDBSNvTLyyPKNJnkfYC4uGnYbDqHSMq8EuemyEg/o0YdZPLk1dx8835Wr67E6NHteO65Rhw9GnlRQfkiItg8YgSfT5jAwVataDVtGsMefphaa9dy8Q+TiUiI0HunMOf1xgb9jC4/kKuNNEJKcYuuUcDkc/2GYRh3GIax1jCMtS4dFhrShuXmkmZLZBU9dTaXhIoi5abMzMzfvUFcnI8xY/YzefJqRo48xFdfVeaGG9rzyiv1OHXKeVHB5SUns+zuu5n/8MN4oqLo9fLL9PnnP0k4dOii7isiIeGc+ennuSk3V7sDh7Jgd7riXC5yo6MxbdqaIZQU+adlGEYEMAz47Fy/b5rmm6ZptjNNs1202p0hq6LPR7f8fD4xryUicj0RETusDknkvIqTmypUqHDB+1Ws6OHuu/fw0Udr6N//KNOn1+C66zowZUpL8vIurvg62qQJs599ltU33kjSnj0Mffxx2n78Mc684B2oKSLBc7789PPcFBsbG/zgpNT4fLFB2y4eID4vT89zhaDilMgDgfWmaR4NVDBivYF5eTiBj8yx6nJJqAhIbqpcuYAHH9zJ+++vpVOnE8yc2YK//OUKZs9uQkGBvcT3Ne12tvfvz+fPP8/u7t1pPG8ewx96iHrLllEqh4eJSFmi907lQGHRFdxnuvQ8V+gpTtF1Hb8zviPhY1huLtuMmmw26hATM9vqcESKIqC5qXZtF089tY1nnplF/foZ/O9/bXnggREsXNgIr7fkox0FCQl8c+utfPnkk+QkJ9P1rbcY8OyzJO3ZU4rRi4jF9N6pHLBivFBFV+gp0jsGwzBigX7AtMCGI1aq4vXSoaCAj81biY2bhs1WYHVIIucVzNxUt+4p7r9/EY89No/KlbP54IOOPPzwMFasSMHvN0p835P16jH3iSdYcccdxGZkMOipp+j89ttEZWWVYvQiEmx671R+FBZdwd1IQ+OFoeeCW8YDmKaZCyQFOBax2JC8PGzAZG4kPv4uq8MRuSArclNq6jEee2w+mzZV57PPWjNxYjdmz27KyJHf0abNQYyS1F82G3u6dSOtbVuaz5hB4/nzqb12LRtHjICBA8F5cc+SiUjw6b1T+eD32/H7o4K2e6Hd5yO2oIDsmJigrCelR9ueyI+G5eayjuakRZ7E6dxtdTgiZZZhQMuWh3nmmdn86U9L8XptvPRSb555ZgBbt1Yp8X090dGsv+46vvj73zlevz7tP/6YuO7dsS9ZUorRi4hIafH5CjdBCdZ4YazO6ApZKroEgLoeDy3dbiZzM/HxH1kdjkhIsNmgY8f9jB//BWPGrOLUqRgmTOjPc8/1Zc+ekn/AnVW9Oovuv5/F990H+fnEDR9OzM03Y+zXMT8iImWJzxcHBK/o0sHIoUtFlwAw9MwZIZ8Z/YmJmWtxNCKhxW436dlzF88/P4Prr1/DgQMVeeqpQbz0Uk8OHUos2U0Ng4Nt2pDzzTfkP/44jq++Ir5jRyInTACdhSgiUiYEu9MVdyb/65mu0KOiS8A0GZpbwFK6kRm/CsNwWx2RSEiKiPAzYMA2XnhhOlde+R1bt1bl0UeHMHFiF44fjyvZTaOiKLj/frJXr8YzaBBREyYQ36EDjpkzwTRL9xsQEZFi+anTFZxnuuJVdIUsFV1CY4+HRt58JnM9cXHa2VbkYkVHexkxYjMvvDCdAQN+YPXqOjz44DAmTWpPZmZUie5p1qyJ6913yZk1CzM+ntibbyZ2xAhs27aVcvQiIlJUP3W6glt0abww9KjoEobk5uHFzqzIWjid+6wORyRsxMe7ue669fzznzPo2XMXixc34v77r+DTT1uTmxtRonv6unUjZ+lSXM8/j/2774jr2pWoRx6B06dLOXoREbmQYD/TFZeXh89mwxUZGZT1pPSo6CrvTJOhOT4W0I/8+DlWRyMSlipVcjF69GomTJhJ27ZpzJ7dlL/85QpmzmxGQUGRTu74JYcD9x13kL1+Pe6bbybijTeIb9cO53//C35/6X8DIiJyTl5vYafL4QhS0ZWfXzhaWKLzScRKKrrKuTZuN7X9OfzPGExMzHyrwxEJa1WqZDN27HKefXYWqalHmTKlNfffP4L581PxeIqfjs2kJPL//W9yFi/GX68eMffcQ2zfvtjXrQtA9CIi8mtBHy/My9PzXCFKRVc5NyTbxEUUX8UVYBgeq8MRKRdq187kz3/+mieemEP16qf58MMOPPTQcJYtq4ffX/xPL/2tWpE7dy55EydiO3yYuD59iP7TnzCOHQtA9CIicpbPF4dheIK2CVmcy6XnuUJUCeZaLiw6OprWrVuX6Nrq1auXcjRFExFRsucrLta+ffssWbdfv37Y/H6GTZrGbAbTdWAGCQn9Ar7u0qVLA77GuWRmZlqy7o4dOyxZV84tOzu7xP8Njh07tpSjKXTvvbBkSRZ/+1sMb73VlSVLOvLooy4GD3ZjGPDiiy8W634Rt9xCz2XL6DR5MhFTpvB1z5582749fru9WPe56qqrivX60jJ16lRL1h08eLAl665fv96SdQ8fPmzJunJuUVFRNGnSpETX7t69u5SjKZqGDRtasu79999vybq5ueceH8zOrsupU/m0bdsmIOvOnfvLY3wePHGCHVFRv/l6afN6vQG9/+8ZNWqUJesGgzpd5VjDQ+kkezNZUKkrCQkZVocjUi4ZBvTq5WHBgtO8/342AKNHx9O3byKLFzuLvSu8OzKSBX378p+77iKtZk0GzJ/P2IkTqbdnTwCiFxEp3zyeKCIignd2YkWfjxPF/BBNygYVXeVYs80nySKegy31MKaI1QwDhgxxs2zZaV59NYeTJw2uvjqBSZNGk5ZWs9j3O5GczIfXX89H116Lw+fjlg8/5NpPP6WCRV1fEZFw5HZHExGRH5S1ovx+4kyTE46ADKpJgKnoKqccPh+dj3zPLPsgqqbonB+RssJuh1GjCvjmm0wmTMglIyOZ9967nU8+uY6jRysX72aGwY7UVF4bO5avevemwe7d3P2f/9D7669xevQMp4jIxXK7o4JWdFXy+QA4qU5XSFKpXE7V25lJopnNyjqXYrMdsjocEfmVyEi47bZ8MjNfZ/XqTqxc2ZWJE8fSrNkWevVaTKVKJ4t8L6/DwbLu3dnYsiX9vvqKXkuX0mrjRub168fWxo219bCISAm53dHEx58IylpJKrpCmoqucqrFlgwySOJU2xxirA5GRH5XRISHbt2W0bbtGlau7Mrq1Z3YurUprVuvp3v3JSQkZBf5XlkJCUy98krWtm3LoLlzuXbKFPbUrcuXAwZwvHIxu2giIhLU8cKznS490xWaNF5YDtlcHrplrmNO7GXEJJ62OhwRKYLo6Hz69FnIPfe8RNu2a9mwoTWvvjqOBQv6k5dXvO2D99epw8Tbb2fWwIFUTU9n7MSJDJg3j6j84LxxEBEJF4XjhcHZSCNJRVdIU6erHIpekEEseXzXuBqQZ3U4IlIMcXE5DBz4JZ06rWTp0l58801n1q1rS+fOK+nUaRWRkUU7K8Zvs7GmfXu2NG1Kn8WL6fjttzTfvJmFffqwoVWrwH4TIiJhwDSD+0yXxgtDm4qucih1/UYOGtU53dyFnuQQCU0VK2YyfPgMunRZweLFl7FkyWWsWdORbt2W0a7dGhyOop2x4oqJYdbgwaxt04ZBc+cy/IsvaLduHa5GjXC1bBng70JEJHR5vZGYpj1ona5KPh8uwyBPz+GGJI0XljN5Bx10y13K4ks6YNiLeQCQiJQ5l1xynGuu+R9jxkykatUjzJ8/gFdfvZf169vg9xc9xadXq8a7o0cz5YoriM/OpsFNN1Hz8cdxZOgMPxGRc3G7owCCOl54wm7X5kchSp2uciZm7jEi8LCtdbzVoYhIKapR4zA33vhf9u6ty6JFfZk1azgrV3ald+9FNGmyFcMowocshsHm5s3Z3qgRt2dkkPzBByQsXMixu+7ixPXXYzqdgf9GRERChNtd+DxtMDfS0PNcoUudrnLE67XRbtdK9kfU4VjNCKvDEZEASEnZx623vs21136Mw+Fj6tRreOutO9m5syFmEZvb7shIjo4bx87p08lt04Zq//oXDa66iriVKwMbvIhICCkoCH6n65SKrpBVpKLLMIwKhmFMMQxjm2EYPxiG0TnQgUnpO7imEj18S9nUpL1a0xIWlJvOzTAgNXU7d9zxOldcMYWCgkgmT76R99+/lf37axf5Pu46ddj/2mvse/VVDJ+PlLvuovZ99+E8eDCA0YuEB+Wn8OfxBLfTlaROV0graqfrJWCuaZqXAi2BHwIXkgRK1aV7sWFy9LIUq0MRKS3KTedhs5k0b76ZP/7xVQYN+oJTpyrywQdj+PjjGzhypGqR75Pdowc7p00jfdw44latotGIEVR+7TUMV3A+3RUJUcpPYS6oz3SZJkler4quEHbBosswjESgB/AOgGmabtM0MwMdmJSu48cr0DdjHrvjG5BZTYegSuhTbio6u91Hu3Zrueeel+nbdz6HDtXkrbfGMmXK1WRkJBXpHmZEBMfHjGHHzJlk9e1LlYkTaTR8OAnz51PkuUWRckL5qXz46ZmuwBddcaZJBDqjK5QVpdOVAhwH3jMMY4NhGG8bhhH76xcZhnGHYRhrDcNYm5OTU+qBysU58HUynfiW3e2bWR2KSGkpdm7Kzc0NfpRliNPpoUuXFdxzz//RvfvX7NzZkNdf/xNffDGM06cTi3QPb5UqpE2YwO733sOXmEid++8n5bbbiNy5M8DRi4SUC+ann+emrKwsa6KUi/JTpyvw44WVvIXHgOiMrtBVlKLLAbQBXjdNszWQCzz86xeZpvmmaZrtTNNsFxcXV8physXweu2kbtgIwL6OjS2ORqTUFDs3xcb+piYrl6KiCujdezH33vsSHTqsZtOmlrz66r3MmzeA3Nyi/TvKa9uWXZ98wqHHHiNqxw4aXnMN1SZMwKY3jyJQhPz089yUkJBgRYxykQoKCjtdTmfgi66zByOr0xW6ilJ0HQQOmqb57Zl/nkJhIpEQsXlzQ670TGVXlVSyKlWyOhyR0qLcdJFiY3O5/PK53H33y7RosZHVqzvyyivjWLy4N9nZRfjjwW7n5LXXsuOLLzh51VUkffIJqUOHUnHKFDjzBkGknFJ+Kgc8niicThc2W+BHrFV0hb4L/qlqmmY6kGYYRuqZL/UBtgY0KilVJ5ZG0YLN7O2kLpeED+Wm0pOYeJqhQ2cyduyrNGiwk2XLejFoUCrvvZdMfv6Fdzr1VajA4cceY9cnn1CQkkLNZ56h/g03ELNxYxCiFyl7lJ/KB7c7OqhndAGcdOiI3VBV1N0L7wE+MgxjE9AK+EfgQpLSdPRoJbod/BofNna2bGF1OCKlTbmpFCUnn+Cqqz7j9tvfoFkzF//+dzWGDEnl008r4fFc+Pr8Sy9lz3vvcWDCBJwZGdS/6SZqPvYYjuPHAx+8SNmj/BTmCgqig3pGF+iZrlBWpKLLNM3vzswdtzBNc4RpmqcCHZiUjm+/ac51TGZfvUbkxcdbHY5IqVJuCoxq1Y7w+uv7ePfd3dSo4eZvf6vB8OGNmD27woWnBg2D04MGsWPmTI6NGUPi3Lk0GjaM5PffxyhK5SYSJpSfwp/HExXUM7qybTbcOmc1ZBW10yUhyONxwBoX9dnDzrbNrQ5HREJMu3Z5vP/+Hl57bR+xsX4eeaQWV1/dkMWL4y+4S7w/Joaj48axc/p0ctu2pdqLL9Jg5EjiVqwITvAiIgFWOF4YvE6XnucKbSq6wtimTY24omA6HpuDnc1VdIlI8RkGdO+ezf/+t4vnnz+Ax2MwblxdbrqpPqtXX3inQ3ft2ux/9VX2vfYahmmSMnYsde69F+fBg0GIXkQkcArHC4PT6aqooivkqegKY9+ubMZ1tsnsa5xKQXS01eGISAiz2WDAgNNMm7aDJ588yNGjDm67rR533lmXLVsunF+yu3dn59SpHLnvPmK//ZZGI0ZQ5ZVXMPLyghC9iEjpKxwvDF6nS89zhTYVXWEqPT2ZOgd2U9V/lG2tWlkdjoiECacTRo48xaxZO3jggcNs2xbN9dc34M9/rs3u3ZHnvdaMiCDj1lvZ8cUXnO7fn8pvvUWj4cNJnDuXC84rioiUMcHcvVDjhaFPRVeY+uabFlxvfITbGcHuJk2sDkdEwkxkpMlNN51g9uzt/PGPR/nmmzhGjmzI44/X5NAh53mv9VauzMF//IPdH3yAr2JFaj/4ICljxhC1Y0eQohcRuTg+nw2vNyIonS7DNKmoTlfIU9EVhtxuB5vWNuAa22fsatYUb0SE1SGJSJiKi/Nz113H+PLL7dx4YwZz5yYydGgjxo+vRkbG+c+TyWvdml2TJ3PoiSeI2rWLBtdcQ8cPPyQiJydI0YuIlIzHUzhWHYxOV6LfjwMdjBzqVHSFoY0bL6V7wTISfVkaLRSRoKhY0cf996cza9Z2Row4xaefJjFoUCovvVSFrKzz/FFjt3Py6qvZ8cUXnLzmGlIXLeLKRx6h0eLFGH5/8L4BEZFicLujAILS6dIZXeFBRVcYWrWqJX+IfB9XdDT7GjWyOhwRKUeqVvXy178e5vPPd9C7dxbvvFOZgQMv5e23LyEv7/fPl/ElJnL40Uf54qmnyKxRgy6TJjHk6aepvHNnEKMXESkat/tspyt4RZc6XaFNRVeYOXToEjLSEhnsncWOFi3wO84/3iMiEgi1a7t57rk0PvtsJ61b5/Lyy1UZPDiVyZOT8Hh+v/g6Vbs2cx96iCV33UVUdjaD/vEPur/5JtGndK6siJQdPxVdgR8vrKROV1gIyDtyl8vFxo0bS3RtampqKUdTNMuXL7dk3ZkzZ5bq/Xbv/gvDjOlE+/J5OyeHDTNmnPN1Jf35XKxRo0ZZsu68efMsWbdKlSqWrCvn5vF4OHz4cImu7du3bylHUzQnT560ZN2GDRuW2r1uvx169kzms89aM358dd56K4Err9xE1657sdnOsWuhYbC3Y0fSWrWi+axZNJs7l9obNrBx6FC29uuH33n+jTpKIjExsdTvWRQej8eSdVNSUixZV87NNE3cbneJrj1y5EgpR1M0Vv25euLECUvWTU9P/8U/Hz1aC4Ds7IO/+b3SVFBQQEJ+YWF32OejoKAgYGv93FVXXRWUdX5typQplqw7fvz4gK+hTlcY8fmiOX68Pzc7XyPD6WSjRW8iRER+rVGjDB59dAEPPriQ+PgC3nyzC488Mpg1a2r97m7x3shINowcyYy//50jl15Ku88+Y/gTT1Bj06bgBi8i8itnN9JwOAJ/1mDymedbT9n0tj2UafYsjBw/3pc4n4e+/m+ZUbUKfuP3R3hERILNMKB58yM0a3aEtWtrMWVKK15+uScpKSe4+uoNNGt27k+LsytXZtG4cdTYtIkOkyfT79//Jq1lS1Zfdx3Z6iaLiAXJLJhSAAAgAElEQVS83hgAnM7AF11JPh8nbTZ8el8X0lR0hZH09BHcGPEGEW4/X11yidXhiIick2FA+/ZptGlzkBUrUpg2rQXPP9+Xxo3TGTlyHfXrHz/ndYdatODzJk1ovGABrWbOZMTjj/P95ZezacgQvFFRQf4uRKQ883iCV3Ql+/2cUJcr5KnoChPZ2ank5qZyQ/R7HIqKYmtcnNUhiYicl91u0qPHHjp33seiRQ2ZObMZf/vbYFq1OsCVV66nVq3M31zjdzj4fuBA9nTuTNvPPqPF7NnUX7mStddcw96OHQsrOhGRAPN4YjAMDzZb4J/LrOT3k6FNNEKeyuYwcfTocKoa++ji2sHC5GS98RCRkOF0+rn88u3861+fc+WV69m+vSpPPjmciRO7c+xY/DmvcVWowPLbb2f2o4/iSkig58SJDJgwgYoHDgQ5ehEpj7zeGJzOvKC83To7XiihTT/BMOD1xnL8eF9Gx47HDixITrY6JBGRYouK8jJ06Caef34KAwduYf36Ojz66BVMmtSJU6diznnN8YYNmf3Xv7Ji9GgqHD7M0KeeouN//0tkTk6QoxeR8sTjiQnKaCEUjheq0xX6NF4YBo4f74/fH8M1/hnsjolhb2ys1SGJiJRYXJybq69eR79+W/niixYsWZLK8uUN6NNnG4MHbyYu7pdbJps2Gzt79mR/u3a0mjGDSxcuJOXbb9kwciQ7evbE1CfEIlLKPJ4YHI7AH4zsME0q6pmusKCfYIgzTUhPH86l0YtonXeMr9TlEpEwUaGCi5tu+pZ//GMa7dvvY968pjz44EhmzmyBy/XbzwzdsbGsvuEGZj79NKdq1aLzpEkMefppKu/YYUH0IhLOCscLcwO+TsUz28Wr0xX6VHSFuJycpuTlNWB09L8AWKhdC0UkzFSunMPtty/n2Wc/p3HjI0yf3oaHHhrJ/PlN8Hh++0Yks1Yt5j34IF+PHUtUdjaDxo+n+8SJxJw6ZUH0IhKOgjVemOTzAeiZrjCg8cIQl54+DJstjxH5S/k+Lo7D2jZZRMJUjRqZ3HPPYvbsSWbq1DZMntyBefOaMHz4Rrp23YXd/rNTlg2DfR06cLBlS5rPnk2zOXOovWEDm4YO5fv+/fE7ndZ9IyIS8rze4IwXnj0YOUNFV8jTTzCEeb3xZGT0oXPFd0nNy9HZXCJSLtSrl8EDD8zngQfmUaGCi/fe68rjj49g9eq6nHl/8iNvZCQbrryS6X//O0eaNKHtlCmMePxxam7caE3wIhIWgt3pOqHxwpBXpE6XYRj7gGzAB3hN02wXyKCkaI4duxy/P4qbHG/jBxYlJVkdkkhQKTeVb02aHKFx49ls2FCLadPa8Prrvahd+wQjR66nefNDv9jKOadyZRbdey/VN2+m48cf0/f//o+0li1ZPWoU2VWrWvdNSNhSfgpfpgkeTzQORxCKLnW6wkZxxgt7m6aZEbBIpFjObqARF/s9g05vZ0NiIiciI60OS8QKyk3lmGFAmzZptGp1kG++SWHGjNb8+9/9aNjwKFddtY5GjY794vWHmzfn82efpfFXX9Hy888Z8fjjbL38chg2DHSovJQ+5acw5PNFAfagdbq8QJaKrpCnn2CIys5ugcuVQp+Kr1MrP1+7FopIuWazmXTpsod//GM6N920imPH4hk/fhAvvtiX/fsr/eK1foeD7wcMYPr48ezt1InmX36Js3lzbJ98UviJlojIeXg80QBBKbqS/X5O2myYwTiFWQKqqEWXCcw3DGOdYRh3nOsFhmHcYRjGWsMw1rpcgX+wsLxLTx+G3Z7DNb4v8BgGX2u0UMon5Sb5BYfDz2WXbee556Zy1VVr2bPnEp56ahivv96T9PSEX7zWVaECy2+7jdmPPYZZtSqOW27B0acPxnffWRS9hJnz5qef56asrCwLwpOS8ngKD2sPynihz6ft4sNEUYuubqZptgEGAn8yDKPHr19gmuabpmm2M02zXXR0dKkGKb/k8SSQkdGbyslz6HMindUVKpCtnbikfFJuknOKjPQxePAWnn9+KkOGbGTjxpo89tgI3nuvCydOxPzitccbNMC7YgXe11/H2L4dR+fO2O++G06csCh6CRPnzU8/z00JCQnnvoOUSV5vLBCcTleSDkYOG0X6KZqmeejMr8eA6UCHQAYl53fs2EBMM5KB8W9Txe3WroVSbik3yYXExLgZOXIDzz03lcsu28bKlfV5+OGRTJ7cnqysnz0Ha7Phv/VWPFu24B87Ftu77+Js2hTbG2/Amd3DRIpD+Sl8BXO8MMnv186FYeKCRZdhGLGGYcSf/XugP7Al0IHJuZkmHD06jPj4zQzJ2US+zcbySpUufKFImFFukuJITMznhhtWM378NDp12sOCBY156KGrmD69FXl5P5sUqFgR34sv4l2zBrNlSxzjxuHo1Alj2TLrgpeQo/wU3rze4I4XqtMVHoryU6wCLDcMYyOwGphtmubcwIYlvycrqzUuVx1qVplGr4wMlleqhEufgEj5pNwkxZacnMuYMSv4+98/p1mzQ8yc2YoHHxzJiy/a+Pkjf2bTpnjnzsUzeTJGZibOvn2x33wzHDxoXfASSpSfwpjHE5zxwgifj3jT1DNdYeKCW8abprkHaBmEWKQI0tOHY7dnc7ljGhW9Xu1aKOWWcpNcjGrVTvOnP33Nvn1JTJ3ahkceqcErr5g8+qiP0aP9OJ2AYWBeeSWeAQOwv/ACthdewPbFF/geeQT/uHGgYzrkdyg/hbez44WB7nQlFBQAqNMVJvRTDCFudwVOnOhJ5cpz6H/iCNl2O99WrGh1WCIiIatu3RP85S8LWLDAQ506Jnff7aBFCyeffGLjzJmkEBOD769/xbNxI2a/fjieeAJnq1YYs2dri3mRcujseKHTmR/QdX4sutTpCgsqukLIsWODME0ndSpPpcfJkyxNSsKjTz9ERC5ajx4mixd7mT7dQ2ysyS23OGjf3sGsWcZPdVVKCt5PP8UzezY4nTivvBLH8OGwY4elsYtIcHk8MTgceRiG/8IvvgiJ6nSFFf0UQ4RpGhw9OoyEhO+4LH8jsT4fC7RroYhIqTEMGDTIZPVqL5MmeXG5DEaOdNKrl4MlS346mNTs2xfPunV4n3sOY+VKnG3aYH/0UcjOtjB6EQmWwqIr8Oc+JqrTFVZUdIWI06fbkp9fkypVPqdvRgYnnU42JCZaHZaISNix2eDaa/1s3OjhP//xkpZm0L+/k8GDHaxbd6b4cjrx33df4Rbz112H/V//wtm8ObaPP9bIoUiY83pjcDpzA77O2aIrQ52usKCfYohITx+Ow5FJ7QoL6XLyJIuSk/EZxoUvFBGREnE6YcwYP99/7+G557xs2GDQpYuTUaMc/PDDmRdVrYrvrbfwLFuGWaMGjj/8AUfv3hgbNlgau4gEjscTE5QzuhLcbvKBXL3fCwsqukKA212Jkye7U7nyHHplphNpmtq1UEQkSKKj4b77/Gzb5uHxx30sWGDQpo2T226zs29f4WvMDh3wLluGd+JEjF27cHTujP1Pf4KMDEtjF5HS5/UGb7zwhN1eOPssIU9FVwg4enQwpumgatWZ9D1+nCORkWyJj7c6LBGRciUhAZ54wsf27R7uucfPp5/aaNbMyZ//bOfoUcBmwz96dOHI4d13Y3vvPZzNmmF7/XXweq0OX0RKSbA6XYkFBdpEI4zoJ1nGFW6gMZTExHVUc+yhXWYmC5OT9amHiIhFkpPh+ed9bN3q4aab/EycaOPSS5389a92MjOBChXwvfACnnXrMFu1wnHffTg6dcJYutTq0EWkFBQWXcF5pksHI4cPFV1lXGZmBwoKqlOlyuf0zMjAAXylXQtFRCxXsya8/rqPjRs9DBni57nn7KSmOvnnP23k5gKNG+OdMwfP//6HkZWFs18/7DfeCGlpVocuIhchmOOFJ9XpChuOQNw0JiaGVq1alejazMzMUo6maC6xqJCpXr36eX9/795riYw8TfPmOxm8JIuD8fHkNWhA9YvsdLlcgU8W57J69WpL1k1JSbFk3a+//tqSdeXcXC4XmzdvLtG1sbGxpRxN0XTs2NGSdWfOnGnJumvWrLFk3aysrIu6vmtXqFMnmdmzO/P44yk8/3wu/fuvoXPnLTgcfhx3303bhQtpO2MGxuefs6ZfPzb07k2BRVMLgwcPtmRdObecnByWLVtWomvvuuuuUo6maBYtWmTJup07d7Zk3WPHjgHg89nw+SJJSnJQs2bNwC1omiS63aQ7neTlBX6U8dcWLFgQ9DUB2rdvb8m6waDyuQxzuSpy5Ehb6tZdTHJ+NpdmZLCidm2NFoqIlEE1a2Zw551fMG7cZ1xySSZTpvTi73+/idWrL8XtiOTbgQP57yOPsL9xY7rMns2N48dTb8sWbTEvEkLc7igAIiLyA7pOpMdDhM+n7eLDiH6SZdjevZdhmnbq1VtIl7Q0bMCKWrWsDktERM6jXr0j3HPPVO66awYxMQV89FF/nnvuejZurEdWpSS+vPVWpv/xj/gcDka89x5XvP02Fc98ii4iZZvbHQ1AZGRgJ4biz0wkHdcH7WEjIOOFcvFM02DPnj5UqbKRuLijdE1LY3fFiqRr10IRkTLPMKBx4wOkph5g06YGzJ7diXffHULt2ukMGbIKUuHjhx6i6ZIldJk3j5tfeIH13bvzbb9+uKOirA5fRH5HsDpdcWeKLu1eGD5UdJVRR460xuVKplWrD6ianU39U6eY1KKF1WGJiEgx2GzQqtUumjffzZo1jZkzpyP/+c8VNGyYxpAhq3D36MG21q3p/uWXtP/6axqvW8eyIUP4oU2bwotFpEw52+kKeNF15jkujReGDxVdZdSePf2IijpF9epr6botDT+wUqOFIiIhyW436dRpK+3abWfFimbMn9+ef//7Gpo23cXAgStwXXstmzp3pvf06QycPJmWK1ey6IorOKa8L1KmFBSc7XRpvFCKR0VXGZSXl8SRI61p3Hg6NsNL1wMH2JaczMmYGKtDExGRi+Bw+OjZcyOdOm1lyZKWLFzYln/962batPmByy9fRfo9NWm6di3dZs/mhpdeYnPHjqwYOBBXXJzVoYsIP40XRkYGp9Ol8cLwoaKrDNqzpw8AKSkLqXP6NDWzs3mrYUOLoxIRkdISGemhf/+1dOr0HYsWtWP58tZs2JBKp06bOd03np3Nm9NpwQJaL1tGo40bWXn55Wzs0gVTB6WKWCpo44X5+eQ7neSr0xU2VHSVMX6/jb17L6Nq1e+Ijc2g26YDeA2DbwJ5FoSIiFgiJiafIUOW0737Br76qiPffNOcNWua0q3bd2T2rciWjh3pPX06l82YQYtvvmHRFVdwsEEDq8MWKbeCNl6Yl0dOdHRA15DgUtFVxhw50pb8/ErUq/c2mCZd0tLYVKUK2ZGRVocmIiIBkpiYy8iRi+jVax3z5nXm66/bsWpVC3r1WsuR0TVounMDPWfO5JrXX2d7y5YsHTqU7IoVrQ5bpNxxu6Ow2bzY7d6ArhPncpEdEwMeT0DXkeBR0VXG7NnTl+joE1Srtp5GJ05wSV4enzRrZnVYIiISBElJp7n++rn07r2GOXO6MnduV5Yvb02fPt+y6/81odOyhXRYuJB6W7eyuk8f1vbqhc/ptDpskXLD7Y4mIiKfQE/9xeflcTIhQUVXGFHRVYbk5l5CenpLmjSZis3mp2taGm6bjTXVq1sdmoiIBFG1aie49daZ7N9flS+/7Mbnn/dm6dK29OvXgsseaE/v2TPpOncuTVevZsnw4exu2pSAvwsUEdzuqIAfjAyFz3Ttr1IFsrICvpYER5GLLsMw7MBa4JBpmkMCF1L5tWdPX6BwAw2b30/ntDTWVa9Ovj7FFPldyk0SzurUSWfs2Cns2FGLOXO68emnl7P4kvYMHNiBQZ2/pM/nMxj+3nvsa9SIxSNGcKpKFatDlp9Rfgo/bndUwDfRMEyTOJdLz3SFmeJ0usYBPwAJAYqlXPP77ezd25tq1dYTE3OSpkePU6GgQGdziVyYcpOEvUaN0mjYcDJbttRnzpyuTJo0lEU1OzBkcG+uzphMl3lzufmFF9jQvTvf9O+POyrK6pClkPJTmCkoiA540RVdUIDd7ydHRwWFlSJt/m8YRk1gMPB2YMMpvw4fbkdBQQXq118AQLcDB8hzOFhfrZrFkYmUXcpNUp4YBjRvvpv77/8v1103h7y8KN545xpu3/wKT1//f2xt3562S5fyhwkTaLJmDfj9Vodcrik/hafCTldgxwvPntGVrU5XWCnqiWv/BzwI/G4GNwzjDsMw1hqGsTY7O7tUgitPdu/uR0zMcapW/Q6Hz0eHQ4dYU6MGHp3JInI+xcpNHj2QLGHAZjNp1+4HHnroPa68ciHHj1dgwrt3cm3Wx7x8/V/JqliRAZ98wqhXX6VKWprV4ZZn581PP89NeWfeZEvZF4zxwjhXYVGnoiu8XLDoMgxjCHDMNM1153udaZpvmqbZzjTNdvHx8aUWYHmQk1OFY8dakJKyEMMwaZ2eTqzHw/Lata0OTaTMKklucur5SAkjDoefrl038sgj7zJo0DL27avOfR89xeCKc/hs8K0knjzJ9S+9RL///Y9ofRgaVEXJTz/PTTEaIwsZbnd0wDfSiD9TdOmZrvBSlGe6ugLDDMMYBEQBCYZhfGia5o2BDa382LOnL4bhIyVlMQBdDxwgKyKCLZUrWxyZSJmm3CQCREZ66dNnDV26bGLx4nYsW9aGUZvfolebMTzjeIpOqxfScNMmVg0YwMYuXfBrgiIYlJ/CkGkGp9P1Y9GlYjysXLDTZZrmI6Zp1jRNsy4wClikpFF6fD4He/f2pnr1tURHnyLS66XtkSOsqlULn62o058i5Y9yk8gvRUcXMGjQCh599B26dNnIkg0d6bX2S/7Q5hMO1ahL7xkzuPHFF6m1c6fVoYY95afw5PFEYJq2wI8Xnhk3zdGGOGFF7+otduhQB9zuBOrV+wqA9ocOEenzsUK7FoqISAnEx+dxxRWLefjh92jdehsfrhtJ07TveKrVeBwFbq5+4w2qjxuH49Ahq0MVCSlud+G4X6DHC+NcLnKjotSVDjPFKrpM0/xa50yUrj17+hIbe5QqVTYB0DUtjYzoaLYnJ1scmUjoUG4S+a1KlbIYNWo+998/idRL9/P0dw9TP38nH6XeSuySJaQMHkzSa69h5Af2U/vyTvkpfLjdhZ2nYIwXqssVftTpstCRI4kcP96MevW+wjBMYt1uWqans7JWLUzDsDo8EREJA1WrnuSWW2Zx330fkVwrixu3v0P7uC38UL8/ya+8Qt3Bg4lbsKDwgRUR+V1nO13B2L0wW89zhR0VXRZasqQRhuGlbt2vAeh08CAO02SFdi0UEZFSVqvWUe68cxpjx36Kv2Z1mn3/OddVmcdpXzw17rmHmmPGELF7t9VhipRZP3W6Arx7YV6edi4MQyq6LOLx2FmxogE1aqwhKuo0ULhr4eG4OPZWqGBxdCIiEq4aNDjI5MkH+M9/DrI+sSfV0jfzt8r/wrHhe+oOH84l48dj0xbzIr9RUBCc8UJ1usKTii6LrF1bh9zcKOrVWwBARZeLJsePF3a5NFooIiIBZBhw2WW5zJixjwn/PMZbUXdT07WT6Yk3UXHSJFIGDCBh6lTw/+654yLlzk8baQSu6LL5/cTk5+uZrjCkossiX3+dSpUqp6lc+XsAOqelYQPtWigiIkFjs8HQodnMnr2Xu5/yMdY+kXbmGn5wN6DaY49Re9QoojZtsjpMkTIhGOOFsfn52NAZXeFIRZcFDh2qwM6dVenZcweGUfjgcte0NPZWqMDhhASLoxMRkfLG6YRRo04zf/5e+jxQix7GMm5iEq5tR6lzzTVUeewx7BkZVocpYqmz44VOZ0HA1jh7Rle2nukKOyq6LPD116k4HD66di08oLJKTg4NT55Ul0tERCwVFWUyZswpFizcR8IfB9LEvo0X+Atx0z6n7uUDqPjBB+DxWB2miCXc7micznxstsDt9BnnKuyiqdMVflR0BVlBgZ2VK+vTtu0+4uMLPynpkpYGoF0LRUSkTIiP93PvvSeYvjCDLbc8ShvHRhbmdaHy+PHUGnoFMatWWR2iSNC53VFBOaML0O6FYUhFV5CtWZOCyxVJr17bf/xa1wMH2JaUxAl9qiEiImVIpUo+HnnkOC/Pj+SdkZ8wwjaD9P1+av3hD1wy9l4cBw9aHaJI0LjdUURGBna7+LOdLo0Xhh9HIG5qs9mILuF/LN99910pR1M0W7ZsCco68+d3IyHhEPv3f8iBA3B88WJqZ2XxaEICy5cvD0oMAPXr1w/aWj9XqVIlS9ZdZdGnsg0bNrRkXTk3v9+Py1WyPzCPHj1aytEUTe/evS1Zt0qVKpasGxcXZ8m6a9eutWTd9u3bW7Jucf97ttng7nsOkTaiOn98azFtl/yXRxf/g1pLl3Dg+htIv2kU/sjIC94nNTW1pCGHtcjISBo0aFCia5ctW1bK0RTNtm3bLFk3KSnJknXr1KmDzVaR+HiTOnXqBGydmlu34jcMkhs1Itlmo0ePHgFb63x8Pp8l63rCeHxZna4gOnWqNidONKR+/YU/7go/wuXCC3yhrUFFRKSMq1XLxaPP7CPlrQFc33oV03wjaPDfd2ky8g9UWLgEzMA96yJitfz8CKKiAreJBkB0bi6uuLjCTzokrOgnGkS7dvXBZnOTknLmUynTZHh+PssjIjhht1sbnIiISBE1apTLX/4vk+MvP8wfUmZxMLsSLZ75K9VHP0zk7n1WhycSEPn5kURFuQO6RkxODnmxsQFdQ6yhoitIPJ5I9u3rSu3a3xIZmQtA/RMnqOvzMUNzuyIiEoJatsxi9HvxzPvHBzxzyT9J2reNtrfeSuQjb2PLzrE6PJFSFYxOV0xODnkWjVlLYKnoCpIDBzrj9cbQoMHCH7/WZf9+CoC5Gi0UEZEQZRjQsWs2PT7twFsPzOKT2NG0X/khlw4fTf7ri8HvtzpEkVIRrE6XS0VXWFLRFSS7dvUhMfEAyck7ADD8fjodOMCiyEiyNLcrIiIhzmaDTkN8VJ95M6/cPJU9tvr0/+Qpkgb/hRNf7rM6PJGL4vPZ8HicgX+mS52usKV3+0Fw8mQKJ0/Wp0GDRT9uoNH42DEq5udrtFBERMKKwwGtxyRxetZzfNDvBSq5jnDFc7eQc/XrbFtizS6gIhcrPz8CIKBFl93rJSo/X0VXmFLRFQS7dvXBbi+gbt2ftoTvcuAALoeDrzRaKCIiYSgyClIeb8+WKR8wp/md9D02lWq9GvFRu3+zd0f4bgst4Sk/v/BIhECOF0bnFD4HqaIrPKnoCjCPJ5r9+7tQu/YqIiLyALD7fHRIS2NdjRq4zra+REREwlBkciSxr17P8tcncSSlKzes+3/kp7bk1eELOHLE6uhEiuanoitwna6YM0WXnukKTyq6Amzfvi54vVG/2ECjZXo6cW43KwN4uJ6IiEhZ4mhSnUt3z+bE+1+QlODm7pn9WV3zSp4bu4+TJ62OTuT8fhovDGCnK7dwd2t1usKTiq4AMs3C0cIKFfaRlLT7x6933r+f7IgINletamF0IiIiQWYYJN0yhMpHt3DiL//gcmMe977RmLeqP8lzT+aRo13mpYwKZqdL53SFJxVdAXTyZH0yM+vSoMHCHzfQiPR6aXvwIKtr1cKnA5FFRKQ8iooi6YVHiNq3nYKBV/BQwTOMeqYx42pM4eWXTAoCu0GcSLEFYyONmOxsQJ2ucHXBosswjCjDMFYbhrHRMIzvDcN4OhiBhYOdO/vgcORTt+7KH7/W+tAhonw+jRaKXCTlJpEwULMmFb78GJYsIblBBd7Jupqm9/VlSMr3vP8+eL1WB1gyyk/hJxgbacTk5OC123Frk7WwVJROVwFwmWmaLYFWwADDMDoFNqzQ53bHcOBAZ+rUWYnT6frx61327+dkdDTbLrnEwuhEwoJyk0i46NGD2B/WYb76Gj3iNzDnSEsy/3AfXZpkMnVq4bh+iFF+CjNB6XTl5hZuoqFN1sLSBYsus9DZKWvnmb9CL/0F2b593fD5In+xgUaM203LI0f4pnZtTB2ILHJRlJtEwozDgfGnP+LcuxP7nbczzniZOXsa8eVV79Chnd/q6IpF+Sn85OdHYrd7cTp9AVtDByOHtyK98zcMw24YxnfAMWCBaZrfnuM1dxiGsdYwjLVZWVmlHWdIKdxA4zIqVdpNpUp7f/x6+7Q0nH4/qzRaKFIqipubvKE6qyRSniQlYbzxOsa6dVTqlMo73MbbWzpaHVWxXSg//Tw35WgHkTIvPz8ioKOFUDheqKIrfBWp6DJN02eaZiugJtDBMIxm53jNm6ZptjNNs11CQkJpxxlSMjIacvp07V90uaBwtDA9Lo7dlSpZFJlIeClubnI4HMEPUkRKpnVrjGVL4aOPaJF82Opoiu1C+ennuSlOb7TLvPz8yICOFoKKrnBXrBk30zQzgcXAgMCEEx527eqLw5FH7dqrfvxaostF02PHCrtcmtUVKVXKTSJhyjDg+usxtm2zOpISU34KD8HqdOlg5PBVlN0LLzEMo8KZv48G+gGhm/0CrKAglgMHOlK37gqczp8+EemYlobNNLVroUgpUW4SKUfi462OoFiUn8JPoDtdjoICnB6PzugKY0WZtakGfGAYhp3CIu1T0zRnBTas0LV3b3f8/ohzjhYeSEzkUGKiRZGJhB3lJhEpq5Sfwkx+fiSVKp0O2P1/PBhZna6wdcGiyzTNTUDrIMQS8kwTdu/uQ1LSTipWPPDj15NzcmiUkcEnLVpYGJ1IeFFuEpGySvkp/BSOFwZwu3gVXWFP+5aXouPHLyUrq8ZvulydDxQWYNq1UERERCT0FI4XBvBg5NxcQEVXOFPRVYp27eqD05lL7drf/OLrnffvZ2dSEsf1P5KIiIhISI7AqkUAACAASURBVDFNdbrk4qnoKiUFBfGkpXUgJWUZDsdPn4RUP32aupmZ2kBDREREJATl59sxTVtgO11nii7tXhi+VHSVkj17euD3O8+5gYbfMPimdm2LIhMRERGRksrLcwIEtNMVnZODOyICb0REwNYQa6noKgWmabB792Vccsk2EhMP/fw36LJ/P1srV+Z0dLR1AYqIiIhIibhcZ4uuwHa6NFoY3lR0lYKjR5uQnV2N+vV/2eVKOXmSqjk5Gi0UERERCVHB6HSp6Ap/KrpKwa5dfYiIyKZ27dW/+HqX/fvx2mysqVXLoshERERE5GIEq+hy6WDksKai6yK5XAkcPNiOlJRl2O2eH79umCadDhxgY7Vq5Go+V0RERCQk5eUVHmsbyPHC6Jwc8uLjA3Z/sZ6Krou0d29PTNPxmw00Uo8fJ8nlYqU20BAREREJWQHvdJkmMbm5Gi8Mc45A3NTpdFKjRo0SXbt27dpSjqZosrOzi32NaRrs3NmbpKRNGMYOfn6L9jt3km+3syQxkYLz3LtZs2YlCfei1a9f35J1t2zZYsm6jRo1smTd77//3pJ15dwqVKjA8OHDS3TtG2+8UcrRFM3u3bstWbdFixaWrNumTRtL1n311VctWffgwYOWrOt0Oi1Zt0ePHpasW9Z5PB7S09NLdG3Hjh1LOZqiadq0qSXrTp48Oehrbt1qB9qydesqIiJcpX7/GLcbu8/H9pMnWbNmzS9+LyEhodTXK4rt27dbsm7r1q0tWTcY1Om6CMePtyIvryq1a8/9xdftfj9djxzh2ypVKHAEpK4VERERkSAoKCjcgdrhyA/I/RMLCjtoWZGRAbm/lA0qui7CgQMDiIg4TdWqq37x9VYZGSR4PCytXt2iyERERESkNBQUROFw5GGzmQG5f0J+YTGXFRUVkPtL2aCiq4Ty8ytx9GhHatVagN3u/cXv9Th0iByn8/+zd+dxclX3nfc/p6pubb2rF6kXSS0BQkgCsQhszGJWI2MW2xFgMHji2OHJzNiJ82Sy5/E8E2ezMxMnE3v8hAEcxwbjsHhshAFhzGYwGIEQ2kFbq9W7eu+uveo8f1RLaFd3q6pvddX3/Xr1S0j31j2/Qt0/9bfPuefydn29S9WJiIiISC4kEkEcJ/fLCg+qnJjpGtZMV1FT6Jqm9vbrsNbLggXrjvhzfzrNh7u7eW3ePFJer0vViYiIiEguZENXJG/X10xXaVDomgZrPbS1raaubgNlZV1HHFvV00M4ndbSQhEREZEiEI+H8jrTdeieLj1iqKgpdE1Db++FxGL1x2ygAfDRzk4GAwE21dW5UJmIiIiI5FIiEcj7TNeY45DWCqmiptA1Dfv2rSYQGGTevDeO+PNwMsmq3l5+2dhIxhiXqhMRERGRXEkk8jvTVRmPa2lhCVDomqJotI6enlXMn/8cHk/6iGMf7u7Gn8nw0jSfUSYiIiIihSUez/M9XfG4tosvAQpdU7Rv3/WAYcGCZ485dmVnJz2hEDuqq2e+MBERERHJuXzvXlgViyl0lQCFrinIZDzs23cD9fUbCId7jzhWGY9z/oED2Q00tLRQREREZNZLpz2kUv68z3QNa3lh0VPomoLe3ouJx2tZuPDYDTQu7+rCay0va2mhiIiISFFIJLJhKF+hy2QyVCQSmukqAacMXcaY+caYF4wxW40xW4wxvzcThRWitrbVBAL9NDT8+phjV3R2sq+8nL0VFS5UJlJ61JtEpFCpPxWPRCIEkLflheWJBB5rtZFGCZjMTFcK+ANr7TLgw8B/NsYsy29ZhScSaaCv70IWLFiHx5M54lhdNMqKgYHsBhpaWigyU9SbRKRQqT8ViXg8vzNdh57RpZmuonfK0GWt7bLWvj3x36PANqDk1tDt2/cxwLJgwbpjjl3R2QnAK3ogssiMUW8SkUKl/lQ8PlhemJ+ZrspYDIBhha6iN6V7uowxrcAFwBvHOXavMWa9MWb90NBQbqorEJmMl/b262loeItQ6MAxx6/s7OT9qiq6yspcqE5EJtubxsfHZ7o0ESlxJ+pPh/emSCR/mzTI6cn3TFflwZkuLS8sepMOXcaYcuBx4CvW2pGjj1tr77PWrrLWrqousi3Te3o+RDw+57gbaDSNjXHm8LCezSXikqn0pjL9YEREZtDJ+tPhvSkcDrtToJzSB/d05Xd5oWa6it+kQpcxxiHbNB6y1j6R35IKT1vbaoLBPhoa3jrm2JWdnWSAVxobZ74wkRJX6r1JRAqX+lNxSCSyYSifywszwJjfn5frS+GYzO6FBngA2Gat/Yf8l1RYxsfnceDABSxY8CzGHLmBBtby0Y4OtsyZw0Ao5E6BIiWq1HuTiBQu9afiEY/nd6arMh5nNBDAevQUp2I3mb/hy4B7gGuMMe9MfNyY57oKxr59N2BMmgULnjvm2OKREVrGx/VsLhF3lHRvEpGCpv5UJOLxIF5vCq83mZfrV8bj2rmwRPhOdYK19pdASe6Dnsn4aG+/joaGXxMMDhxz/MqODlLG8KqWForMuFLuTSJS2NSfikciEcTvj+Xt+lWxGMPaRKMkaC7zJLq7P0wiUX3cDTSMtVzZ2cmG+npGtQ5XREREpOhkQ1d+7ueCD5YXSvFT6DqJtrbVhEI91NdvOObY0sFB6mMxXtazuURERESKUiIRJBDI30xXZSymnQtLhELXCYyNNdPfv5KFC5/BGHvM8Ss7Ooh7PLwxb54L1YmIiIhIvsXjobwtL/Sm05Qnk3pGV4lQ6DqB7AYaKVpafn7MMU8mw2VdXbw5dy5R3ylvixMRERGRWSif93RVJhKAntFVKhS6jiOddmhvv5Z5814nGBw65vjK/n5qEgktLRQREREpYvF4/pYXVsay19VMV2lQ6DqOrq6PkExWsmDBsRtoQHZp4bjPx/qGhhmuTERERERmSj5nuqricQBtGV8iFLqOY9++1YTDndTVvXvMMSed5tLubl6fN4+k1+tCdSIiIiKSb9Ye3EgjP7sXVmimq6QodB1ldHQBAwMrTriBxkW9vZSlUrykpYUiIiIiRSuZ9GOtB78/npfrH5zp0j1dpUGh6yhtbTfg8SRpaXn+uMc/2tnJkN/Pxrq6Ga5MRERERGZKIhECyNtzuirjcVIeDxHHycv1pbDkZeu9aDTK1q1bp/XaG2+8McfVTM6GDRtIp/3s33819fWvkMn0ED3qayyUSnFxTw/PNDYyHs/NTz36+/tzcp2pSqVSrozrc2m3x7ffftuVcauqqlwZV47PWks6nXa7jCnZtm2bK+P+/OfH7tw6Ez75yU+W1Lj333+/K+Ned911rowruffKK6+4Mu6SJUtcGXcme1MstgiA9957k9WrL8r59Rfv3k20vJyLVq064TmvvfZazsedjGuvvdaVcUdHR10ZdyZopuswvb0fJZWqoLn5qeMe/0hfH4FMhhf0bC4RERGRopbJVADg9Y7n5frhsTEi5eV5ubYUHoWuw3R03EQ4vI/q6o3HPX5NTw+9gQBbNHshIiIiUtTS6Wwg8njyM/sSHh9X6CohCl0TRkcXMTy8nObmpzDm2OOVySQXDQzwwty52OOdICIiIiJFI5PJBiLNdEkuKHRN6Oi4CY8nQWPjuuMev6K3F5+1WlooIiIiUgLyPtM1Nka0rCwv15bCo9AFRKMeuruvo6HhJRzn+F9YV3d30x4Os1M/kRAREREpeh/MdI3l/Nq+RAJ/IsG4vq8sGQpdwAsvzCWdLqO5ee1xj9fGYpw3NMQLc+dy3LWHIiIiIlJUPpjpiuT82uHx7JJFLS8sHQpdwJNPNlFWtoeqqi3HPX5Vby8e4Bdz585sYSIiIiLiikymHI9nDGMyOb92eCw7exbR8sKSUfKh6733ytmxo/KEG2gAXN3Tw/sVFezXF4aIiIhISUinK/B4cr+0ED4IXVHNdJWMkg9da9c2EQikmTfvueMeb4pEWDoykl1aKCIiIiIlIZMpy8v9XAAhLS8sOT63C3BTJOLl+efnctVVvaRSx98O9OqeHgBeVOgSERERKRn5nOkqO7i8UKGrZJT0TNfzz88lGvVxyy2dxz/BWq7u6WFTVRW9weDMFiciIiIirsnnTFd4bIyE45D0+/NyfSk8pwxdxpgHjTG9xpjNM1HQTLE2u4HGGWeMsnTpyHHPWTQ2Ruv4uJ7NJVKgirU/icjspt5UHNLp8rze06X7uUrLZGa6/hVYnec6Ztz27RXs3FnBTTd1nnQDjbQxvNTQMLPFichk/StF2J9EZNb7V9SbZr1MpiKv93RpaWFpOWXosta+DAzMQC0zau3aJoLBFNdd13P8EyaWFr5dU8Owpn5FClKx9icRmd3Um4pDOl2G1zual2uHx8a0XXyJydk9XcaYe40x640x68fG8vNTgVwZG/PywgtzueaaXsrK0sc955yRERpjMe1aKDLLHd6bIpHcP+BSRGQ61JsKm7U+rA3h8Rx/o7XTFR4b00xXiclZ6LLW3metXWWtXVVe4J9EP//5PGIxL7fc0nHCc67u7ibh8fCqlhaKzGqH96ZwOOx2OSIigHpToUuns7NQeZnpslahqwSV3O6FBzfQWLJkhCVLjj8j57GWj/b28kZtLeO+kt5VX0RERKTkZDIVAHmZ6fLH4/jSaS0vLDElF7q2bKlkz55ybrrpBNvEAysHB6lNJLS0UERERKQEpdPZWah8zHSF9YyukjSZLeN/CPwKONsYs98Y84X8l5U/a9c2EQ6nuPba3hOec3VPDxGvl9fr6mawMhGZqmLrTyJSHNSbZr9MJhuI8rFlvEJXaTrl2jlr7Z0zUchMGB318eKLDaxe3U0odPwNNJxMhit6e3m1vp6E1zvDFYrIVBRTfxKR4qHeNPt9MNOVx9Cl5YUlpaSWF65bN49EwsvNN594A41V/f1UpFJaWigiIiJSovI60zWevU9MM12lpWRC18ENNM45Z5gzzjjxTZFX9/Qw7Di8NWfODFYnIiIiIoViJma6ogpdJaVkQte771axb1/ZSTfQCKbTXNrXx8sNDaQ9JfO/RkREREQOczB05euerlgwSFo7ZJeUkkkWa9c2UVaW5OqrT7yBxof7+ghlMlpaKCIiIlLCMplyjEng8SRyfu3w2BhR3c9VckoidA0PO7z8cgMf+1gPwWDmhOdd09PDgUCAzdXVM1idiIiIiBSSTKYcjycPD0Yme0+X7ucqPSURup55Zh7JpIebbjrxBhrlySQX9/fzYkMDGWNmsDoRERERKSTpdAVeb+4fjAzZmS6FrtJT9KHLWnjqqSZWrBhi0aLICc+7vK8Px1pemDdvBqsTERERkUKTyZTl5X4uUOgqVUUfujZsqGb//vBJN9AAuKa7m45QiB0VFTNUmYiIiIgUonS6HK83D8sLMxlCkYie0VWCij50rV3bREVFko9+tO+E5/gHBlg5OJjdQENLC0VERERKWvaertwvLwxGo3gyGc10laC87VWZTqen9bqvf/3rOashHq/mpZe+z4IFT/KP/3jfCc+7ta2Ny4AX5s3DzHDoKnfpi661tdWVcYPBoCvjtre3uzLuXO2EWVBGRkZ49tlnp/XacDic42omJxI58bLofFq4cKEr465du9aVcb/2ta+5Mu6FF17oyrgPPPCAK+P+2Z/9mSvjFrpwOMzKlSun9VqfS9uOV1ZWujLuTL3fdLqCUGj80Hi7d+/OyXXnDQ4CsDcSmdQ1rbU5GXeqHMdxZdz6+npXxp0JRT3T1dHxMax1aGn52UnPu6qri13l5ezTTx1ERERESl4mU56XjTQqolEARkOhnF9bClvRhi5rDfv3r6am5l3Ky/ef8Ly5kQjnDA9rAw0RERERwVpIp8vyck/XodDl0sofcU/Rhq7+/guIRpuYP/8Us1zd3QC8qGVgIiIiIiUvkwkBXrze3O9eWK6ZrpJVtKGrvf1GHGeIuXNfPel5H+3qYmt1NT365BcREREpeZlM9naTfGykURGNkgHGNdNVcooydMVic+jru5Tm5p/j8SRPeN6CsTEWj43xkpYWioiIiAjZ7eKBvMx0VUSjjAeDZDxF+S24nERR/o13dNyAtV5aWp466XlXdXWRBl5W6BIRERER8hy6YjHGtLqqJBVd6LLWw/79q5kzZwNlZV0nO5Grurp4d84cBgOBmStQRERERApWOp19cLHHk597urSJRmkqutB14MBFxGJzT7mBxpKREZqiUV5sbJyhykRERESk0B28pytfywu1iUZpKrrQ1d5+I37/IA0NvzrpeVd1dZE0hle1a6GIiIiITMj3PV0KXaWpqEJXNFpHX98lNDc/i8eTOuF5Hmu5srub9XV1jLn0xG0RERERKTwfhK7c7l7oSacpj8d1T1eJKqrQ1dGxGjC0tDx90vNWDA5SF49raaGIiIiIHCEbujI53zK+PB4H9IyuUjWp0GWMWW2M2WGM2WmM+ZN8FzUdmYyH/ftvoLb2bcLhnpOee1VXFzGvl9fr62eoOhHJh9nQm0SkNKk/zV6ZTBkezzjG2Jxet0IPRi5ppwxdxhgv8G3g48Ay4E5jzLJ8FzZVBw5cQjxef8oNNHyZDJf39PCr+nriPt8MVSciuTZbepOIlB71p9ktnS7P+dJCUOgqdZOZ6boE2Gmt3W2tTQCPALfmt6ypa2+/kUCgn/r6N0563gX9/VQmk1paKDL7zYreJCIlSf1pFsuGrvxsogFoy/gSZaw9+dSpMWYNsNpa+8WJ398DfMha+6WjzrsXuHfityuAzbkvt2DVAQfcLmKGlNJ7hdJ7v2dbayvcLmIy1JsmpdQ+f/V+i1tR9Sf1ppL63NX7LW6T6k05W19nrb0PuA/AGLPeWrsqV9cudKX0fkvpvUJpvl+3a8g19Sa932JViu/X7RpySb1J77dYleL7ncx5k1le2AHMP+z3LRN/JiLiJvUmESlU6k8icoTJhK43gbOMMYuMMX7gM8BP81uWiMgpqTeJSKFSfxKRI5xyeaG1NmWM+RLwLOAFHrTWbjnFy+7LRXGzSCm931J6r6D3W7DUmyZF77e46f0WqGn0p1nz3nJE77e46f0exyk30hAREREREZHpm9TDkUVERERERGR6FLpERERERETyKKehyxiz2hizwxiz0xjzJ7m8dqExxsw3xrxgjNlqjNlijPk9t2uaCcYYrzFmgzFmrdu15JsxptoY85gxZrsxZpsx5lK3a8onY8zvT3wubzbG/NAYUzRPbyyl3gSl2Z/Um4pXMfcmKK3+VIq9CdSf3K4pn6bSn3IWuowxXuDbwMeBZcCdxphlubp+AUoBf2CtXQZ8GPjPRf5+D/o9YJvbRcyQfwKesdYuBVZSxO/bGNMM/C6wylq7guyN359xt6rcKMHeBKXZn9SbilAx9yYoyf5Uir0J1J+K0lT7Uy5nui4Bdlprd1trE8AjwK05vH5BsdZ2WWvfnvjvUbKfVM3uVpVfxpgW4BPA/W7Xkm/GmCrgSuABAGttwlo75G5VeecDQsYYHxAGOl2uJ1dKqjdB6fUn9Sb1plmspPpTqfUmUH9Sf/pALkNXM9B+2O/3U+RfSAcZY1qBC4A33K0k7/4R+CMg43YhM2AR0Ad8d2JJwP3GmDK3i8oXa20H8N+BfUAXMGytXeduVTlTsr0JSqY/qTcVqSLvTVDC/alEehOoP6k/TdBGGqfJGFMOPA58xVo74nY9+WKMuQnotda+5XYtM8QHXAh8x1p7ATAOFO1ae2NMDdmfri4CmoAyY8zd7lYlp6sU+pN6k3qTzD6l0JtA/Qn1pyPkMnR1APMP+33LxJ8VLWOMQ7ZpPGStfcLtevLsMuAWY8xesssfrjHG/MDdkvJqP7DfWnvwJ3CPkW0kxeo6YI+1ts9amwSeAD7ick25UnK9CUqqP6k3qTfNZiXXn0qoN4H6k/rTYXIZut4EzjLGLDLG+MneSPbTHF6/oBhjDNk1q9ustf/gdj35Zq39U2tti7W2lezf7S+stUX700ZrbTfQbow5e+KPrgW2ulhSvu0DPmyMCU98bl9L8dz8WlK9CUqrP6k3qTfNciXVn0qpN4H6E+pPR/DlalRrbcoY8yXgWbK7dzxord2Sq+sXoMuAe4BNxph3Jv7sz6y1P3OxJsmtLwMPTfxDuBv4vMv15I219g1jzGPA22R3l9oA3OduVblRgr0J1J+KnXpTkSjB/qTeVPzUn07AWGtnqjYREREREZGSo400RERERERE8kihS0REREREJI8UukRERERERPJIoUtERERERCSPFLpERERERETySKFLREREREQkjxS6RERERERE8kihS0REREREJI8UukRERERERPJIoUtERERERCSPFLpERERERETySKFLREREREQkjxS6RERERERE8kihS0REREREJI8UukRERERERPJIoUtERERERCSPFLpERERERETySKFLREREREQkjxS6RERERERE8kihS0REREREJI8UukRERERERPJIoUtERERERCSPFLpERERERETySKFLREREREQkjxS6RERERERE8kihS0REREREJI8UukRERERERPJIoUtERERERCSPJhW6jDG/b4zZYozZbIz5oTEmmO/CRERORb1JRAqV+pOIHO6UocsY0wz8LrDKWrsC8AKfyXdhIiIno94kIoVK/UlEjjbZ5YU+IGSM8QFhoDN/JYmITJp6k4gUKvUnETnEd6oTrLUdxpj/DuwDosA6a+26o88zxtwL3AtQVlZ20dKlS3Nda0EaHARn9w7CThLPeSvcLkfktLz11lsHrLX1btcxGbOqN3V3Q0cHW8wKlq4M4PXOfAkis12x9aeC6E0ictom25uMtfbkJxhTAzwO3AEMAY8Cj1lrf3Ci16xatcquX79+ahXPUokE/GHtg/zT2Bfgtdfg0kvdLklk2owxb1lrV7ldx2TMqt60bx8sXMif81cs/Jc/5957Z74EkdmumPtTKX3fJFJsJtubJrO88Dpgj7W2z1qbBJ4APnK6BRYLvx/C/+E2xgkT/c6/ul2OSCmZPb1pwQLsFVfwW4GHeOD+k/+gS0SKwuzpTyIyIyYTuvYBHzbGhI0xBrgW2JbfsmaXu/9jBY+xBs+jj0Ak4nY5IqViVvUmc9ddnBHfRuzNd9m82e1qRCTPZlV/EpH8O2Xosta+ATwGvA1smnjNfXmua1ZZvhzeOOfzBGIj2B//H7fLESkJs643rVmD9fm4x/Mw3/2u28WISD7Nuv4kInk3qd0LrbX/1Vq71Fq7wlp7j7U2nu/CZpsLv3Ile2hl+J/03ZTITJlVvamuDnPDDfyHwA/5/vcyJBJuFyQi+TSr+pOI5N1kt4yXU7jjTg8PO79J5ZvPZ2+aFxE52l13UR9t5+z+V1m71u1iREREZKYodOVIRQWMfPJzeLDE//e/uV2OiBSiW27BhsP8dtnDPPCA28WIiIjITFHoyqFbv7KIX3A18X/5VzjFVvwiUoLKyzG33sqazL/z/NMJOjrcLkhERERmgkJXDl16Kaxr/E0q+3bBL3/pdjkiUojuuotwdIBr7XN873tuFyMiIiIzQaErh4yBxi/9BiNUMPRNbaghIsfxsY/BnDn8fsPDPPigJsVFRERKgUJXjt35xTIeM7cTWvvvMDbmdjkiUmj8frjtNq4a+j907Rrn5ZfdLkhERETyTaErxxoaYNcVv0kgOU7qR4+7XY6IFKK77sKXiHBH6Kc8+KDbxYiIiEi+KXTlwWV/dBnvcyYD3/xXt0sRkUJ0+eXQ0sJX6h/m0UdheNjtgkRERCSfFLry4IbVhicqf5OGLS/C7t1ulyMihcbjgTvvZEXHM4Si/fzoR24XJCIiIvlkbB7u4m5tbbV/8Rd/Ma3XJpPJHFczOX/5l3+Z0+tVDv8226J/xf8Iz+UfKk98nlvvNxAIuDLu8uXLXRl3w4YNrox78cUXuzLuz372s2m9zhjzlrV2VY7LKRhz5861d9xxx7Re+8gjj+S0lhWpFL8YHOQ/mv/K/d6bqan5+HHPW7RoUU7Hnaz33nvPlXGNMa6M29TU5Mq4bW1troxbXl7uyrhdXV3Tfm0x96eGhoZp9ya3/n1btcqdv4q9e/e6Mu6uXbtcGXdgYMCVce+9915XxvV6va6MO93cApPvTZrpypOBsmf5OddxezSO0fZkInKUzV4vO7xePmu+Syp1EanUUrdLEhERkTxR6MoTn28f3/deykI7yKUJd2azRKSAGcMTgQCXZ/bRwi5isbvcrkhERETyRKErj54r62KIKm4bd2cZh4gUth8HgwDc7f0asdgarHVcrkhERETyQaErn0Lr+BGf4pZEN+WZjNvViEiB2ev1st7n4077E6ytI5G4we2SREREJA8UuvLImDgPB5oIk+CmqP5Xi8ixHg8GOS8zxArzgpYYioiIFCklgTzbUvY621jK7RGf26WISAH6aSBAGrjb+zckEleTTje6XZKIiIjkmEJXnjn+rXzPs5pL0/tpTabcLkdECkyfx8PLjsMdmVcAD7HY9LaNFhERkcKl0DUDfhxOkMbDbZEKt0sRkQL0RDBIaybOZd77iMXuwlp3nlUlIiIi+aHQNQOGwj/nGa7n9tgQHj2zS0SO8pTfTwy42/NtMplWkslL3S5JREREckihawZ4PCM87CynxQ5yedztakSk0Ix5PKzz+/l0ags++rWhhoiISJFR6Johz5ftpJ85rBmvdLsUESlATwSDNNgMNzh/Szx+E5mMliOLiIgUi1OGLmPM2caYdw77GDHGfGUmiisqgV/zQ3MTNyXbqNQzu0ROW7H1puf9foaN4S4eBsLE459yuyQRmaZi608icvpOGbqstTustedba88HLgIiwI/zXlmRMQZ+FKwgRIKbx8vcLkdk1iu23hQ3hrWBADenuinzvK0lhiKzWLH1JxE5fVNdXngtsMta25aPYordjrJXeJdzuT2qmS6RHCuK3vREIECFtXzS+StSqQtJpc5xuyQROX1FREXb/AAAIABJREFU0Z9E5PRMNXR9Bvjh8Q4YY+41xqw3xqwfHR09/cqKkNfXyw+8l3JJpo0zkwpeIjk0qd4UjUZnuKypedVx6PF4+Ix9DkgQi93pdkkicvqO259mU28SkdM36dBljPEDtwCPHu+4tfY+a+0qa+2qigrdAH4iPy4bJomPNWP1bpciUhSm0ptCodDMFjdFGWP4cSDA9YkxGvyPEovdRibjc7ssEZmmk/Wn2dSbROT0TWWm6+PA29bannwVUwpGQ6/yNNdye7wTr57ZJZILRdWbnggECAC3e/8Ra2sZGrrS7ZJEZPqKqj+JyPRNJXTdyQmW78jkGZPi4cB8GhnkimjQ7XJEikFR9aZ3fD52e73clnoXj6eDvr6b3S5JRKavqPqTiEzfpEKXMaYMuB54Ir/llIaXy7fQRx23j5e7XYrIrFaUvckYHg8EuDyZoNX/LwwPf4hEosHtqkRkioqyP4nItE0qdFlrx621tdba4XwXVAqss4eHPddxY/o9qtPaUENkuoq1Nz0RCOABPuP5LuDlwIEb3S5JRKaoWPuTiEzPVHcvlBz5UchDgCSfjDW5XYqIFJhdPh/v+HysSXRTUbGevr6bsda4XZaIiIhMk0KXS3aV/Yq3Wcld8XG3SxGRAvREIMAFqRQXV32XeLyF0dEL3C5JREREpkmhyyUeT5QfOOdyod3L0oTf7XJEpMD8n0CADHB7Zi1e7yh9fbe4XZKIiIhMk0KXi54s6ySBwx3RRrdLEZEC0+318qrjsHqgl9o5zzAwcDWpVJnbZYmIiMg0KHS5aDSwlSe5ijtSe/DpmV0icpQnAgEWxmJcWf49rA0yMPAxt0sSERGRaVDocpEx8HCgmgYGuSY21+1yRKTArA0ESBrDJyNvEQq9r2d2iYiIzFIKXS57ObSBLuZxZ0z3dYnIkYY9Hl6rquL6gX7m1v2E8fHlRCJnuF2WiIiITJFCl8usd5CHPR9mdWYLtWmv2+WISIF5traWhmSS6wM/xJiEZrtERERmIYWuAvBIcByHFJ+KtLpdiogUmF9WVzPu8XDjcDs1NS/T3/9xMhnH7bJERERkCnz5uGg8Hmf37t3Tem0mk8lxNZPz2c9+1pVxd+/ejbWGN39yIZ9LD/LeFVdkb/bKs9dffz3vYxxPVVWVK+N6ve7MIo6P6zlshcQYQygUmtZrv/CFL+S4msl57LHHWFdWxjX9/VQ0/BsDqevYv/8Cysufyeu4juNOsJs71537W93qEYFAwJVxfb68/PMv0xSJRHj77ben9drpfr91ut59911Xxv3TP/1TV8bt7+93ZdzOzk5Xxt24caMr4y5ZssSVcWeCZroKgDGWnzWcz7L0+zT16K9ERI70ZHk5VZkMq3ken6+TkZE1bpckIiIiU6Dv8AvEpuVpYgT40PaI26WISIF5LRym3+vllrERKiqeIBK5gmRynttliYiIyCQpdBWITNUIzwQ+yo2Db+BN6ZldIvKBtDE8VV7ONePjNJX/O+BhdPTTbpclIiIik6TQVUB+sXABtQyyZIdukheRIz1ZXk7QWj4e30Eo9BojI2uwNv/3f4qIiMjpU+gqIO1nD7GfJq5u63C7FBEpMO8Eg7T7fNw8NkZl5eOkUvOJRi9xuywRERGZBIWuAmJ8aZ6svoyr468THtYzu0TkMMbwZEUFH4lEWBB4Co9nhJGR29yuSkRERCZBoavAvL40hJcMF27VsiEROdKT5eX4gE9E+ikvf5Lx8RtIpyvcLktEREROQaGrwIw2jvKG9wJu7N2AzWhDDRH5wM5AgG1+/8QSw0exNsjY2M1ulyUiIiKnoNBVgJ5tWsbSzE7m7tNPsEXkSGsrKrgwFuNMzzv4/dsYGfkNt0sSERGRU1DoKkCblyWIEOLynQNulyIiBWZteTkAN42NUln5GPH4ecTjZ7tclYiIiJyMQlcBSoVTPBO+jJtGf4knrg01ROQDnY7Dm8Egt4yNUVH+EyDByMgat8sSERGRk5hU6DLGVBtjHjPGbDfGbDPGXJrvwkrdy2c0UM0wZ20tc7sUkYJVqr1pbUUFZyUSLEv3Ul7+HKOjt2Kt3+2yROQwpdqfROT4JjvT9U/AM9bapcBKYFv+ShKAfYsjtJkWru943+1SRApZSfamp8vLSQI3j2aXGGYyNYyPX+N2WSJypJLsTyJyfKcMXcaYKuBK4AEAa23CWjuU78JKnsfws7qLuCr5KwJ9VW5XI1JwSrk3DXq9vBoOc/PYGOHgq/h8nXpml0gBKeX+JCLHN5mZrkVAH/BdY8wGY8z9xphj1rwZY+41xqw3xqyPRCI5L7QUvbnMwYPl4m0Jt0sRKURT7k3RaHTmq8yTJysqaEqlWBWPUFHxOJHI5SST89wuS0SyTtmfDu9NyWTSnSpFZMZMJnT5gAuB71hrLwDGgT85+iRr7X3W2lXW2lXhcDjHZZamoTlpXvNfwM0Db5BJa88TkaNMuTeFQqGZrjFvfl5WRsSYiSWGTwAeRke1fbxIgThlfzq8NzmO40aNIjKDJvOd/H5gv7X2jYnfP0a2kcgMeL5lMWfZXTTsrHO7FJFCU9K9KeLx8HxZGR8fGyPsaycUepWRkd/AWuN2aSJS4v1JRI51ytBlre0G2o0xBx8Ecy2wNa9VySFbzkkxRhkf3dPldikiBUW9KbvEsCaT4bJIhMrKx0ml5hONfsjtskRKnvqTSHEaH4df/hK++U246y4466zJv9Y3yfO+DDxkjPEDu4HPT71MmY6E38OzlZdw88gLPDr6KTwVo26XJFJISro3/TIcZtDj4ebRUX7RsA6PZ5iRkTWEw6+7XZqIlHh/EpntEgnYtAnefPODjy1bIJPJHm9uhosvhp07J3e9SYUua+07wKpp1iyn6bUllfzG+lGWbg3z3ocUukQOKvXelDSGZ8rLuXV0lDKiVFQ8ycjIGtLp/4bXq14h4qZS708is0kmAzt2HBmw3nkH4vHs8TlzsgHr1luzv158MTQ2Zo+ZSa7qn+xMl7hoT4thz9strO7ezA7bgDHW7ZJEpEA8WVHBnSMjXDs+zmMVjzI8fDdjYzdTVfWw26WJiIgUHGthZKSarq75dHW10N3dwv/6XzA68bPKsjK46CL40pc+CFiLFk0+XJ2IQtdsYAzPzDuX/9j5NN/e/yXS8zvcrkhECsT6YJAun4+bR0d5snErfv82RkbWKHSJiIgA4+NldHe3HBGyIpFyADyeFA0NXdx9dzZcXXIJLF0KXm/u61DomiXWL/OS6TR8+L0xXp3vdjUiUiisMawtL+c3h4aoyaQZrnyUAwe+Sjy+lEBgu9vliYiIzJh4PEB3d/MRAWtkpGbiaIa6ul4WL95OY+N+Ghv3U1/fhc+X5u/+7u/yXptC1ywxWOHwq+BKPjXyIi/GP4ITKJ6HvIrI6XmyooLfHhpi9dgYD1U8yYEDf8LIyBrq6//K7dJERETyIpXy0dPTSHd3NmB1dbUwMFDHwc3Zq6r6aWrax0UXvUZj437mzu3A70+c/sDpNGzfDuvXw1tvTfplCl2zyIuLmvjzbe8wd8enGThvj9vliEiB2Ob3s9NxuHl0lEeqhigvX8fo6C3U1X0DY3LwD4yIiIiLMhkPBw7MPRSuurtb6OubRyaTXQdYVjZCY+N+li17h8bG/cybt59wOHL6A6fT2R02Dgas9euzO2xEJq4dDk/6Ugpds8i7Z3gZ3lbONfv28th5blcjIgXDGJ6sqOD3BwaYl0wSqXycsbGbGBu7loqKp92uTkREZNKshcHB2iPuw+rpaSKV8gMQCESZN28/l1zy8kTAaqeiYuS0N7o4FLDeeuvIgDU+nj0eDsMFF8Bv/3Z2p42LLoKzzwbf5OKUQtcsknR8PDfnAm4deIaHDnyeQF2n2yWJSIFYOxG6bhob439Xv4bP18Ho6BqFLhERKVjWQixWy+DgmQwOnsnbb59Hd3cL8XgIAJ8vwdy5naxc+euJ+7DaqakZOO2dvE0mQ93AAM09PbR0d8MVV8CGDUcGrPPPhy984YOAdZo7bCh0zTKvLw2z5rUIy7c77Lzc7WpEpFDscxzeCQS4ZXSU+2tqqKh4gsHB/0wy2YjjdLldnoiICPF4OUNDZx0KWYODZxKPZze6MCZFQ0MPS5e+e2iji7q6HjyezGmNaazNBqzubpq7u2np7qapt5dAIrv8PuHzZbcu/K3fOjJgTXIGa7IUumaZ3Q0hdvoWcPOBX/Pf0/PxenW/hohk/bSigq8eOMCZ8TjJyscZHPwyo6OfZs6cb7tdmoiIlJhUKsjQ0OIjAlYkMu/Q8fLy/TQ0bKSmZic1NTupqtrLOee0ntaYxlpqD5vBau7upqmnh+BEwEr6fHQ2NPDWihV0zJvH/nnz6Kut5W++8Y3TGncy8ha6PB7PtF6XTCZzXMnkOI7jyri9vb1Tfs2Tc1r4/d7X+Mt3v0y0+e1pjVtTU3Pqk/Lg6afdWep01VVXuTLuxo0bXRlXjs8Yg5nmou/Rg09NnGF9fX2TPvf7mQx/DlzT28uvgiN4vS8yOPgpUqn/NuWlGPPnu/Nsio4Od55D2Nzc7Mq4Z555pivj9vf3uzKuHF9VVRU33HDDtF5bVlaW42om55vf/KYr4/7zP/+zK+PW1ta6Mu43ZiAMHM+3vvWtKZ2fyTjEYmcRiSw/9BGLLQKyy/Ecp4tweDONjT8iHN5MOLwNr3f80OuHh7Mff/iHX5rKoAT376f8vfco37GDiu3bKXvvPXwTm1yk/X7GzzqLgYsvZmzJEsaWLiWycOGhGazGiY+ZopmuWejF+Ul+t9fDx7rG+Yk73yeISAHq83h40efjtkSCvw4E8Pu/TzT6AOn0Ffh8L7tdnoiIFAFrPcRii44KWGdhbXajC59vgHB4C1VVPycc3kI4vAXHGTy9QTMZgh0dlO/Y8cHHe+/hm7gHK+P3M3bmmfTecANjZ5/N2NlnE2ltzfkSwdNROJXIpPUH/bwSPIc7Ys/xaPRD+EO6X0NEsh5zHL6TSrEqneZN5ymi0SESibsVukREZMqshUSi+YiAFY2eQyaT3Srd4xkjHN5Kff1DhMNbJwJW1+ntJGjtBwFr+/bsTNZ77+EbGwOyAWv8jDPou/56xpYuPRSwbAEFrOMp7OrkhNY1hfib3Vs4Y98dtJ+t0CUiWWsdh29Go9yWTLLeF8Pv/3cSic9h7R9izLDb5YmISAEbGgqxd289XV3/iUhkGZHIMtLpgxtdxAmFdjBnzk8nlghuIRBoO72dBK2lJZHgnEiEZdEoK37v944MWI7D+Jln0nfddR/MYC1aVPAB63hmX8UCwOtzHYb2VHDLwG6+ZT0Yc3o7u4hIcRg1hmd8Pj6VTPJnwSB+/0MkEveSSKwhEHjA7fJERKRARCJ+9u6tY+/eOvbsqWfv3noGBw/eI5giGNxNVdWLh5YIBoM78XhS0x/QWpoTCc6JRlkWibAsEuGcaJTKdBqAhDHE58yh79prjwxYLu27kGsKXbNUwuPhqaqz+PTQz/jmgS/ir9/gdkkiUiAe8/v5ZCTClakULzgb8XjeJZG4R6FLRKRExeNe9u2rZe/e+omgVU9PT9Wh43PnDrNkSRetrQdobe3j6af/Bo8nNv0BraUpkWDZRMA6ZyJgVU0ErKQxvB8Msq66mq3hMFtDIXYFg3zz28W7265C1yz2i/mWzw7FuLzDz6/r3a5GRArFcz4fw8BtySQvOA5+/w+Ixb5BOn0uXu8mt8sTEZE8SqUMnZ1z2LPn4AxWHZ2dNWQy2Z3Fa2rGaW3t4yMfeZ/W1j5aWw9QVnbkI4iefXYKgctaGhMJlkej2WWCkQhLo1GqjwpYz1VXsy0UYms4zM5gkNQ0dzqfrRS6ZrEdFSG2+1pYM/4av0zU4vcPuV2SiBSAuDH81HG4NZnk/7aWjPPvxGJfI5G4m1Doj90uT0REciSTgZ6eKvburWfPnuwMVnv7HJLJ7Lf4ZWUxWlsPcP75+w7NYlVXR6c/4ETAWnYwYE38enTAev6ogJUssYB1PApds5kxPN1Qz+93vk5Fx58TX/Si2xWJSIF41O/nnmSSj6VS/NQZwnHWkkzeTjD4VYyJu12eiIhMkbUwMFB26P6rvXvraGurIxrNbtUeCCRZsKCfq67axqJF2YBVXz86/Z0EraUxmTy0NPDgMsGagwEL2BkK8YuqKraGw2wLh3lfAeuEFLpmuReafXy508vHe/v5cSunt0WniBSNX3q9dBvDbYkEP3UcHOf7JJO/QTJ5I37/j90uT0RETiGVquHdd1sOBaw9e+oZHQ0B4PWmmT9/gA99aBetrX0sWnSAxsYhPJ5p7iRoLWUDA9S1tVG3dy/f2rWLZUcFrF2hEC9OBKyDM1gJBaxJU+ia5Qb8fl4On8WdkZ/yg5FPUF611e2SRKQAZIzhCcfhC4kEVdYy5HsJY9pJJu9W6BIRKTDpdBnR6DKi0RUTH8tJJpvZvh2MsTQ2DnHuue20th5g0aI+WloGcJxp7lxtLWWDg4cCVm1bG3VtbYRGRwHIeDy87/fz0sGAFQrxfiikgHWaFLqKwLpmP9e838k57U20K3SJyIRHHYf/lEhwSzLJ9/1+/P6HiMf/iExmPh5Pu9vliYiUpEzGTyx29qFwFY2uIB5fBGRDjePsJxTaRG3tD7nnnnNYuLCfYDA5vcGsJXwwYE2ErKMD1mBTE/tWrqR/4UIOLFzIQEsL/3TffTl6t3LQpEKXMWYvMAqkgZS1dlU+i5Kpeb2ujP6dFXxqeDP/kArh853GDZIis4h608lt8HrZ5fGwJpE4InQlEncSDH7D7fJEipr6kwBY6yUeP4NIZPmhWax4/CyszT57yuc7QCi0maqqZwiFNhMKbcbn+2BjtLPP/spUBiM8NHQoWB0MWYcHrKHGRtrPO48DCxdyoLWVgZYW0n5/Tt+zHN9UZrquttYeyFslMm0pj4dn5ixkTf+TfKP3j/A1veB2SSIzSb3pRIzhUcfhj+Jx5mUydHva8fleIpH4LIHA32PMNNf+i8hkqT+VEGshkZh/2BLBFUSjS7E2DIDHM0IotJXa2u8dCliO0zPt+/EPBqzatjbqJ34Nj4wA2SXmQ01NtJ97LgdaWw/NYKUDgVy9XZkiLS8sEs+1ePlsf4IrOy2/bnK7GhEpFI85Dn8Sj/PpZJL/FQjgON8nlXqQdPoKfL6X3S5PRGTWSiYbDi0RjERWEIstJ53OPnDYmBjB4HbmzHmcUGgLodBm/P590/5hV+joGay2NsLDw8AHAWv/ihXZJYKtrfQrYBWcyYYuC6wz2c+Uf7HWHrPQ0xhzL3AvQGVlZe4qlEnZWV7OVqeZO+PP8mLkbMLhvW6XJDIT1JtOYafXywavlzWHQtdTxGKDJBL3KHSJ5NdJ+9PhvamqqsqF8mQqUqnKifuvzj0UtFKphoNHCQbfp7LyuUMzWMHgLoxJTWusumSSZdEoy2Ixrv+f/5PatjbKDgtYw42NdCxb9sEM1vz5pBSwCt5kQ9fl1toOY0wD8JwxZru19oh/rSeayX0AjY2NWrPigqfnVfEH7eup3n87iSV73S5HZCaoN03CY47DX8dinJFOs8sbx3EeJZH4HNZWYcyw2+WJFKuT9qfDe1Nzc3NJ9qZClcmESKXOJZE4n2TyfJLJlXR1LTp03O/fQ1nZG4TDmwmFthAMbsfjmd7zD2uTSZbFYiyPRrNBKxplbiob1jLAsM9H57Jl9C9cSN/ChQwsWKCANUtNKnRZazsmfu01xvwYuATQj0gLzAuN5fxuu5ebDrTx2Jk+PJ7p/YRFZLZQb5qcJxyHr8VirEkm+brXi9//AxKJe0kkbiMQuN/t8kSKkvrT7GCtQzJ5zkS4ygasVGoJ4AXA4+nA73+HurqfTMxibcXrHZ3WWLWpFMui0RMGrD2BAL8uK2NLKMTWUIjtwSD/1x/8QY7eqbjtlKHLGFMGeKy1oxP//THgL/NemUzZkOPwYsUiPjv6KA/2/xbV9a+4XZJI3qg3TV6Xx8MvJ5YYfj0QwOt9F49nI4nE3QpdInmg/lSYrPWQSp1xRMBKJpcD2Zkjj6cfx3mHYPBpHOcdHOcdvN7sPii1tbVTGmvOUQFr+VEBa+9EwNo6EbC2BYNEvd5cvl0pMJOZ6ZoL/Nhkt1bxAQ9ba5/Ja1Uybc81+7l+ey/ndsyhvd7takTySr1pCh71+/nnaJSVmQwbJ2a7YrG/J50+F693k9vliRQb9SeXWQvp9PyjAtZ5WFsOgDFjOM67lJU9eFjAap/WToIHA9aywwLWvMMCVpvfz5sTAWvLxAxWRAGr5JwydFlrdwMrZ6AWyYE3aqro81Ry2/hr/G28gUCg1+2SRPJCvWlqfuo4/I9olNsSCTaGQjjOo8RiXyORuJtQ6I/dLk+kqKg/zbx0uu6ogHU+mczB2ak4jrOFUOjRQwHL59uFMZkpj1NzWMBaPrHZRWPygwcX7/H7eeuwgLVNAUsmaMv4IpP2eHimfh6f6VnL17q+TqD1CbdLEpECMGwMz/l8fDqZ5KvBIHiGcJy1JJO3Ewx+FWOmdxO4iMhMy2QqDgWrZHIlicT5ZDLNE0fT+HzvEQg8h+NswO9/B59vO8YkT3rN45mTyXBuMsl5ySQXj4+zLBql6aiAtSEc5geHLREcV8CSE1DoKkLrGsPc05Pimu4xXl9o9ABUEQHgUcfhE6kUl6XTvOLz4fd/n2RyDcnkjfj9P3a7PBGRY1gbJJFYRjJ5PolENmCl02ccOu717sHvfxPH+d8TAWsTHk90yuPUZDKcl0xybjLJyomgNT+dPnR8r9/PO+EwD4VCbA0G2R4KMaaAJVOg0FWE9pSVsSnQxD3xJ3h2+Cqqq9e7XZKIFIBnHYfRaJQ1iQSv+Hx4vS9jzD6SyXsUukTEddb6SCaXHApY2dmsswEHAI+nG8d5h1DoUfz+jTjORjyeoSmPUz0RsA7/WHBYwNrt9fK24/DdcJh3HYdNjoO/XjfKy+lR6CpSzzaV8V/2bKS+43dIKnSJCBA1hqcch1uTSf7QWhIG/P6HiMf/mExmPh5Pu9slikiJsNaQSrWSTF5wKGAlEiuAIADGDOH3b6S8/Dv4/Rvx+zfi9XaTyUztPqzqiSWCKw+bxTo8YO3xetngOHzvsIA14vEcc52p7V0ociyFriL1fH0NX97j41NDm3koWYHjTO+ZEiJSXB51HD6TTHJ9KsVTjoPf/zDx+B+TSNxFMPh1t8sTkSKU3Umw8YgZrETiPKytAsCYCI6zibKyfzssYO2d8k6CVccJWAsPXyLo9fKO4/BvhwWs4eMELJF8UOgqUqOOw0tVzdw1/Ajf7v1j6pt/4nZJIlIAXvT56DOGNckkTzkOHk87Pt+LJBKfJRD4hu4BFZHTlk7XHBWwVpLJNEwcTeI42wiHf4LjZAOWz/c+xqRPes2jVR22ycXBj9bDAlab18tGx+EH4TAbFbCkACh0FbF1zWV8bLiNCzvD7GtiWs+eEJHikjaGHzsO9yQSVFjLqDE4zg9IpR4knb4Sn+8lt0sUkVkkkykjmTzviICVTi84eBSfbyeBwEuHZrAcZ+uUd0utzGRYkUxyXiLBeYkE5yaTLDoqYL3rODx8WMAaUsCSAqPQVcR+XV1Nt7eSOxPP8v+MnU1FxQ63SxKRAvCo43BvIsEnkkke8ftxnKeIxQZJJO5W6BKRE0qlvHR21tPePo/BwX8gkVhJKnUWkA04Xu++iWD1bxO/bsLjGZvSGBUTM1jnJhLZGaxE4oiAtW8iYP3wsCWCgwpYMgsodBWxjDGsa6jlrq6f8Rdd94FCl4gAb3q9tE0sMXzE78eYOI7zKInE57C2CmOG3S5RRFyWyRh6emppb59He/tc2tvn0dVVTzqd3Sbd4+nDcTYSCq2dCFjv4PUOTGmM8uMErMWHBax2r5dNjsMjZWVsmghY/Vq2I7NUXkKXMQYzzS+KpqamHFczOdOt93TF4/l9IOlP54T5XFea1Qe6+HkLeL3Z8dLpqa2dzpVzzjnHlXETiYQr4y5YsODUJ8mM8Xq91NZObw8qt3rEjTfemJfrbti4kZu3beMzV1/NSCjE4OAennkmyFln/b8sWfIce/bsycu4hSqZnPqDU3Ohvd2dHSPnzJnjyrhyYp5pztbcf//9pz22tZBMLiAWW0E0ei6x2ApisWVYG56obZRgcDNVVU8SDG4iFNrMX//170zctjB/4uOmk47hi0So2buXml27qNmzh5rdu6ns6jp0fLyujsEVK9h0xhkMLFrE0OLFxCsrAThj4uOTwPPPP3/a73c6vvjFL7oybk9Pjyvjrlu3zpVx//Zv/9aVcS+//PK8j6GZriLXFgrxTrCBz8V+yGODn6K27hm3SxKRAvBqayuf3LqVD7e3s27JEmpq2qip2cPu3VexZMlzbpcnInmUTNYTi5078bGCaHQFmUw1AMbECQS2UV39OMHgJoLBTfj9bcdssnOyn0P5olGq9+xhzu7d1OzeTc2ePVR2dh46Pl5by+DixbRdeSWDixczeFjAEilWCl0l4KmGEH++bwvze/6IiEKXiAAdVVW0VVfzkbY21i1ZAsDixS/y1lufZ2BgIVBaM10ixSqdriIWW37YDNa5pFJzJ46mCATep6LiOUKhTQSDmwkE3seY1KSv74vFjgxYu3dT0dWFsdmQFqmtZWDxYtouv5zBM85gcNEi4lVVeXinIoVNoasEPDenhj/Y18nt0Tf4/2LzCQb1AFQRgdcWLuTOjRtpGBujt7yc1tbX2LDhs+zefRW1tS+6XZ6ITFEmEyIWO+ewGaxzSSYXHjruOHsJh98gGNw8MYu1HY8nNunrhzMZzonFWB6Lccm3vsWcXbuOCViDixax7/LLGTg4g6WAJQIodJWEcZ+P56vruGvoYf6+7xsE59/ndkkiUgB+NRG6Lm1r4yfLl+P3jzN//pu0tV1GTY0fj8edeyFF5NRSKQ89PQ2gS+9yAAAgAElEQVQMDt5xKGTF42cC2Y0ufL4ugsFNVFc/RjC4hWBwM17v6KSvH85kWDoRsFbEYiyLxVicSHDwzrNIKsXg4sXsu+wyBg7OYFVX5/6NihQJha4S8bOGCj4x1MVHDhjea/G6XY6IFIADZWVsr6/nsr17+cmyZWAMixe/RFvbZQwMXEld3c/dLlFEgEwGDhyopaOjmY6ORjo6mujunksqlf02zusdJBjcRHn584c2uvD5Dkz6+qGjAtbyWIxFiQQHv1vo8fnYEgzydGUlW4JBtgSDfPmv/zoP71SkeCl0lYj1FRV0+iq4J/U4vzv8Ebzen7ldkogUgNcWLuS31q9n/tAQ7TU1zJ27hbKyPvr6blboEnGBtTA0VEVHR9OhgNXZ2Ug8HgDA74/T1NTNhz70Js3Nnaxf/x0cp+OkG1scLnicgLX4sIDV6/OxJRDg6cpKtk4ErD6fvl0UOV36KioRGWP4WV0Fn+9eh9P7W2QaFbpEBN5YsIDPvfUWl7W18UhNDcZYFi16ic2bP00sNo9gsNvtEkWKXiwW4PnnrzwUtCKRMgC83hTz5vWwcuUmmps7aWnppK6uH4/ng50E332344TXDWYyLI3HWR6NsjwWY3k8zhnx+KGA1ef1siUY5NmKikMzWH2Ok8+3KlKyFLpKyFN1c/hidye3jLzPY/X1+Hx9bpckIi4bDQTY1NjIR9ra+NHKlVhjWLz4ZTZv/jR9fZ9g/vwH3C5RpOgNDMzhpZcup77+AEuXvk9zcyfNzV3MnduDz5eZ1DUCBwPWxOzV8liMM+LxQ9/o9Xm9bA0Gea68nC3BIJsVsERmlEJXCdkfDPJWuI7PR77HA0NfpLZO30yJCLy6cCFf6uxkSV8fOxoaKCs7QFXVm/T1fYKWlgePeT6PiORWXV0/v/M7f08gMLmHdPuSSRq6u2ns7OScri5WHBWwDkwErOcPC1i9Pt/JH64lInml0FVinmoo56t732Pp0GJ6a9V/RQTeam4m5vVyWVsbOxoaAKivf5KdO/+K4eFVVFe/6XKFIsXN70+cMHB5k0nmTgSsxs5OGjs6qO/rw5PJzoD1TywR/MVhAatHAUuk4Ch0lZjna2r4L20d3JN+lr+KXkQ4/JbbJYmIy+KOw1stLXxo3z6+d+GFpL1e5sx5Ba93hL6+mxS6RGaIN5lkbk8P8zo7aeroYF5nJ/W9vXgnAtZ4OEx3UxPvL11KV1MTXc3NfOfJJxWwRGaBSYcuY4wXWA90WGtvyl9Jkk8Rr5fna2q4Y+BHfHXoPoUumfXUm3LjtYX/P3t3Hh9Xfd/7//U9Z/aRNPIi79iAWRyHhM0YzL5vhgSzhSwEaBLaPtKb9v5626a5afNIb5tHbtPb3KQ3LSGhSQmrA5jNCVtsA2ExNmA2g4NtvEu2ZFnrSBrNnO/vD8lCm9HCjL4jzfv5eOhh6Zwz831PUD6jz5zv+Z55nLF9O5+qqWHD7Nl4XoaqqifYu/ezZLMVhEJNriOKjDvDrU+phga++pOf9Gmw0okE1bNmsfmYY3oarKZUamCDpYZLZFwYyZmuPwfeBSoKlEXGyONTK7my/g9c2Jxmba4M329xHUnk41BtyoM3Z8ygORLhjO3b2TB7NgBVVY9TU3M9dXUXM2PGA44TioxLw6pPsbY20jNn8vKZZ/Y0WI2DNVgiMm55Qx8Cxpg5wFLg54WNI2Ph9fJydvhJbuZumpuXuo4jMmqqTfmT833Wzp3Lybt2Ec1mAUgm3yeZfI99+650nE5k/BlJfdo7cyb33Hwzqy+6iPc++UkaKyvVcIlMMMNquoD/C/w1cMh1S40xtxpj1htj1re2tuYlnBSGNYaHK2OczypSDUtcxxH5OFSb8ujFefOI5XKctGtXz7aqqsdJp4+htfUYh8lExqWPrE+qTSKlZcimyxhzBbDPWvuRF/9Ya2+31i6y1i5KJpN5CyiF8UgqhYfl+o51tLfrjykZf1Sb8m9TVRX7EwnO2L69Z9vUqU9hTIfOdomMwHDqk2qTSGkZzpmuM4DPGGO2AfcB5xtj7ipoKim43eEwL8UruJlf0Nhwjes4IqOh2pRn1hhenDuXT1dXU9HZtXx1KNTM5MnPUld3MUEQcZxQZNxQfRKRPoZsuqy1f2utnWOtPRy4AVhlrf1SwZNJwa1IJZjPBxzfNJUg0F3pZXxRbSqMFw8/nJC1nF9f37Nt2rTHyOUqqK8/x2EykfFD9UlE+hvuNV0yAT1dXk6zCfNl+yAtLRe6jiMiRWB7ZSW7Kiq4uK6uZ1tFxatEo3uordWK/CIiIqMxoqbLWrtG98GZONo8jyfKE1zP/WQbLncdR2TUVJvyyBhenDePE5ubmdbR0b3JUlW1ksbGxbS3z3AcUGR8UX0SEdCZrpK3IlVBGWkub9tJZ+ds13FEpAi8OG8eABft39+zrapqJRBQW6vbTIiIiIyUmq4S91o8zgfhODdzJ42NV7uOIyJFYF95OW+VlfWZYhiN7iWVeoXa2qVYq7cOERGRkdA7Z6kzhodTSc7lWSY3nKQ/pkQEgKemTuWYdJoj0umebVVVj5PJzKSx8WSHyURERMYf/YUtPFJRQQB8MfcE6fTpruOISBH43eTJ5Og7xXDy5OcIhRqprdU9u0REREZCTZdQEw7zQqKMm/gFTQ3LXMcRkSJwIBJhXSrVNcXQWgA8r5OpU5+kvv4cstkKxwlFRETGDzVdAsDDqXIOZycnt4TIZie5jiMiReDpqVOZ3dHBJ1taerZVVT2GtRHq6i52mExERGR8UdMlADxTVkaTCXELd9HU9BnXcUSkCKyZNIkOY7i41xTDZHIzyeR77NunKYYiIiLDpaZLAOjwPH5TkeQaHiBouOTgbCIRKWHpUIgXJk3iwv378XsVhaqqx0inj6G19RiH6URERMYPNV3S46FUigTtXNX5Gu3tn3YdR0SKwFNTpzK5s5OTGxt7tk2d+jTGdOhsl4iIyDCFCvKkoRBTp04d1WOnTJmS5zTDYx2d2rn6ajf3xlq3bt2AbVlr2VnfwB+13MHvvO+ycOFteR/3wIEDeX/O4Vi7dq2TcefMmeNkXBlcEASkey2BPhLTp0/Pc5rhmTVrlpNx33jjDQCe9Dy+5XmcV13NM97Bz+maKC9/mtrai5g06Xt4XoeTjPmUTCadjNvZ2elk3JZe1+mJe+Xl5Zx77rmjeuw111yT3zDDtHz5cifjXnmlmw97Vq9e7WTcSCTiZNzTT3ezmvVnPjNxL3HRmS75kDGsnncYp/My8Z0zyGZjrhOJiGMZz+PpigoubG4mGgQ92ysrHyIIUjQ3X+AwnYiIyPigpkv6eHbuXHIYvpS7j927dc8uEYGVFRWUBQHn9Do7kky+Qji8i4YGN2frRURExhM1XdLHgViM16dP4ybzC3Z8cK7rOCJSBNYlk9SGQlze67ouYyyVlQ/T2rqETMbNFEgREZHxQk2XDLB63jxm2xpOOrCb5ubZruOIiGOBMfy2ooJzWlooz+V6tldWPgwENOim6iIiIh9JTZcMsG7GDJrCUW7mF2zbpus1RAQeT6WIWMtFTU0928LhapLJl2hoWIa1ejsRERE5FL1LygBZ3+f3h81mGSto3nECQeC7jiQijr0Ti7EtEmFprymGAJWVD5LNzqS19TRHyURERIqfmi4Z1Kq5c4mRYVnmt9TULHIdR0RcM4aVFRUsTqep6rXMeXn5Kny/QQtqiIiIfAQ1XTKorZWVbKuo4I/MzzXFUEQA+E0qhQdc1muKoed1kko9RnPzBWSzKXfhREREipiaLhmcMayeO5dT7GtM3hulrW2y60Qi4ti2aJS3Y7FBphiuwNoIjY1XOEomIiJS3NR0ySE9N3cuWeNxM79ix47zXMcRkSLwm1SK49rbmdfR0bMtFttELPY2DQ3XYK3DcCIiIkVKTZccUmM0yqszpnOT+QW7tp2DtcZ1JBFx7LcVFQTA5b2mGELX2a6OjmNpb1/oJpiIiEgRG7LpMsbEjDGvGGPeMMa8Y4z57lgEk+Kweu5cpts6zky/QV3dJ13HEemh2uTGvnCYdYlE1xTDXqe1UqmVGNOuBTVEUH0SkYGGc6arAzjfWns8cAJwqTFGawOXiFdnzKAhEuUr5mds364FNaSoqDY5sjKV4ohMhoXt7T3bfL+Z8vJnaGxcShBEHaYTKQqqTyLSx5BNl+3S0v1juPtLs/ZLRM7zeP6wOVxhV9K+6ygymaTrSCKAapNLT1dU0AkDFtSYNOkhgqCC5uYL3QQTKRKqTyLS37Cu6TLG+MaYDcA+4Glr7dpBjrnVGLPeGLO+paVl4JPIuLVq3jwiZPmcfYhdu85yHUekx0hrUzqdHvuQE1CT7/NceTmXNTXh9ZpimEi8Qji8kwMHNMVQZKj61Ls2NTQ0uAkpImNmWE2XtTZnrT0BmAMsNsYcN8gxt1trF1lrF5WVleU7pzi0PZViayrFV72fsm2bPsGW4jHS2pRIJMY+5AS1sqKC6dksi3o1ssZYKisfJp0+jUxmtsN0Iu4NVZ9616bKyko3IUVkzIxo9UJrbQOwGri0MHGkWK2aN4/jg3eY19hMQ8MRruOI9KHaNPaeLS+n1fMGuWfXI0BAQ8MyN8FEiozqk4jA8FYvrDLGVHZ/HwcuAt4rdDApLs/PmUOn8biFO7SghhQF1Sa32j2PZ8rLuaipiXAQ9GwPh6tJJl+koeEqrNVdSaQ0qT6JSH/DeUecCaw2xrwJrKNrXvLjhY0lxaY5GmX9zBnc6N1JzY4l5HIR15FEVJscW5lKkQoCzup3HW9l5UNkszNpbV3iKJmIc6pPItJHaKgDrLVvAieOQRYpcqvmzWPJnpe4KHiW3XtO47DDnnMdSUqYapN7LyeT7Pd9ljY1saqiomd7efkqfL+BhoZllJW94DChiBuqTyLSn+Z+yLC9Pm0a9dEoX/VvY9s2TTEUKXU5Y3iiooJzm5tJ5nI92z2vk1TqMZqbLyCbTTlMKCIiUhzUdMmwBZ7Hs3Pncmnuaby6abS0THcdSUQcW5lKEbOWC5qb+2yvrFyBtREaG69wlExERKR4qOmSEVk9dy4hAr7Ir9ix43zXcUTEsTficXaFwwNWMYzFNhGLvU1DwzVY3RJWRERKnJouGZFdFRX8YdIkvha6je3bziMI9CskUtKMYWUqxWmtrUzJZvvsqqx8iI6OY2lvX+gonIiISHHQX8wyYqvnzuUT2S0s7NjOvn26Tlik1K2sqCAEXNLU1Gd7KvUbjGmnoeEaN8FERESKhJouGbHfz5lDxvP4ivdTLaghImyJxdgUjXJ5vymGvt9MRcXTNDZeThBEHaUTERFxT02XjFhrJMLaWbP4PPdSX/0p2tu1OplIqVuZSnFiWxtzMpk+2ysrVxAEFTQ3X+gomYiIiHtqumRUVs+dy6SghSv5DTt2nOs6jog49pvu+3Rd1u9sVyLxCuHwTg4cuNpFLBERkaKgpktG5c1p09gfi/G18P9j+/YLtDqZSImrjkR4NR7niqYmehcEYyyVlQ+TTp9GJjPHYUIRERF3QoV40mw2S0NDw6geO2XKlDynGZ7y8nIn4+7cudPJuC+//PLHfo67fZ+vtz9PeafH88/niETWDfmYZDL5sccdjQsucHPt2Zo1a5yMK4PzPI9odHTXFm3fvj3PaYZnxowZTsatr68f8WOWh8P876Ympu/bx7vhcK89vwS+TnX1JZSX/+Ajn2Py5MkjHjcf9u3b52Tc0f4+flyufq9kcL7vU1lZOarHzp49O89phme0f+d9XBs2bHAy7mhqYj784z/+o5Nxv/Od7zgZ9+qrJ+6sCJ3pklFbnkjgY7mRO0inP+86jog49ngsRiewrL29z3bf30Mk8ixtbZ/DWr3tiIhI6dG7n4za1lCIdeEwt5jbaG+7kiAocx1JRByq9zzWRKNc3daG6TfnOJG4hyCYTSZztqN0IiIi7qjpko/l/kSCBXYPp/A27e2fcR1HRBxbEYsxOwhY3NnZZ3s0+hTG1NPWprPiIiJSetR0ycfyaCxGG/AV80NNMRQRnoxGSRvDsra2PtuNyRCPP0h7+6UEgZvrtkRERFxR0yUfS4vnsTIe53r7MH7nQjo7j3EdSUQcSnseT0SjXNneTrjfFMN4/B4gQlvbxL1QWkREZDBquuRjuz8ep5IOruIBTR0SEVbEYky2lrM7OvpsD4ffIxTaQFvb53WbCRERKSlquuRjezESYafv8xXvX2lruxZrI64jiYhDz0aj1BvD1f1WMQRIJO4lm11INnu8g2QiIiJuqOmSj80aw6/jcc4PNjArSNPefrHrSCLiUKcxPB6LcWlHB/Eg6LMvFnsYaNM1oCIiUlLUdEleLI/H8YCbzP/TFEMRYUU8TsJaLuk3xdDzmojFVtLevgxr447SiYiIjC01XZIXO0IhXoxEuJn/pKPjbHK52a4jiYhDa8NhdnvegBslA8Tj92JtBe3tlztIJiIiMvbUdEneLI/HOcrWcQYvkE5f7zqOiDhkjeHheJzzOjqY1G+KYSTyEr6/jba2GxylExERGVtDNl3GmMOMMauNMRuNMe8YY/58LILJ+PN4LEarMfyR98+0td2AtcZ1JJnAVJuK34pYjDBwRb+zXcZY4vH7yWTOJJud5yacSAGpPolIf8M505UF/tJauxA4Dfi6MWZhYWPJeJT2PB6PxbgueIpobjKZzFmuI8nEptpU5N4JhdgUCg24UTJAPH4/ENDW9rmxDyZSeKpPItLHkE2XtbbaWvta9/fNwLuALtiRQd0Xj1NOJ9dyp1Ynk4JSbRoHjGFFLMaSzk5m5XJ9dvl+NZHIGtrarsdazXSXiUX1SUT6G9E7nTHmcOBEYO0g+241xqw3xqxPp9P5SSfjztpIhG2+zx95P6K9/VKCYJLrSFIChlubWltbxzpayVsRiwFw1SBnuxKJewiC2WQy54x1LJExc6j61Ls2HThwwEU0ERlDw266jDFlwIPAX1hrm/rvt9bebq1dZK1dlEgk8plRxhNjWB6Pc06wicPZQ1vb1a4TyQQ3ktqUTCbHPmCJ2xEKsT4cHnQVw2j0aYyp11lxmbA+qj71rk2TJukDSpGJblhNlzEmTFfRuNta+1BhI8l49+tEggC4xftn0unPY63rRDJRqTaNDytiMY7LZjmms7PPdmMyxOMP0NFxCUEw2VE6kcJQfRKR3oazeqEB7gDetdb+a+EjyXi32/d5IRLhJnsvuewCOjuPdx1JJiDVpvHj0ViMHBzynl0Qoa3tmjHPJVIoqk8i0t9wznSdAdwInG+M2dD9pTtayke6L5Fgnm3kbJ6mrU1Th6QgVJvGiTrf5/lIpKvp6nfqOxx+j3D49e7bTDgKKJJ/qk8i0kdoqAOstb8HdMMlGZEnYjGajOGr3vd4ru0xysu/i+cNvJBeZLRUm8aXh+JxftzYyEmdnbwWifTZF4/fR1PT/yabPR7Y7CagSB6pPolIf1qnVwqizRgejcVYlnuBpDW0t1/hOpKIOPTbaJR2Bp9iGIutANq0oIaIiExYarqkYJYnEiTJ8TnzE00xFClxLZ7H09Eon21vx+83j9DzmonFVtLevowgiDlKKCIiUjhquqRg1ofDbPZ9/si7jUzmNLLZI11HEhGHVsTjVAUBZ2YyA/bF4/dgbQWtrZc4SCYiIlJYarqkcIxheSLB6bntzOc90ukbXCcSEYdWRaM0GsOyQW6UHIm8jO9vo6npOgfJRERECktNlxTUA/E4OeCr/ndpa7sOa4dcu0VEJqgOY1gZi3F5RwexflMMjbHE4/fR3n4anZ1zHSUUEREpDDVdUlA1vs+z0Sg3Bo9CMJXW1nNcRxIRhx6KxSi3lgs6Ogbsi8eXAzmamnTPLhERmVjUdEnBLY/HmW3TXGge1NQhkRL3UiRCjedx9SBTDH2/mkTieZqbr8FavT2JiMjEoXc1KbgnYzEajOEr3j+TTp9DNlvlOpKIOBIYwyOxGBd0dFARBAP2l5c/QC43g3T6TAfpRERECkNNlxRchzE8HI9zZe51UrTQ3LzMdSQRcWhFPE4UWDrIPbuSyd/hefU0N+usuIiITBwFW9Ugl8uN6nHr1q3Lc5LhmT59upNxy8vLnYz7jW98Y2wH3LmT+L//O583/8RP6/+YtrbvYszYDb9w4cKxG6yXYJBP8sUd3/dJpVKjeuyOHTvynGZ4WlpanIz72c9+tnBPbi1777+fW5NJ0lde2WfXmjVrSKUe5cCBLwBVhEIHCpejl9ra2jEZpz/f952MGw6HnYwrgwuHw8yYMWNUj/32t7+d5zTDs3jxYifjXnrppU7GvfPOO52Mu3HjRifjfv/733cy7t133+1k3CVLlhR8DJ3pkjFRM2cOtdOmcRN3Yu1RBIGmDomULGNYd9RRHLNnD6nW1gG7U6kHgQhNTVcOfKyIiMg4pKZLxoYxvHXyyZxm97GAV8hmv+w6kYg4tO6oo/CARVu2DNgXjb5PLPYmjY3X0m9leRERkXFJTZeMmXdOPJEscIv5DtnsVVhb4TqSiDiyt7KS7VOncsrmzYPuT6UeJJM5hvb248Y4mYiISP6p6ZIx01pezlO+z412FT4RslldKC9Syl45+mgOr61lWkPDgH3l5Ssxpo3GxmsdJBMREckvNV0ypu4KhZhJhkvN7ZpiKFLiXp0/nwAGPdvl+y2Ulz9Jc/NSgiA29uFERETySE2XjKnf+j77gZvNjwiCk8nlNHVIpFQ1JJP8YdasrqZrkIu3UqmHCIJympsvdpBOREQkf9R0yZjqNIb7QyGuDP7AJKrJZm9yHUlEHFp31FHMaGxkbl3dgH3x+CuEw9tpbLzGQTIREZH8UdMlY+6uUIgo8EXzbbLZz2Ft1HUkEXHk9SOPpNPzWPz++wP2GdN1tqut7VQymcMcpBMREckPNV0y5t70fd70PG7mQWAyuZzuxSNSqtLRKO/MncuiLVswg9xMvKLiYSBHY+PVYx9OREQkT9R0iRN3hUKcbBv5FE/Q2akFNURK2StHHUVlOs3R1dUD9oXDe0kmf09T0zKs1VuWiIiMT3oHEyeWh0J0Ard4/4sgOJ8gmOc6kog48ta8ebSHwyz+iHt2ZbMzaG09c4yTiYiI5MeQTZcx5j+NMfuMMW+PRSApDXXG8Fvf5wvBWkJ0kM3e6DqSjEOqTxNDZyjE60ccwYlbtxIeZIphWdlqfL9eC2rIuKHaJCL9DedM1y+BSwucQ0rQXaEQ08mx1Ps+2eyXNHVIRuOXqD5NCOuOOopkJsPZra0D9hnTSUXFo7S0nEc2O8lBOpER+yWqTSLSy5B/5VprnwPqxyCLlJinfJ99wC38HGvnkMud7zqSjDOqTxPHe7Nn0xSLcUVz86D7U6kHgQhNTZ8Z22Aio6DaJCL95e3UgjHmVmPMemPM+nQ6na+nlQksawz3hUJcHuxiKu/pnl1SEL1rU0tLi+s4cgiB5/Hq/Pmc19JCMpcbsD8afZ9Y7A0aG68Z7D7KIuNO79q0f/9+13FEpMDy1nRZa2+31i6y1i5KJBL5elqZ4O4OhwkDX/a+RS63FGunuo4kE0zv2lRWVuY6jnyEV446ipi1XHiI5jiVepBM5hja2z81xslE8q93bZoyZYrrOCJSYLqIRpx6x/N4zfO4yT4BRMhmb3AdSUQc+WD6dHaFw1zR1DTo/vLy32BMG42N145xMhERkY9HTZc4d1coxKdtGyeZO+nsvElTh0RKlTE8Xl7OknSaKdnsgN2+30J5+ZM0Ny8lCGIOAoqIiIzOcJaMvxd4CTjWGLPLGPOVwseSUvLrUIgO4BbzL1j7CYLgFNeRZJxQfZp4Hq+oIARc+hELagRBGc3Nl4xtMJERUG0Skf5CQx1grf38WASR0nXAGFb6Pjfk3ub/o55s9sv4/jrXsWQcUH2aeDZHo7wXjXJFUxN3Txq4PHw8vo5weBuNjdeQSj3iIKHI0FSbRKQ/TS+UovCrUIipWK7yvkM2ey3WJl1HEhFHHi8v58T2duZkMgP2GQOp1Ara2haTycx1kE5ERGTk1HRJUVjl+1Qbw03cC5STzV7tOpKIOPKbigoAlh5iimFFxQogR2Oj6oSIiIwParqkKOSM4Z5QiEuC/czg92SzX3YdSUQc2RMOsz4e71rFcJCVdcLhfSSTz9PUtAxrfQcJRURERkZNlxSNu0MhQsBN/ncIgiUEwbGuI4mII4+Xl3N0JsMxHR2D7k+lHiSbnU5r6xljnExERGTk1HRJ0fiD57HW8/hy8DyQIZu90XUkEXHkifJyOoErDjHFsKxsDb6/X/fsEhGRcUFNlxSVu0IhFtpOTvV+TGfnF7E27DqSiDjQEArxQjLJ0qYmzCBTDI3ppKLiUVpaziObHbjKoYiISDFR0yVF5cFQiDbgFv4dqCKXu8x1JBFx5PGKCmZns5zY1jbo/lTqQSBMU9NnxzaYiIjICKnpkqLSZAyP+j7XBx8QY4sW1BApYavKykgbc8gphtHoZmKxDTQ2XjPYehsiIiJFQ02XFJ27wmEmAVf7f08udxFBMNN1JBFxIO15rCor47LmZkKH6KpSqYfIZI6mvf3TY5xORERk+EKFeNJkMskpp5wyqsfW19fnOc3w7Nmzx8m4iUTCybiu+P7Qyzv/3vPY2dHBzTzKPfgEwZcJh//lY43bcYgV0Art6KOPdjKuHJrnje6zpsrKyjwnGZ66ujon486d6+bGwzt37uzz8y9yOa7I5Thm+3aeHKR+WHs78E327LmESGTlqMd19d/X1XuAq9crg6uvr+e+++4b1WMPO+ywPKcZntHW0o/re9/7npNxQ6GC/Mk8pBkzZjgZd+3atU7GbWlpcTLuWNCZLik6gTHcFw5zfq6Fw7wHyGRuxFrjOpaIOPA7z2M/8LlsdtD9xjTj+yvIZq/D2tL6EEtERMYPNV1SlO6JRPCBm73vY+3h5HJnuY4kIg50GsOKUIgrcjkSh5hiGAr9F5FpHUUAACAASURBVFBBLnfV2IYTEREZJjVdUpS2eh4v+D435jYAB8hkdM8ukVK13PdJAktzuUH3e94LGLNZC++IiEjRUtMlReuecJijbY6z/O+TzX4Ga3UNgkgpetHz2GUM1x9yiiGEQr8iCM4iCOaPcToREZGhqemSovVwOEwrcIv5LyBGZ+e1riOJiAPWGH7t+1wUBEw+xBRD378byJHN6qy4iIgUHzVdUrRajOGRcJhrsntJmpfIZG5yHUlEHFkeChEGrjrE2S7Pq8bzniKX+yLWDr1KqoiIyFhS0yVF7e5wmArgutA/EASfJpc73nUkEXHgTWN41xiuP8R1XQCh0J1YO4sguHAMk4mIiAxNTZcUtRd8n+3G8OVgNdCmBTVESpUxLA+FOCsImB0Egx7i+78FarWghoiIFB01XVLUrDHcHYlwTq6D+aE76Oy8DmtjrmOJiAO/7r458nWHONtlTCeh0L3kckuxtmoso4mIiHwkNV1S9O4Nh/GAL5sfA5Vks1e6jiQiDnzgebzieYdcxRC6phhCmGz2hrELJiIiMgQ1XVL0dngez/k+N2Y347GZTEZTh0RK1XLf53hrWXCIKYae9y6e9wrZ7Jc5xEKHIiIiY25YTZcx5lJjzCZjzGZjzDcLHUqkv7vCYY6wlvPC3yOXO5sgOMJ1JCkCqk2l56FQiBxw3Uee7fovrF1IECwau2Ai/ag+iUhvQzZdxhgf+AlwGbAQ+LwxZmGhg4n09lg4TBNws30QyJHJfMl1JHFMtak07TWGNZ7XtYrhIe/Z9SDQSjar20yIG6pPItLfcM50LQY2W2u3WmszwH3AZwsbS6SvtDE8HA5zVbaJlP8InZ1f0L14RLWpRC0PhTjSWk45xBRDY5rx/RXkctdibWKM04kAqk8i0o+xQ0x6N8ZcC1xqrf1q9883Aqdaa/+s33G3Ard2/3gc8Hb+4xatqUCd6xBjpJReK5Te6z3WWlvuOsRwqDYNS6n9/ur1TmwTqj6pNpXU765e78Q2rNoUytdo1trbgdsBjDHrrbUlM5m+lF5vKb1WKM3X6zpDvqk26fVOVKX4el1nyCfVJr3eiaoUX+9wjhvO9MLdwGG9fp7TvU1ExCXVJhEpVqpPItLHcJqudcDRxpgjjDER4Abg0cLGEhEZkmqTiBQr1ScR6WPI6YXW2qwx5s+AJwEf+E9r7TtDPOz2fIQbR0rp9ZbSawW93qKl2jQser0Tm15vkRpFfRo3ry1P9HonNr3eQQy5kIaIiIiIiIiM3rBujiwiIiIiIiKjo6ZLRERERESkgPLadBljLjXGbDLGbDbGfDOfz11sjDGHGWNWG2M2GmPeMcb8uetMY8EY4xtjXjfGPO46S6EZYyqNMQ8YY94zxrxrjFniOlMhGWP+e/fv8tvGmHuNMTHXmfKllGoTlGZ9Um2auCZybYLSqk+lWJtA9cl1pkIaSX3KW9NljPGBnwCXAQuBzxtjFubr+YtQFvhLa+1C4DTg6xP89R7058C7rkOMkR8BT1hrFwDHM4FftzFmNvANYJG19ji6Lvy+wW2q/CjB2gSlWZ9UmyagiVyboCTrUynWJlB9mpBGWp/yeaZrMbDZWrvVWpsB7gM+m8fnLyrW2mpr7Wvd3zfT9Us1222qwjLGzAGWAj93naXQjDEp4GzgDgBrbcZa2+A2VcGFgLgxJgQkgD2O8+RLSdUmKL36pNqk2jSOlVR9KrXaBKpPqk8fymfTNRvY2evnXUzw/yMdZIw5HDgRWOs2ScH9X+CvgcB1kDFwBFAL/KJ7SsDPjTFJ16EKxVq7G/gXYAdQDTRaa59ymypvSrY2QcnUJ9WmCWqC1yYo4fpUIrUJVJ9Un7ppIY2PyRhTBjwI/IW1tsl1nkIxxlwB7LPWvuo6yxgJAScB/2GtPRFoBSbsXHtjzCS6Pl09ApgFJI0xX3KbSj6uUqhPqk2qTTL+lEJtAtUnVJ/6yGfTtRs4rNfPc7q3TVjGmDBdReNua+1DrvMU2BnAZ4wx2+ia/nC+MeYut5EKahewy1p78BO4B+gqJBPVhcAH1tpaa20n8BBwuuNM+VJytQlKqj6pNqk2jWclV59KqDaB6pPqUy/5bLrWAUcbY44wxkToupDs0Tw+f1Exxhi65qy+a639V9d5Cs1a+7fW2jnW2sPp+m+7ylo7YT9ttNbWADuNMcd2b7oA2OgwUqHtAE4zxiS6f7cvYOJc/FpStQlKqz6pNqk2jXMlVZ9KqTaB6hOqT32E8jWqtTZrjPkz4Em6Vu/4T2vtO/l6/iJ0BnAj8JYxZkP3tm9Za3/jMJPk138D7u5+I9wK3OI4T8FYa9caYx4AXqNrdanXgdvdpsqPEqxNoPo00ak2TRAlWJ9UmyY+1adDMNbascomIiIiIiJScrSQhoiIiIiISAGp6RIRERERESkgNV0iIiIiIiIFpKZLRERERESkgNR0iYiIiIiIFJCaLhERERERkQJS0yUiIiIiIlJAarpEREREREQKSE2XiIiIiIhIAanpEhERERERKSA1XSIiIiIiIgWkpktERERERKSA1HSJiIiIiIgUkJouERERERGRAlLTJSIiIiIiUkBqukRERERERApITZeIiIiIiEgBqekSEREREREpIDVdIiIiIiIiBaSmS0REREREpIDUdImIiIiIiBSQmi4REREREZECUtMlIiIiIiJSQGq6RERERERECkhNl4iIiIiISAGp6RIRERERESkgNV0iIiIiIiIFpKZLRERERESkgIbVdBlj/rsx5h1jzNvGmHuNMbFCBxMRGYpqk4gUK9UnEeltyKbLGDMb+AawyFp7HOADNxQ6mIjIR1FtEpFipfokIv0Nd3phCIgbY0JAAthTuEgiIsOm2iQixUr1SUR6hIY6wFq72xjzL8AOoA14ylr7VP/jjDG3ArcCJJPJkxcsWJDvrCJSYK+++mqdtbbKdY7hUG0SKS0TrT6pNolMDMOtTcZa+9EHGDMJeBD4HNAA/Bp4wFp716Ees2jRIrt+/fqRJRYR54wxr1prF7nOMRyqTSKlZSLXJ9UmkfFruLVpONMLLwQ+sNbWWms7gYeA0z9uQBGRj0m1SUSKleqTiPQxnKZrB3CaMSZhjDHABcC7hY0lIjIk1SYRKVaqTyLSx5BNl7V2LfAA8BrwVvdjbi9wLhGRj6TaJCLFSvVJRPobciENAGvtd4DvFDiLiMiIqDaJSLFSfRKR3oa7ZLyIiIiIiIiMgpouERERERGRAlLTJSIiIiIiUkBqukRERERERApITZeIiIiIiEgBqekSEREREREpIDVdIiIiIiIiBaSmS0REREREpIDUdImIiIiIiBRQqBBPumfPHv7u7/5uVI/dvHlzntMMT0NDg5NxFy9e7GTctWvXOhk3k8k4GTcIAifjHn300U7G/dnPfuZk3GJXU1PDD37wg1E9dsqUKXlOMzwLFixwMm46nXYyrqsaMX/+fCfj7t2718m4a9ascTLu3//93zsZt9i9/vrrlJWVjeqxxpg8pxkea62TcV29XpnYmpubCz6GznSJiIiIiIgUkJouERERERGRAlLTJSIiIiIiUkBqukRERERERApITZeIiIiIiEgBqekSEREREREpIDVdIiIiIiIiBaSmS0REREREpIDUdImIiIiIiBSQmi4REREREZECUtMlIiIiIiJSQEM2XcaYY40xG3p9NRlj/mIswomIHIpqk4gUK9UnEekvNNQB1tpNwAkAxhgf2A2sKHAuEZGPpNokIsVK9UlE+hvp9MILgC3W2u2FCCMiMkqqTSJSrFSfRGTETdcNwL2D7TDG3GqMWW+MWd/a2vrxk4mIDJ9qk4gUq0HrU+/aZK11EEtExtKwmy5jTAT4DPDrwfZba2+31i6y1i5KJpP5yici8pFUm0SkWH1Ufepdm4wxYx9ORMbUSM50XQa8Zq3dW6gwIiKjoNokIsVK9UlEgJE1XZ/nENN3REQcUm0SkWKl+iQiwDCbLmNMErgIeKiwcUREhk+1SUSKleqTiPQ25JLxANbaVmBKgbOIiIyIapOIFCvVJxHpbaSrF4qIiIiIiMgIqOkSEREREREpIDVdIiIiIiIiBaSmS0REREREpIDUdImIiIiIiBSQmi4REREREZECUtMlIiIiIiJSQGq6RERERERECkhNl4iIiIiISAGFCvGk1lqstaN67AsvvJDnNMOTyWScjNvR0eFk3J07dzoZ98orr3Qy7saNG52M29DQ4GRcGVxZWRlLliwZ1WNd/X+1ubnZybiPPPKIk3HPPPNMJ+OuW7fOybhz5sxxMu7kyZOdjCuHZoxxHUFECkhnukRERERERApITZeIiIiIiEgBqekSEREREREpIDVdIiIiIiIiBaSmS0REREREpIDUdImIiIiIiBSQmi4REREREZECUtMlIiIiIiJSQGq6RERERERECkhNl4iIiIiISAGp6RIRERERESmgYTVdxphKY8wDxpj3jDHvGmOWFDqYiMhQVJtEpFipPolIb6FhHvcj4Alr7bXGmAiQKGAmEZHhUm0SkWKl+iQiPYZsuowxKeBs4GYAa20GyBQ2lojIR1NtEikh1rpOMCKqTyLS33CmFx4B1AK/MMa8boz5uTEm2f8gY8ytxpj1xpj16XQ670FFRPoZcW1qaGgY+5Qi8vFs2QKXXuo6xUgNWZ961yY7zppKERm54TRdIeAk4D+stScCrcA3+x9krb3dWrvIWrsokdAZdBEpuBHXpsrKyrHOKCKjlcnA974Hxx0HL73kOs1IDVmfetcmY4yLjCIyhobTdO0Cdllr13b//ABdhURExCXVJpGJ6vnn4cQT4X/+T1i6FN5913WikVJ9EpE+hmy6rLU1wE5jzLHdmy4ANhY0lYjIEFSbRCag+nr46lfh7LOhpQUee4zmXzzAn/yv2a6TjYjqk4j0N9zVC/8bcHf36jtbgVsKF0lEZNhUm0QmAmvhrrvgL/+yq/H6q7+C73yH515NcvPxsG2b64CjovokIj2G1XRZazcAiwqcRURkRFSbRCaAP/wB/vRPYdUqOPVUePpp2o45nm9/G374QzjiCHjuOTjrLNdBR0b1SUR6G9bNkUVERETyqqMDvvtd+NSn4NVX4T/+A158kfWdx3PyyfCv/wp/8ifwxhtw5pmuw4qIfDzDnV4oIiIikh9r1nR1VJs2wQ03wA9/SOeUGfzjd+Gf/glmzIAnn4SLL3YdVEQkP3SmS0RERMZGXR3cfDOcd17XkvBPPAH33svbdTM49VT4h3+AL3wB3n5bDZeITCxqukRERKSwrOUTL78MCxbA3XfD3/4tvP02uQsv4Qc/gJNPhl274KGH4M47QbfUE5GJRtMLRUREpGAqa2o47/77mb15M5xxBvz0p/DJT7J5c9dJrxdegGXL4LbbYNo012lFRApDTZeIiIjknd/ZyclPPcXJTz9NZyTCqhtu4Py778Yaj9v+A/7H/4BwGH71K/jiF8EY14lFRApHTZeIiIjk1Zz33uPc5cuprK1l06JF/H7ZMtoqKjh6t8dXvgJPP911zdYdd8CcOa7TiogUnpouERERyYt4czNnPvQQx65fT0NVFQ9//evsWrAAa+GVtcfy7W9DNtu1Ovwf/7HObolI6ShI0xXp7CSRTpOOx1VRRUREJrogYOFLL3H6I48QzmR45dJLefXii8mFwzQ3x7nvvnN58835nHkm/PKXMH++68AiImOrIE1X1f79fOuHP6TF89gVjfb9ikTYFY2yNxIhGKQhW7BgQSEiDemNN95wMm4kEnEy7pVXXulk3OrqaifjlpWVORn3xRdfdDKuDK6trY0333xzVI+9/PLL85xmeHbt2uVk3L/5m79xMm5DQ4OTcR955BEn47qqTZs2bcrbc83cv5/PrVnD/Opq3p81i/vPPZe9kyfD1q1s2XI8q1dfTyYT4/TTV7BmzTJ8P29DC2CtdTKu0YfqUgCufp/HQkGarp2RCP+nqoo5mQxzOjo4qq2NcxobCff6HzIL7OnXiO2ORmmORKhJJGhXVRYRESla4c5OLl23jgs2bKAtEuGuCy5g7YIFYAzt7XGef/5aNm1aTFXVDi688FdMmVKD7y9zHVtExImCNF0toRD3TJ/eZ5tnLdMyGQ7LZJjd0cGc7q/ZmQzHtbZSkct1Hbh1KwD7IxFq4nH2JBJUx+NUd/+7Jx6nIRLRtEURERFHPrF9O9c/+yxTm5p4ecECHj7jDFrjcQC2b1/AqlVfIJ2u4JRTfsOiRU/i+4HjxCIibo3ZQhqBMdREo9REo6wrLx+wvyKbZU5HBwsiEWa2tTErnWZmWxvHHzjABdXVfe7inPb9Po3Ywe/3xOPsi8XIebrns4iISL5VtLZy9e9/z8nvv8/eykp+dNVVbO5efjCTifDii1fx9ttnMXlyNUuX/oxp03Y6TiwiUhyKZvXCplCIjaEQe6dMGbAvnMsxo72dmd2N2MGm7LDWVhbX1REJPvwELWcM+2KxnrNiPWfIuv9tCxXNSxYRERkXjLWc8fbbXPnSS4RzOVYuXswzJ59MtvtSgD175vPMM1+kqWkKJ574DKeeupJQKOs4tYhI8RgXHUin77MzmWRnMjlgn7GWyR0dzGprG9CUnbVvH6nOzj7HN4TDfaYqHvy+Jpdjr+dp2qKIiEgvs+rquGH1ao7Yu5dNc+Zw/znnUDtpEgDZbIi1a5fy+uvnU1Gxn6uv/jGzZm1xnFhEpPiMi6bro1hj2B+LsT8W463uN4HeEp2dXU1Yv6ZsYUMD59TU0Hu5jjSww/fZ7vts6/W13ffZ6ftk1JCJiEiJiHR2ctkrr3Dehg2kYzH+66KLWH/MMT0fTu7bdxjPPHMj9fUzOe645zn99IeJRDKOU4uIFKeCNF1BECUIonheRyGefkTS4TBbwmG2VFQM2BcKAqZ1T1sM3n+fw3M55uVyHJ7LcVYmQ6LXsQGw2/N6GrL+jVmTriMTEZEJ4pMffMB1zz3HlOZmXly4kEdOP510LAZALuexfv0lrF9/CYlEE1de+RPmzXvPcWIRkeJWkKarvf1INmz4PZHIXqLR7USjO4jFdhCNHvyqxhj3c72znseeRII9iQRv7N7dd6e1VAVBn0bs4NfFmQzTgr4rMR0wpk8z1rspq/Y8rM6SiYhIkUu1tHDN889z4pYtVE+ezA+vvpqts2b17K+vn8HTT99Ibe1cjj32Fc466wFisTaHiUVExoeCNF2RyG6mTLmd9vZ5dHQcxoEDl5HL9V6xMEs0uru7GdtONLqTaHQ7sdhOrM1iTBHcGM0Yan2fWt9n3SC7E0HA4UHAvH5N2fHZLEs7Ogj3OradD6ctbu83bTGSy5HRPclERMQhEwSc9dZbXPHyy/hBwKOnncaqE08k1/3+FASGDRvOY+3aK4hE2rnssp8zf/4bjlOLiIwfBWm6QqEmZs78Wc/P1kI2W0lHxzw6OubS3j6Xjo6ur+bmU7A21nPsxo0dJBK7+33tIpncTTjcUDTrXKQ9j42ex8ZBVkP0rWV2r7NkvZuy0zo7Ke99t+1nnqE2GqU6kaDm4MIe3cvf1yQSNIXDWtxDREQKZs6+fdywZg3z9u3j3cMOY/m551KXSvXsb2ycyjPPfInq6vkceeQbnHvufSQSLQ4Ti4iMP2OykIYxEA43EA43UFbW95Mxaw2dnVV0dMyjvf0wjDmWdHoOLS2HU1u7BGs/jBgKtZJI7BrQkCUSuwmHW8fipQxLzhh2+D47BjuDZS1TrO1pxJZMm8bMdJoZbW2ctH8/U/fs6XN4ayjU955k3U1ZdSJBbSxGoIZMRERGIZrJsHTtWs55801a4nF+cfHFvHb00T0f9FkL77xzBi+8sAxjclx44Z0ce+w6fQ4oIjIKw2q6jDHbgGYgB2SttYvyFcAYSySyj0hkH+Xl65jS6z5dQeDR3j6ddHoO6fRs0unZtLbOoaFhITU150KvWyaHww0kk7sGNGOJxB583/2CHj2MYb8x7Pc8XguH+WD+/D67o7kcM9ramJFOf7jaYjrN4S0tnLpvH5FeZ8myxrC3182h+zRm8TgduieZTHCFrE0iE9mntm7luueeY1JLC88fdxyPLVlCWzTas7+lpZLf/e4L7Nz5CQ477F3OP/8eyssbHCYef1SfRKS3kfxVfp61tq5gSQbheQGJRDWJRDX0u7IqlwvT1jZzQENWV7eITOaSPsdGo7Ukk7uIx3eTTH7YkMXjNXie+wU9euvwfbaXlbG9rGzAPs9apnSvtjjrYGPW3ZQdW11Nebbva6mPRAZtxqoTia6PMPVxpUwMY16bRMareF0dn/7Zz5j5yivsnjKF/7zkErbNnNmz31r4wx8W8eyz1xEEPuecs5zjjntebxejp/okIsA4vk+X73dSVraDsrIdA/Zls/GeRqz31969Z5PNfrh0vDE5YrEaEondpNNv4PtbCIW24Psf4Hm7MSYY8NwuBcZQG49TG4/z5iD7yzo7u86O9WrGZqbTfLq+nvPb2+m9qH37Cy9Qn0pRV1nJ/lSK/b2+P1BeTqDFPUREJgyTy3HkypV84t57IQh4+PTTWX388X1qfVtbGatXf46tW09g5swtXHDBXVRWql8QEcmH4TZdFnjKdC0r+FNr7e39DzDG3ArcChCJRPKXcBRCoTYqKjZTUbF5wL5Mpry7CZvTpyFrb/8C1iZ7HdmO72/D97cSCm3F97fi+1vw/a143r6i/NSvJRzm/VSK93tdAH1QOJdjeveNoWem0xwXjzOloYFp9fV84oMPCOdyPcfmjKGhvLxPQ7a/spK67n87HP/3FellRLVp8uTJYxxPxL3K99/nhNtuo3LrVmpOPpk3b72V3731Vp9jtm79NKtX30BHR4zTT3+YE05YhecVwUrC49tH1qfetckU4x8VIpJXw226zrTW7jbGTAOeNsa8Z619rvcB3cXkdoBkMlm0lToSaSYSeY/Kyr43ctyw4Q2CYDq53JHkcvPJ5Y4gm51PLnckmcwFwIdz3Y1p6W7CPmzGDjZmnlecc947fZ9dZWXs6p62uHnhwp59xloqWluZ0tDAlMZGpjQ2MrX7+09v3kxZW997sLTE433OjO1PpXoasqZkUtMWZSyNqDbNmzevaGuTSL6F0mkW3n03R/z2t7RXVvLKX/0Ve5Ys6VOjOzriPPfctWzatJiqqh1cddWvmDKlxmHqCeUj61Pv2uT7vmqTyAQ3rKbLWru7+999xpgVwGLguY9+1PhiDPj+Xnx/L/BSn33WegTBHLLZI7obsiPJ5Y4kmz2ejo4rAb/X8+zH9z/omaZ48OxYV0OWHtsXNUzWGBrLymgsK2PrnDkD9sc6Orqase5GbGr394fv2cOJmzbh9VrcIxMKfXh2rPcZslSK+oqKAc8t8nGUQm0SGTFrmfXSS3zqjjuIHTjAB5ddxsYvfIFsMtnnsB07jmXVqi/S2lrBKaf8hkWLnsT3i2ta/Xim+iQivQ3ZdBljkoBnrW3u/v5i4B8KnqyIGBPg+zvw/R3As332WRsml5vb04xls11nyjKZMwmCz/U51vOq+5whC4W20tISJZGoxvM6x/AVjUx7NMruadPYPW3agH1+Lsek5uYPG7JeZ8uO3rGDaK/FPQJgfyLBvrIy9paV9fx78PtWTVuUEVBtEhkosW8fn779dma8+ioNRxzB2r/5GxqOOabPMW1tPmvWXM/bb5/FpEnVXHvtz5g+faejxBOT6pOI9DecM13TgRXd841DwD3W2icKmmocMaaTUKhrAY7+rE2QzR7eZ8piLjefjo7LsHYqAC+8AJAjHt9HIrGne9n7Pd03hN5DLLYXzyveTx5zvk9dZSV1lZUDd1pLeTrdc5ZsamMjiepqpre0cNKePVS2t/c5vCUS+bAJSyZ7vt9bVsaBRAKraYvSl2qTSDeTzTL/scdYcP/9YAxv3XILW5cuxfZbFGnjxsn827+dRE1NghNOWMVppz1OKFS8H/qNY6pPItLHkE2XtXYrcPwYZJlwjEkTDm8kHN44YF8QVJDLHcmcOed3L3fftaDHnj0Xks0mez1HZ/ey+QMbsmi0rrgvnzKG5mSS5mSSbbNmAVBdXd2zO9rZyfTWVqa1tDC9+2taSwtH1NezeOdOQr2mLXZ6HvuSyQFnxw42aJ26J1nJUW0S6TLpvfc44bbbSG3fTvUpp/Dm175GW1VVn2MyGY977/0EjzxyFNOmpVm27MfMnj3ww0LJD9UnEelPf6k64nlNeN4GZs3q2zVZC5lMZZ9G7OC/+/efSBB8uKCH77cTj+8hmdw9oCELhxuLuyEDOsJhdlRWsmOQs2ReEDAlne7TjB38/tjaWhL97km2Px4/5LTFZk1bFJEJKNzaysJf/YrDn3qK9smTWfvNb1J96qkDjtuyJcWPfnQyO3dWcPHFH3DzzW/z4otquERExpKariJjDESjDUSjDUya9E6ffdYa2tun9mnE0unZNDcfwb59S7D2w/+coVBz99mx3T2N2MF/Q6HiXNCjt8DzqC0ro7asjLf777SW8kymqxFrbu5qylpbmd7Swqdrapjcb7XFdDhMTTLJ3u6vmu6pizXJJPvjcQLP6z+CiEjxspbZL7zAp+64g2hTE1uuuIL3Pv95svF4n8OyWcODDx7Dr399LKlUB3/3dy9y0kn7HIUWESltarrGEWMs8Xgt8XgtU6Zs6LMvCHza2qYPaMgOHPgk1dXnQq9bI0ci9bz1VgOTJtVSWVnLpEm13d/vHx9z+42hORqlORply5QpA3ZHslmqupuwg19Tm5uZ29jIoupqwsGH18hljaE2kaCmrGxAU7Y3maRD0xZFpIgkamo4/vbbmf766xyYP5+Xvv1tGufPH3Dczp3l/PjHJ7F58yTOPnsnX/vam5SVjYP6LiIyQekvygnC83Ikk3tIJvdQVbWuz75cLkI6PZN0eg6trbNIp2cDR/PBB58gne49FSWgvLyBysq6Xo1Y178VTeCejgAAIABJREFUFfXjZinhTCjE7lSK3b1uEt3Z2fXHhmctk9vamN7dlM1obWV6ayszWlo4qr6e8s6+f5QciMX6NGM13deQ1SSTNEajuieZiIwJ09nJUY8+yoLlywl8nze/+lW2Xnop9FsoI5eDxx+fz913LyQez/LXf/0KS5bscZRaREQOUtNVAnw/Q3n5dsrLt/dsW9h9c+SOjigNDVU0NEzlwIFpHDgwlYaGKjZtOpGOjkTP8cbkSKX2M2lSXU8j1vVvHeXlDRgzPu7rGBhDXSJBXSLBO/0uNAdIZjJdjVhLS1dj1trKjNZWFtbWctaOHfSeiNjm+z1nxPqfIatNJMhp2qKI5MHkjRs54bbbqNi5k91LlvDWV75C+yBn+WtqEvzbv53Exo1TWby4mj/90w1UVnY4SCwiIv2p6Spx0WgH06fvYvr0XX22Wwvt7UkOHKjqacQOHKiioaGKnTvnk832XtCjs+fs2MFGrLJyH5Mm1ZFINI+rk0GtkQhbIhG2TJo0YF8ol2Na9+IeB8+QTW9tZVZzMyfU1BDtNW0xZwx18Tibsll2hEJs8322h0JdX75PixoyERlCuLmZT955J4c/8wzpqipe+ta32HvKKQOOsxaeeupwfvnL4/A8yze+8SrnnrtzXNVeEZGJTk2XDMoYiMdbicdbmTVrW5991kJra2pAQ1ZfP52tWxcSBB/+WkUi7X3OjBmzmfLy/7+9O4+Pqr73P/76zkz2HUICISGBsAiyg4ooBXEBFIu7ttarrZV6f9Uut/dxr7W399r22trbe+2uj1q12krtdQER4SqIIKKICAhlkT0sSQghgWxkmcx8f38kQPZMwkwmmXk/H495TDjL93wOxg/znnPmO4UkJBwnMrKqh8/qwtQ7nRQkJFCQkNBqnbGWlJqaVrctxh8/zryaGvp7m9+aWeJwcNjpJM/l4khjIDsbzE44HPpOMpFwZi2Z77/PuD/9iYjKSvYtWMDnd92FJzq61aYlJdH8/veT2Lo1nQkTTvDQQ1tJTa1uY1AREQkmhS7pMmMgPr6M+PgysrL2N1vn9TooL0/m9Om0ZoGssDCbvXsnYu2cc9tGRZWTkFBIfPzxc0Gs4bkIl6tv3RJjjaE0JobSmBh2p6aeW75hwwYA4r1esj0esuvrya6vJ6fx5yl1dSzweGj6qYxqYxqC2NmrY02ukh11OqlTIBMJWXEFBUz4wx9I276d0pEj+ezBBykfOrTVdtbCunWZ/PGP46mvd7Bw4TbmzDmELqKLiPROCl3iVw6Hl+TkUpKTS8nJab6uvt7J/v1eKioGUVk5kPLyhueionHk5c1stm1MTEmTEHb+OS6uCKfT03Mn5CeVDgc7HQ52RkS0WueylsyzgazF85V1dcQ2+ZJoL1DYGMjyGgNZ09sXy/SKS6RPcrjdjFiyhJGvvYY3IoJtCxdy6LrrWk2UAVBWFskf/jCBDRsGc9FFJTz88BYyMvrWnQMiIuEmIKErPj6emTNndr5hG77whS/4uRrf7NjR6tugesS8efOCctxFixb1+DFdLg9ZWVXAvsbHeW53FGVlAygrS6esLI2ysnTKy9M4dmwatbXx57Yzxkt8fAnJyUUkJp4gKano3M/x8aU4HG1P6JGfnx/AM2tfbW3nV+xqgT3AHmPA5Wp4nGUtA6wlx+Mhx+tlqMfTcJXM6+Xq6mrSbfPzPWUMhx0OuPNOyM1teAwb1vA8eHCbL+DCidvtprCwsNv7BsOyZcuCctzkNr60vCcMGjQoKMeNaOMNkZ7wwgsvcPHJk/zjtm1kVlayPiOD58aN41RREfzlL622Lyy8lG3b/h9udxxjxrzI8OFLWbmy6zPLBuvvWfzP6O6HkGZt35iozF9C+fdZV7qkV4iIqCU19RipqcdaraupiaW8PI3Tp9PPPZeVpXP8+HDc7vOfcXA43CQmFpOU1BDGmj5bm983P1RuDMXGUOxwsKmN1XHWNlwVaxLIcrxe2LIFFi+G+vrzG0dGwtCh50NY01A2bBi0+GJVEQmsmKoqHtq6lWuOHOF4bCw/mjaNrenpbW7rdsfx97/fz9Gjs0lKOsD06f9OYuKRHq5YRES6S6FLer3o6DNER+eRlpbXbLm1UF2deO7q2NlQVlaWzrFjF+PxnH/n2uk8c+57zM4/8omLyycysrKHz8h/qoxhl8vFrhbLT+7b1xC4jh6FAwcaHgcPnv95/XqoqGi+U0ZGj9UtEtasZdzWrcxesYLI6mpeGzGCV0aOpK6dL2M/cWI8W7d+i9raFEaO/F9GjXoVh6O+zW1FRKR3UuiSPssYiI0tJza2nEGDmt+u6PUaqqr6nbtVMT8/jqqqDMrKhnP8+BVYe/42u4iI8hZB7Pyzy1XT06flPy5Xw5WtoUPhmmuar7MWSkrOh7CzjxdfDE6tImGi34kTzF26lOxDhzg2ZAj/lZvLkcTENretr49i5857ycu7nvj4o1x66ROkpOxvc1sREendFLokJDkcloSEEhISSsjM3E1y8vnPdHm9Ls6cSaeqajBVVRnnnktKxpGfP7vZOFFRJW0GstjYQpzOPvxOszGQmtrwuOyy88sVukQCwul2M/3995n2/vu4IyJYcfPNbJsyhSOb2rpxGEpLR7Fly7epqhpIbu5SRo9ehNNZ18NVi4iIvyh0SdhxOOqJj88nPr715BoeTxRVVYOaBLKGR1HRZdTVNZ1YwEtMzIk2A1lMzAkcjq5/sF1EQlP2/v3MXbqUfiUl7Jg4kdXz5nGmje/7A/B4XHz++ZfZv38BsbEnueKKH5KaurOHKxYREX9T6BJpwumsJTExj8TEvFbr3O64ZlfGzj7y86+ivj7u3HbGuImNPU5cXAFVVZtxOg/gdB7E4diPw3EcY8JrJiKRcBVbWcnVK1Yw9rPPONWvHy9/9avkjRjR7vanTw9ly5bvUFGRTXb2Si6++HkiIvrwLc4iInKOQpeIjyIiqkhO3kdycvPPj1kLdXVJjWGseSCrqfkq0HRWwCqczkNNgljDs9N5AGNK+uYMiyLSnNfLhM2buertt4msq+PDq67io1mzqG9nWnqv18G+fbexZ88dREaWM23aj0lP39LDRYuISCApdIlcIGMgKqqMqKgy+vVrPo/ghg0b8Xoz8HqH4fEMx+MZhseTS339xdTVXQ9ENBmnrDGEnQ9iZ4OZw9FipkER6ZX6FxUx7403yDp8mCM5Obx9002UpKW1u31FRSZbtnyL06dHkpn5PuPG/bFPz6gqIiJtU+gSCSBjLE5nPk5nPhERHzRbZ60LrzcLjye38TEMrzeX+vrLqKu7FXA0GedEYwhreYXsEMbo9iORYHO53Uxfs4ZpH3xAXWQky2+5he2TJ4PD0eb2Xi989NElrF37PVyuGi655OdkZGzo4apFRKSnKHSJBIkx9Y23Gh4C3m22ztooPJ4cPJ5cvN7cc8Gsru5arG3+5akOxzGczgM4HAfPBbO9extmim/nbiYR8aOh+/YxZ+lSUkpL2T55Mu/NnUt1fHy725eWJvHaa/PJyxvCwIGfMGHCU0RHn+7BikVEpKcpdIn0QsbU4nLtweXa02qd1xvfeLti7rnbFb3eXOrqbsbahhkWR40Cp7MheI0cCSNGNDyf/Tkrq9034EXER3EVFVy9fDkXb99OSWoqi+6/nyO5ue1uby1s2jSRFSuuxhgvt976Fm73s/osp4hIGPA5dBljnMCnQL61dn7gShKRjjgclTgc23G5tjdbbi1Y2w+PZxi/+c3b7NsHe/fCvn2wdi2cOXN+2+hoyM1tHcj6IvUm6XFeL5M2bWLWO+/gcrv54Oqr2TBzJh5X+/+klpfHs3jx9ezdm8uwYXncdttykpPL2bixB+uWHqf+JCJndeVK17eB3UBigGoRkQtgDBhTisNRyr33Nl9nLRQU0CyI7d0Ln38Ob70FbndwavYT9SbpMQOOH2fuG2+QeeQIecOG8c6CBZQOGNDu9tbCtm1jWLbsOurrXdx440ouu2yzrjSHD/UnEQF8DF3GmEzgBuBx4J8CWpGI+J0xMHhww2PWrObrPB44cqQhhM2dG5Tyuk29SXpKRF0dV7z3HpetX09NdDTLbruNHZMm0dG9gZWVMSxdOpedOy8iKyuf229/i9TU0h6sWoJJ/UlEmvL1StevgH8BEtrbwBizEFgIkJDQ7mYi0suc/ezX0KHBrqRbutSbEhP1ZrN0Xe6ePVz35psknzrFtilTWDNvHtWxsR3us3v3cBYvvp6ammjmzFnDjBkbcTj0xehhpsP+1LQ3GX2wTyTkdRq6jDHzgRPW2s3GmFntbWetfQZ4BiA9PV3/sohIQHWnN2VkZKg3ic/iy8u55q23GL1jBycHDOClBx7gaCfvTtTURPHWW9ewZct4Bg0q4mtfe5lBg4p7qGLpLXzpT017k9PpVG8SCXG+XOm6AviiMeZ6IBpINMa8ZK39SmBLExHpkHqTBITxepm0cSMzV67E5fHw/rXX8vGMGXg7mCgDYP/+bF5//QbKyxOYNetDZs9ej8vl7aGqpZdRfxKRZjoNXdba7wPfB2h8t+af1TREJNjUmyQQ0goKmPfGG2QcO8ah4cN5Z8ECTvXv3+E+dXURvP32VXz88RRSU0t48MG/kJVV0EMVS2+k/iQiLel7ukREJOxF1NYyY/VqLvnoI6pjYlh6553sGj++w4kyAA4fHsxrr82npKQf06dv4rrr1hIZWd8zRYuISJ/RpdBlrV0LrA1IJSIi3aTeJBcia+tWbn7xRZLKyth6ySWsnTuXmpiYDvepr3fy7rsz+OCDy0hKKuf++xeRm3ukhyqWvkT9SURAV7pERCRMxZaUcNlf/0r2li2cSE/nz3fdRX52dqf7FRSk8eqrN1JUlMbUqZ9x/fWriY6u64GKRUSkr1LoEhGRsGI8HkavXs2kJUswXi+f3nYbqydMwOt0drifx2N4//3Lee+9K4mLq+Yf/uEVLrroQA9VLSIifZlCl4iIhI3+hw5x+Ysvknr4MMfGjePje+6hcsAAvIWFHe534kQ/XnvtRo4dy2DcuF0sWLCS2NjqHqpaRET6OoUuEREJeRHV1UxavJiLVq+mJjGRtf/4j+RdckmnE2V4vbBhwyW8885MIiLqueuuNxg/fncPVS0iIqFCoUtEREKXtQzZvJnLFi0itqyMz6+6ii233oo7NrbTXUtLk3j99Rs4dCibUaP2c/PNK0hMrOqBokVEJNQodImISEiKO3mSaS+9RNa2bZRmZbHmoYc4mZvb6X7WwqefTmD58qsxBm65ZTlTpmzv7KKYiIhIuxS6REQkpBiPhzGrVjFxyRIANt15J7uuvRbbyUQZAOXl8SxZMo89e4YzdOhhbrttOSkpZYEuWUREQpxCl4iIhIzUAweY/uKL9Dt6lCMTJ7Lx7rupSk3tdD9rYfv2Mbz55nW43S7mz1/FtGmf4nD0QNEiIhLyFLpERKTPizhzhsmvv85Fa9ZwJjmZ9x56iCOTJ3c6UQZARUUUL798Ezt2jCYzs4Dbb1/GgAGlPVC1iIiEi4CErpiYGEaPHt2tfUtKSvxcjW+OHz8elOMePXo0KMetqakJynHvu+++oBw3Pz8/KMe9++67g3JcaVtCQgKzZs3q1r6bNm3ybzE++sY3vhGU45aWBid0PPHEE13bwVouz8/na9u2kVhTw/Lhw/nbmDHUFBbC8uWd7l5QMIUtWx6kri6egQN/Q0rKC6xe7elm9V2XkJDQY8dqKlj/1kr7vF5vt/YzQfqwobU2KMeV0Nbd/w/6Al3pEhGRPimtqooHtm5lUlERB5KT+dn06RxMSfFpX7c7lm3b7uPw4dkkJeUxZMhCYmL2BrhiEREJVwpdIiLSpzi9Xm7ct4/bd+/GawzPjx/P27m5eH38ANaJE2PZvPmbnDnTj1GjFjN69CscPKjAJSIigaPQJSIifcaokhIWbtlCdnk5GzMyeG7CBEp9+M4tgPr6SHbs+AoHDlxPfHwBs2b9G/377wtwxSIiIgpdIiLSB8TV1XH3jh1cd+gQxbGx/Ozyy9mckeHz/iUlI/n004eorMwgN3c5Y8cuwuWqC2DFIiIi5yl0iYhI72UtVx49yn3bt5NQV8ebI0bwypgx1Lh8++fL43Gxe/cd7NmzgNjYUmbMeIy0tB0BLlpERKQ5hS4REemVBlZW8sDWrUw4cYJ9KSn855VXkpec7PP+p09n8+mnD1NWlkNOzmrGj3+RiIgzAaxYRESkbQpdIiLSq7g8Hhbs3cutn3+O2+HgjxMnsmrYMLw+To3t9TrYu/cmdu26ncjISi6//GdkZGwOcNUiIiLtU+gSEZFeY3RxMd/YupXMigo+zMzkhfHjORUT4/P+FRUZbNr0MKdOjSAz80MmTvwjUVGVAaxYRET6moavmXPQEIVclJdDfX3Dw+Np/tzZMl8pdImISNA5T58m6ze/4Sfr1lEUG8vj06ezddAgn/e31rB//zx27Lgbl6uOSy99kqysjwJYsYhI72etAZw0vOQ/+9zws7Utl59fb62j2bZNnxv2c7a5vvWYZ392Ym3by8+P2d6y5svPr297efP1jnbqaR6BkpK6/3fsK4UuEREJHmvpv2IFmb/6Fc6KCpaMHMmro0dT5+NEGQBVVQPYvPmbFBePZeDAzUye/DQxMacDWLSI9CYtr1p0HBJ8DR7ONl70dzVAtLdf0+Xn626+X/PzOb9f6xDR9vk1Hb83qW98eJr87MWYlss8TZ4bfm6+TS3GeJpt23y9p8XPTdd7Wh3r5z9/HJcLnE6aPfuy7KqrfDtzhS4REQmKqLw8sp94gsTNm6kcN47Djz7Kotde83l/ayEvbzbbt98HGCZPfpqcnNX4+NEvkT6nIVy0fGEdQftXJpou7yxsNA0GnV3F6OhKSFuBpL1g4WwxfsvlLWtu78pGb3w5W0fLF/3gaRIUWgeEhlDQPFjAGaAeh6N5SGk6RvMw0Ty8nD+et9VxG9a13uf8mK33aft47Y3ZVrjq+G/NNvyS97h/+qfHA36MTn9LjTHRwDogqnH716y1/xHowkREOqLe1HeZ2loGvfgiA194AW90NHnf/z4nb7oJHL6/I1tdncyWLf/I8eNTGDBgB1Om/J64uOIAVi3iu672J693DNXVb9HZVZmGR2/SMjh0FCDau2LhoSGgNLxgb72u5Qv6tl/wdx48fAkJLcdsP0AY01YgObtfcIKD9G6+vDVQC8y21lYaYyKA9caY/7PWfhzg2kREOqLe1AclbNpE9hNPEH3kCCVz5nD0u9+lvn//Lo1x9OgVbN36dTyeSMaPf57hw/9PL3Kkt+lif6rC4fiA1mGlrSslLQNMewGkrSsbHV29aDlOyyszzY9hbb2uKot0QaehyzZc5zs79VNE40P/uolIUKk39S2uU6fI/NWvSF2xgprMTPb+9reUT5vWpTFqaxP47LOvc+zYFaSk7GPq1N+SmFgQoIpFuq+r/cnhOExU1De6dSyj5CN9nLH2/CfQrG1142lby5o+OwBXkzFaTsnhBJwdjOEAePLJ1tMUtpyysL1lPvLpJlhjjBPYDAwHfm+t3djGNguBhQD9+vXzuQARke7qam9KS0vr2QIFvF5Sly0j87e/xVFVRcHXvkbhV7+KjY7u0jCFhVPYvPlB6uriufjivzJy5Bs4HN4AFS1y4TrrT017k4JTiLEWB61f/J/7uTEgtBsSOgoQLdb5sv7cdm0ct6P1TT8N2DS0nF3XrMbGfVt+grCzdWeXB933vtd6mcPRfMaMljNqnF3mI59Cl7XWA0w0xiQDS4wxY621O1ps8wzwDEBOTo7ebRaRgOtqbxo1apR6Uw+KPniQ7CeeIGHrViomTeLwI49QM2xYl8Zwu2PYvv0+8vKuJjHxMFde+TjJyXmBKVjEjzrrT017k9Pp7P29qUmQaPPFfReDRFv7+hokmgWCdtY5m6z3ZV3LqTuaBo02w0I7Aaa3TutxVntz+3kAjzGtbmj1Nt2uxfrz03yAx+FoPV6LfZve3NruOmupbzxOWzWe+7nJNm19crCtc2m6vbfxmGeX5RcVtQ5Tvr4Z4uN2Xfq9sNaeNsasAeYCOzrbXkSkJ6g39S6mpoZBf/oTA//8Z7xxcRz64Q8pmT+/SxNlAJw4MZbNm7/JmTP9GDVqMaNHv4LT2YVvohTpBXzpT2nW8nW3u1mQaHWLFa3DQLtXLGgeRhwttmt6RaNVUGoMV30pSLT7whqavYBvNWF4G+vqmq5vEiRahYUmL+q9tPHiv53g0NG6ttZ3tM6XMNEyQPX2D+IFa/ZCEhMDfghfZi8cALgbm0YMcC3w84BXJiLSAfWm3inx448Z8vOfE33sGCdvuIFj3/429SkpXRqjvj6SHTu+woED1xMfX8CsWT+kf/+9AapYxP+62p8GW8tP3O5my9qbw69pkGi2jPNXDFpeaail+Tv/rV6YN67ztnVcY9q+OtFyWReCRFshpK1jnDu/JvW2Fax6e5AQAd/euBgEvNh4b7IDeMVa+1ZgyxIR6ZR6Uy/iOnmSrF/9iv7vvEPNkCHseeopKi65pMvjlJSM4NNPH6KycjC5uSsYO3YRLldtACoWCagu9adtxpAaHd0sRPkaJIL1ebCgXZEQ6aN8mb1wOzCpB2oREfGZelMv4fWS+sYbZP7udzhqaih44AEK770XGxXVpWHq6gzPPpvB2rX/SUxMKTNm/Ii0tL8HqGiRwOpqf/IaQ7Wu1oiEtN58i66IiPRiMfv3k/3TnxL/979TPmUKhx95hNqcnC6Ps3dvDI89NpR9+2LJzn6PCRNeICLijP8LFhERCRKFLhER6RJHdTWDnn2W9EWL8MTHc+ixxyi5/vouf66ivh7+8peBPPNMBomJHv77v/exYcNTAapaREQkeBS6RETEZ0kffsiQ//ovogoKKP7iFzn28MN4kpO7PE5eXhQ/+tFQduyI5+qrS3nkkSMkJ9ezYUMAihYREQkyhS4REelURHExWU8+Sb9336U6J4fP//AHKidP7vI4Xi+88koav/vdYKKiLP/5nwe57rpSTT4mIiIhTaFLRETa5/Ew4PXXGfzUUzjcbvIffJDj99yDjYzs8lCFhZH8+Mc5fPppItOnl/Fv/5bHgAHuzncUERHp4xS6RESkTTF79pDz058St2sX5Zde2jBRRlZWl8exFpYt68+TTw7BWvjBD/JYsOCkrm6JiEjYUOgSEZFmTFUVmb/8Jen/+7/UJyVx8Cc/oXTOnG59AenJkxE8/ng269cnM3lyBf/+74cYPLguAFWLiIj0XgpdIiJyTuy775L62GO4Cgspvvlmjj30EJ7ExG6NtWpVCj//eTbV1Q6++92j3HVXEQ6HnwsWERHpAxS6REQEZ0EBqT/+MXGrVlE3YgSfP/sslRMmdGus06ed/OIXQ1i5sj9jxlTx2GOHGDq0xs8Vi4iI9B0BCV0JCQnMmjWrW/ueOnXKv8X4aOLEiUE57ieffBKU42ZmZgbluJs2bQrKcYOlvLw82CVIE9XV1ezevbtb+6ampvq5Gt/89re/Dej4xutlxrZtzPvoIxzW8tYVV7B28mRe+dGPujVedfVVlJb+Aq83kcTEX1Be/hTf+57H5/0TEhK6ddwLdc899wTluOvWrQvKcT/66KOgHFfa1r9/f2699dZglyEdsNYG5bgmzD78GsrnqytdIiJhKrOoiDtWrybrxAl2Z2fz+uzZlCQldWssrzee06d/SFXVl4iI+JwBA+4lMnKnnysWERHpmxS6RETCTFRtLddv2MCV27ZRGRPDi9dfz2cjRnRrogyAmppplJb+Dx5PBgkJT5GU9CTGaLIMERGRsxS6RETChbWMO3CAW9auJbGyko/Gj2f59OnUREd3azivN4qyskeorLwfl+sQaWm3ERW12c9Fi4iI9H0KXSIiYSClvJxb1q5l7MGD5Kem8qcbbuDIoEHdHq+2dgKlpb+kvn448fEvkJT0MxyOaj9WLCIiEjoUukREQpjD6+ULW7cyd8MGAJbOmMG6iRPxOp3dGs/aCMrLv0V5+TdxOosYMODLREev92fJIiIiIUehS0QkRA0pLOSO1asZfPIkO4cO5fWrruJUN79zC6CubhSlpb/E7R5LbOyrpKQ8hsNR4ceKRUREQpNCl4hIiImureWGDz9k+vbtlMfH8/z8+fw9N7fbE2VY66Ci4kHKyv4Jh6OM1NT7iYlZ5eeqRUREQpdCl4hIqLCWifv2cfPatcRXV7N+4kRWXH45tVFR3R7S7c6htPRJ6uqmEhOznJSUR3E6g/N9iiIiIn2VQpeISAjoV1bGbe+9x+jDhzmalsazCxZwND292+NZa6is/AfKyh4F6ujX72FiY5d292KZiIhIWFPoEhHpwxweD7O2bGHOxo14jWHJzJmsnzABr8PR7THLy5MpLl5Ebe2VREevISXlX3C5ivxYtYiISHhR6BIR6aNyCgq4ffVqMkpK2J6by+JZsyhLSOj2eNbCrl2X8P77N+N2e0lJeYS4uL/q6paIiMgF6jR0GWOygD8D6YAFnrHW/jrQhYmIdCSce1NMTQ3z169n+o4dnEpI4Nkbb2Rnbu4FjVlVFc/q1Xdw8OA4Bg/ej9d7Hy7XET9VLBJewrk/iUjbfLnSVQ98z1q7xRiTAGw2xqyy1u4KcG0iIh0Jv95kLZP37OGmdeuIq65mzeTJvD1tGnWRkRc07L59E1i9+jbc7ii+8IU3mDRpHYsXK3CJXIDw608i0qFOQ5e1thAobPy5whizGxgMqHGISNCEW29KPX2a2957j1FHjnA4PZ0/3HQT+WlpFzRmTU0sa9bcwp49U0hPP8KcOYvo1++EnyoWCV/h1p9EpHNd+kyXMSYHmARsbGPdQmAhQEZGhh9KExHxja+9KSUlpUfr8genx8NVmzdz3caNeJxOXp81iw/Hj8dewEQZAIcOXcS7795JdXUCl1++gqlTV+N0ev1UtYitVnKfAAAQVklEQVSc1V5/atqb4uPje7wuEelZPocuY0w88DrwHWttecv11tpngGcAxo0bZ/1WoYhIB7rSm4YMGdKnetOA3bv550WLGFhaymcjRrBk5kzKL/DFWV1dFOvWfZEdO6bTv38hCxY8R1raMT9VLCJNddSfmvamtLS0PtWbRKTrfApdxpgIGprGImvt4sCWJCLim1DtTZEVFUz8618ZtnYtpQkJPLNgAbuHDr3gcY8dG8bKlV+mvDyFKVNWc/nl/4fL5fFDxSLSUqj2JxHpHl9mLzTAc8Bua+2TgS9JRKRzIdmbrCXngw+Y+NJLRFZVsfvGG3lhyBDqIiIuaNj6+gg+/PB6tm79AklJJdxxx+/IyDjkp6JFpKWQ7E8ickF8udJ1BXAP8HdjzGeNyx611q4IXFkiIp0Kqd6UUFDA1OeeI33XLk6OGMGm+++nLDubuo2tPqbWJcePZ7Fy5ZcpLR3I+PHrmTFjGRERdX6qWkTaEVL9SUQunC+zF64H9NWYItKrhEpvcrjdjF66lDFLl+KJjGTT/fdzYPZsuMCJMjweJ598ci2ffHINcXHl3Hzz02Rn7/VT1SLSkVDpTyLiP12avVBERPwnbedOpj73HImFhRyePp2t99xDTXLyBY978uRA3nnnboqLMxk9ehMzZy4mOrrGDxWLiIhIdyh0iYj0sKjycia+9BJDP/iAyrQ01n7/+xwfP/6Cx/V6DVu2XMWGDfOIiqpm/vznGD58hx8qFhERkQuh0CUi0lOsZejatUz8619xVVez86ab2HXzzXgiIy946NOnU3nnnS9TWDiU4cO3MXv2q8TGVvmhaBEREblQCl0iIj0gMT+fqc8+S9rnn1M8ahSb7r+f8qysCx7XWti+/Qo++OBGnE4Pc+f+hVGjtmD0aRIREZFeQ6FLRCSAnHV1jFmyhIuWLaM+OppPFi7k4MyZFzxRBkBFRTKrVt3FkSOjyM7ezbXX/i/x8WV+qFpERET8SaFLRCRA0rdvZ+rzz5NQVMShGTP47O67qU1KuuBxrYXdu6eydu0tWOtg9uxXGDdug65uiYiI9FIKXSIifhZ1+jSTXnqJnA8/pHzgQNb84AcUjR3rl7HPnIln9erbOXBgPIMHH+C6614mKanEL2OLiIhIYCh0iYj4i9dL7po1THj5ZZy1tey45RZ2LViA1w8TZQDs3z+O1avvoK4uihkzljJp0vs4HNYvY4uIiEjgKHSJiPhB0pEjTH3uOQbs3cuJ0aPZdP/9VAwe7Jexa2piWLv2Fj7/fCppaUeZM2cR/fsX+WVsERERCbyAhC6v10tNTfe+iPPdd9/1czW+yczMDMpxTZh9COPgwYNBOa7DD5MWdEeyH77oVvzH6/VSVdW9adSffvrpNpdHe708WFzMrSUlVDqdPJqRwVKA55/vfqFNTJz4ryxbdhNVVXHMnPkeV1yxDqfTCyT4Zfz2PPzwwwEdvz1PPfVUUI7rdruDctyEhMD+d2xPTk5OUI4r7Qu31wN9jf77yIXSlS4RkW66sqKCfzt+nCy3m8XJyfxPWhqnXf5pq15vLEVF/8yuXXeSmnqCO+9cxKBBhX4ZW0RERHqWQpeISBelut08UlTEvPJyDkRGcm92Np/Gxflt/KqqyRQU/BS3ezCXX76eWbPew+Wq99v4IiIi0rMUukREfOSwljtOneI7J04QaS2/GTCA5/v3x+2n21e93khOnPgWpaX3EhFxjJyce7nmmqF+GVtERESCR6FLRMQHF9XU8B8FBYyvqWFDXBw/HjiQI1FRfhu/uvpi8vN/Rl1dLikpfyM9/X9wOM4ACl0iIiJ9nUKXiEgHImprufLdd/newYOUOZ38y+DBLE9MxF/fRGyti+Lib3Dy5EJcrpMMGfIA8fEf+WVsERER6R0UukRE2pG7axfXvvkmSadP82pyMr9MT6fM6fTb+DU1uRQU/IyamotJSlrKwIE/w+ms8Nv4IiIi0jsodImItJBQVsbVb77JqJ07KU5P56UHH+Rn69b5bXxrHZSU3Etx8bdwOCrIzPwWiYmr/Ta+iIiI9C4KXSIijYzXy+QNG5jxzjs4vF7enzOHT2bMwOtygZ9CV11dFvn5j1NdPYWEhFUMGvRjXK5Sv4wtIiIivZNCl4gIkH7sGHOWLGFQfj4HR45k5YIFlPXv77fxrYVTp+6kqOifMaaejIx/JSnpLX99NExERER6MYUuEQlrkbW1zFi5kskffcSZ+HiWfulLfD5+vN8mygBwu9MpKPgJVVVXEBf3IRkZPyQioshv44uIiEjvptAlImFrxM6dXLt0KfEVFWy97DLWzZlDbUyM38a3FsrKbuT48Uex1sXAgT8iJeUVXd0SEREJM52GLmPM88B84IS1dmzgSxIR8U13+1PC6dNcu3QpI3bv5sTAgbzxla9QMGSIX2urr+9HYeG/U1FxLTExmxk8+AdERh716zFEpHfSaycRacmXK10vAL8D/hzYUkREuuwFutKfrOWSDz7gylWrwFrWzJvHp1deideP08ADlJdfTWHhf+D1JpCW9gv69/8zxnj9egwR6dVeQK+dRKSJTkOXtXadMSYn8KWIiHRNV/tT/+JiZi9fzv6LLmLVF79Ieb9+fq3H40ng+PFHKSv7ItHRO8nI+CrR0Qf8egwR6f302klEWvLbZ7qMMQuBhQCDBg3y17AiIhekaW+aYAxL7r6bvWPH+nWiDIDKyukUFPyE+vpUUlN/z4ABz2BMvV+PISKho2lvio+PD3I1IhJoDn8NZK19xlo71Vo7NSUlxV/DiohckKa9qWTgQPaOG+fXwOX1xlJY+EOOHPkjTmclQ4d+ibS0pxS4RKRDTXtTjB8n8BGR3kmzF4pI2LAOv73PBMCZM5PJz38ctzuTfv3+RFrab3A46vx6DBEREen7FLpERLrI642kuPhhSkruIyIin+zs+4iL2xzsskRERKSX6vRtX2PMy8AGYJQx5pgx5v7AlyUi0rlg9Kfq6jEcOvQqJSVfIyXlFXJzb1HgEpFm9NpJRFryZfbCL/VEISIiXdWT/claFydPPkBx8TdwuUoZMmQh8fEf9tThRaQP0WsnEWlJtxeKiHSiqKg/hw4toqZmLElJyxg48Kc4neXBLktERET6CIUuEZF2eL2G9esvYeXKGVhbTmbmd0hMXBXsskRERKSPUegSEWlDSUkSr756A3l5WYwZs5f6+q/jcpUEuywRERHpgxS6RESasBY++WQCy5fPxhjL7be/xeTJO/nLXxS4REREpHsUukREGpWVxfP66/PYu3cYw4fncdttK0hOrgh2WSIiItLHKXSJSNizFj77bAxLl16Lx+NgwYKVTJu2FWOCXZmIiIiEAoUuEQlrlZUxLFkyh507R5GdfYzbb19OaurpYJclIiIiIUShS0TC1s6dI1i8eA41NVHMm7eGGTM24XDYYJclIiIiIUahS0TCTnV1FMuWXc2WLePIyDjOAw/8jYEDTwa7LBEREQlRAQldxcXFPP30093a97LLLvNzNb75+OOPg3LcqKiooBx3/vz5QTluampqUI77xhtvBOW4wfp7lrZVV1fz9tsePvnkHqqrk7n44sVcfPESioo8FBV1vG9JSXBmL0xISAjKcZcuXRqU4yYnJwfluL/+9a+DctyUlJSgHPfUqVNBOa6ISLjSlS4RCRtVVf1Zu/ZREhPzufba/6B//4PBLklERETCgEKXiISN2tpERo1azvjxr+ByuYNdjoiIiIQJhS4RCRsJCYVMnrwo2GWIiIhImHEEuwARkZ4SEVET7BJEREQkDCl0iYiIiIiIBJBCl4iIiIiISAApdImIiIiIiASQQpeIiIiIiEgAKXSJiIiIiIgEkEKXiIiIiIhIACl0iYiIiIiIBJBPocsYM9cYs8cYs98Y80igixIR8YV6k4j0VupPItJUp6HLGOMEfg/MA8YAXzLGjAl0YSIiHVFvEpHeSv1JRFry5UrXpcB+a+1Ba20d8DdgQWDLEhHplHqTiPRW6k8i0oyx1na8gTG3AXOttV9v/PM9wGXW2odabLcQWNj4x7HADv+X22ulAieDXUQPCadzhfA731HW2oRgF+EL9SafhNvvr843tIVUf1JvCqvfXZ1vaPOpN7n8dTRr7TPAMwDGmE+ttVP9NXZvF07nG07nCuF5vsGuwd/Um3S+oSoczzfYNfiTepPON1SF4/n6sp0vtxfmA1lN/pzZuExEJJjUm0Skt1J/EpFmfAldm4ARxpihxphI4C7gzcCWJSLSKfUmEemt1J9EpJlOby+01tYbYx4C3gGcwPPW2p2d7PaMP4rrQ8LpfMPpXEHn22upN/lE5xvadL69VDf6U585Nz/R+YY2nW8bOp1IQ0RERERERLrPpy9HFhERERERke5R6BIREREREQkgv4YuY8xcY8weY8x+Y8wj/hy7tzHGZBlj1hhjdhljdhpjvh3smnqCMcZpjNlqjHkr2LUEmjEm2RjzmjHmc2PMbmPM5cGuKZCMMd9t/F3eYYx52RgTHeya/CWcehOEZ39SbwpdodybILz6Uzj2JlB/CnZNgdSV/uS30GWMcQK/B+YBY4AvGWPG+Gv8Xqge+J61dgwwDfhmiJ/vWd8Gdge7iB7ya+Bta+1FwARC+LyNMYOBbwFTrbVjafjg913Brco/wrA3QXj2J/WmEBTKvQnCsj+FY28C9aeQ1NX+5M8rXZcC+621B621dcDfgAV+HL9XsdYWWmu3NP5cQcMv1eDgVhVYxphM4Abg2WDXEmjGmCTgC8BzANbaOmvt6eBWFXAuIMYY4wJigYIg1+MvYdWbIPz6k3qTelMfFlb9Kdx6E6g/qT+d58/QNRg42uTPxwjx/5HOMsbkAJOAjcGtJOB+BfwL4A12IT1gKFAM/KnxloBnjTFxwS4qUKy1+cB/A0eAQqDMWrsyuFX5Tdj2Jgib/qTeFKJCvDdBGPenMOlNoP6k/tRIE2lcIGNMPPA68B1rbXmw6wkUY8x84IS1dnOwa+khLmAy8LS1dhJQBYTsvfbGmBQa3l0dCmQAccaYrwS3KrlQ4dCf1JvUm6TvCYfeBOpPqD8148/QlQ9kNflzZuOykGWMiaChaSyy1i4Odj0BdgXwRWNMHg23P8w2xrwU3JIC6hhwzFp79h2412hoJKHqGuCQtbbYWusGFgPTg1yTv4Rdb4Kw6k/qTepNfVnY9acw6k2g/qT+1IQ/Q9cmYIQxZqgxJpKGD5K96cfxexVjjKHhntXd1tong11PoFlrv2+tzbTW5tDw3/Y9a23IvttorT0OHDXGjGpcdDWwK4glBdoRYJoxJrbxd/tqQufDr2HVmyC8+pN6k3pTHxdW/SmcehOoP6H+1IzLX0e11tYbYx4C3qFh9o7nrbU7/TV+L3QFcA/wd2PMZ43LHrXWrghiTeJfDwOLGv8hPAh8Ncj1BIy1dqMx5jVgCw2zS20FngluVf4Rhr0J1J9CnXpTiAjD/qTeFPrUn9phrLU9VZuIiIiIiEjY0UQaIiIiIiIiAaTQJSIiIiIiEkAKXSIiIiIiIgGk0CUiIiIiIhJACl0iIiIiIiIBpNAlIiIiIiISQApdIiIiIiIiAfT/AfAEoAmDiA4nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1080x1080 with 9 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the Results\n",
    "\n",
    "model.eval();\n",
    "\n",
    "ang_loss_all = []\n",
    "\n",
    "for batch_i, data in enumerate(test_loader):\n",
    "    # get the input images and their corresponding labels\n",
    "    inputs, output_gt, _, _ = data\n",
    "    inputs, output_gt = inputs.to(dev), output_gt.to(dev)\n",
    "    \n",
    "\n",
    "    # forward pass to get outputs\n",
    "    outputs = model(inputs).squeeze().detach().cpu()\n",
    "    \n",
    "    gt = output_gt.cpu().squeeze()\n",
    "    \n",
    "    c = -output_gt[:,2]*torch.cos(output_gt[:,0]) + output_gt[:,1]*torch.sin(output_gt[:,0])\n",
    "    angle_params = torch.stack((-torch.sin(output_gt[:,0]),torch.cos(output_gt[:,0]),c),axis=1).detach().cpu()\n",
    "  \n",
    "    # Calculate angular loss\n",
    "    ang_loss = torch.mean(torch.abs(torch.rad2deg(torch.atan2(-angle_params[:,0]*outputs[:,1] + angle_params[:,1]*outputs[:,0]\n",
    "                                         ,angle_params[:,1]*outputs[:,1]+angle_params[:,0]*outputs[:,0]).cpu())))\n",
    "\n",
    "    ang_loss_all.append(ang_loss)\n",
    "\n",
    "    \n",
    "print(ang_loss_all)\n",
    "\n",
    "plt.figure(figsize=[15, 15])\n",
    "\n",
    "for ii in range(9):\n",
    "    \n",
    "    plt.subplot(3,3,ii+1)\n",
    "    plt.imshow(inputs[ii].cpu().squeeze(),cmap='gray', vmin=0, vmax=1)\n",
    "    \n",
    "    # Plot the ground truth lines\n",
    "    x_sample = torch.linspace(-1,1,inputs.shape[-1])\n",
    "    y_sample = -angle_params[ii,0]/angle_params[ii,1]*x_sample - angle_params[ii,2]/angle_params[ii,1]\n",
    "    \n",
    "    plt.plot(x_sample*W/2+W/2,y_sample*W/2+W/2,'b')\n",
    "    plt.xlim([0,W])\n",
    "    plt.ylim(([0,W]))\n",
    "    \n",
    "    # Plot the estimated lines\n",
    "    y_est = -outputs[ii,0]/outputs[ii,1]*x_sample - outputs[ii,2]/outputs[ii,1]\n",
    "    plt.plot(x_sample*W/2+W/2,y_est*W/2+W/2,'r')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cde81a4",
   "metadata": {},
   "source": [
    "# 5x5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "597d6b30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1080 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load dataset \n",
    "\n",
    "data_folder = 'foj_data/grayscale_lines/'\n",
    "\n",
    "with open(data_folder + 'line_data_5_100000_grey_multicolor_noise_random_uncentered.pkl','rb') as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "# wedges = data['wedges']\n",
    "wedges_grey = data['wedges_grey']\n",
    "params = data['params']\n",
    "boundaries = data['boundaries']\n",
    "wedges = data['wedges']\n",
    "\n",
    "\n",
    "line_data = LineDataset(wedges_grey, params, boundaries, wedges)#, transform=trainTransform)\n",
    "data_size = len(line_data)\n",
    "\n",
    "print(data_size)\n",
    "\n",
    "train_proportion = .85\n",
    "# Split dataset into training and testing\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(line_data, [int(data_size*train_proportion), int(data_size*(1-train_proportion))], generator=torch.Generator().manual_seed(42))\n",
    "\n",
    "# Create loaders for the training and testing data\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=1000, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=500, shuffle=False) #len(test_dataset)\n",
    "\n",
    "\n",
    "W,H = 5,5\n",
    "\n",
    "img_show = 1\n",
    "plt.figure(figsize=[15, 15])\n",
    "plt.subplot(131)\n",
    "plt.imshow(wedges[img_show,:,:].squeeze().permute(1,2,0).cpu())\n",
    "plt.title('RGB Image')\n",
    "plt.axis('off');\n",
    "plt.subplot(132)\n",
    "plt.imshow(wedges_grey[img_show,:,:].squeeze().cpu(),cmap='gray', vmin=0, vmax=1)\n",
    "plt.title('Grayscale Image')\n",
    "plt.axis('off');\n",
    "plt.subplot(133)\n",
    "plt.imshow(boundaries[img_show,:,:].squeeze().cpu(),cmap='gray', vmin=0, vmax=1)\n",
    "plt.title('Boundaries')\n",
    "plt.axis('off');\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "49a00284",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1              [-1, 8, 4, 4]              40\n",
      "              ReLU-2              [-1, 8, 4, 4]               0\n",
      "            Conv2d-3              [-1, 8, 3, 3]             264\n",
      "              ReLU-4              [-1, 8, 3, 3]               0\n",
      "            Conv2d-5              [-1, 8, 2, 2]             264\n",
      "            Linear-6                    [-1, 3]              99\n",
      "================================================================\n",
      "Total params: 667\n",
      "Trainable params: 667\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.00\n",
      "Params size (MB): 0.00\n",
      "Estimated Total Size (MB): 0.01\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "class offCenterLineNet(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "                \n",
    "        self.conv1 = nn.Conv2d(1, 8, kernel_size=2) #64 is good\n",
    "        self.conv2 = nn.Conv2d(8, 8, kernel_size=2)\n",
    "        self.conv3 = nn.Conv2d(8, 8, kernel_size=2)\n",
    "        self.fc = nn.LazyLinear(3)\n",
    "        self.maxpool = nn.MaxPool2d(2)\n",
    "#         self.avgpool = nn.AvgPool2d(2)\n",
    "        self.activate = nn.ReLU()\n",
    "#         self.batchnorm = nn.BatchNorm2d(128)\n",
    "    \n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.conv1(x)\n",
    "#         x = F.relu(x)\n",
    "        x = self.activate(x)\n",
    "#         x = self.maxpool(x)\n",
    "#         x = self.batchnorm(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.activate(x)\n",
    "#         x = F.relu(x)\n",
    "#         x = self.batchnorm(x)\n",
    "        x = self.conv3(x)\n",
    "#         x = self.maxpool(x)\n",
    "#         x = self.avgpool(x)\n",
    "        x = x.view(x.shape[0],-1)\n",
    "        \n",
    "        x = self.fc(x)\n",
    "         \n",
    "        # We're defining\n",
    "        # a = - sin(theta)\n",
    "        # b = cos(theta)\n",
    "        # c = -cy*cos(theta)+cx*sin(theta)\n",
    "        # Hence, we want to normalize the vector by 1/sqrt(a^2 + b^2)\n",
    "        norm_factor = (torch.norm(x[:,:2],p=2,dim=1)).unsqueeze(1)       \n",
    "        out = x/(norm_factor)#+eps)\n",
    "#         print('Output shape=',x.shape)\n",
    "\n",
    "#         out = x\n",
    "        \n",
    "        return out\n",
    "    \n",
    "model = offCenterLineNet()\n",
    "model = model.to(dev)\n",
    "summary(model, input_size=(1, H, W))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7b402a37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Avg. Train Loss: 0.45436347056837645, Avg. Test Loss: 0.4076485335826874\n",
      "Epoch: 2, Avg. Train Loss: 0.3535603561822106, Avg. Test Loss: 0.3371735215187073\n",
      "Epoch: 3, Avg. Train Loss: 0.2630556955057032, Avg. Test Loss: 0.19916090369224548\n",
      "Epoch: 4, Avg. Train Loss: 0.12294933471609565, Avg. Test Loss: 0.09420251846313477\n",
      "Epoch: 5, Avg. Train Loss: 0.5615666286033743, Avg. Test Loss: 0.5973995327949524\n",
      "Epoch: 6, Avg. Train Loss: 0.4758999035638921, Avg. Test Loss: 0.2890114486217499\n",
      "Epoch: 7, Avg. Train Loss: 0.15846227784367167, Avg. Test Loss: 0.0925314724445343\n",
      "Epoch: 8, Avg. Train Loss: 0.07170126319808119, Avg. Test Loss: 0.06511638313531876\n",
      "Epoch: 9, Avg. Train Loss: 0.060380270156790226, Avg. Test Loss: 0.052725885063409805\n",
      "Epoch: 10, Avg. Train Loss: 0.05414823736338054, Avg. Test Loss: 0.049271684139966965\n",
      "Epoch: 11, Avg. Train Loss: 0.07586004173054414, Avg. Test Loss: 0.06790969520807266\n",
      "Epoch: 12, Avg. Train Loss: 0.06967009866938871, Avg. Test Loss: 0.06784581393003464\n",
      "Epoch: 13, Avg. Train Loss: 0.06687231769456584, Avg. Test Loss: 0.06322360038757324\n",
      "Epoch: 14, Avg. Train Loss: 0.06096375014852075, Avg. Test Loss: 0.3775343894958496\n",
      "Epoch: 15, Avg. Train Loss: 0.05968251053024741, Avg. Test Loss: 0.053442537784576416\n",
      "Epoch: 16, Avg. Train Loss: 0.05429244663785485, Avg. Test Loss: 0.05213964730501175\n",
      "Epoch: 17, Avg. Train Loss: 0.05369810667984626, Avg. Test Loss: 0.051844459027051926\n",
      "Epoch: 18, Avg. Train Loss: 0.05326755997889182, Avg. Test Loss: 0.05136647820472717\n",
      "Epoch: 19, Avg. Train Loss: 0.05247406074229409, Avg. Test Loss: 0.05056670680642128\n",
      "Epoch: 20, Avg. Train Loss: 0.051645573447732365, Avg. Test Loss: 0.04980182275176048\n",
      "Epoch: 21, Avg. Train Loss: 0.05086293606197133, Avg. Test Loss: 0.049063220620155334\n",
      "Epoch: 22, Avg. Train Loss: 0.050082738785182726, Avg. Test Loss: 0.048394590616226196\n",
      "Epoch: 23, Avg. Train Loss: 0.04933268966920236, Avg. Test Loss: 0.047766003757715225\n",
      "Epoch: 24, Avg. Train Loss: 0.04860599571291138, Avg. Test Loss: 0.04711795970797539\n",
      "Epoch: 25, Avg. Train Loss: 0.04791518147377407, Avg. Test Loss: 0.046487100422382355\n",
      "Epoch: 26, Avg. Train Loss: 0.047274541372762005, Avg. Test Loss: 0.0460461787879467\n",
      "Epoch: 27, Avg. Train Loss: 0.046784276033149046, Avg. Test Loss: 0.04554423689842224\n",
      "Epoch: 28, Avg. Train Loss: 0.046514476704246854, Avg. Test Loss: 0.045097269117832184\n",
      "Epoch: 29, Avg. Train Loss: 0.0459187446271672, Avg. Test Loss: 0.0487871989607811\n",
      "Epoch: 30, Avg. Train Loss: 0.04517627191894195, Avg. Test Loss: 0.04376930743455887\n",
      "Epoch: 31, Avg. Train Loss: 0.045203046632163665, Avg. Test Loss: 0.04484241455793381\n",
      "Epoch: 32, Avg. Train Loss: 0.04521926247021731, Avg. Test Loss: 0.043197836726903915\n",
      "Epoch: 33, Avg. Train Loss: 0.04402169177637381, Avg. Test Loss: 0.04235236719250679\n",
      "Epoch: 34, Avg. Train Loss: 0.043650330164853264, Avg. Test Loss: 0.04295250400900841\n",
      "Epoch: 35, Avg. Train Loss: 0.043709634814192266, Avg. Test Loss: 0.04201235994696617\n",
      "Epoch: 36, Avg. Train Loss: 0.0429254639236366, Avg. Test Loss: 0.04123548045754433\n",
      "Epoch: 37, Avg. Train Loss: 0.04208446670981014, Avg. Test Loss: 0.040548402816057205\n",
      "Epoch: 38, Avg. Train Loss: 0.0414398114909144, Avg. Test Loss: 0.03997639939188957\n",
      "Epoch: 39, Avg. Train Loss: 0.04088420083417612, Avg. Test Loss: 0.03954488784074783\n",
      "Epoch: 40, Avg. Train Loss: 0.04050508031950278, Avg. Test Loss: 0.03911604732275009\n",
      "Epoch: 41, Avg. Train Loss: 0.040039625763893125, Avg. Test Loss: 0.038642317056655884\n",
      "Epoch: 42, Avg. Train Loss: 0.03963435095022706, Avg. Test Loss: 0.03823701664805412\n",
      "Epoch: 43, Avg. Train Loss: 0.03919350767836851, Avg. Test Loss: 0.03784529119729996\n",
      "Epoch: 44, Avg. Train Loss: 0.03878520249443896, Avg. Test Loss: 0.037511203438043594\n",
      "Epoch: 45, Avg. Train Loss: 0.03842296915895799, Avg. Test Loss: 0.0371558777987957\n",
      "Epoch: 46, Avg. Train Loss: 0.03806148526423118, Avg. Test Loss: 0.03679049760103226\n",
      "Epoch: 47, Avg. Train Loss: 0.03774119085248779, Avg. Test Loss: 0.036479827016592026\n",
      "Epoch: 48, Avg. Train Loss: 0.03758871314280173, Avg. Test Loss: 0.03627980127930641\n",
      "Epoch: 49, Avg. Train Loss: 0.03713925204732839, Avg. Test Loss: 0.0360223725438118\n",
      "Epoch: 50, Avg. Train Loss: 0.036778458339326525, Avg. Test Loss: 0.03563252463936806\n",
      "Epoch: 51, Avg. Train Loss: 0.03641266445903217, Avg. Test Loss: 0.03527505323290825\n",
      "Epoch: 52, Avg. Train Loss: 0.036071353098925424, Avg. Test Loss: 0.03496870771050453\n",
      "Epoch: 53, Avg. Train Loss: 0.035785561997224304, Avg. Test Loss: 0.03470189496874809\n",
      "Epoch: 54, Avg. Train Loss: 0.03551302083274897, Avg. Test Loss: 0.03441091626882553\n",
      "Epoch: 55, Avg. Train Loss: 0.035252421261633145, Avg. Test Loss: 0.034172169864177704\n",
      "Epoch: 56, Avg. Train Loss: 0.0349582328735029, Avg. Test Loss: 0.03384766727685928\n",
      "Epoch: 57, Avg. Train Loss: 0.034713814078884964, Avg. Test Loss: 0.03363589942455292\n",
      "Epoch: 58, Avg. Train Loss: 0.034493472339475854, Avg. Test Loss: 0.03348657488822937\n",
      "Epoch: 59, Avg. Train Loss: 0.034282946477041526, Avg. Test Loss: 0.03330643102526665\n",
      "Epoch: 60, Avg. Train Loss: 0.03407750609604751, Avg. Test Loss: 0.03322188928723335\n",
      "Epoch: 61, Avg. Train Loss: 0.03385357672677321, Avg. Test Loss: 0.033164020627737045\n",
      "Epoch: 62, Avg. Train Loss: 0.03366011573987849, Avg. Test Loss: 0.03283834457397461\n",
      "Epoch: 63, Avg. Train Loss: 0.033469744727892034, Avg. Test Loss: 0.03316007927060127\n",
      "Epoch: 64, Avg. Train Loss: 0.03329144190339481, Avg. Test Loss: 0.033282287418842316\n",
      "Epoch: 65, Avg. Train Loss: 0.03308949016911142, Avg. Test Loss: 0.032997336238622665\n",
      "Epoch: 66, Avg. Train Loss: 0.03288884458734709, Avg. Test Loss: 0.03390411287546158\n",
      "Epoch: 67, Avg. Train Loss: 0.03274192915243261, Avg. Test Loss: 0.03448210656642914\n",
      "Epoch: 68, Avg. Train Loss: 0.03261426485636655, Avg. Test Loss: 0.1302945911884308\n",
      "Epoch: 69, Avg. Train Loss: 0.03239793869502404, Avg. Test Loss: 0.03263073414564133\n",
      "Epoch: 70, Avg. Train Loss: 0.03224826748756801, Avg. Test Loss: 0.03644024580717087\n",
      "Epoch: 71, Avg. Train Loss: 0.032097905173021204, Avg. Test Loss: 0.032140523195266724\n",
      "Epoch: 72, Avg. Train Loss: 0.031889812955084966, Avg. Test Loss: 0.031478457152843475\n",
      "Epoch: 73, Avg. Train Loss: 0.03172259429360137, Avg. Test Loss: 0.030931422486901283\n",
      "Epoch: 74, Avg. Train Loss: 0.031561477460405406, Avg. Test Loss: 0.03071339800953865\n",
      "Epoch: 75, Avg. Train Loss: 0.03141813631005147, Avg. Test Loss: 0.03069331869482994\n",
      "Epoch: 76, Avg. Train Loss: 0.0312575409298434, Avg. Test Loss: 0.03018764592707157\n",
      "Epoch: 77, Avg. Train Loss: 0.03112089189098162, Avg. Test Loss: 0.030106626451015472\n",
      "Epoch: 78, Avg. Train Loss: 0.03100827868808718, Avg. Test Loss: 0.029882030561566353\n",
      "Epoch: 79, Avg. Train Loss: 0.03085589739767944, Avg. Test Loss: 0.02975449711084366\n",
      "Epoch: 80, Avg. Train Loss: 0.03072620954583673, Avg. Test Loss: 0.029598359018564224\n",
      "Epoch: 81, Avg. Train Loss: 0.030629287068458164, Avg. Test Loss: 0.02939782105386257\n",
      "Epoch: 82, Avg. Train Loss: 0.030484967306256293, Avg. Test Loss: 0.029291538521647453\n",
      "Epoch: 83, Avg. Train Loss: 0.03035879051860641, Avg. Test Loss: 0.02915276773273945\n",
      "Epoch: 84, Avg. Train Loss: 0.030214040266240343, Avg. Test Loss: 0.02908429503440857\n",
      "Epoch: 85, Avg. Train Loss: 0.03014320244683939, Avg. Test Loss: 0.028792936354875565\n",
      "Epoch: 86, Avg. Train Loss: 0.029992692084873422, Avg. Test Loss: 0.028704799711704254\n",
      "Epoch: 87, Avg. Train Loss: 0.02987779087441809, Avg. Test Loss: 0.02852499671280384\n",
      "Epoch: 88, Avg. Train Loss: 0.029804594003978897, Avg. Test Loss: 0.028495797887444496\n",
      "Epoch: 89, Avg. Train Loss: 0.029630860598648296, Avg. Test Loss: 0.028306666761636734\n",
      "Epoch: 90, Avg. Train Loss: 0.02971050581511329, Avg. Test Loss: 0.0285035353153944\n",
      "Epoch: 91, Avg. Train Loss: 0.029534628132686896, Avg. Test Loss: 0.028691573068499565\n",
      "Epoch: 92, Avg. Train Loss: 0.02934483824407353, Avg. Test Loss: 0.02806597761809826\n",
      "Epoch: 93, Avg. Train Loss: 0.02924642442342113, Avg. Test Loss: 0.029307467862963676\n",
      "Epoch: 94, Avg. Train Loss: 0.07685585920425023, Avg. Test Loss: 0.15334771573543549\n",
      "Epoch: 95, Avg. Train Loss: 0.1050642432535396, Avg. Test Loss: 0.07290805131196976\n",
      "Epoch: 96, Avg. Train Loss: 0.054704515241524754, Avg. Test Loss: 0.039290476590394974\n",
      "Epoch: 97, Avg. Train Loss: 0.048199693595661834, Avg. Test Loss: 0.15412910282611847\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 98, Avg. Train Loss: 0.052631315457470275, Avg. Test Loss: 0.04123595729470253\n",
      "Epoch: 99, Avg. Train Loss: 0.042582061229383246, Avg. Test Loss: 0.03864563629031181\n",
      "Epoch: 100, Avg. Train Loss: 0.04065762775785783, Avg. Test Loss: 0.034930575639009476\n",
      "Epoch: 101, Avg. Train Loss: 0.0358407689806293, Avg. Test Loss: 0.033036381006240845\n",
      "Epoch: 102, Avg. Train Loss: 0.03444768012884785, Avg. Test Loss: 0.03238586708903313\n",
      "Epoch: 103, Avg. Train Loss: 0.03399077756878208, Avg. Test Loss: 0.0315127857029438\n",
      "Epoch: 104, Avg. Train Loss: 0.03490361448596505, Avg. Test Loss: 0.03382709622383118\n",
      "Epoch: 105, Avg. Train Loss: 0.034590672635856794, Avg. Test Loss: 0.03269147872924805\n",
      "Epoch: 106, Avg. Train Loss: 0.033783271207528956, Avg. Test Loss: 0.03212857246398926\n",
      "Epoch: 107, Avg. Train Loss: 0.033190773120697806, Avg. Test Loss: 0.03183003142476082\n",
      "Epoch: 108, Avg. Train Loss: 0.03322260325007579, Avg. Test Loss: 0.03295598924160004\n",
      "Epoch: 109, Avg. Train Loss: 0.03348575262900661, Avg. Test Loss: 0.031630732119083405\n",
      "Epoch: 110, Avg. Train Loss: 0.03246983909869895, Avg. Test Loss: 0.030925840139389038\n",
      "Epoch: 111, Avg. Train Loss: 0.03224813609438784, Avg. Test Loss: 0.030761975795030594\n",
      "Epoch: 112, Avg. Train Loss: 0.031971059432801076, Avg. Test Loss: 0.03033662773668766\n",
      "Epoch: 113, Avg. Train Loss: 0.0316564122105346, Avg. Test Loss: 0.029809005558490753\n",
      "Epoch: 114, Avg. Train Loss: 0.031444739988621545, Avg. Test Loss: 0.029538454487919807\n",
      "Epoch: 115, Avg. Train Loss: 0.030502873681047385, Avg. Test Loss: 0.02886684238910675\n",
      "Epoch: 116, Avg. Train Loss: 0.030138851680299814, Avg. Test Loss: 0.028743155300617218\n",
      "Epoch: 117, Avg. Train Loss: 0.03009839371285018, Avg. Test Loss: 0.02870732545852661\n",
      "Epoch: 118, Avg. Train Loss: 0.03006127283853643, Avg. Test Loss: 0.02868674322962761\n",
      "Epoch: 119, Avg. Train Loss: 0.03003105768824325, Avg. Test Loss: 0.0286257304251194\n",
      "Epoch: 120, Avg. Train Loss: 0.02993937901714269, Avg. Test Loss: 0.02857610024511814\n",
      "Epoch: 121, Avg. Train Loss: 0.029920695042785477, Avg. Test Loss: 0.028546171262860298\n",
      "Epoch: 122, Avg. Train Loss: 0.029886332680197324, Avg. Test Loss: 0.02859322912991047\n",
      "Epoch: 123, Avg. Train Loss: 0.029923090010004885, Avg. Test Loss: 0.028568770736455917\n",
      "Epoch: 124, Avg. Train Loss: 0.02984541961375405, Avg. Test Loss: 0.028475305065512657\n",
      "Epoch: 125, Avg. Train Loss: 0.02978917125831632, Avg. Test Loss: 0.028522975742816925\n",
      "Epoch: 126, Avg. Train Loss: 0.029767018140238875, Avg. Test Loss: 0.02841997519135475\n",
      "Epoch: 127, Avg. Train Loss: 0.0297815661658259, Avg. Test Loss: 0.028639351949095726\n",
      "Epoch: 128, Avg. Train Loss: 0.029802882539875366, Avg. Test Loss: 0.028418442234396935\n",
      "Epoch: 129, Avg. Train Loss: 0.029688630537951694, Avg. Test Loss: 0.028350187465548515\n",
      "Epoch: 130, Avg. Train Loss: 0.029631051530732828, Avg. Test Loss: 0.028319574892520905\n",
      "Epoch: 131, Avg. Train Loss: 0.029655287283308365, Avg. Test Loss: 0.028266293928027153\n",
      "Epoch: 132, Avg. Train Loss: 0.029639539538937457, Avg. Test Loss: 0.028227634727954865\n",
      "Epoch: 133, Avg. Train Loss: 0.029558486009345335, Avg. Test Loss: 0.02825019508600235\n",
      "Epoch: 134, Avg. Train Loss: 0.02963841796359595, Avg. Test Loss: 0.02816055901348591\n",
      "Epoch: 135, Avg. Train Loss: 0.029508854470708792, Avg. Test Loss: 0.028336185961961746\n",
      "Epoch: 136, Avg. Train Loss: 0.029485884067766806, Avg. Test Loss: 0.02825864590704441\n",
      "Epoch: 137, Avg. Train Loss: 0.02946324153419803, Avg. Test Loss: 0.028095752000808716\n",
      "Epoch: 138, Avg. Train Loss: 0.029405414291164455, Avg. Test Loss: 0.02811785228550434\n",
      "Epoch: 139, Avg. Train Loss: 0.02937852041248013, Avg. Test Loss: 0.028087835758924484\n",
      "Epoch: 140, Avg. Train Loss: 0.029363811695400407, Avg. Test Loss: 0.028002958744764328\n",
      "Epoch: 141, Avg. Train Loss: 0.02931838390581748, Avg. Test Loss: 0.028035329654812813\n",
      "Epoch: 142, Avg. Train Loss: 0.02935969941318035, Avg. Test Loss: 0.027971547096967697\n",
      "Epoch: 143, Avg. Train Loss: 0.029297806169180308, Avg. Test Loss: 0.028178442269563675\n",
      "Epoch: 144, Avg. Train Loss: 0.029323437371674706, Avg. Test Loss: 0.028094040229916573\n",
      "Epoch: 145, Avg. Train Loss: 0.029215584037935033, Avg. Test Loss: 0.027913400903344154\n",
      "Epoch: 146, Avg. Train Loss: 0.029421232969445342, Avg. Test Loss: 0.02787191979587078\n",
      "Epoch: 147, Avg. Train Loss: 0.029202015895177336, Avg. Test Loss: 0.02799343131482601\n",
      "Epoch: 148, Avg. Train Loss: 0.029132386669516563, Avg. Test Loss: 0.027882762253284454\n",
      "Epoch: 149, Avg. Train Loss: 0.029082531810683362, Avg. Test Loss: 0.0278481375426054\n",
      "Epoch: 150, Avg. Train Loss: 0.029033791317659267, Avg. Test Loss: 0.027880949899554253\n",
      "Epoch: 151, Avg. Train Loss: 0.029037983014303097, Avg. Test Loss: 0.027964599430561066\n",
      "Epoch: 152, Avg. Train Loss: 0.02900140815797974, Avg. Test Loss: 0.027786819264292717\n",
      "Epoch: 153, Avg. Train Loss: 0.02900000335100819, Avg. Test Loss: 0.028002364560961723\n",
      "Epoch: 154, Avg. Train Loss: 0.028938049209468505, Avg. Test Loss: 0.027660544961690903\n",
      "Epoch: 155, Avg. Train Loss: 0.029090497423620784, Avg. Test Loss: 0.027617689222097397\n",
      "Epoch: 156, Avg. Train Loss: 0.02981665351373308, Avg. Test Loss: 0.035384923219680786\n",
      "Epoch: 157, Avg. Train Loss: 0.04303777857738383, Avg. Test Loss: 0.06852338463068008\n",
      "Epoch: 158, Avg. Train Loss: 0.05899412811678999, Avg. Test Loss: 0.05612649768590927\n",
      "Epoch: 159, Avg. Train Loss: 0.043270027111558355, Avg. Test Loss: 0.036225151270627975\n",
      "Epoch: 160, Avg. Train Loss: 0.03372515078414889, Avg. Test Loss: 0.031965792179107666\n",
      "Epoch: 161, Avg. Train Loss: 0.03098270051619586, Avg. Test Loss: 0.034149691462516785\n",
      "Epoch: 162, Avg. Train Loss: 0.04499815575340215, Avg. Test Loss: 0.0499938428401947\n",
      "Epoch: 163, Avg. Train Loss: 0.042029848957762996, Avg. Test Loss: 0.040155939757823944\n",
      "Epoch: 164, Avg. Train Loss: 0.03685695450095569, Avg. Test Loss: 0.03522229194641113\n",
      "Epoch: 165, Avg. Train Loss: 0.048735241241314835, Avg. Test Loss: 0.061534106731414795\n",
      "Epoch: 166, Avg. Train Loss: 0.057390933834454594, Avg. Test Loss: 0.06042936444282532\n",
      "Epoch: 167, Avg. Train Loss: 0.04649932559798745, Avg. Test Loss: 0.045977432280778885\n",
      "Epoch: 168, Avg. Train Loss: 0.04963354060755056, Avg. Test Loss: 0.05248226597905159\n",
      "Epoch: 169, Avg. Train Loss: 0.048545116931200026, Avg. Test Loss: 0.04603031650185585\n",
      "Epoch: 170, Avg. Train Loss: 0.04305640717639642, Avg. Test Loss: 0.041106656193733215\n",
      "Epoch: 171, Avg. Train Loss: 0.31468451404396225, Avg. Test Loss: 0.12023577094078064\n",
      "Epoch: 172, Avg. Train Loss: 0.12532301650327796, Avg. Test Loss: 0.09238343685865402\n",
      "Epoch: 173, Avg. Train Loss: 0.09324195139548358, Avg. Test Loss: 0.08374328166246414\n",
      "Epoch: 174, Avg. Train Loss: 0.0844617425080608, Avg. Test Loss: 0.07935521751642227\n",
      "Epoch: 175, Avg. Train Loss: 0.08032247029683169, Avg. Test Loss: 0.07712183892726898\n",
      "Epoch: 176, Avg. Train Loss: 0.07796026555930867, Avg. Test Loss: 0.07594773173332214\n",
      "Epoch: 177, Avg. Train Loss: 0.07662125549772207, Avg. Test Loss: 0.07529671490192413\n",
      "Epoch: 178, Avg. Train Loss: 0.07585902047507903, Avg. Test Loss: 0.07484982162714005\n",
      "Epoch: 179, Avg. Train Loss: 0.07555096390492776, Avg. Test Loss: 0.0748143419623375\n",
      "Epoch: 180, Avg. Train Loss: 0.07519325964591082, Avg. Test Loss: 0.07458022981882095\n",
      "Epoch: 181, Avg. Train Loss: 0.0749990240615957, Avg. Test Loss: 0.07451414316892624\n",
      "Epoch: 182, Avg. Train Loss: 0.07480803561561247, Avg. Test Loss: 0.07430659234523773\n",
      "Epoch: 183, Avg. Train Loss: 0.07527646431151558, Avg. Test Loss: 0.0751095712184906\n",
      "Epoch: 184, Avg. Train Loss: 0.07774623702554141, Avg. Test Loss: 0.0770946815609932\n",
      "Epoch: 185, Avg. Train Loss: 0.07725187671535155, Avg. Test Loss: 0.07690224796533585\n",
      "Epoch: 186, Avg. Train Loss: 0.0757653551943162, Avg. Test Loss: 0.07662641257047653\n",
      "Epoch: 187, Avg. Train Loss: 0.07535690314629499, Avg. Test Loss: 0.07630275189876556\n",
      "Epoch: 188, Avg. Train Loss: 0.07500720208182055, Avg. Test Loss: 0.07594554871320724\n",
      "Epoch: 189, Avg. Train Loss: 0.07470703650923337, Avg. Test Loss: 0.075546033680439\n",
      "Epoch: 190, Avg. Train Loss: 0.07446811378878705, Avg. Test Loss: 0.07513049244880676\n",
      "Epoch: 191, Avg. Train Loss: 0.07426155174479765, Avg. Test Loss: 0.07464582473039627\n",
      "Epoch: 192, Avg. Train Loss: 0.08106145337224006, Avg. Test Loss: 0.08868902921676636\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 193, Avg. Train Loss: 0.09058993143193862, Avg. Test Loss: 0.08812899887561798\n",
      "Epoch: 194, Avg. Train Loss: 0.08908701696816612, Avg. Test Loss: 0.08720187842845917\n",
      "Epoch: 195, Avg. Train Loss: 0.08836050235173282, Avg. Test Loss: 0.08686558902263641\n",
      "Epoch: 196, Avg. Train Loss: 0.0880903126562343, Avg. Test Loss: 0.08663744479417801\n",
      "Epoch: 197, Avg. Train Loss: 0.08785776259268031, Avg. Test Loss: 0.08637429028749466\n",
      "Epoch: 198, Avg. Train Loss: 0.08779830643359353, Avg. Test Loss: 0.085447758436203\n",
      "Epoch: 199, Avg. Train Loss: 0.08852119498393114, Avg. Test Loss: 0.08804689347743988\n",
      "Epoch: 200, Avg. Train Loss: 0.09495621682966457, Avg. Test Loss: 0.08940296620130539\n",
      "Epoch: 201, Avg. Train Loss: 0.08864602525444591, Avg. Test Loss: 0.08409394323825836\n",
      "Epoch: 202, Avg. Train Loss: 0.08584873807780882, Avg. Test Loss: 0.08444254845380783\n",
      "Epoch: 203, Avg. Train Loss: 0.08542831242084503, Avg. Test Loss: 0.08414004743099213\n",
      "Epoch: 204, Avg. Train Loss: 0.08521047173177494, Avg. Test Loss: 0.08378483355045319\n",
      "Epoch: 205, Avg. Train Loss: 0.0852751101641094, Avg. Test Loss: 0.08427685499191284\n",
      "Epoch: 206, Avg. Train Loss: 0.08500270300051745, Avg. Test Loss: 0.08382304012775421\n",
      "Epoch: 207, Avg. Train Loss: 0.08592023314798579, Avg. Test Loss: 0.08598455786705017\n",
      "Epoch: 208, Avg. Train Loss: 0.08874647371909197, Avg. Test Loss: 0.0878305584192276\n",
      "Epoch: 209, Avg. Train Loss: 0.0883380552425104, Avg. Test Loss: 0.08694768697023392\n",
      "Epoch: 210, Avg. Train Loss: 0.08762977517703001, Avg. Test Loss: 0.08599407970905304\n",
      "Epoch: 211, Avg. Train Loss: 0.08612276929266313, Avg. Test Loss: 0.08478362113237381\n",
      "Epoch: 212, Avg. Train Loss: 0.08534812085768756, Avg. Test Loss: 0.08407831192016602\n",
      "Epoch: 213, Avg. Train Loss: 0.08482905161731383, Avg. Test Loss: 0.08382680267095566\n",
      "Epoch: 214, Avg. Train Loss: 0.0845795882098815, Avg. Test Loss: 0.08369076997041702\n",
      "Epoch: 215, Avg. Train Loss: 0.08441406584837857, Avg. Test Loss: 0.08324117958545685\n",
      "Epoch: 216, Avg. Train Loss: 0.08455595602007474, Avg. Test Loss: 0.08387652039527893\n",
      "Epoch: 217, Avg. Train Loss: 0.08495276947231854, Avg. Test Loss: 0.08350756764411926\n",
      "Epoch: 218, Avg. Train Loss: 0.08408281838192659, Avg. Test Loss: 0.08273741602897644\n",
      "Epoch: 219, Avg. Train Loss: 0.08369743736351237, Avg. Test Loss: 0.08216013014316559\n",
      "Epoch: 220, Avg. Train Loss: 0.0835148366058574, Avg. Test Loss: 0.08221045136451721\n",
      "Epoch: 221, Avg. Train Loss: 0.08432531646069358, Avg. Test Loss: 0.08144364506006241\n",
      "Epoch: 222, Avg. Train Loss: 0.08244759282645057, Avg. Test Loss: 0.0800456702709198\n",
      "Epoch: 223, Avg. Train Loss: 0.0882086817832554, Avg. Test Loss: 0.09365642070770264\n",
      "Epoch: 224, Avg. Train Loss: 0.0937447751269621, Avg. Test Loss: 0.08554797619581223\n",
      "Epoch: 225, Avg. Train Loss: 0.08464045042500776, Avg. Test Loss: 0.08318159729242325\n",
      "Epoch: 226, Avg. Train Loss: 0.08252586538300795, Avg. Test Loss: 0.08300992101430893\n",
      "Epoch: 227, Avg. Train Loss: 0.08159085547222811, Avg. Test Loss: 0.08083504438400269\n",
      "Epoch: 228, Avg. Train Loss: 0.08096998807261972, Avg. Test Loss: 0.08033819496631622\n",
      "Epoch: 229, Avg. Train Loss: 0.08971633157309364, Avg. Test Loss: 0.11761640757322311\n",
      "Epoch: 230, Avg. Train Loss: 0.12400375017348458, Avg. Test Loss: 0.1304088830947876\n",
      "Epoch: 231, Avg. Train Loss: 0.16462620935019326, Avg. Test Loss: 0.1710793375968933\n",
      "Epoch: 232, Avg. Train Loss: 0.171402508020401, Avg. Test Loss: 0.17478714883327484\n",
      "Epoch: 233, Avg. Train Loss: 0.168794287127607, Avg. Test Loss: 0.1671087145805359\n",
      "Epoch: 234, Avg. Train Loss: 0.16599092483520508, Avg. Test Loss: 0.16353468596935272\n",
      "Epoch: 235, Avg. Train Loss: 0.18958087949191824, Avg. Test Loss: 0.2158510386943817\n",
      "Epoch: 236, Avg. Train Loss: 0.2319015374955009, Avg. Test Loss: 0.2341109961271286\n",
      "Epoch: 237, Avg. Train Loss: 0.23466261467512917, Avg. Test Loss: 0.22943922877311707\n",
      "Epoch: 238, Avg. Train Loss: 0.2933913989978678, Avg. Test Loss: 0.3362182080745697\n",
      "Epoch: 239, Avg. Train Loss: 0.3443929356687209, Avg. Test Loss: 0.33660152554512024\n",
      "Epoch: 240, Avg. Train Loss: 0.33791795583332285, Avg. Test Loss: 0.33274564146995544\n",
      "Epoch: 241, Avg. Train Loss: 0.334589187187307, Avg. Test Loss: 0.3302350342273712\n",
      "Epoch: 242, Avg. Train Loss: 0.33178528266794544, Avg. Test Loss: 0.3283660411834717\n",
      "Epoch: 243, Avg. Train Loss: 0.32961248124347015, Avg. Test Loss: 0.33030930161476135\n",
      "Epoch: 244, Avg. Train Loss: 0.33290045752244835, Avg. Test Loss: 0.3254016637802124\n",
      "Epoch: 245, Avg. Train Loss: 0.2945868027560851, Avg. Test Loss: 0.27032357454299927\n",
      "Epoch: 246, Avg. Train Loss: 0.26886570330928355, Avg. Test Loss: 0.2657008767127991\n",
      "Epoch: 247, Avg. Train Loss: 0.2651874179349226, Avg. Test Loss: 0.2640324831008911\n",
      "Epoch: 248, Avg. Train Loss: 0.26265468527289, Avg. Test Loss: 0.2643500566482544\n",
      "Epoch: 249, Avg. Train Loss: 0.26127099745413834, Avg. Test Loss: 0.2579782009124756\n",
      "Epoch: 250, Avg. Train Loss: 0.25746451826656563, Avg. Test Loss: 0.2508432865142822\n",
      "Epoch: 251, Avg. Train Loss: 0.25611853319055894, Avg. Test Loss: 0.24605855345726013\n",
      "Epoch: 252, Avg. Train Loss: 0.24584419692263884, Avg. Test Loss: 0.2421823889017105\n",
      "Epoch: 253, Avg. Train Loss: 0.24234903174288133, Avg. Test Loss: 0.24082811176776886\n",
      "Epoch: 254, Avg. Train Loss: 0.24618085447479696, Avg. Test Loss: 0.25825682282447815\n",
      "Epoch: 255, Avg. Train Loss: 0.2589638096444747, Avg. Test Loss: 0.26242464780807495\n",
      "Epoch: 256, Avg. Train Loss: 0.25701844709761, Avg. Test Loss: 0.2562441825866699\n",
      "Epoch: 257, Avg. Train Loss: 0.3279059171676636, Avg. Test Loss: 0.3977254331111908\n",
      "Epoch: 258, Avg. Train Loss: 0.3977425143999212, Avg. Test Loss: 0.3914121091365814\n",
      "Epoch: 259, Avg. Train Loss: 0.39310377029811633, Avg. Test Loss: 0.3882766366004944\n",
      "Epoch: 260, Avg. Train Loss: 0.3891326252151938, Avg. Test Loss: 0.3853166401386261\n",
      "Epoch: 261, Avg. Train Loss: 0.3864398619707893, Avg. Test Loss: 0.38332584500312805\n",
      "Epoch: 262, Avg. Train Loss: 0.3830949885003707, Avg. Test Loss: 0.3859899640083313\n",
      "Epoch: 263, Avg. Train Loss: 0.37955241028000325, Avg. Test Loss: 0.3759324252605438\n",
      "Epoch: 264, Avg. Train Loss: 0.37671124619596147, Avg. Test Loss: 0.3739011585712433\n",
      "Epoch: 265, Avg. Train Loss: 0.37211412997806775, Avg. Test Loss: 0.3665262460708618\n",
      "Epoch: 266, Avg. Train Loss: 0.368707872839535, Avg. Test Loss: 0.3642384707927704\n",
      "Epoch: 267, Avg. Train Loss: 0.3668205965967739, Avg. Test Loss: 0.36217615008354187\n",
      "Epoch: 268, Avg. Train Loss: 0.3635382157914779, Avg. Test Loss: 0.3589075803756714\n",
      "Epoch: 269, Avg. Train Loss: 0.3589496384648716, Avg. Test Loss: 0.3609365224838257\n",
      "Epoch: 270, Avg. Train Loss: 0.3561939460389754, Avg. Test Loss: 0.3439672887325287\n",
      "Epoch: 271, Avg. Train Loss: 0.3421358848319334, Avg. Test Loss: 0.3430716097354889\n",
      "Epoch: 272, Avg. Train Loss: 0.3375087692457087, Avg. Test Loss: 0.33450356125831604\n",
      "Epoch: 273, Avg. Train Loss: 0.3325371356571422, Avg. Test Loss: 0.3270455598831177\n",
      "Epoch: 274, Avg. Train Loss: 0.327517623761121, Avg. Test Loss: 0.3227457106113434\n",
      "Epoch: 275, Avg. Train Loss: 0.31688280140652375, Avg. Test Loss: 0.30557024478912354\n",
      "Epoch: 276, Avg. Train Loss: 0.306338927675696, Avg. Test Loss: 0.30110570788383484\n",
      "Epoch: 277, Avg. Train Loss: 0.30271935357766994, Avg. Test Loss: 0.298321008682251\n",
      "Epoch: 278, Avg. Train Loss: 0.2980549139135024, Avg. Test Loss: 0.2871716320514679\n",
      "Epoch: 279, Avg. Train Loss: 0.2878324196619146, Avg. Test Loss: 0.2868475019931793\n",
      "Epoch: 280, Avg. Train Loss: 0.28455874131006353, Avg. Test Loss: 0.2801119089126587\n",
      "Epoch: 281, Avg. Train Loss: 0.2773379259249743, Avg. Test Loss: 0.2665804624557495\n",
      "Epoch: 282, Avg. Train Loss: 0.2666554864715127, Avg. Test Loss: 0.2618035674095154\n",
      "Epoch: 283, Avg. Train Loss: 0.34864143588963675, Avg. Test Loss: 0.4731406569480896\n",
      "Epoch: 284, Avg. Train Loss: 0.47151883419822244, Avg. Test Loss: 0.4303121566772461\n",
      "Epoch: 285, Avg. Train Loss: 0.42923904306748334, Avg. Test Loss: 0.4263223111629486\n",
      "Epoch: 286, Avg. Train Loss: 0.42678794930962954, Avg. Test Loss: 0.4237697422504425\n",
      "Epoch: 287, Avg. Train Loss: 0.4339195514426512, Avg. Test Loss: 0.4392756521701813\n",
      "Epoch: 288, Avg. Train Loss: 0.4399879679960363, Avg. Test Loss: 0.4343159794807434\n",
      "Epoch: 289, Avg. Train Loss: 0.4341279594337239, Avg. Test Loss: 0.42724916338920593\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 290, Avg. Train Loss: 0.4214914009851568, Avg. Test Loss: 0.411496102809906\n",
      "Epoch: 291, Avg. Train Loss: 0.40322731803445255, Avg. Test Loss: 0.39640581607818604\n",
      "Epoch: 292, Avg. Train Loss: 0.3764268920702093, Avg. Test Loss: 0.2817561626434326\n",
      "Epoch: 293, Avg. Train Loss: 0.25506725907325745, Avg. Test Loss: 0.27032408118247986\n",
      "Epoch: 294, Avg. Train Loss: 0.24897648271392372, Avg. Test Loss: 0.24654459953308105\n",
      "Epoch: 295, Avg. Train Loss: 0.24622913406175725, Avg. Test Loss: 0.24329286813735962\n",
      "Epoch: 296, Avg. Train Loss: 0.24358273797175464, Avg. Test Loss: 0.24071963131427765\n",
      "Epoch: 297, Avg. Train Loss: 0.24131776287275203, Avg. Test Loss: 0.23810338973999023\n",
      "Epoch: 298, Avg. Train Loss: 0.24273150177562938, Avg. Test Loss: 0.24088621139526367\n",
      "Epoch: 299, Avg. Train Loss: 0.2417242162367877, Avg. Test Loss: 0.23851929605007172\n",
      "Epoch: 300, Avg. Train Loss: 0.2378435822094188, Avg. Test Loss: 0.23279079794883728\n",
      "Epoch: 301, Avg. Train Loss: 0.2321052272530163, Avg. Test Loss: 0.22919556498527527\n",
      "Epoch: 302, Avg. Train Loss: 0.22822889492792242, Avg. Test Loss: 0.22548356652259827\n",
      "Epoch: 303, Avg. Train Loss: 0.22411805899704204, Avg. Test Loss: 0.2221461832523346\n",
      "Epoch: 304, Avg. Train Loss: 0.22112494286368875, Avg. Test Loss: 0.22740015387535095\n",
      "Epoch: 305, Avg. Train Loss: 0.21613931761068456, Avg. Test Loss: 0.21087081730365753\n",
      "Epoch: 306, Avg. Train Loss: 0.20975799718323876, Avg. Test Loss: 0.2069406360387802\n",
      "Epoch: 307, Avg. Train Loss: 0.2050890978644876, Avg. Test Loss: 0.20236451923847198\n",
      "Epoch: 308, Avg. Train Loss: 0.19987082831999836, Avg. Test Loss: 0.197315514087677\n",
      "Epoch: 309, Avg. Train Loss: 0.18973941364709068, Avg. Test Loss: 0.18463627994060516\n",
      "Epoch: 310, Avg. Train Loss: 0.18210237867691936, Avg. Test Loss: 0.17810015380382538\n",
      "Epoch: 311, Avg. Train Loss: 0.1773287757354624, Avg. Test Loss: 0.1736517995595932\n",
      "Epoch: 312, Avg. Train Loss: 0.19860044086680692, Avg. Test Loss: 0.21082580089569092\n",
      "Epoch: 313, Avg. Train Loss: 0.20767790815409493, Avg. Test Loss: 0.20406284928321838\n",
      "Epoch: 314, Avg. Train Loss: 0.20193924675969516, Avg. Test Loss: 0.1984710693359375\n",
      "Epoch: 315, Avg. Train Loss: 0.21158886306426106, Avg. Test Loss: 0.27838069200515747\n",
      "Epoch: 316, Avg. Train Loss: 0.2985353946685791, Avg. Test Loss: 0.2944526970386505\n",
      "Epoch: 317, Avg. Train Loss: 0.2962330162525177, Avg. Test Loss: 0.2912684679031372\n",
      "Epoch: 318, Avg. Train Loss: 0.28884563901845145, Avg. Test Loss: 0.2857261002063751\n",
      "Epoch: 319, Avg. Train Loss: 0.2812701134120717, Avg. Test Loss: 0.27641561627388\n",
      "Epoch: 320, Avg. Train Loss: 0.2721570132409825, Avg. Test Loss: 0.26521602272987366\n",
      "Epoch: 321, Avg. Train Loss: 0.26283210235483506, Avg. Test Loss: 0.2566338777542114\n",
      "Epoch: 322, Avg. Train Loss: 0.2540189050576266, Avg. Test Loss: 0.24860984086990356\n",
      "Epoch: 323, Avg. Train Loss: 0.2450983589186388, Avg. Test Loss: 0.23719915747642517\n",
      "Epoch: 324, Avg. Train Loss: 0.23244176857611712, Avg. Test Loss: 0.22699502110481262\n",
      "Epoch: 325, Avg. Train Loss: 0.23520847629098332, Avg. Test Loss: 0.2648773789405823\n",
      "Epoch: 326, Avg. Train Loss: 0.2628762401202146, Avg. Test Loss: 0.2541801631450653\n",
      "Epoch: 327, Avg. Train Loss: 0.24850137198672576, Avg. Test Loss: 0.24059519171714783\n",
      "Epoch: 328, Avg. Train Loss: 0.23717156701228198, Avg. Test Loss: 0.23953068256378174\n",
      "Epoch: 329, Avg. Train Loss: 0.25095120124957143, Avg. Test Loss: 0.2607402205467224\n",
      "Epoch: 330, Avg. Train Loss: 0.2562645568567164, Avg. Test Loss: 0.24878984689712524\n",
      "Epoch: 331, Avg. Train Loss: 0.24174224331098446, Avg. Test Loss: 0.23287706077098846\n",
      "Epoch: 332, Avg. Train Loss: 0.22713423353784223, Avg. Test Loss: 0.2195580154657364\n",
      "Epoch: 333, Avg. Train Loss: 0.21315573927234202, Avg. Test Loss: 0.2073948234319687\n",
      "Epoch: 334, Avg. Train Loss: 0.20140058573554545, Avg. Test Loss: 0.19236651062965393\n",
      "Epoch: 335, Avg. Train Loss: 0.18658612773698918, Avg. Test Loss: 0.1799846887588501\n",
      "Epoch: 336, Avg. Train Loss: 0.17486770328353432, Avg. Test Loss: 0.1637246012687683\n",
      "Epoch: 337, Avg. Train Loss: 0.15684122776283937, Avg. Test Loss: 0.151930034160614\n",
      "Epoch: 338, Avg. Train Loss: 0.1509114329429234, Avg. Test Loss: 0.14648084342479706\n",
      "Epoch: 339, Avg. Train Loss: 0.14266463211354088, Avg. Test Loss: 0.13532909750938416\n",
      "Epoch: 340, Avg. Train Loss: 0.18686866172972846, Avg. Test Loss: 0.28314629197120667\n",
      "Epoch: 341, Avg. Train Loss: 0.24135481750263887, Avg. Test Loss: 0.2245374172925949\n",
      "Epoch: 342, Avg. Train Loss: 0.2349109146524878, Avg. Test Loss: 0.23126383125782013\n",
      "Epoch: 343, Avg. Train Loss: 0.22477686913574443, Avg. Test Loss: 0.22208072245121002\n",
      "Epoch: 344, Avg. Train Loss: 0.21681209785096786, Avg. Test Loss: 0.21623064577579498\n",
      "Epoch: 345, Avg. Train Loss: 0.21428085828528684, Avg. Test Loss: 0.212192103266716\n",
      "Epoch: 346, Avg. Train Loss: 0.2086753240403007, Avg. Test Loss: 0.20791016519069672\n",
      "Epoch: 347, Avg. Train Loss: 0.2029070093351252, Avg. Test Loss: 0.2012549340724945\n",
      "Epoch: 348, Avg. Train Loss: 0.227287435706924, Avg. Test Loss: 0.24424336850643158\n",
      "Epoch: 349, Avg. Train Loss: 0.24057718129719005, Avg. Test Loss: 0.23825402557849884\n",
      "Epoch: 350, Avg. Train Loss: 0.23375921547412873, Avg. Test Loss: 0.23055262863636017\n",
      "Epoch: 351, Avg. Train Loss: 0.23382027920554666, Avg. Test Loss: 0.23210403323173523\n",
      "Epoch: 352, Avg. Train Loss: 0.2279129627872916, Avg. Test Loss: 0.22526855766773224\n",
      "Epoch: 353, Avg. Train Loss: 0.22104854022755344, Avg. Test Loss: 0.2186988741159439\n",
      "Epoch: 354, Avg. Train Loss: 0.2148239915861803, Avg. Test Loss: 0.21296176314353943\n",
      "Epoch: 355, Avg. Train Loss: 0.21026740302057828, Avg. Test Loss: 0.2074129730463028\n",
      "Epoch: 356, Avg. Train Loss: 0.20092830675489762, Avg. Test Loss: 0.19734220206737518\n",
      "Epoch: 357, Avg. Train Loss: 0.19328796863555908, Avg. Test Loss: 0.19289390742778778\n",
      "Epoch: 358, Avg. Train Loss: 0.17086495511672076, Avg. Test Loss: 0.16016754508018494\n",
      "Epoch: 359, Avg. Train Loss: 0.15539529130739324, Avg. Test Loss: 0.15560637414455414\n",
      "Epoch: 360, Avg. Train Loss: 0.15052396777798147, Avg. Test Loss: 0.15051695704460144\n",
      "Epoch: 361, Avg. Train Loss: 0.1454775959253311, Avg. Test Loss: 0.14613834023475647\n",
      "Epoch: 362, Avg. Train Loss: 0.140430848300457, Avg. Test Loss: 0.1369672268629074\n",
      "Epoch: 363, Avg. Train Loss: 0.13151399501982858, Avg. Test Loss: 0.1303573101758957\n",
      "Epoch: 364, Avg. Train Loss: 0.12725131853538402, Avg. Test Loss: 0.12923458218574524\n",
      "Epoch: 365, Avg. Train Loss: 0.1301900393822614, Avg. Test Loss: 0.14856261014938354\n",
      "Epoch: 366, Avg. Train Loss: 0.14138417962719413, Avg. Test Loss: 0.13252362608909607\n",
      "Epoch: 367, Avg. Train Loss: 0.12890212334254209, Avg. Test Loss: 0.12974393367767334\n",
      "Epoch: 368, Avg. Train Loss: 0.12673696077921812, Avg. Test Loss: 0.12703952193260193\n",
      "Epoch: 369, Avg. Train Loss: 0.12417546335388632, Avg. Test Loss: 0.12446736544370651\n",
      "Epoch: 370, Avg. Train Loss: 0.12156048057710424, Avg. Test Loss: 0.1217927634716034\n",
      "Epoch: 371, Avg. Train Loss: 0.11933987491271075, Avg. Test Loss: 0.11882678419351578\n",
      "Epoch: 372, Avg. Train Loss: 0.11684993987574296, Avg. Test Loss: 0.11619425565004349\n",
      "Epoch: 373, Avg. Train Loss: 0.1146997778731234, Avg. Test Loss: 0.11439280211925507\n",
      "Epoch: 374, Avg. Train Loss: 0.1131262613569989, Avg. Test Loss: 0.1122029572725296\n",
      "Epoch: 375, Avg. Train Loss: 0.1100491093362079, Avg. Test Loss: 0.10774797946214676\n",
      "Epoch: 376, Avg. Train Loss: 0.1065185241839465, Avg. Test Loss: 0.10554403811693192\n",
      "Epoch: 377, Avg. Train Loss: 0.10454348010175368, Avg. Test Loss: 0.1036641001701355\n",
      "Epoch: 378, Avg. Train Loss: 0.10242873850990744, Avg. Test Loss: 0.10138309001922607\n",
      "Epoch: 379, Avg. Train Loss: 0.10111459064133027, Avg. Test Loss: 0.10085083544254303\n",
      "Epoch: 380, Avg. Train Loss: 0.10324411032830967, Avg. Test Loss: 0.10089531540870667\n",
      "Epoch: 381, Avg. Train Loss: 0.09993660835658803, Avg. Test Loss: 0.09823621064424515\n",
      "Epoch: 382, Avg. Train Loss: 0.09811085567754858, Avg. Test Loss: 0.09833578020334244\n",
      "Epoch: 383, Avg. Train Loss: 0.09714563488960266, Avg. Test Loss: 0.09648448973894119\n",
      "Epoch: 384, Avg. Train Loss: 0.09423025250434876, Avg. Test Loss: 0.09292171150445938\n",
      "Epoch: 385, Avg. Train Loss: 0.09335697722785613, Avg. Test Loss: 0.09328221529722214\n",
      "Epoch: 386, Avg. Train Loss: 0.09144070218591129, Avg. Test Loss: 0.09034720063209534\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 387, Avg. Train Loss: 0.0859933986383326, Avg. Test Loss: 0.07479408383369446\n",
      "Epoch: 388, Avg. Train Loss: 0.0734509535572108, Avg. Test Loss: 0.07121442258358002\n",
      "Epoch: 389, Avg. Train Loss: 0.07046252844088217, Avg. Test Loss: 0.06881234794855118\n",
      "Epoch: 390, Avg. Train Loss: 0.06857361911850816, Avg. Test Loss: 0.06633248925209045\n",
      "Epoch: 391, Avg. Train Loss: 0.06595620425308452, Avg. Test Loss: 0.06390334665775299\n",
      "Epoch: 392, Avg. Train Loss: 0.06412658989429473, Avg. Test Loss: 0.06216539815068245\n",
      "Epoch: 393, Avg. Train Loss: 0.06163079466889886, Avg. Test Loss: 0.05954520404338837\n",
      "Epoch: 394, Avg. Train Loss: 0.059144281595945356, Avg. Test Loss: 0.057160358875989914\n",
      "Epoch: 395, Avg. Train Loss: 0.057084280559245276, Avg. Test Loss: 0.05493037775158882\n",
      "Epoch: 396, Avg. Train Loss: 0.05513778723338071, Avg. Test Loss: 0.053148236125707626\n",
      "Epoch: 397, Avg. Train Loss: 0.05359173013883479, Avg. Test Loss: 0.0516422763466835\n",
      "Epoch: 398, Avg. Train Loss: 0.0526512110934538, Avg. Test Loss: 0.051629289984703064\n",
      "Epoch: 399, Avg. Train Loss: 0.051709041832124485, Avg. Test Loss: 0.04926373064517975\n",
      "Epoch: 400, Avg. Train Loss: 0.049581768539022, Avg. Test Loss: 0.04785553738474846\n",
      "Epoch: 401, Avg. Train Loss: 0.048499864821924886, Avg. Test Loss: 0.04631546139717102\n",
      "Epoch: 402, Avg. Train Loss: 0.04696498057421516, Avg. Test Loss: 0.04517130181193352\n",
      "Epoch: 403, Avg. Train Loss: 0.04568479828098241, Avg. Test Loss: 0.043636128306388855\n",
      "Epoch: 404, Avg. Train Loss: 0.044343605243107855, Avg. Test Loss: 0.04265972971916199\n",
      "Epoch: 405, Avg. Train Loss: 0.04378210937275606, Avg. Test Loss: 0.04247641935944557\n",
      "Epoch: 406, Avg. Train Loss: 0.04313395860440591, Avg. Test Loss: 0.04140324145555496\n",
      "Epoch: 407, Avg. Train Loss: 0.04243307731607381, Avg. Test Loss: 0.0406845323741436\n",
      "Epoch: 408, Avg. Train Loss: 0.044167524663841023, Avg. Test Loss: 0.04426347091794014\n",
      "Epoch: 409, Avg. Train Loss: 0.04343828282812062, Avg. Test Loss: 0.04150307923555374\n",
      "Epoch: 410, Avg. Train Loss: 0.04308355025508825, Avg. Test Loss: 0.040609367191791534\n",
      "Epoch: 411, Avg. Train Loss: 0.04975681686226059, Avg. Test Loss: 0.04820927232503891\n",
      "Epoch: 412, Avg. Train Loss: 0.0463859139558147, Avg. Test Loss: 0.04421520233154297\n",
      "Epoch: 413, Avg. Train Loss: 0.043509643437231287, Avg. Test Loss: 0.04124683141708374\n",
      "Epoch: 414, Avg. Train Loss: 0.04127362563329585, Avg. Test Loss: 0.03988311067223549\n",
      "Epoch: 415, Avg. Train Loss: 0.03985007072196287, Avg. Test Loss: 0.0410018116235733\n",
      "Epoch: 416, Avg. Train Loss: 0.03904896417961401, Avg. Test Loss: 0.037533313035964966\n",
      "Epoch: 417, Avg. Train Loss: 0.03831330612301827, Avg. Test Loss: 0.037153907120227814\n",
      "Epoch: 418, Avg. Train Loss: 0.037989756859400696, Avg. Test Loss: 0.03687964007258415\n",
      "Epoch: 419, Avg. Train Loss: 0.03770996976424666, Avg. Test Loss: 0.03718344867229462\n",
      "Epoch: 420, Avg. Train Loss: 0.03746178627890699, Avg. Test Loss: 0.036288607865571976\n",
      "Epoch: 421, Avg. Train Loss: 0.03720415011048317, Avg. Test Loss: 0.03596590831875801\n",
      "Epoch: 422, Avg. Train Loss: 0.03694698604590753, Avg. Test Loss: 0.03570859134197235\n",
      "Epoch: 423, Avg. Train Loss: 0.036719363533398684, Avg. Test Loss: 0.035479720681905746\n",
      "Epoch: 424, Avg. Train Loss: 0.03653331591802485, Avg. Test Loss: 0.035316333174705505\n",
      "Epoch: 425, Avg. Train Loss: 0.036403769035549725, Avg. Test Loss: 0.03517219424247742\n",
      "Epoch: 426, Avg. Train Loss: 0.03642170576050001, Avg. Test Loss: 0.035264212638139725\n",
      "Epoch: 427, Avg. Train Loss: 0.03610527581151794, Avg. Test Loss: 0.034823596477508545\n",
      "Epoch: 428, Avg. Train Loss: 0.03575570732355118, Avg. Test Loss: 0.034573595970869064\n",
      "Epoch: 429, Avg. Train Loss: 0.03552535592633135, Avg. Test Loss: 0.03434311971068382\n",
      "Epoch: 430, Avg. Train Loss: 0.03530646621742669, Avg. Test Loss: 0.03453369438648224\n",
      "Epoch: 431, Avg. Train Loss: 0.03504736138617291, Avg. Test Loss: 0.03409331291913986\n",
      "Epoch: 432, Avg. Train Loss: 0.03487873296527302, Avg. Test Loss: 0.03378747031092644\n",
      "Epoch: 433, Avg. Train Loss: 0.03464782720102983, Avg. Test Loss: 0.033442188054323196\n",
      "Epoch: 434, Avg. Train Loss: 0.03440491572460708, Avg. Test Loss: 0.03322489932179451\n",
      "Epoch: 435, Avg. Train Loss: 0.03429861833505771, Avg. Test Loss: 0.03307498246431351\n",
      "Epoch: 436, Avg. Train Loss: 0.03409935937208288, Avg. Test Loss: 0.032911062240600586\n",
      "Epoch: 437, Avg. Train Loss: 0.033751046350773646, Avg. Test Loss: 0.036446064710617065\n",
      "Epoch: 438, Avg. Train Loss: 0.03355501245926408, Avg. Test Loss: 0.03239614516496658\n",
      "Epoch: 439, Avg. Train Loss: 0.03334596395930823, Avg. Test Loss: 0.03217627853155136\n",
      "Epoch: 440, Avg. Train Loss: 0.033185354379170084, Avg. Test Loss: 0.03206934779882431\n",
      "Epoch: 441, Avg. Train Loss: 0.03310190463329063, Avg. Test Loss: 0.03185603767633438\n",
      "Epoch: 442, Avg. Train Loss: 0.03281815422370153, Avg. Test Loss: 0.03189810737967491\n",
      "Epoch: 443, Avg. Train Loss: 0.03261459476369269, Avg. Test Loss: 0.03147543594241142\n",
      "Epoch: 444, Avg. Train Loss: 0.03247604396413354, Avg. Test Loss: 0.03128392994403839\n",
      "Epoch: 445, Avg. Train Loss: 0.03229113633141798, Avg. Test Loss: 0.031230635941028595\n",
      "Epoch: 446, Avg. Train Loss: 0.032155055158278524, Avg. Test Loss: 0.031007206067442894\n",
      "Epoch: 447, Avg. Train Loss: 0.03204301935346687, Avg. Test Loss: 0.030882643535733223\n",
      "Epoch: 448, Avg. Train Loss: 0.04023171580013107, Avg. Test Loss: 0.04362121969461441\n",
      "Epoch: 449, Avg. Train Loss: 0.036464627547299164, Avg. Test Loss: 0.03191787376999855\n",
      "Epoch: 450, Avg. Train Loss: 0.032020253731923944, Avg. Test Loss: 0.031379468739032745\n",
      "Epoch: 451, Avg. Train Loss: 0.031576884778983454, Avg. Test Loss: 0.030817970633506775\n",
      "Epoch: 452, Avg. Train Loss: 0.03145096050027539, Avg. Test Loss: 0.030513254925608635\n",
      "Epoch: 453, Avg. Train Loss: 0.031353999849628, Avg. Test Loss: 0.030351106077432632\n",
      "Epoch: 454, Avg. Train Loss: 0.03119770652231048, Avg. Test Loss: 0.030161740258336067\n",
      "Epoch: 455, Avg. Train Loss: 0.03107890690512517, Avg. Test Loss: 0.02999875135719776\n",
      "Epoch: 456, Avg. Train Loss: 0.030937228833927827, Avg. Test Loss: 0.0298450980335474\n",
      "Epoch: 457, Avg. Train Loss: 0.03084224420873558, Avg. Test Loss: 0.029732057824730873\n",
      "Epoch: 458, Avg. Train Loss: 0.03074276041896904, Avg. Test Loss: 0.029598316177725792\n",
      "Epoch: 459, Avg. Train Loss: 0.030638643069302335, Avg. Test Loss: 0.02950066328048706\n",
      "Epoch: 460, Avg. Train Loss: 0.030525426698081632, Avg. Test Loss: 0.029431849718093872\n",
      "Epoch: 461, Avg. Train Loss: 0.030434099694385246, Avg. Test Loss: 0.02948606014251709\n",
      "Epoch: 462, Avg. Train Loss: 0.03034572973847389, Avg. Test Loss: 0.02922050841152668\n",
      "Epoch: 463, Avg. Train Loss: 0.030256478072089307, Avg. Test Loss: 0.02905886247754097\n",
      "Epoch: 464, Avg. Train Loss: 0.030132466839516862, Avg. Test Loss: 0.02905084565281868\n",
      "Epoch: 465, Avg. Train Loss: 0.03004051712067688, Avg. Test Loss: 0.029215635731816292\n",
      "Epoch: 466, Avg. Train Loss: 0.02996918868054362, Avg. Test Loss: 0.028855960816144943\n",
      "Epoch: 467, Avg. Train Loss: 0.029820491198231193, Avg. Test Loss: 0.02871759422123432\n",
      "Epoch: 468, Avg. Train Loss: 0.030161443944363032, Avg. Test Loss: 0.030554985627532005\n",
      "Epoch: 469, Avg. Train Loss: 0.030322591193458613, Avg. Test Loss: 0.028686506673693657\n",
      "Epoch: 470, Avg. Train Loss: 0.02971055610653232, Avg. Test Loss: 0.028498083353042603\n",
      "Epoch: 471, Avg. Train Loss: 0.02955186814069748, Avg. Test Loss: 0.02838662825524807\n",
      "Epoch: 472, Avg. Train Loss: 0.02950358011705034, Avg. Test Loss: 0.02833567187190056\n",
      "Epoch: 473, Avg. Train Loss: 0.02940101338660016, Avg. Test Loss: 0.028400810435414314\n",
      "Epoch: 474, Avg. Train Loss: 0.02935527267263216, Avg. Test Loss: 0.028305262327194214\n",
      "Epoch: 475, Avg. Train Loss: 0.029265980115708183, Avg. Test Loss: 0.028928805142641068\n",
      "Epoch: 476, Avg. Train Loss: 0.02912015689208227, Avg. Test Loss: 0.02805517427623272\n",
      "Epoch: 477, Avg. Train Loss: 0.02906058722120874, Avg. Test Loss: 0.02806718274950981\n",
      "Epoch: 478, Avg. Train Loss: 0.028942963831564958, Avg. Test Loss: 0.028065260499715805\n",
      "Epoch: 479, Avg. Train Loss: 0.02899132629527765, Avg. Test Loss: 0.02775566466152668\n",
      "Epoch: 480, Avg. Train Loss: 0.028837077955112738, Avg. Test Loss: 0.02825312688946724\n",
      "Epoch: 481, Avg. Train Loss: 0.02872869091875413, Avg. Test Loss: 0.02764713577926159\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 482, Avg. Train Loss: 0.028600155781297123, Avg. Test Loss: 0.02755940891802311\n",
      "Epoch: 483, Avg. Train Loss: 0.02863665334880352, Avg. Test Loss: 0.028963221237063408\n",
      "Epoch: 484, Avg. Train Loss: 0.028532092426629626, Avg. Test Loss: 0.02763436548411846\n",
      "Epoch: 485, Avg. Train Loss: 0.028370866595822223, Avg. Test Loss: 0.02775365114212036\n",
      "Epoch: 486, Avg. Train Loss: 0.028288344425313614, Avg. Test Loss: 0.029206160455942154\n",
      "Epoch: 487, Avg. Train Loss: 0.028207897855078472, Avg. Test Loss: 0.028056984767317772\n",
      "Epoch: 488, Avg. Train Loss: 0.028197589450899292, Avg. Test Loss: 0.027848439291119576\n",
      "Epoch: 489, Avg. Train Loss: 0.03407403164926697, Avg. Test Loss: 0.06842879951000214\n",
      "Epoch: 490, Avg. Train Loss: 0.10512291850412593, Avg. Test Loss: 0.07245979458093643\n",
      "Epoch: 491, Avg. Train Loss: 0.0622984123580596, Avg. Test Loss: 0.05732150003314018\n",
      "Epoch: 492, Avg. Train Loss: 0.057683749014840406, Avg. Test Loss: 0.060120776295661926\n",
      "Epoch: 493, Avg. Train Loss: 0.05584897780243088, Avg. Test Loss: 0.052507296204566956\n",
      "Epoch: 494, Avg. Train Loss: 0.057313010929261936, Avg. Test Loss: 0.06704051792621613\n",
      "Epoch: 495, Avg. Train Loss: 0.06418926409062217, Avg. Test Loss: 0.045972201973199844\n",
      "Epoch: 496, Avg. Train Loss: 0.04203385351335301, Avg. Test Loss: 0.038286242634058\n",
      "Epoch: 497, Avg. Train Loss: 0.0429138641585322, Avg. Test Loss: 0.03930174186825752\n",
      "Epoch: 498, Avg. Train Loss: 0.10925096019225962, Avg. Test Loss: 0.1423393338918686\n",
      "Epoch: 499, Avg. Train Loss: 0.10059853029601715, Avg. Test Loss: 0.09602122008800507\n",
      "Epoch: 500, Avg. Train Loss: 0.09521264889661003, Avg. Test Loss: 0.08297915756702423\n",
      "Epoch: 501, Avg. Train Loss: 0.10497270419317133, Avg. Test Loss: 0.12285875529050827\n",
      "Epoch: 502, Avg. Train Loss: 0.10652993207468706, Avg. Test Loss: 0.0970843955874443\n",
      "Epoch: 503, Avg. Train Loss: 0.09577965929227716, Avg. Test Loss: 0.08995833247900009\n",
      "Epoch: 504, Avg. Train Loss: 0.07768422790309962, Avg. Test Loss: 0.04128420352935791\n",
      "Epoch: 505, Avg. Train Loss: 0.03997416566399967, Avg. Test Loss: 0.03764835745096207\n",
      "Epoch: 506, Avg. Train Loss: 0.03866425827145577, Avg. Test Loss: 0.036713387817144394\n",
      "Epoch: 507, Avg. Train Loss: 0.037791612393715805, Avg. Test Loss: 0.035950396209955215\n",
      "Epoch: 508, Avg. Train Loss: 0.03741774955654845, Avg. Test Loss: 0.035645972937345505\n",
      "Epoch: 509, Avg. Train Loss: 0.037091661814381095, Avg. Test Loss: 0.03525833413004875\n",
      "Epoch: 510, Avg. Train Loss: 0.036306556774412885, Avg. Test Loss: 0.03408818691968918\n",
      "Epoch: 511, Avg. Train Loss: 0.0347560584106866, Avg. Test Loss: 0.033019669353961945\n",
      "Epoch: 512, Avg. Train Loss: 0.034083176382324276, Avg. Test Loss: 0.03253994509577751\n",
      "Epoch: 513, Avg. Train Loss: 0.033756100846564066, Avg. Test Loss: 0.03224240988492966\n",
      "Epoch: 514, Avg. Train Loss: 0.03363444678047124, Avg. Test Loss: 0.0321943573653698\n",
      "Epoch: 515, Avg. Train Loss: 0.03358925914063173, Avg. Test Loss: 0.03211929649114609\n",
      "Epoch: 516, Avg. Train Loss: 0.03346849011585993, Avg. Test Loss: 0.031901754438877106\n",
      "Epoch: 517, Avg. Train Loss: 0.03334270286209443, Avg. Test Loss: 0.03175092488527298\n",
      "Epoch: 518, Avg. Train Loss: 0.03316221563693355, Avg. Test Loss: 0.03167341649532318\n",
      "Epoch: 519, Avg. Train Loss: 0.03308974901104675, Avg. Test Loss: 0.03155817463994026\n",
      "Epoch: 520, Avg. Train Loss: 0.03307949878713664, Avg. Test Loss: 0.031652048230171204\n",
      "Epoch: 521, Avg. Train Loss: 0.03314463476486066, Avg. Test Loss: 0.03152308985590935\n",
      "Epoch: 522, Avg. Train Loss: 0.03301767404465114, Avg. Test Loss: 0.031626731157302856\n",
      "Epoch: 523, Avg. Train Loss: 0.03301080734852482, Avg. Test Loss: 0.031518060714006424\n",
      "Epoch: 524, Avg. Train Loss: 0.03290864869075663, Avg. Test Loss: 0.031477104872465134\n",
      "Epoch: 525, Avg. Train Loss: 0.033018481424626184, Avg. Test Loss: 0.031514670699834824\n",
      "Epoch: 526, Avg. Train Loss: 0.032902431948220026, Avg. Test Loss: 0.03149566799402237\n",
      "Epoch: 527, Avg. Train Loss: 0.032775562453795884, Avg. Test Loss: 0.03161992132663727\n",
      "Epoch: 528, Avg. Train Loss: 0.032559805100455, Avg. Test Loss: 0.03227990120649338\n",
      "Epoch: 529, Avg. Train Loss: 0.032281525301582674, Avg. Test Loss: 0.036442890763282776\n",
      "Epoch: 530, Avg. Train Loss: 0.032043659971917375, Avg. Test Loss: 0.05658227950334549\n",
      "Epoch: 531, Avg. Train Loss: 0.0319031093707856, Avg. Test Loss: 0.034252941608428955\n",
      "Epoch: 532, Avg. Train Loss: 0.031781766454086584, Avg. Test Loss: 0.031938571482896805\n",
      "Epoch: 533, Avg. Train Loss: 0.03166643328526441, Avg. Test Loss: 0.03098130412399769\n",
      "Epoch: 534, Avg. Train Loss: 0.03157492152908269, Avg. Test Loss: 0.030688636004924774\n",
      "Epoch: 535, Avg. Train Loss: 0.03146755228586057, Avg. Test Loss: 0.030404983088374138\n",
      "Epoch: 536, Avg. Train Loss: 0.03139654634629979, Avg. Test Loss: 0.030285697430372238\n",
      "Epoch: 537, Avg. Train Loss: 0.031307996173991874, Avg. Test Loss: 0.03015330247581005\n",
      "Epoch: 538, Avg. Train Loss: 0.03123916672433124, Avg. Test Loss: 0.030039174482226372\n",
      "Epoch: 539, Avg. Train Loss: 0.03116298087817781, Avg. Test Loss: 0.029950683936476707\n",
      "Epoch: 540, Avg. Train Loss: 0.031089699268341063, Avg. Test Loss: 0.02992314100265503\n",
      "Epoch: 541, Avg. Train Loss: 0.031023450283443228, Avg. Test Loss: 0.029821857810020447\n",
      "Epoch: 542, Avg. Train Loss: 0.030952473028617748, Avg. Test Loss: 0.02977805770933628\n",
      "Epoch: 543, Avg. Train Loss: 0.030891017506227775, Avg. Test Loss: 0.0297098346054554\n",
      "Epoch: 544, Avg. Train Loss: 0.030835609050358044, Avg. Test Loss: 0.02973099984228611\n",
      "Epoch: 545, Avg. Train Loss: 0.030791700762860915, Avg. Test Loss: 0.02960563264787197\n",
      "Epoch: 546, Avg. Train Loss: 0.03074005528846208, Avg. Test Loss: 0.02956504374742508\n",
      "Epoch: 547, Avg. Train Loss: 0.030697997703271755, Avg. Test Loss: 0.02949841320514679\n",
      "Epoch: 548, Avg. Train Loss: 0.030638896345215685, Avg. Test Loss: 0.029466014355421066\n",
      "Epoch: 549, Avg. Train Loss: 0.03059113492422244, Avg. Test Loss: 0.029427893459796906\n",
      "Epoch: 550, Avg. Train Loss: 0.03053161124972736, Avg. Test Loss: 0.029338078573346138\n",
      "Epoch: 551, Avg. Train Loss: 0.030460835664587863, Avg. Test Loss: 0.02929004840552807\n",
      "Epoch: 552, Avg. Train Loss: 0.0304108257898513, Avg. Test Loss: 0.02921617589890957\n",
      "Epoch: 553, Avg. Train Loss: 0.030332419122843183, Avg. Test Loss: 0.02916262298822403\n",
      "Epoch: 554, Avg. Train Loss: 0.03027963151826578, Avg. Test Loss: 0.02911924012005329\n",
      "Epoch: 555, Avg. Train Loss: 0.030234673904145463, Avg. Test Loss: 0.02914997562766075\n",
      "Epoch: 556, Avg. Train Loss: 0.0302282737020184, Avg. Test Loss: 0.029076097533106804\n",
      "Epoch: 557, Avg. Train Loss: 0.030138617184232264, Avg. Test Loss: 0.02893528901040554\n",
      "Epoch: 558, Avg. Train Loss: 0.030058200657367706, Avg. Test Loss: 0.02892674319446087\n",
      "Epoch: 559, Avg. Train Loss: 0.03002683813957607, Avg. Test Loss: 0.02883015386760235\n",
      "Epoch: 560, Avg. Train Loss: 0.029996288370560197, Avg. Test Loss: 0.028758909553289413\n",
      "Epoch: 561, Avg. Train Loss: 0.02993029283688349, Avg. Test Loss: 0.028711147606372833\n",
      "Epoch: 562, Avg. Train Loss: 0.02991066397551228, Avg. Test Loss: 0.028651045635342598\n",
      "Epoch: 563, Avg. Train Loss: 0.029888036693720258, Avg. Test Loss: 0.02865762449800968\n",
      "Epoch: 564, Avg. Train Loss: 0.02977978852303589, Avg. Test Loss: 0.028561020269989967\n",
      "Epoch: 565, Avg. Train Loss: 0.029763453738654362, Avg. Test Loss: 0.02854263223707676\n",
      "Epoch: 566, Avg. Train Loss: 0.029696956167326254, Avg. Test Loss: 0.028444500640034676\n",
      "Epoch: 567, Avg. Train Loss: 0.029702377078287743, Avg. Test Loss: 0.028482284396886826\n",
      "Epoch: 568, Avg. Train Loss: 0.029645030288135303, Avg. Test Loss: 0.028343316167593002\n",
      "Epoch: 569, Avg. Train Loss: 0.02953705316519036, Avg. Test Loss: 0.02831985056400299\n",
      "Epoch: 570, Avg. Train Loss: 0.029565642313922152, Avg. Test Loss: 0.02834486775100231\n",
      "Epoch: 571, Avg. Train Loss: 0.029442277353476074, Avg. Test Loss: 0.028189998120069504\n",
      "Epoch: 572, Avg. Train Loss: 0.029412240162491797, Avg. Test Loss: 0.02818758226931095\n",
      "Epoch: 573, Avg. Train Loss: 0.029378987169441054, Avg. Test Loss: 0.02812553010880947\n",
      "Epoch: 574, Avg. Train Loss: 0.0294555971508517, Avg. Test Loss: 0.028910912573337555\n",
      "Epoch: 575, Avg. Train Loss: 0.03342210001805249, Avg. Test Loss: 0.031235380098223686\n",
      "Epoch: 576, Avg. Train Loss: 0.03067915553555769, Avg. Test Loss: 0.02844301238656044\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 577, Avg. Train Loss: 0.02949592839269077, Avg. Test Loss: 0.02786242961883545\n",
      "Epoch: 578, Avg. Train Loss: 0.029725593481870257, Avg. Test Loss: 0.027883654460310936\n",
      "Epoch: 579, Avg. Train Loss: 0.029246123770580574, Avg. Test Loss: 0.028383372351527214\n",
      "Epoch: 580, Avg. Train Loss: 0.02986104267046732, Avg. Test Loss: 0.028369959443807602\n",
      "Epoch: 581, Avg. Train Loss: 0.02907161269994343, Avg. Test Loss: 0.027822408825159073\n",
      "Epoch: 582, Avg. Train Loss: 0.02894322672749267, Avg. Test Loss: 0.027749983593821526\n",
      "Epoch: 583, Avg. Train Loss: 0.02929568689535646, Avg. Test Loss: 0.027736227959394455\n",
      "Epoch: 584, Avg. Train Loss: 0.02882581933894578, Avg. Test Loss: 0.02765486389398575\n",
      "Epoch: 585, Avg. Train Loss: 0.02876128626658636, Avg. Test Loss: 0.027915891259908676\n",
      "Epoch: 586, Avg. Train Loss: 0.028890380657771053, Avg. Test Loss: 0.028325213119387627\n",
      "Epoch: 587, Avg. Train Loss: 0.029086520303698148, Avg. Test Loss: 0.027437398210167885\n",
      "Epoch: 588, Avg. Train Loss: 0.0371848076581955, Avg. Test Loss: 0.03188570961356163\n",
      "Epoch: 589, Avg. Train Loss: 0.029968705203603296, Avg. Test Loss: 0.02829703688621521\n",
      "Epoch: 590, Avg. Train Loss: 0.03162848239435869, Avg. Test Loss: 0.028767092153429985\n",
      "Epoch: 591, Avg. Train Loss: 0.028874664885156293, Avg. Test Loss: 0.029396114870905876\n",
      "Epoch: 592, Avg. Train Loss: 0.028679440740276785, Avg. Test Loss: 0.028998741880059242\n",
      "Epoch: 593, Avg. Train Loss: 0.02831830290310523, Avg. Test Loss: 0.028662322089076042\n",
      "Epoch: 594, Avg. Train Loss: 0.03783056679017403, Avg. Test Loss: 0.0663452073931694\n",
      "Epoch: 595, Avg. Train Loss: 0.057065626496777815, Avg. Test Loss: 0.045790787786245346\n",
      "Epoch: 596, Avg. Train Loss: 0.03885554119068033, Avg. Test Loss: 0.03041025809943676\n",
      "Epoch: 597, Avg. Train Loss: 0.031443018729195873, Avg. Test Loss: 0.029629260301589966\n",
      "Epoch: 598, Avg. Train Loss: 0.031174017401302562, Avg. Test Loss: 0.030550014227628708\n",
      "Epoch: 599, Avg. Train Loss: 0.03175360172548715, Avg. Test Loss: 0.030707212164998055\n",
      "Epoch: 600, Avg. Train Loss: 0.032126007513964876, Avg. Test Loss: 0.03007669374346733\n",
      "Epoch: 601, Avg. Train Loss: 0.030792179353096905, Avg. Test Loss: 0.02879653126001358\n",
      "Epoch: 602, Avg. Train Loss: 0.02952014407252564, Avg. Test Loss: 0.028142843395471573\n",
      "Epoch: 603, Avg. Train Loss: 0.029224153871045395, Avg. Test Loss: 0.028600869700312614\n",
      "Epoch: 604, Avg. Train Loss: 0.13332890912013895, Avg. Test Loss: 0.7093561291694641\n",
      "Epoch: 605, Avg. Train Loss: 0.08002354910268503, Avg. Test Loss: 0.06713346391916275\n",
      "Epoch: 606, Avg. Train Loss: 0.13451850681620486, Avg. Test Loss: 0.1584075689315796\n",
      "Epoch: 607, Avg. Train Loss: 0.14827485698110918, Avg. Test Loss: 0.1383945792913437\n",
      "Epoch: 608, Avg. Train Loss: 0.13785751540871227, Avg. Test Loss: 0.1361071914434433\n",
      "Epoch: 609, Avg. Train Loss: 0.13415910741862128, Avg. Test Loss: 0.13070377707481384\n",
      "Epoch: 610, Avg. Train Loss: 0.12838923361371546, Avg. Test Loss: 0.12543748319149017\n",
      "Epoch: 611, Avg. Train Loss: 0.12947059536681454, Avg. Test Loss: 0.13483990728855133\n",
      "Epoch: 612, Avg. Train Loss: 0.14610339981668136, Avg. Test Loss: 0.14344657957553864\n",
      "Epoch: 613, Avg. Train Loss: 0.1380267281742657, Avg. Test Loss: 0.13325658440589905\n",
      "Epoch: 614, Avg. Train Loss: 0.12901591465753667, Avg. Test Loss: 0.12550459802150726\n",
      "Epoch: 615, Avg. Train Loss: 0.12223372967804179, Avg. Test Loss: 0.12024711072444916\n",
      "Epoch: 616, Avg. Train Loss: 0.11797005621825947, Avg. Test Loss: 0.11418767273426056\n",
      "Epoch: 617, Avg. Train Loss: 0.10991755723953248, Avg. Test Loss: 0.10450449585914612\n",
      "Epoch: 618, Avg. Train Loss: 0.1042256368433728, Avg. Test Loss: 0.10255889594554901\n",
      "Epoch: 619, Avg. Train Loss: 0.09859704524278641, Avg. Test Loss: 0.08757748454809189\n",
      "Epoch: 620, Avg. Train Loss: 0.08582099623539868, Avg. Test Loss: 0.08191871643066406\n",
      "Epoch: 621, Avg. Train Loss: 0.07752259268480188, Avg. Test Loss: 0.07398520410060883\n",
      "Epoch: 622, Avg. Train Loss: 0.07278745419838849, Avg. Test Loss: 0.07283688336610794\n",
      "Epoch: 623, Avg. Train Loss: 0.11070195839685552, Avg. Test Loss: 0.11807280778884888\n",
      "Epoch: 624, Avg. Train Loss: 0.0760760366478387, Avg. Test Loss: 0.059506893157958984\n",
      "Epoch: 625, Avg. Train Loss: 0.059552234148277955, Avg. Test Loss: 0.05673837661743164\n",
      "Epoch: 626, Avg. Train Loss: 0.059765725232222504, Avg. Test Loss: 0.058056190609931946\n",
      "Epoch: 627, Avg. Train Loss: 0.05854514298193595, Avg. Test Loss: 0.05623454973101616\n",
      "Epoch: 628, Avg. Train Loss: 0.05858733785503051, Avg. Test Loss: 0.05691879615187645\n",
      "Epoch: 629, Avg. Train Loss: 0.05697668628657565, Avg. Test Loss: 0.05414748191833496\n",
      "Epoch: 630, Avg. Train Loss: 0.054321905137861476, Avg. Test Loss: 0.05133283510804176\n",
      "Epoch: 631, Avg. Train Loss: 0.05171631543951876, Avg. Test Loss: 0.05350930243730545\n",
      "Epoch: 632, Avg. Train Loss: 0.05097443987341488, Avg. Test Loss: 0.04898054152727127\n",
      "Epoch: 633, Avg. Train Loss: 0.04940026573398534, Avg. Test Loss: 0.0474555529654026\n",
      "Epoch: 634, Avg. Train Loss: 0.04723819748443716, Avg. Test Loss: 0.04976449906826019\n",
      "Epoch: 635, Avg. Train Loss: 0.04544414089006536, Avg. Test Loss: 0.045304056257009506\n",
      "Epoch: 636, Avg. Train Loss: 0.04415028296849307, Avg. Test Loss: 0.04366747662425041\n",
      "Epoch: 637, Avg. Train Loss: 0.04303851640399765, Avg. Test Loss: 0.04382200166583061\n",
      "Epoch: 638, Avg. Train Loss: 0.04156574457883835, Avg. Test Loss: 0.050736408680677414\n",
      "Epoch: 639, Avg. Train Loss: 0.039910357708440106, Avg. Test Loss: 0.04001178219914436\n",
      "Epoch: 640, Avg. Train Loss: 0.03924795218250331, Avg. Test Loss: 0.03820887953042984\n",
      "Epoch: 641, Avg. Train Loss: 0.04408908157664187, Avg. Test Loss: 0.038253095000982285\n",
      "Epoch: 642, Avg. Train Loss: 0.04703221435056013, Avg. Test Loss: 0.05603639408946037\n",
      "Epoch: 643, Avg. Train Loss: 0.05331194948624162, Avg. Test Loss: 0.05923173204064369\n",
      "Epoch: 644, Avg. Train Loss: 0.05332645528456744, Avg. Test Loss: 0.048308491706848145\n",
      "Epoch: 645, Avg. Train Loss: 0.04855749234557152, Avg. Test Loss: 0.04623986780643463\n",
      "Epoch: 646, Avg. Train Loss: 0.04494703359463636, Avg. Test Loss: 0.04500838741660118\n",
      "Epoch: 647, Avg. Train Loss: 0.044046465701916636, Avg. Test Loss: 0.04980943351984024\n",
      "Epoch: 648, Avg. Train Loss: 0.0431186548927251, Avg. Test Loss: 0.041991591453552246\n",
      "Epoch: 649, Avg. Train Loss: 0.0423417804434019, Avg. Test Loss: 0.04074627906084061\n",
      "Epoch: 650, Avg. Train Loss: 0.042088781341033825, Avg. Test Loss: 0.040452275425195694\n",
      "Epoch: 651, Avg. Train Loss: 0.04164101604153128, Avg. Test Loss: 0.03967692703008652\n",
      "Epoch: 652, Avg. Train Loss: 0.04131441151394564, Avg. Test Loss: 0.03962760418653488\n",
      "Epoch: 653, Avg. Train Loss: 0.041052143188083874, Avg. Test Loss: 0.03937716782093048\n",
      "Epoch: 654, Avg. Train Loss: 0.04080973811009351, Avg. Test Loss: 0.03897203877568245\n",
      "Epoch: 655, Avg. Train Loss: 0.04080410481375806, Avg. Test Loss: 0.03948742896318436\n",
      "Epoch: 656, Avg. Train Loss: 0.04068644073079614, Avg. Test Loss: 0.03919573873281479\n",
      "Epoch: 657, Avg. Train Loss: 0.040198239289662416, Avg. Test Loss: 0.03861119598150253\n",
      "Epoch: 658, Avg. Train Loss: 0.04036196088966201, Avg. Test Loss: 0.0390985868871212\n",
      "Epoch: 659, Avg. Train Loss: 0.03970064472626237, Avg. Test Loss: 0.038283828645944595\n",
      "Epoch: 660, Avg. Train Loss: 0.03956889913362615, Avg. Test Loss: 0.038171716034412384\n",
      "Epoch: 661, Avg. Train Loss: 0.03928331469788271, Avg. Test Loss: 0.038046833127737045\n",
      "Epoch: 662, Avg. Train Loss: 0.03901625172618557, Avg. Test Loss: 0.03806566447019577\n",
      "Epoch: 663, Avg. Train Loss: 0.0386172907317386, Avg. Test Loss: 0.03958944231271744\n",
      "Epoch: 664, Avg. Train Loss: 0.038016124266911956, Avg. Test Loss: 0.03528387472033501\n",
      "Epoch: 665, Avg. Train Loss: 0.0424854910987265, Avg. Test Loss: 0.05005054920911789\n",
      "Epoch: 666, Avg. Train Loss: 0.04118303818737759, Avg. Test Loss: 0.03837040811777115\n",
      "Epoch: 667, Avg. Train Loss: 0.04047620068578159, Avg. Test Loss: 0.043993860483169556\n",
      "Epoch: 668, Avg. Train Loss: 0.06759147030465743, Avg. Test Loss: 0.06129061430692673\n",
      "Epoch: 669, Avg. Train Loss: 0.06681655667283956, Avg. Test Loss: 0.06161422282457352\n",
      "Epoch: 670, Avg. Train Loss: 0.06212114590932341, Avg. Test Loss: 0.05826646834611893\n",
      "Epoch: 671, Avg. Train Loss: 0.058981373248731386, Avg. Test Loss: 0.05618270859122276\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 672, Avg. Train Loss: 0.05578129615853814, Avg. Test Loss: 0.04618532583117485\n",
      "Epoch: 673, Avg. Train Loss: 0.046289975853527295, Avg. Test Loss: 0.045081887394189835\n",
      "Epoch: 674, Avg. Train Loss: 0.04422688567463089, Avg. Test Loss: 0.04187173768877983\n",
      "Epoch: 675, Avg. Train Loss: 0.04233854237724753, Avg. Test Loss: 0.03980514407157898\n",
      "Epoch: 676, Avg. Train Loss: 0.04086233925293473, Avg. Test Loss: 0.03868468850851059\n",
      "Epoch: 677, Avg. Train Loss: 0.03998872659662191, Avg. Test Loss: 0.03762603923678398\n",
      "Epoch: 678, Avg. Train Loss: 0.03889838308095932, Avg. Test Loss: 0.03661583364009857\n",
      "Epoch: 679, Avg. Train Loss: 0.038150214710656334, Avg. Test Loss: 0.035912446677684784\n",
      "Epoch: 680, Avg. Train Loss: 0.038151538459693685, Avg. Test Loss: 0.03602173924446106\n",
      "Epoch: 681, Avg. Train Loss: 0.03881009584840606, Avg. Test Loss: 0.036601435393095016\n",
      "Epoch: 682, Avg. Train Loss: 0.0378646619617939, Avg. Test Loss: 0.03571966290473938\n",
      "Epoch: 683, Avg. Train Loss: 0.03753520872663049, Avg. Test Loss: 0.03538054972887039\n",
      "Epoch: 684, Avg. Train Loss: 0.037627042698509555, Avg. Test Loss: 0.03541054204106331\n",
      "Epoch: 685, Avg. Train Loss: 0.03717447420691743, Avg. Test Loss: 0.034939903765916824\n",
      "Epoch: 686, Avg. Train Loss: 0.03685856671894298, Avg. Test Loss: 0.034699101001024246\n",
      "Epoch: 687, Avg. Train Loss: 0.03683999899555655, Avg. Test Loss: 0.034748613834381104\n",
      "Epoch: 688, Avg. Train Loss: 0.03599065761355793, Avg. Test Loss: 0.03376953676342964\n",
      "Epoch: 689, Avg. Train Loss: 0.036213239830206426, Avg. Test Loss: 0.03391307219862938\n",
      "Epoch: 690, Avg. Train Loss: 0.03585333436289254, Avg. Test Loss: 0.033779438585042953\n",
      "Epoch: 691, Avg. Train Loss: 0.1153309360584792, Avg. Test Loss: 0.10711665451526642\n",
      "Epoch: 692, Avg. Train Loss: 0.10880032760255477, Avg. Test Loss: 0.10341362655162811\n",
      "Epoch: 693, Avg. Train Loss: 0.12589286548249862, Avg. Test Loss: 0.21454940736293793\n",
      "Epoch: 694, Avg. Train Loss: 0.20431604648337645, Avg. Test Loss: 0.1928865909576416\n",
      "Epoch: 695, Avg. Train Loss: 0.18675183951854707, Avg. Test Loss: 0.17441381514072418\n",
      "Epoch: 696, Avg. Train Loss: 0.1518918349462397, Avg. Test Loss: 0.13969522714614868\n",
      "Epoch: 697, Avg. Train Loss: 0.13633636060883017, Avg. Test Loss: 0.12970580160617828\n",
      "Epoch: 698, Avg. Train Loss: 0.12666937971816344, Avg. Test Loss: 0.12094270437955856\n",
      "Epoch: 699, Avg. Train Loss: 0.11819616871721604, Avg. Test Loss: 0.11359311640262604\n",
      "Epoch: 700, Avg. Train Loss: 0.16966492980718612, Avg. Test Loss: 0.17455682158470154\n",
      "Epoch: 701, Avg. Train Loss: 0.08078646686147241, Avg. Test Loss: 0.06003931164741516\n",
      "Epoch: 702, Avg. Train Loss: 0.05862675230292713, Avg. Test Loss: 0.05576891824603081\n",
      "Epoch: 703, Avg. Train Loss: 0.055017046980998095, Avg. Test Loss: 0.05400600656867027\n",
      "Epoch: 704, Avg. Train Loss: 0.053213182047886005, Avg. Test Loss: 0.05276406928896904\n",
      "Epoch: 705, Avg. Train Loss: 0.0519328913267921, Avg. Test Loss: 0.05202889442443848\n",
      "Epoch: 706, Avg. Train Loss: 0.050912306939854345, Avg. Test Loss: 0.05227234214544296\n",
      "Epoch: 707, Avg. Train Loss: 0.050111834398087335, Avg. Test Loss: 0.05495871603488922\n",
      "Epoch: 708, Avg. Train Loss: 0.04948879708262051, Avg. Test Loss: 0.06444259732961655\n",
      "Epoch: 709, Avg. Train Loss: 0.04897272025837618, Avg. Test Loss: 0.05913691595196724\n",
      "Epoch: 710, Avg. Train Loss: 0.04857360321809264, Avg. Test Loss: 0.05077046900987625\n",
      "Epoch: 711, Avg. Train Loss: 0.048261134238804085, Avg. Test Loss: 0.04813145101070404\n",
      "Epoch: 712, Avg. Train Loss: 0.048120920316261404, Avg. Test Loss: 0.04834815859794617\n",
      "Epoch: 713, Avg. Train Loss: 0.04788856905172853, Avg. Test Loss: 0.0471470020711422\n",
      "Epoch: 714, Avg. Train Loss: 0.04768662535968949, Avg. Test Loss: 0.04655607417225838\n",
      "Epoch: 715, Avg. Train Loss: 0.04752102669547586, Avg. Test Loss: 0.046263981610536575\n",
      "Epoch: 716, Avg. Train Loss: 0.047377970069646835, Avg. Test Loss: 0.04604317247867584\n",
      "Epoch: 717, Avg. Train Loss: 0.04704859265509774, Avg. Test Loss: 0.045765507966279984\n",
      "Epoch: 718, Avg. Train Loss: 0.04680596467326669, Avg. Test Loss: 0.04554248973727226\n",
      "Epoch: 719, Avg. Train Loss: 0.04673741122379022, Avg. Test Loss: 0.04549121856689453\n",
      "Epoch: 720, Avg. Train Loss: 0.04659847910789883, Avg. Test Loss: 0.04534468054771423\n",
      "Epoch: 721, Avg. Train Loss: 0.050210110054296604, Avg. Test Loss: 0.054367564618587494\n",
      "Epoch: 722, Avg. Train Loss: 0.05807592956458821, Avg. Test Loss: 0.04571225494146347\n",
      "Epoch: 723, Avg. Train Loss: 0.047013376346405816, Avg. Test Loss: 0.04544222727417946\n",
      "Epoch: 724, Avg. Train Loss: 0.04674450268640238, Avg. Test Loss: 0.045252725481987\n",
      "Epoch: 725, Avg. Train Loss: 0.04648998782915228, Avg. Test Loss: 0.04504867643117905\n",
      "Epoch: 726, Avg. Train Loss: 0.046234197958427314, Avg. Test Loss: 0.04478541016578674\n",
      "Epoch: 727, Avg. Train Loss: 0.046021461881258906, Avg. Test Loss: 0.04463760182261467\n",
      "Epoch: 728, Avg. Train Loss: 0.04578133711920065, Avg. Test Loss: 0.044434670358896255\n",
      "Epoch: 729, Avg. Train Loss: 0.04557574330007329, Avg. Test Loss: 0.04425570368766785\n",
      "Epoch: 730, Avg. Train Loss: 0.04536905126536594, Avg. Test Loss: 0.04406989738345146\n",
      "Epoch: 731, Avg. Train Loss: 0.045252862572669986, Avg. Test Loss: 0.04403427988290787\n",
      "Epoch: 732, Avg. Train Loss: 0.0451054404325345, Avg. Test Loss: 0.043849363923072815\n",
      "Epoch: 733, Avg. Train Loss: 0.045021611978026, Avg. Test Loss: 0.043871235102415085\n",
      "Epoch: 734, Avg. Train Loss: 0.04493773053674137, Avg. Test Loss: 0.04364706575870514\n",
      "Epoch: 735, Avg. Train Loss: 0.04470487298334346, Avg. Test Loss: 0.04345542937517166\n",
      "Epoch: 736, Avg. Train Loss: 0.044550346144858526, Avg. Test Loss: 0.04330901801586151\n",
      "Epoch: 737, Avg. Train Loss: 0.04430845458717907, Avg. Test Loss: 0.04312313348054886\n",
      "Epoch: 738, Avg. Train Loss: 0.04409591660780065, Avg. Test Loss: 0.04289582371711731\n",
      "Epoch: 739, Avg. Train Loss: 0.046581161372801834, Avg. Test Loss: 0.04451203718781471\n",
      "Epoch: 740, Avg. Train Loss: 0.044948659486630384, Avg. Test Loss: 0.043599192053079605\n",
      "Epoch: 741, Avg. Train Loss: 0.04442741914707072, Avg. Test Loss: 0.043233562260866165\n",
      "Epoch: 742, Avg. Train Loss: 0.04407537338488242, Avg. Test Loss: 0.04291779175400734\n",
      "Epoch: 743, Avg. Train Loss: 0.04374881369226119, Avg. Test Loss: 0.0425800122320652\n",
      "Epoch: 744, Avg. Train Loss: 0.043454714864492414, Avg. Test Loss: 0.04228157550096512\n",
      "Epoch: 745, Avg. Train Loss: 0.0433038418783861, Avg. Test Loss: 0.042305223643779755\n",
      "Epoch: 746, Avg. Train Loss: 0.04316388368606568, Avg. Test Loss: 0.042126454412937164\n",
      "Epoch: 747, Avg. Train Loss: 0.04291626850471777, Avg. Test Loss: 0.04167244955897331\n",
      "Epoch: 748, Avg. Train Loss: 0.0425985851270311, Avg. Test Loss: 0.04066092520952225\n",
      "Epoch: 749, Avg. Train Loss: 0.04142828929950209, Avg. Test Loss: 0.04011309891939163\n",
      "Epoch: 750, Avg. Train Loss: 0.04090004799997105, Avg. Test Loss: 0.03973724693059921\n",
      "Epoch: 751, Avg. Train Loss: 0.04056871301111053, Avg. Test Loss: 0.03944440186023712\n",
      "Epoch: 752, Avg. Train Loss: 0.04034339321010253, Avg. Test Loss: 0.03939419612288475\n",
      "Epoch: 753, Avg. Train Loss: 0.040046241046751245, Avg. Test Loss: 0.03892318531870842\n",
      "Epoch: 754, Avg. Train Loss: 0.039646975739913826, Avg. Test Loss: 0.03864869102835655\n",
      "Epoch: 755, Avg. Train Loss: 0.039639818317749924, Avg. Test Loss: 0.03867236524820328\n",
      "Epoch: 756, Avg. Train Loss: 0.039322100930354174, Avg. Test Loss: 0.038358308374881744\n",
      "Epoch: 757, Avg. Train Loss: 0.038756174068240556, Avg. Test Loss: 0.03769342228770256\n",
      "Epoch: 758, Avg. Train Loss: 0.03864330921102973, Avg. Test Loss: 0.037549544125795364\n",
      "Epoch: 759, Avg. Train Loss: 0.03825438057675081, Avg. Test Loss: 0.03731641545891762\n",
      "Epoch: 760, Avg. Train Loss: 0.03818678912871024, Avg. Test Loss: 0.037325602024793625\n",
      "Epoch: 761, Avg. Train Loss: 0.03780197939452003, Avg. Test Loss: 0.03668708726763725\n",
      "Epoch: 762, Avg. Train Loss: 0.03771153118680505, Avg. Test Loss: 0.036496344953775406\n",
      "Epoch: 763, Avg. Train Loss: 0.03754115284365766, Avg. Test Loss: 0.03631441295146942\n",
      "Epoch: 764, Avg. Train Loss: 0.03746393362388891, Avg. Test Loss: 0.03643031045794487\n",
      "Epoch: 765, Avg. Train Loss: 0.03708979250753627, Avg. Test Loss: 0.03588330000638962\n",
      "Epoch: 766, Avg. Train Loss: 0.036868564258603485, Avg. Test Loss: 0.03552379831671715\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 767, Avg. Train Loss: 0.0359124028507401, Avg. Test Loss: 0.034530334174633026\n",
      "Epoch: 768, Avg. Train Loss: 0.03510734964819515, Avg. Test Loss: 0.03396514058113098\n",
      "Epoch: 769, Avg. Train Loss: 0.0346378286533496, Avg. Test Loss: 0.03348549082875252\n",
      "Epoch: 770, Avg. Train Loss: 0.0342601525652058, Avg. Test Loss: 0.033169399946928024\n",
      "Epoch: 771, Avg. Train Loss: 0.03403070437557557, Avg. Test Loss: 0.033170200884342194\n",
      "Epoch: 772, Avg. Train Loss: 0.033912816556061015, Avg. Test Loss: 0.03327193856239319\n",
      "Epoch: 773, Avg. Train Loss: 0.03316814965184997, Avg. Test Loss: 0.033617496490478516\n",
      "Epoch: 774, Avg. Train Loss: 0.03277190204928903, Avg. Test Loss: 0.03753075748682022\n",
      "Epoch: 775, Avg. Train Loss: 0.0325375487041824, Avg. Test Loss: 0.03393836319446564\n",
      "Epoch: 776, Avg. Train Loss: 0.032763093008714564, Avg. Test Loss: 0.03660227730870247\n",
      "Epoch: 777, Avg. Train Loss: 0.03245907748008475, Avg. Test Loss: 0.03326478973031044\n",
      "Epoch: 778, Avg. Train Loss: 0.03227059459861587, Avg. Test Loss: 0.03206653892993927\n",
      "Epoch: 779, Avg. Train Loss: 0.033310775743687855, Avg. Test Loss: 0.03364378213882446\n",
      "Epoch: 780, Avg. Train Loss: 0.032969985003857054, Avg. Test Loss: 0.03274513781070709\n",
      "Epoch: 781, Avg. Train Loss: 0.03240562933771049, Avg. Test Loss: 0.031816672533750534\n",
      "Epoch: 782, Avg. Train Loss: 0.03209024902214022, Avg. Test Loss: 0.03116053156554699\n",
      "Epoch: 783, Avg. Train Loss: 0.032348791707087966, Avg. Test Loss: 0.03155266121029854\n",
      "Epoch: 784, Avg. Train Loss: 0.032048109699698055, Avg. Test Loss: 0.031035108491778374\n",
      "Epoch: 785, Avg. Train Loss: 0.03184726354392136, Avg. Test Loss: 0.03075133077800274\n",
      "Epoch: 786, Avg. Train Loss: 0.03159968528677436, Avg. Test Loss: 0.030410047620534897\n",
      "Epoch: 787, Avg. Train Loss: 0.03118342498646063, Avg. Test Loss: 0.030067449435591698\n",
      "Epoch: 788, Avg. Train Loss: 0.030909573944175945, Avg. Test Loss: 0.029826369136571884\n",
      "Epoch: 789, Avg. Train Loss: 0.030687325162922635, Avg. Test Loss: 0.02964196167886257\n",
      "Epoch: 790, Avg. Train Loss: 0.030576324835419656, Avg. Test Loss: 0.0295404102653265\n",
      "Epoch: 791, Avg. Train Loss: 0.030453003044514097, Avg. Test Loss: 0.029380634427070618\n",
      "Epoch: 792, Avg. Train Loss: 0.03027028110535706, Avg. Test Loss: 0.029388802126049995\n",
      "Epoch: 793, Avg. Train Loss: 0.030179643148885053, Avg. Test Loss: 0.029215175658464432\n",
      "Epoch: 794, Avg. Train Loss: 0.030109877358464633, Avg. Test Loss: 0.029158243909478188\n",
      "Epoch: 795, Avg. Train Loss: 0.03002304480794598, Avg. Test Loss: 0.029105886816978455\n",
      "Epoch: 796, Avg. Train Loss: 0.030006794960183256, Avg. Test Loss: 0.029026692733168602\n",
      "Epoch: 797, Avg. Train Loss: 0.02991702955435304, Avg. Test Loss: 0.02900037169456482\n",
      "Epoch: 798, Avg. Train Loss: 0.029980091356179295, Avg. Test Loss: 0.02906475029885769\n",
      "Epoch: 799, Avg. Train Loss: 0.02985127121210098, Avg. Test Loss: 0.028880048543214798\n",
      "Epoch: 800, Avg. Train Loss: 0.029872916616937695, Avg. Test Loss: 0.028816526755690575\n",
      "Epoch: 801, Avg. Train Loss: 0.030134499357903705, Avg. Test Loss: 0.028974855318665504\n",
      "Epoch: 802, Avg. Train Loss: 0.029769943807931507, Avg. Test Loss: 0.028773337602615356\n",
      "Epoch: 803, Avg. Train Loss: 0.029721479271264638, Avg. Test Loss: 0.028720008209347725\n",
      "Epoch: 804, Avg. Train Loss: 0.029602442857097178, Avg. Test Loss: 0.028769178315997124\n",
      "Epoch: 805, Avg. Train Loss: 0.029708968738422676, Avg. Test Loss: 0.028611039742827415\n",
      "Epoch: 806, Avg. Train Loss: 0.029489955612841776, Avg. Test Loss: 0.02854822389781475\n",
      "Epoch: 807, Avg. Train Loss: 0.029823574686751647, Avg. Test Loss: 0.02855309471487999\n",
      "Epoch: 808, Avg. Train Loss: 0.02944271437385503, Avg. Test Loss: 0.028443094342947006\n",
      "Epoch: 809, Avg. Train Loss: 0.029398481153389985, Avg. Test Loss: 0.02835940755903721\n",
      "Epoch: 810, Avg. Train Loss: 0.02935071250095087, Avg. Test Loss: 0.028290117159485817\n",
      "Epoch: 811, Avg. Train Loss: 0.029796138318145975, Avg. Test Loss: 0.02881431207060814\n",
      "Epoch: 812, Avg. Train Loss: 0.029567964572240323, Avg. Test Loss: 0.028156418353319168\n",
      "Epoch: 813, Avg. Train Loss: 0.029132516813628814, Avg. Test Loss: 0.027973832562565804\n",
      "Epoch: 814, Avg. Train Loss: 0.028959664351799908, Avg. Test Loss: 0.02800389565527439\n",
      "Epoch: 815, Avg. Train Loss: 0.029331421523409732, Avg. Test Loss: 0.027985060587525368\n",
      "Epoch: 816, Avg. Train Loss: 0.02893585461904021, Avg. Test Loss: 0.027841776609420776\n",
      "Epoch: 817, Avg. Train Loss: 0.029153379622627706, Avg. Test Loss: 0.02871495857834816\n",
      "Epoch: 818, Avg. Train Loss: 0.029612452230032754, Avg. Test Loss: 0.028049346059560776\n",
      "Epoch: 819, Avg. Train Loss: 0.02875814718358657, Avg. Test Loss: 0.027804534882307053\n",
      "Epoch: 820, Avg. Train Loss: 0.028668522155460188, Avg. Test Loss: 0.027555039152503014\n",
      "Epoch: 821, Avg. Train Loss: 0.028550849767292247, Avg. Test Loss: 0.02750958316028118\n",
      "Epoch: 822, Avg. Train Loss: 0.028962873645565088, Avg. Test Loss: 0.03000405803322792\n",
      "Epoch: 823, Avg. Train Loss: 0.03083759947296451, Avg. Test Loss: 0.02890964411199093\n",
      "Epoch: 824, Avg. Train Loss: 0.030045025510823026, Avg. Test Loss: 0.027963176369667053\n",
      "Epoch: 825, Avg. Train Loss: 0.03420388223055531, Avg. Test Loss: 0.030568081885576248\n",
      "Epoch: 826, Avg. Train Loss: 0.031188474310671583, Avg. Test Loss: 0.030352644622325897\n",
      "Epoch: 827, Avg. Train Loss: 0.030142212900168757, Avg. Test Loss: 0.028040915727615356\n",
      "Epoch: 828, Avg. Train Loss: 0.028707553512033294, Avg. Test Loss: 0.027245942503213882\n",
      "Epoch: 829, Avg. Train Loss: 0.028380555725272965, Avg. Test Loss: 0.02728484943509102\n",
      "Epoch: 830, Avg. Train Loss: 0.02832198927507681, Avg. Test Loss: 0.02724691852927208\n",
      "Epoch: 831, Avg. Train Loss: 0.028295182261396858, Avg. Test Loss: 0.02733258157968521\n",
      "Epoch: 832, Avg. Train Loss: 0.02824746092014453, Avg. Test Loss: 0.027342285960912704\n",
      "Epoch: 833, Avg. Train Loss: 0.02944983303108636, Avg. Test Loss: 0.03004542365670204\n",
      "Epoch: 834, Avg. Train Loss: 0.035572748916114075, Avg. Test Loss: 0.029987066984176636\n",
      "Epoch: 835, Avg. Train Loss: 0.029158585233723416, Avg. Test Loss: 0.027278592810034752\n",
      "Epoch: 836, Avg. Train Loss: 0.028225027265794136, Avg. Test Loss: 0.027281668037176132\n",
      "Epoch: 837, Avg. Train Loss: 0.028227424555841613, Avg. Test Loss: 0.027006516233086586\n",
      "Epoch: 838, Avg. Train Loss: 0.028193151534480206, Avg. Test Loss: 0.028607618063688278\n",
      "Epoch: 839, Avg. Train Loss: 0.029689443987958572, Avg. Test Loss: 0.02867950312793255\n",
      "Epoch: 840, Avg. Train Loss: 0.02886370096136542, Avg. Test Loss: 0.0345708467066288\n",
      "Epoch: 841, Avg. Train Loss: 0.02802405800012981, Avg. Test Loss: 0.03634189814329147\n",
      "Epoch: 842, Avg. Train Loss: 0.0278203215011779, Avg. Test Loss: 0.03384549170732498\n",
      "Epoch: 843, Avg. Train Loss: 0.02774592105518369, Avg. Test Loss: 0.03240867331624031\n",
      "Epoch: 844, Avg. Train Loss: 0.027734956167200033, Avg. Test Loss: 0.02810748480260372\n",
      "Epoch: 845, Avg. Train Loss: 0.02770611961536548, Avg. Test Loss: 0.036729101091623306\n",
      "Epoch: 846, Avg. Train Loss: 0.027715265509836814, Avg. Test Loss: 0.032233066856861115\n",
      "Epoch: 847, Avg. Train Loss: 0.027878725769765238, Avg. Test Loss: 0.027121763676404953\n",
      "Epoch: 848, Avg. Train Loss: 0.02777863493298783, Avg. Test Loss: 0.029431208968162537\n",
      "Epoch: 849, Avg. Train Loss: 0.027476133318508372, Avg. Test Loss: 0.02860720083117485\n",
      "Epoch: 850, Avg. Train Loss: 0.02746650328969254, Avg. Test Loss: 0.028664203360676765\n",
      "Epoch: 851, Avg. Train Loss: 0.027434278783552788, Avg. Test Loss: 0.028415367007255554\n",
      "Epoch: 852, Avg. Train Loss: 0.03236428387463093, Avg. Test Loss: 0.027262357994914055\n",
      "Epoch: 853, Avg. Train Loss: 0.02773942907943445, Avg. Test Loss: 0.04555939510464668\n",
      "Epoch: 854, Avg. Train Loss: 0.027373274569125736, Avg. Test Loss: 0.03323867917060852\n",
      "Epoch: 855, Avg. Train Loss: 0.027312953397631644, Avg. Test Loss: 0.033281516283750534\n",
      "Epoch: 856, Avg. Train Loss: 0.02973117383525652, Avg. Test Loss: 0.03448104485869408\n",
      "Epoch: 857, Avg. Train Loss: 0.03112149887225207, Avg. Test Loss: 0.027645720168948174\n",
      "Epoch: 858, Avg. Train Loss: 0.02799545145210098, Avg. Test Loss: 0.027628237381577492\n",
      "Epoch: 859, Avg. Train Loss: 0.028749048140119103, Avg. Test Loss: 0.028847724199295044\n",
      "Epoch: 860, Avg. Train Loss: 0.02822463578161071, Avg. Test Loss: 0.027496734634041786\n",
      "Epoch: 861, Avg. Train Loss: 0.027660091725342412, Avg. Test Loss: 0.02728370577096939\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 862, Avg. Train Loss: 0.027390614765531878, Avg. Test Loss: 0.02705024927854538\n",
      "Epoch: 863, Avg. Train Loss: 0.027641519422040267, Avg. Test Loss: 0.028422055765986443\n",
      "Epoch: 864, Avg. Train Loss: 0.027050053919939435, Avg. Test Loss: 0.028659163042902946\n",
      "Epoch: 865, Avg. Train Loss: 0.02695158367209575, Avg. Test Loss: 0.036175381392240524\n",
      "Epoch: 866, Avg. Train Loss: 0.02694701681680539, Avg. Test Loss: 0.03221527859568596\n",
      "Epoch: 867, Avg. Train Loss: 0.026943664603373583, Avg. Test Loss: 0.029378728941082954\n",
      "Epoch: 868, Avg. Train Loss: 0.02687951845719534, Avg. Test Loss: 0.031777430325746536\n",
      "Epoch: 869, Avg. Train Loss: 0.026808822439873918, Avg. Test Loss: 0.026821346953511238\n",
      "Epoch: 870, Avg. Train Loss: 0.032944046837442065, Avg. Test Loss: 0.06350713223218918\n",
      "Epoch: 871, Avg. Train Loss: 0.2625447452068329, Avg. Test Loss: 0.3108349144458771\n",
      "Epoch: 872, Avg. Train Loss: 0.26374478357679704, Avg. Test Loss: 0.18255464732646942\n",
      "Epoch: 873, Avg. Train Loss: 0.1597137979724828, Avg. Test Loss: 0.11306444555521011\n",
      "Epoch: 874, Avg. Train Loss: 0.11191838585278567, Avg. Test Loss: 0.09804990887641907\n",
      "Epoch: 875, Avg. Train Loss: 0.11734479893656338, Avg. Test Loss: 0.11640401929616928\n",
      "Epoch: 876, Avg. Train Loss: 0.11733503166367026, Avg. Test Loss: 0.11081200838088989\n",
      "Epoch: 877, Avg. Train Loss: 0.10561267032342798, Avg. Test Loss: 0.09143951535224915\n",
      "Epoch: 878, Avg. Train Loss: 0.09152076200527304, Avg. Test Loss: 0.07521933317184448\n",
      "Epoch: 879, Avg. Train Loss: 0.07529158206547008, Avg. Test Loss: 0.07207613438367844\n",
      "Epoch: 880, Avg. Train Loss: 0.07144312994445072, Avg. Test Loss: 0.06955686211585999\n",
      "Epoch: 881, Avg. Train Loss: 0.06840709816007053, Avg. Test Loss: 0.06577973812818527\n",
      "Epoch: 882, Avg. Train Loss: 0.0635283186155207, Avg. Test Loss: 0.06156355142593384\n",
      "Epoch: 883, Avg. Train Loss: 0.05902539820355528, Avg. Test Loss: 0.05806157737970352\n",
      "Epoch: 884, Avg. Train Loss: 0.055486422689522016, Avg. Test Loss: 0.055068761110305786\n",
      "Epoch: 885, Avg. Train Loss: 0.05861017826725455, Avg. Test Loss: 0.06220657005906105\n",
      "Epoch: 886, Avg. Train Loss: 0.06091991829521516, Avg. Test Loss: 0.05247538909316063\n",
      "Epoch: 887, Avg. Train Loss: 0.05156357029781622, Avg. Test Loss: 0.048974499106407166\n",
      "Epoch: 888, Avg. Train Loss: 0.048757061669055156, Avg. Test Loss: 0.04692329466342926\n",
      "Epoch: 889, Avg. Train Loss: 0.04322643056511879, Avg. Test Loss: 0.040838852524757385\n",
      "Epoch: 890, Avg. Train Loss: 0.06179203456815551, Avg. Test Loss: 0.06545938551425934\n",
      "Epoch: 891, Avg. Train Loss: 0.06738542353405672, Avg. Test Loss: 0.06409701704978943\n",
      "Epoch: 892, Avg. Train Loss: 0.07042361213003888, Avg. Test Loss: 0.0687062218785286\n",
      "Epoch: 893, Avg. Train Loss: 0.0700090625706841, Avg. Test Loss: 0.06627362221479416\n",
      "Epoch: 894, Avg. Train Loss: 0.07121399641036988, Avg. Test Loss: 0.05873825401067734\n",
      "Epoch: 895, Avg. Train Loss: 0.05989051917020012, Avg. Test Loss: 0.058121807873249054\n",
      "Epoch: 896, Avg. Train Loss: 0.056628857114735774, Avg. Test Loss: 0.05311186984181404\n",
      "Epoch: 897, Avg. Train Loss: 0.054523433876388215, Avg. Test Loss: 0.05344463139772415\n",
      "Epoch: 898, Avg. Train Loss: 0.0487114823258975, Avg. Test Loss: 0.03503758832812309\n",
      "Epoch: 899, Avg. Train Loss: 0.03402899722842609, Avg. Test Loss: 0.03452332317829132\n",
      "Epoch: 900, Avg. Train Loss: 0.03375150434234563, Avg. Test Loss: 0.034696828573942184\n",
      "Epoch: 901, Avg. Train Loss: 0.03329868822851602, Avg. Test Loss: 0.03286828100681305\n",
      "Epoch: 902, Avg. Train Loss: 0.03291767940801733, Avg. Test Loss: 0.03204527497291565\n",
      "Epoch: 903, Avg. Train Loss: 0.03365113599335446, Avg. Test Loss: 0.033755142241716385\n",
      "Epoch: 904, Avg. Train Loss: 0.03295961164814584, Avg. Test Loss: 0.03196258470416069\n",
      "Epoch: 905, Avg. Train Loss: 0.03242985089035595, Avg. Test Loss: 0.03190465271472931\n",
      "Epoch: 906, Avg. Train Loss: 0.03314474150538445, Avg. Test Loss: 0.03226538002490997\n",
      "Epoch: 907, Avg. Train Loss: 0.03191291972556535, Avg. Test Loss: 0.03105277754366398\n",
      "Epoch: 908, Avg. Train Loss: 0.03152892600525828, Avg. Test Loss: 0.030693138018250465\n",
      "Epoch: 909, Avg. Train Loss: 0.03157958467217053, Avg. Test Loss: 0.030859943479299545\n",
      "Epoch: 910, Avg. Train Loss: 0.03139704722253715, Avg. Test Loss: 0.030599243938922882\n",
      "Epoch: 911, Avg. Train Loss: 0.03126335672157652, Avg. Test Loss: 0.030665958300232887\n",
      "Epoch: 912, Avg. Train Loss: 0.031188804261824663, Avg. Test Loss: 0.030384106561541557\n",
      "Epoch: 913, Avg. Train Loss: 0.031125685200095177, Avg. Test Loss: 0.03011799231171608\n",
      "Epoch: 914, Avg. Train Loss: 0.031020471322185852, Avg. Test Loss: 0.03015938214957714\n",
      "Epoch: 915, Avg. Train Loss: 0.030988467922982047, Avg. Test Loss: 0.02999762073159218\n",
      "Epoch: 916, Avg. Train Loss: 0.031080675716785824, Avg. Test Loss: 0.02998773381114006\n",
      "Epoch: 917, Avg. Train Loss: 0.03090012255398666, Avg. Test Loss: 0.029548315331339836\n",
      "Epoch: 918, Avg. Train Loss: 0.03127394741510644, Avg. Test Loss: 0.03109436109662056\n",
      "Epoch: 919, Avg. Train Loss: 0.029266830533742905, Avg. Test Loss: 0.030710944905877113\n",
      "Epoch: 920, Avg. Train Loss: 0.0290381339543006, Avg. Test Loss: 0.029029976576566696\n",
      "Epoch: 921, Avg. Train Loss: 0.02888648985501598, Avg. Test Loss: 0.028700141236186028\n",
      "Epoch: 922, Avg. Train Loss: 0.02888257777427926, Avg. Test Loss: 0.029152827337384224\n",
      "Epoch: 923, Avg. Train Loss: 0.028793832089971095, Avg. Test Loss: 0.02854243852198124\n",
      "Epoch: 924, Avg. Train Loss: 0.02865212277016219, Avg. Test Loss: 0.02832556888461113\n",
      "Epoch: 925, Avg. Train Loss: 0.02857718277065193, Avg. Test Loss: 0.028177954256534576\n",
      "Epoch: 926, Avg. Train Loss: 0.02851100605638588, Avg. Test Loss: 0.028090402483940125\n",
      "Epoch: 927, Avg. Train Loss: 0.028456861394293168, Avg. Test Loss: 0.028060758486390114\n",
      "Epoch: 928, Avg. Train Loss: 0.028389009241672123, Avg. Test Loss: 0.028027381747961044\n",
      "Epoch: 929, Avg. Train Loss: 0.02832112820709453, Avg. Test Loss: 0.027962876483798027\n",
      "Epoch: 930, Avg. Train Loss: 0.02831254371387117, Avg. Test Loss: 0.02783001773059368\n",
      "Epoch: 931, Avg. Train Loss: 0.02821232661166612, Avg. Test Loss: 0.027924712747335434\n",
      "Epoch: 932, Avg. Train Loss: 0.028073767484987484, Avg. Test Loss: 0.027509698644280434\n",
      "Epoch: 933, Avg. Train Loss: 0.028062969248961, Avg. Test Loss: 0.027473503723740578\n",
      "Epoch: 934, Avg. Train Loss: 0.027964811947415857, Avg. Test Loss: 0.027304096147418022\n",
      "Epoch: 935, Avg. Train Loss: 0.028035219057517893, Avg. Test Loss: 0.027175303548574448\n",
      "Epoch: 936, Avg. Train Loss: 0.02795460454243071, Avg. Test Loss: 0.02710770256817341\n",
      "Epoch: 937, Avg. Train Loss: 0.0278664169504362, Avg. Test Loss: 0.02728731743991375\n",
      "Epoch: 938, Avg. Train Loss: 0.027835295809542433, Avg. Test Loss: 0.027143752202391624\n",
      "Epoch: 939, Avg. Train Loss: 0.027759995158104334, Avg. Test Loss: 0.026990579441189766\n",
      "Epoch: 940, Avg. Train Loss: 0.027736203569699736, Avg. Test Loss: 0.026930121704936028\n",
      "Epoch: 941, Avg. Train Loss: 0.02769609041073743, Avg. Test Loss: 0.026972364634275436\n",
      "Epoch: 942, Avg. Train Loss: 0.02771154429544421, Avg. Test Loss: 0.026759779080748558\n",
      "Epoch: 943, Avg. Train Loss: 0.027624918827239206, Avg. Test Loss: 0.02677765302360058\n",
      "Epoch: 944, Avg. Train Loss: 0.027567194796660366, Avg. Test Loss: 0.026742029935121536\n",
      "Epoch: 945, Avg. Train Loss: 0.027512202433803503, Avg. Test Loss: 0.02686239778995514\n",
      "Epoch: 946, Avg. Train Loss: 0.027549032428685356, Avg. Test Loss: 0.02666940912604332\n",
      "Epoch: 947, Avg. Train Loss: 0.02753438743598321, Avg. Test Loss: 0.02661299891769886\n",
      "Epoch: 948, Avg. Train Loss: 0.02744295445873457, Avg. Test Loss: 0.02664344385266304\n",
      "Epoch: 949, Avg. Train Loss: 0.027381362327758004, Avg. Test Loss: 0.02672881819307804\n",
      "Epoch: 950, Avg. Train Loss: 0.027438375770169145, Avg. Test Loss: 0.026511622592806816\n",
      "Epoch: 951, Avg. Train Loss: 0.027324415546129733, Avg. Test Loss: 0.026423409581184387\n",
      "Epoch: 952, Avg. Train Loss: 0.027295802117270583, Avg. Test Loss: 0.02642221935093403\n",
      "Epoch: 953, Avg. Train Loss: 0.027176440309952286, Avg. Test Loss: 0.026295317336916924\n",
      "Epoch: 954, Avg. Train Loss: 0.02716645046192057, Avg. Test Loss: 0.02633420005440712\n",
      "Epoch: 955, Avg. Train Loss: 0.027653602203902075, Avg. Test Loss: 0.026350460946559906\n",
      "Epoch: 956, Avg. Train Loss: 0.02717873096904334, Avg. Test Loss: 0.026371508836746216\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 957, Avg. Train Loss: 0.027174831576207106, Avg. Test Loss: 0.026273181661963463\n",
      "Epoch: 958, Avg. Train Loss: 0.027068404283593684, Avg. Test Loss: 0.026181431487202644\n",
      "Epoch: 959, Avg. Train Loss: 0.027030954970156444, Avg. Test Loss: 0.026151416823267937\n",
      "Epoch: 960, Avg. Train Loss: 0.0513663327869247, Avg. Test Loss: 0.07219996303319931\n",
      "Epoch: 961, Avg. Train Loss: 0.04720790692988564, Avg. Test Loss: 0.03150947391986847\n",
      "Epoch: 962, Avg. Train Loss: 0.034815187511198664, Avg. Test Loss: 0.028654171153903008\n",
      "Epoch: 963, Avg. Train Loss: 0.10171418742221945, Avg. Test Loss: 0.2154683917760849\n",
      "Epoch: 964, Avg. Train Loss: 0.20270251982352314, Avg. Test Loss: 0.24059435725212097\n",
      "Epoch: 965, Avg. Train Loss: 0.18259634813841652, Avg. Test Loss: 0.16912822425365448\n",
      "Epoch: 966, Avg. Train Loss: 0.1659267476376365, Avg. Test Loss: 0.16663233935832977\n",
      "Epoch: 967, Avg. Train Loss: 0.1630358298035229, Avg. Test Loss: 0.16201378405094147\n",
      "Epoch: 968, Avg. Train Loss: 0.1592756352003883, Avg. Test Loss: 0.1631183624267578\n",
      "Epoch: 969, Avg. Train Loss: 0.1525148728314568, Avg. Test Loss: 0.14760054647922516\n",
      "Epoch: 970, Avg. Train Loss: 0.1497016298420289, Avg. Test Loss: 0.1485944390296936\n",
      "Epoch: 971, Avg. Train Loss: 0.1526815126047415, Avg. Test Loss: 0.08271559327840805\n",
      "Epoch: 972, Avg. Train Loss: 0.06538361113737612, Avg. Test Loss: 0.0502006858587265\n",
      "Epoch: 973, Avg. Train Loss: 0.05666752462001408, Avg. Test Loss: 0.04418816789984703\n",
      "Epoch: 974, Avg. Train Loss: 0.045027384512564717, Avg. Test Loss: 0.04127317667007446\n",
      "Epoch: 975, Avg. Train Loss: 0.04206682671518887, Avg. Test Loss: 0.03873836621642113\n",
      "Epoch: 976, Avg. Train Loss: 0.0407015303040252, Avg. Test Loss: 0.0382065586745739\n",
      "Epoch: 977, Avg. Train Loss: 0.045091932047815884, Avg. Test Loss: 0.04253627732396126\n",
      "Epoch: 978, Avg. Train Loss: 0.04325343493153067, Avg. Test Loss: 0.03992912545800209\n",
      "Epoch: 979, Avg. Train Loss: 0.04081489678253146, Avg. Test Loss: 0.0382598377764225\n",
      "Epoch: 980, Avg. Train Loss: 0.03922222721226075, Avg. Test Loss: 0.036964621394872665\n",
      "Epoch: 981, Avg. Train Loss: 0.038483046017148914, Avg. Test Loss: 0.036090586334466934\n",
      "Epoch: 982, Avg. Train Loss: 0.0378424634828287, Avg. Test Loss: 0.035420339554548264\n",
      "Epoch: 983, Avg. Train Loss: 0.03720145562992377, Avg. Test Loss: 0.035177573561668396\n",
      "Epoch: 984, Avg. Train Loss: 0.036720861165839086, Avg. Test Loss: 0.03462504222989082\n",
      "Epoch: 985, Avg. Train Loss: 0.03598297032363275, Avg. Test Loss: 0.04990386590361595\n",
      "Epoch: 986, Avg. Train Loss: 0.03547035771257737, Avg. Test Loss: 0.033472806215286255\n",
      "Epoch: 987, Avg. Train Loss: 0.034822397547609664, Avg. Test Loss: 0.03304923325777054\n",
      "Epoch: 988, Avg. Train Loss: 0.03420530818402767, Avg. Test Loss: 0.032599445432424545\n",
      "Epoch: 989, Avg. Train Loss: 0.03373007305404719, Avg. Test Loss: 0.031994156539440155\n",
      "Epoch: 990, Avg. Train Loss: 0.036280882095589356, Avg. Test Loss: 0.04793499410152435\n",
      "Epoch: 991, Avg. Train Loss: 0.05146772848332629, Avg. Test Loss: 0.0485793836414814\n",
      "Epoch: 992, Avg. Train Loss: 0.11779748205752934, Avg. Test Loss: 0.08450234681367874\n",
      "Epoch: 993, Avg. Train Loss: 0.09210410214522306, Avg. Test Loss: 0.08492320775985718\n",
      "Epoch: 994, Avg. Train Loss: 0.07800722494721413, Avg. Test Loss: 0.07097947597503662\n",
      "Epoch: 995, Avg. Train Loss: 0.06929187695769702, Avg. Test Loss: 0.06778275966644287\n",
      "Epoch: 996, Avg. Train Loss: 0.06523412571233862, Avg. Test Loss: 0.05949128419160843\n",
      "Epoch: 997, Avg. Train Loss: 0.05599257485831485, Avg. Test Loss: 0.04653947427868843\n",
      "Epoch: 998, Avg. Train Loss: 0.04772070852272651, Avg. Test Loss: 0.04499433562159538\n",
      "Epoch: 999, Avg. Train Loss: 0.046015999334699964, Avg. Test Loss: 0.04412544146180153\n",
      "Epoch: 1000, Avg. Train Loss: 0.045486365828443974, Avg. Test Loss: 0.0436486192047596\n",
      "Epoch: 1001, Avg. Train Loss: 0.04517190381884575, Avg. Test Loss: 0.04339718073606491\n",
      "Epoch: 1002, Avg. Train Loss: 0.04466144438175594, Avg. Test Loss: 0.042909156531095505\n",
      "Epoch: 1003, Avg. Train Loss: 0.044560718010453616, Avg. Test Loss: 0.0429011769592762\n",
      "Epoch: 1004, Avg. Train Loss: 0.04408091389957596, Avg. Test Loss: 0.042496584355831146\n",
      "Epoch: 1005, Avg. Train Loss: 0.05516787942718057, Avg. Test Loss: 0.061172399669885635\n",
      "Epoch: 1006, Avg. Train Loss: 0.06035048646085402, Avg. Test Loss: 0.05833035334944725\n",
      "Epoch: 1007, Avg. Train Loss: 0.057262318099246305, Avg. Test Loss: 0.06176221743226051\n",
      "Epoch: 1008, Avg. Train Loss: 0.06543441024773261, Avg. Test Loss: 0.11415845900774002\n",
      "Epoch: 1009, Avg. Train Loss: 0.09285398826879614, Avg. Test Loss: 0.09242594987154007\n",
      "Epoch: 1010, Avg. Train Loss: 0.11602788874331643, Avg. Test Loss: 0.10282627493143082\n",
      "Epoch: 1011, Avg. Train Loss: 0.10518700121080174, Avg. Test Loss: 0.09129245579242706\n",
      "Epoch: 1012, Avg. Train Loss: 0.09066663568510729, Avg. Test Loss: 0.08864717930555344\n",
      "Epoch: 1013, Avg. Train Loss: 0.08819182900821461, Avg. Test Loss: 0.08698230236768723\n",
      "Epoch: 1014, Avg. Train Loss: 0.08642356991767883, Avg. Test Loss: 0.08463075757026672\n",
      "Epoch: 1015, Avg. Train Loss: 0.08653692848542158, Avg. Test Loss: 0.08640435338020325\n",
      "Epoch: 1016, Avg. Train Loss: 0.08509077981990927, Avg. Test Loss: 0.08350881934165955\n",
      "Epoch: 1017, Avg. Train Loss: 0.08331352218109019, Avg. Test Loss: 0.08178385347127914\n",
      "Epoch: 1018, Avg. Train Loss: 0.08432777050663443, Avg. Test Loss: 0.08409345149993896\n",
      "Epoch: 1019, Avg. Train Loss: 0.08326373319415485, Avg. Test Loss: 0.08254699409008026\n",
      "Epoch: 1020, Avg. Train Loss: 0.08233296573162079, Avg. Test Loss: 0.0824097990989685\n",
      "Epoch: 1021, Avg. Train Loss: 0.08197760424193214, Avg. Test Loss: 0.08097048848867416\n",
      "Epoch: 1022, Avg. Train Loss: 0.08202598279013354, Avg. Test Loss: 0.08047809451818466\n",
      "Epoch: 1023, Avg. Train Loss: 0.08247702139265398, Avg. Test Loss: 0.08442553877830505\n",
      "Epoch: 1024, Avg. Train Loss: 0.08312095403671264, Avg. Test Loss: 0.08182761818170547\n",
      "Epoch: 1025, Avg. Train Loss: 0.08167203550829608, Avg. Test Loss: 0.07929099351167679\n",
      "Epoch: 1026, Avg. Train Loss: 0.07962179569637075, Avg. Test Loss: 0.07591870427131653\n",
      "Epoch: 1027, Avg. Train Loss: 0.07572004716185962, Avg. Test Loss: 0.07314851880073547\n",
      "Epoch: 1028, Avg. Train Loss: 0.07422438132412293, Avg. Test Loss: 0.06968795508146286\n",
      "Epoch: 1029, Avg. Train Loss: 0.06954699382185936, Avg. Test Loss: 0.06675253063440323\n",
      "Epoch: 1030, Avg. Train Loss: 0.06737762544961537, Avg. Test Loss: 0.06712193042039871\n",
      "Epoch: 1031, Avg. Train Loss: 0.06583313990165206, Avg. Test Loss: 0.09475842863321304\n",
      "Epoch: 1032, Avg. Train Loss: 0.06578893258291132, Avg. Test Loss: 0.06247469782829285\n",
      "Epoch: 1033, Avg. Train Loss: 0.062161266321645064, Avg. Test Loss: 0.06100504845380783\n",
      "Epoch: 1034, Avg. Train Loss: 0.05866904657553224, Avg. Test Loss: 0.05558153986930847\n",
      "Epoch: 1035, Avg. Train Loss: 0.05549273188499843, Avg. Test Loss: 0.05476702004671097\n",
      "Epoch: 1036, Avg. Train Loss: 0.05460291154244367, Avg. Test Loss: 0.053812555968761444\n",
      "Epoch: 1037, Avg. Train Loss: 0.05473797194221441, Avg. Test Loss: 0.05335669219493866\n",
      "Epoch: 1038, Avg. Train Loss: 0.05632421497036429, Avg. Test Loss: 0.05456884205341339\n",
      "Epoch: 1039, Avg. Train Loss: 0.05502628035405103, Avg. Test Loss: 0.053334519267082214\n",
      "Epoch: 1040, Avg. Train Loss: 0.05390267705216127, Avg. Test Loss: 0.052235014736652374\n",
      "Epoch: 1041, Avg. Train Loss: 0.05283362247488078, Avg. Test Loss: 0.05088134855031967\n",
      "Epoch: 1042, Avg. Train Loss: 0.05235488550627933, Avg. Test Loss: 0.0507744662463665\n",
      "Epoch: 1043, Avg. Train Loss: 0.05229688589187229, Avg. Test Loss: 0.051368676126003265\n",
      "Epoch: 1044, Avg. Train Loss: 0.0522850216311567, Avg. Test Loss: 0.05051262304186821\n",
      "Epoch: 1045, Avg. Train Loss: 0.05091908004354028, Avg. Test Loss: 0.04573730751872063\n",
      "Epoch: 1046, Avg. Train Loss: 0.047597347594359345, Avg. Test Loss: 0.0448705330491066\n",
      "Epoch: 1047, Avg. Train Loss: 0.04654532732332454, Avg. Test Loss: 0.044199660420417786\n",
      "Epoch: 1048, Avg. Train Loss: 0.04575456135413226, Avg. Test Loss: 0.042898695915937424\n",
      "Epoch: 1049, Avg. Train Loss: 0.04456354318296208, Avg. Test Loss: 0.04270952194929123\n",
      "Epoch: 1050, Avg. Train Loss: 0.044041629968320624, Avg. Test Loss: 0.0423172190785408\n",
      "Epoch: 1051, Avg. Train Loss: 0.04353078279425116, Avg. Test Loss: 0.04169932007789612\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1052, Avg. Train Loss: 0.043085678973618674, Avg. Test Loss: 0.04170209541916847\n",
      "Epoch: 1053, Avg. Train Loss: 0.042988208023940815, Avg. Test Loss: 0.04181993752717972\n",
      "Epoch: 1054, Avg. Train Loss: 0.04334792144158307, Avg. Test Loss: 0.041320230811834335\n",
      "Epoch: 1055, Avg. Train Loss: 0.042562334590098436, Avg. Test Loss: 0.040647804737091064\n",
      "Epoch: 1056, Avg. Train Loss: 0.04186460143503021, Avg. Test Loss: 0.04021194204688072\n",
      "Epoch: 1057, Avg. Train Loss: 0.0415333108866916, Avg. Test Loss: 0.0408003032207489\n",
      "Epoch: 1058, Avg. Train Loss: 0.04401165238198112, Avg. Test Loss: 0.041369907557964325\n",
      "Epoch: 1059, Avg. Train Loss: 0.042695323991424894, Avg. Test Loss: 0.04034636169672012\n",
      "Epoch: 1060, Avg. Train Loss: 0.0416789085330332, Avg. Test Loss: 0.03969147056341171\n",
      "Epoch: 1061, Avg. Train Loss: 0.04104662305291961, Avg. Test Loss: 0.039222344756126404\n",
      "Epoch: 1062, Avg. Train Loss: 0.040509801379898014, Avg. Test Loss: 0.03857220336794853\n",
      "Epoch: 1063, Avg. Train Loss: 0.03996422575677142, Avg. Test Loss: 0.03803910315036774\n",
      "Epoch: 1064, Avg. Train Loss: 0.039298646283500334, Avg. Test Loss: 0.03736887127161026\n",
      "Epoch: 1065, Avg. Train Loss: 0.03890299827736967, Avg. Test Loss: 0.03717697039246559\n",
      "Epoch: 1066, Avg. Train Loss: 0.04836029265733326, Avg. Test Loss: 0.03999927267432213\n",
      "Epoch: 1067, Avg. Train Loss: 0.03923448061241823, Avg. Test Loss: 0.03830477595329285\n",
      "Epoch: 1068, Avg. Train Loss: 0.037966222841950024, Avg. Test Loss: 0.036959245800971985\n",
      "Epoch: 1069, Avg. Train Loss: 0.03693442221950082, Avg. Test Loss: 0.03606681898236275\n",
      "Epoch: 1070, Avg. Train Loss: 0.03643650651416358, Avg. Test Loss: 0.0365229994058609\n",
      "Epoch: 1071, Avg. Train Loss: 0.03592404381317251, Avg. Test Loss: 0.035134270787239075\n",
      "Epoch: 1072, Avg. Train Loss: 0.03550056078854729, Avg. Test Loss: 0.034541528671979904\n",
      "Epoch: 1073, Avg. Train Loss: 0.03690640003803898, Avg. Test Loss: 0.03600504994392395\n",
      "Epoch: 1074, Avg. Train Loss: 0.03585772001568009, Avg. Test Loss: 0.03455810248851776\n",
      "Epoch: 1075, Avg. Train Loss: 0.03467424820889445, Avg. Test Loss: 0.0338834673166275\n",
      "Epoch: 1076, Avg. Train Loss: 0.03423317830790492, Avg. Test Loss: 0.03460204601287842\n",
      "Epoch: 1077, Avg. Train Loss: 0.03341332305880154, Avg. Test Loss: 0.03208427131175995\n",
      "Epoch: 1078, Avg. Train Loss: 0.032949493562473973, Avg. Test Loss: 0.031779784709215164\n",
      "Epoch: 1079, Avg. Train Loss: 0.032947222143411635, Avg. Test Loss: 0.03167086839675903\n",
      "Epoch: 1080, Avg. Train Loss: 0.03327326196081498, Avg. Test Loss: 0.032000523060560226\n",
      "Epoch: 1081, Avg. Train Loss: 0.033175252662862045, Avg. Test Loss: 0.03191422298550606\n",
      "Epoch: 1082, Avg. Train Loss: 0.032729304625707514, Avg. Test Loss: 0.031380873173475266\n",
      "Epoch: 1083, Avg. Train Loss: 0.03245327878086006, Avg. Test Loss: 0.031154803931713104\n",
      "Epoch: 1084, Avg. Train Loss: 0.03228014065500568, Avg. Test Loss: 0.030981549993157387\n",
      "Epoch: 1085, Avg. Train Loss: 0.03215393978444969, Avg. Test Loss: 0.03028937801718712\n",
      "Epoch: 1086, Avg. Train Loss: 0.0315962450030972, Avg. Test Loss: 0.029930537566542625\n",
      "Epoch: 1087, Avg. Train Loss: 0.031082741653217987, Avg. Test Loss: 0.029782546684145927\n",
      "Epoch: 1088, Avg. Train Loss: 0.030956187164958786, Avg. Test Loss: 0.02966749109327793\n",
      "Epoch: 1089, Avg. Train Loss: 0.03084785622708938, Avg. Test Loss: 0.029704434797167778\n",
      "Epoch: 1090, Avg. Train Loss: 0.030740628435331232, Avg. Test Loss: 0.02958589792251587\n",
      "Epoch: 1091, Avg. Train Loss: 0.03059443938819801, Avg. Test Loss: 0.029450267553329468\n",
      "Epoch: 1092, Avg. Train Loss: 0.03048513956806239, Avg. Test Loss: 0.029353076592087746\n",
      "Epoch: 1093, Avg. Train Loss: 0.030405431087402738, Avg. Test Loss: 0.02959485538303852\n",
      "Epoch: 1094, Avg. Train Loss: 0.0306238834910533, Avg. Test Loss: 0.03318559750914574\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-cbfffbb35a24>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mnum_batches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;31m# get the input images and their corresponding labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/torch_cuda9/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/torch_cuda9/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    559\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/torch_cuda9/lib/python3.6/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.conda/envs/torch_cuda9/lib/python3.6/site-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'each element in list of batch should be of equal size'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0mtransposed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdefault_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefault_collate_err_msg_format\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/torch_cuda9/lib/python3.6/site-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'each element in list of batch should be of equal size'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0mtransposed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdefault_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefault_collate_err_msg_format\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/torch_cuda9/lib/python3.6/site-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mstorage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new_shared\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0melem_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__module__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'numpy'\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0melem_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'str_'\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0melem_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'string_'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Now let's train the initial network \n",
    "\n",
    "model = offCenterLineNet()\n",
    "model = model.to(dev)\n",
    "model.apply(weights_init_uniform)\n",
    "\n",
    "model.train();\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=.01) \n",
    "# scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=500, gamma=0.1)\n",
    "\n",
    "n_epochs = 2400\n",
    "\n",
    "mse_loss = nn.MSELoss()\n",
    "ce_loss = nn.CrossEntropyLoss()\n",
    "\n",
    "for epoch in range(0,n_epochs):  # loop over the dataset multiple times\n",
    "    \n",
    "    if epoch == 0:\n",
    "        train_loss_over_time = [] # to track the loss as the network trains\n",
    "        test_loss_over_time = []\n",
    "        \n",
    "    if epoch == 5:\n",
    "        optimizer = torch.optim.Adam(model.parameters(),lr=.001) \n",
    "        \n",
    "        \n",
    "    running_loss = 0\n",
    "    num_batches = 0\n",
    "    \n",
    "    for batch_i, data in enumerate(train_loader):\n",
    "        \n",
    "        # get the input images and their corresponding labels\n",
    "        num_batches += 1\n",
    "\n",
    "        inputs, output_gt, _, _ = data\n",
    "        inputs, output_gt = inputs.to(dev), output_gt.to(dev)\n",
    "        \n",
    "        # zero the parameter (weight) gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # forward pass to get outputs\n",
    "        output_line_params = model(inputs)\n",
    "        \n",
    "\n",
    "        # make the ground truth\n",
    "        c = -output_gt[:,2]*torch.cos(output_gt[:,0]) + output_gt[:,1]*torch.sin(output_gt[:,0])\n",
    "        gt_line_params = torch.stack((-torch.sin(output_gt[:,0]),torch.cos(output_gt[:,0]),c),dim=1)\n",
    "        \n",
    "        # calculate the loss\n",
    "#         print(output_line_params[:,:,0,50])\n",
    "        \n",
    "        loss = mse_loss(output_line_params,gt_line_params)\n",
    "        \n",
    "        # backward pass to calculate the parameter gradients\n",
    "        loss.backward()\n",
    "\n",
    "        # update the parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        # to convert loss into a scalar and add it to running_loss, we use .item()\n",
    "        running_loss += loss.item()\n",
    "      \n",
    "\n",
    "#     scheduler.step()\n",
    "    \n",
    "    # Calculate test data loss after each epoch\n",
    "    with torch.no_grad():\n",
    "        test_loss = 0\n",
    "        num_batches_test = 0\n",
    "        for batch_i, data in enumerate(test_loader):\n",
    "            num_batches_test += 1\n",
    "\n",
    "            # Add code here\n",
    "            inputs, output_gt, _, _ = data\n",
    "            inputs, output_gt = inputs.to(dev), output_gt.to(dev)\n",
    "\n",
    "\n",
    "            # zero the parameter (weight) gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward pass to get outputs\n",
    "            output_line_params = model(inputs)\n",
    "\n",
    "            # make the ground truth\n",
    "            c = -output_gt[:,2]*torch.cos(output_gt[:,0]) + output_gt[:,1]*torch.sin(output_gt[:,0])\n",
    "            gt_line_params = torch.stack((-torch.sin(output_gt[:,0]),torch.cos(output_gt[:,0]),c),dim=1)\n",
    "    \n",
    "\n",
    "            # calculate the loss\n",
    "    #         print(output_line_params[:,:,0,50])\n",
    "\n",
    "            loss = mse_loss(output_line_params,gt_line_params)\n",
    "            \n",
    "            test_loss += loss\n",
    "                    \n",
    "        test_loss_over_time.append(test_loss/num_batches_test)\n",
    "\n",
    "    # Calculate model loss:\n",
    "    avg_loss = running_loss/num_batches\n",
    "    train_loss_over_time.append(avg_loss)\n",
    "    \n",
    "#     print('Epoch: {}, Avg. Train Loss: {},'.format(epoch + 1, train_loss_over_time[-1]))\n",
    "\n",
    "\n",
    "    print('Epoch: {}, Avg. Train Loss: {}, Avg. Test Loss: {}'.format(epoch + 1, train_loss_over_time[-1], test_loss_over_time[-1]))\n",
    "    \n",
    "print('Finished Training')\n",
    "\n",
    "plt.figure()\n",
    "plt.semilogy(np.arange(0,n_epochs),train_loss_over_time[0:])\n",
    "plt.semilogy(np.arange(0,n_epochs),test_loss_over_time[0:])\n",
    "plt.legend(['Training loss', 'Testing loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d6f63287",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor(8.8662), tensor(8.0923), tensor(8.9567), tensor(8.9602), tensor(8.8223), tensor(8.0413), tensor(8.4526), tensor(9.4679), tensor(8.9621), tensor(9.9734), tensor(9.0215), tensor(8.7702), tensor(9.3271), tensor(8.7216), tensor(8.8626), tensor(9.1375), tensor(8.9578), tensor(9.0916), tensor(9.0248), tensor(8.5992), tensor(7.7984), tensor(9.0774), tensor(9.3534), tensor(8.4078), tensor(9.5434), tensor(8.9704), tensor(9.5357), tensor(9.7880), tensor(9.1081), tensor(9.6935)]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1080 with 9 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the Results\n",
    "\n",
    "model.eval();\n",
    "\n",
    "ang_loss_all = []\n",
    "\n",
    "for batch_i, data in enumerate(test_loader):\n",
    "    # get the input images and their corresponding labels\n",
    "    inputs, output_gt, _, _ = data\n",
    "    inputs, output_gt = inputs.to(dev), output_gt.to(dev)\n",
    "    \n",
    "\n",
    "    # forward pass to get outputs\n",
    "    outputs = model(inputs).squeeze().detach().cpu()\n",
    "    \n",
    "    gt = output_gt.cpu().squeeze()\n",
    "    \n",
    "    c = -output_gt[:,2]*torch.cos(output_gt[:,0]) + output_gt[:,1]*torch.sin(output_gt[:,0])\n",
    "    angle_params = torch.stack((-torch.sin(output_gt[:,0]),torch.cos(output_gt[:,0]),c),axis=1).detach().cpu()\n",
    "  \n",
    "    # Calculate angular loss\n",
    "    ang_loss = torch.mean(torch.abs(torch.rad2deg(torch.atan2(-angle_params[:,0]*outputs[:,1] + angle_params[:,1]*outputs[:,0]\n",
    "                                         ,angle_params[:,1]*outputs[:,1]+angle_params[:,0]*outputs[:,0]).cpu())))\n",
    "\n",
    "    ang_loss_all.append(ang_loss)\n",
    "\n",
    "    \n",
    "print(ang_loss_all)\n",
    "\n",
    "plt.figure(figsize=[15, 15])\n",
    "\n",
    "for ii in range(9):\n",
    "    \n",
    "    plt.subplot(3,3,ii+1)\n",
    "    plt.imshow(inputs[ii].cpu().squeeze(),cmap='gray', vmin=0, vmax=1)\n",
    "    \n",
    "    # Plot the ground truth lines\n",
    "    x_sample = torch.linspace(-1,1,inputs.shape[-1])\n",
    "    y_sample = -angle_params[ii,0]/angle_params[ii,1]*x_sample - angle_params[ii,2]/angle_params[ii,1]\n",
    "    \n",
    "    plt.plot(x_sample*W/2+W/2,y_sample*W/2+W/2,'b')\n",
    "    plt.xlim([0,W])\n",
    "    plt.ylim(([0,W]))\n",
    "    \n",
    "    # Plot the estimated lines\n",
    "    y_est = -outputs[ii,0]/outputs[ii,1]*x_sample - outputs[ii,2]/outputs[ii,1]\n",
    "    plt.plot(x_sample*W/2+W/2,y_est*W/2+W/2,'r')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51b3f2b3",
   "metadata": {},
   "source": [
    "# 3x3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "50ad23a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1080 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load dataset \n",
    "\n",
    "data_folder = 'foj_data/grayscale_lines/'\n",
    "\n",
    "with open(data_folder + 'line_data_3_50000_grey_bicolor_noiseless_uncentered.pkl','rb') as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "# wedges = data['wedges']\n",
    "wedges_grey = data['wedges_grey']\n",
    "params = data['params']\n",
    "boundaries = data['boundaries']\n",
    "wedges = data['wedges']\n",
    "\n",
    "\n",
    "line_data = LineDataset(wedges_grey, params, boundaries, wedges)#, transform=trainTransform)\n",
    "data_size = len(line_data)\n",
    "\n",
    "print(data_size)\n",
    "\n",
    "train_proportion = .85\n",
    "# Split dataset into training and testing\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(line_data, [int(data_size*train_proportion), int(data_size*(1-train_proportion))], generator=torch.Generator().manual_seed(42))\n",
    "\n",
    "# Create loaders for the training and testing data\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=1000, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=500, shuffle=False) #len(test_dataset)\n",
    "\n",
    "\n",
    "W,H = 3,3\n",
    "\n",
    "img_show = 1\n",
    "plt.figure(figsize=[15, 15])\n",
    "plt.subplot(131)\n",
    "plt.imshow(wedges[img_show,:,:].squeeze().permute(1,2,0).cpu())\n",
    "plt.title('RGB Image')\n",
    "plt.axis('off');\n",
    "plt.subplot(132)\n",
    "plt.imshow(wedges_grey[img_show,:,:].squeeze().cpu(),cmap='gray', vmin=0, vmax=1)\n",
    "plt.title('Grayscale Image')\n",
    "plt.axis('off');\n",
    "plt.subplot(133)\n",
    "plt.imshow(boundaries[img_show,:,:].squeeze().cpu(),cmap='gray', vmin=0, vmax=1)\n",
    "plt.title('Boundaries')\n",
    "plt.axis('off');\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "ef770929",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1             [-1, 16, 1, 1]             160\n",
      "            Linear-2                    [-1, 3]              51\n",
      "================================================================\n",
      "Total params: 211\n",
      "Trainable params: 211\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.00\n",
      "Params size (MB): 0.00\n",
      "Estimated Total Size (MB): 0.00\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "class offCenterLineNet(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "                \n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3) #64 is good\n",
    "#         self.conv2 = nn.Conv2d(32, 32, kernel_size=3)\n",
    "#         self.conv3 = nn.Conv2d(128, 8, kernel_size=3)\n",
    "        self.fc = nn.LazyLinear(3)\n",
    "#         self.fc2 = nn.LazyLinear(32)\n",
    "        self.maxpool = nn.MaxPool1d(2)\n",
    "#         self.avgpool = nn.AvgPool2d(2)\n",
    "        self.activate = nn.ReLU()\n",
    "#         self.batchnorm = nn.BatchNorm2d(128)\n",
    "    \n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "#         x = self.activate(x)\n",
    "#         x = self.maxpool(x)\n",
    "#         x = self.batchnorm(x)\n",
    "#         x = self.conv2(x)\n",
    "#         x = self.activate(x)\n",
    "#         x = F.relu(x)\n",
    "#         x = self.batchnorm(x)\n",
    "#         x = self.conv3(x)\n",
    "\n",
    "#         x = self.avgpool(x)\n",
    "        x = x.view(x.shape[0],-1)\n",
    "#         x = self.fc2(x)\n",
    "#         x = self.maxpool(x)\n",
    "        x = self.fc(x)\n",
    "         \n",
    "        # We're defining\n",
    "        # a = - sin(theta)\n",
    "        # b = cos(theta)\n",
    "        # c = -cy*cos(theta)+cx*sin(theta)\n",
    "        # Hence, we want to normalize the vector by 1/sqrt(a^2 + b^2)\n",
    "        norm_factor = (torch.norm(x[:,:2],p=2,dim=1)).unsqueeze(1)       \n",
    "        out = x/(norm_factor)#+eps)\n",
    "#         print('Output shape=',x.shape)\n",
    "\n",
    "#         out = x\n",
    "        \n",
    "        return out\n",
    "    \n",
    "model = offCenterLineNet()\n",
    "model = model.to(dev)\n",
    "summary(model, input_size=(1, H, W))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "dfc53e7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Avg. Train Loss: 0.6946289705675702, Avg. Test Loss: 0.6561244130134583\n",
      "Epoch: 2, Avg. Train Loss: 0.5556854619536289, Avg. Test Loss: 0.2968456745147705\n",
      "Epoch: 3, Avg. Train Loss: 0.24297720956247906, Avg. Test Loss: 0.13609765470027924\n",
      "Epoch: 4, Avg. Train Loss: 0.07730438499603161, Avg. Test Loss: 0.03503692150115967\n",
      "Epoch: 5, Avg. Train Loss: 0.024698651677300763, Avg. Test Loss: 0.0188535638153553\n",
      "Epoch: 6, Avg. Train Loss: 0.017501207913250424, Avg. Test Loss: 0.015794113278388977\n",
      "Epoch: 7, Avg. Train Loss: 0.014819080075032489, Avg. Test Loss: 0.013207240030169487\n",
      "Epoch: 8, Avg. Train Loss: 0.012175352659163087, Avg. Test Loss: 0.010666919872164726\n",
      "Epoch: 9, Avg. Train Loss: 0.009640213708544886, Avg. Test Loss: 0.008305150084197521\n",
      "Epoch: 10, Avg. Train Loss: 0.007755632328172756, Avg. Test Loss: 0.00691048800945282\n",
      "Epoch: 11, Avg. Train Loss: 0.00679008049760447, Avg. Test Loss: 0.006411120295524597\n",
      "Epoch: 12, Avg. Train Loss: 0.006420815320209015, Avg. Test Loss: 0.006166690960526466\n",
      "Epoch: 13, Avg. Train Loss: 0.0062538044375562395, Avg. Test Loss: 0.006101697683334351\n",
      "Epoch: 14, Avg. Train Loss: 0.006168544400743273, Avg. Test Loss: 0.0059544784016907215\n",
      "Epoch: 15, Avg. Train Loss: 0.006086276421799909, Avg. Test Loss: 0.005927916616201401\n",
      "Epoch: 16, Avg. Train Loss: 0.00604894666304422, Avg. Test Loss: 0.005866074003279209\n",
      "Epoch: 17, Avg. Train Loss: 0.00599980057585378, Avg. Test Loss: 0.005814839620143175\n",
      "Epoch: 18, Avg. Train Loss: 0.0059566915490079754, Avg. Test Loss: 0.005785644985735416\n",
      "Epoch: 19, Avg. Train Loss: 0.005914869003517683, Avg. Test Loss: 0.00575643265619874\n",
      "Epoch: 20, Avg. Train Loss: 0.0058771338053914, Avg. Test Loss: 0.005726912524551153\n",
      "Epoch: 21, Avg. Train Loss: 0.005839191366333601, Avg. Test Loss: 0.0056720818392932415\n",
      "Epoch: 22, Avg. Train Loss: 0.005834201015098844, Avg. Test Loss: 0.005723611917346716\n",
      "Epoch: 23, Avg. Train Loss: 0.005806435830891132, Avg. Test Loss: 0.005631980020552874\n",
      "Epoch: 24, Avg. Train Loss: 0.005757866871304983, Avg. Test Loss: 0.0055845268070697784\n",
      "Epoch: 25, Avg. Train Loss: 0.005727616290366927, Avg. Test Loss: 0.005563001148402691\n",
      "Epoch: 26, Avg. Train Loss: 0.005691945910193893, Avg. Test Loss: 0.005547639913856983\n",
      "Epoch: 27, Avg. Train Loss: 0.005664925426677909, Avg. Test Loss: 0.005540261976420879\n",
      "Epoch: 28, Avg. Train Loss: 0.005664576592227054, Avg. Test Loss: 0.005478724837303162\n",
      "Epoch: 29, Avg. Train Loss: 0.005612818448436122, Avg. Test Loss: 0.005463619250804186\n",
      "Epoch: 30, Avg. Train Loss: 0.005583871329246566, Avg. Test Loss: 0.005422899499535561\n",
      "Epoch: 31, Avg. Train Loss: 0.005551531975872295, Avg. Test Loss: 0.005451322067528963\n",
      "Epoch: 32, Avg. Train Loss: 0.0055291119659709375, Avg. Test Loss: 0.005408642813563347\n",
      "Epoch: 33, Avg. Train Loss: 0.0055053980457921365, Avg. Test Loss: 0.00538143515586853\n",
      "Epoch: 34, Avg. Train Loss: 0.00550054423077855, Avg. Test Loss: 0.005418229848146439\n",
      "Epoch: 35, Avg. Train Loss: 0.005482516283992418, Avg. Test Loss: 0.005314271431416273\n",
      "Epoch: 36, Avg. Train Loss: 0.005431418058050926, Avg. Test Loss: 0.005293029360473156\n",
      "Epoch: 37, Avg. Train Loss: 0.005399473552960296, Avg. Test Loss: 0.005258601158857346\n",
      "Epoch: 38, Avg. Train Loss: 0.005371966669985721, Avg. Test Loss: 0.005261857528239489\n",
      "Epoch: 39, Avg. Train Loss: 0.005369957081627014, Avg. Test Loss: 0.00523746944963932\n",
      "Epoch: 40, Avg. Train Loss: 0.005335446858648644, Avg. Test Loss: 0.005207573529332876\n",
      "Epoch: 41, Avg. Train Loss: 0.0053336691804403485, Avg. Test Loss: 0.005209629889577627\n",
      "Epoch: 42, Avg. Train Loss: 0.0053071810235810835, Avg. Test Loss: 0.005203829612582922\n",
      "Epoch: 43, Avg. Train Loss: 0.005287711562718763, Avg. Test Loss: 0.005156830884516239\n",
      "Epoch: 44, Avg. Train Loss: 0.0052773974684262, Avg. Test Loss: 0.005191671662032604\n",
      "Epoch: 45, Avg. Train Loss: 0.005235696081505265, Avg. Test Loss: 0.005089606624096632\n",
      "Epoch: 46, Avg. Train Loss: 0.005216390782490719, Avg. Test Loss: 0.005104679614305496\n",
      "Epoch: 47, Avg. Train Loss: 0.005205105936024771, Avg. Test Loss: 0.005088169127702713\n",
      "Epoch: 48, Avg. Train Loss: 0.005204200549700925, Avg. Test Loss: 0.005045915022492409\n",
      "Epoch: 49, Avg. Train Loss: 0.005170098181034244, Avg. Test Loss: 0.0050676679238677025\n",
      "Epoch: 50, Avg. Train Loss: 0.005151924027433229, Avg. Test Loss: 0.005122797563672066\n",
      "Epoch: 51, Avg. Train Loss: 0.005151971752300512, Avg. Test Loss: 0.005012775305658579\n",
      "Epoch: 52, Avg. Train Loss: 0.0051153799259038854, Avg. Test Loss: 0.005002351012080908\n",
      "Epoch: 53, Avg. Train Loss: 0.0051019075434914855, Avg. Test Loss: 0.004992048256099224\n",
      "Epoch: 54, Avg. Train Loss: 0.00509580496568666, Avg. Test Loss: 0.00498972600325942\n",
      "Epoch: 55, Avg. Train Loss: 0.005084084238597127, Avg. Test Loss: 0.004946274217218161\n",
      "Epoch: 56, Avg. Train Loss: 0.005056145351899918, Avg. Test Loss: 0.004935618489980698\n",
      "Epoch: 57, Avg. Train Loss: 0.00504684503471782, Avg. Test Loss: 0.004929804243147373\n",
      "Epoch: 58, Avg. Train Loss: 0.005057665898442962, Avg. Test Loss: 0.004921295680105686\n",
      "Epoch: 59, Avg. Train Loss: 0.005038598855567533, Avg. Test Loss: 0.00494772894307971\n",
      "Epoch: 60, Avg. Train Loss: 0.005019822764362014, Avg. Test Loss: 0.004892031662166119\n",
      "Epoch: 61, Avg. Train Loss: 0.005009778959373402, Avg. Test Loss: 0.004871996585279703\n",
      "Epoch: 62, Avg. Train Loss: 0.004974663647454839, Avg. Test Loss: 0.004858311265707016\n",
      "Epoch: 63, Avg. Train Loss: 0.0049612217171247615, Avg. Test Loss: 0.004881154280155897\n",
      "Epoch: 64, Avg. Train Loss: 0.0049525980382811195, Avg. Test Loss: 0.004856585059314966\n",
      "Epoch: 65, Avg. Train Loss: 0.004935355196425388, Avg. Test Loss: 0.004824007395654917\n",
      "Epoch: 66, Avg. Train Loss: 0.004935409018206735, Avg. Test Loss: 0.004801758099347353\n",
      "Epoch: 67, Avg. Train Loss: 0.004919675817756459, Avg. Test Loss: 0.004798688925802708\n",
      "Epoch: 68, Avg. Train Loss: 0.0049295345169687, Avg. Test Loss: 0.004813778679817915\n",
      "Epoch: 69, Avg. Train Loss: 0.0048984304222083365, Avg. Test Loss: 0.004799230024218559\n",
      "Epoch: 70, Avg. Train Loss: 0.004909523188807937, Avg. Test Loss: 0.004788221325725317\n",
      "Epoch: 71, Avg. Train Loss: 0.004910799945423076, Avg. Test Loss: 0.004810274112969637\n",
      "Epoch: 72, Avg. Train Loss: 0.004900331284071124, Avg. Test Loss: 0.004787947982549667\n",
      "Epoch: 73, Avg. Train Loss: 0.004890545899438304, Avg. Test Loss: 0.004762295633554459\n",
      "Epoch: 74, Avg. Train Loss: 0.004878548168858817, Avg. Test Loss: 0.004771154373884201\n",
      "Epoch: 75, Avg. Train Loss: 0.004880656076725139, Avg. Test Loss: 0.004806095268577337\n",
      "Epoch: 76, Avg. Train Loss: 0.004879683938397225, Avg. Test Loss: 0.004759698640555143\n",
      "Epoch: 77, Avg. Train Loss: 0.004875818798101918, Avg. Test Loss: 0.004789923317730427\n",
      "Epoch: 78, Avg. Train Loss: 0.00487451084218053, Avg. Test Loss: 0.004786110483109951\n",
      "Epoch: 79, Avg. Train Loss: 0.004860146382693635, Avg. Test Loss: 0.004745561629533768\n",
      "Epoch: 80, Avg. Train Loss: 0.004874923104030448, Avg. Test Loss: 0.004749714862555265\n",
      "Epoch: 81, Avg. Train Loss: 0.004865174311711345, Avg. Test Loss: 0.004753188230097294\n",
      "Epoch: 82, Avg. Train Loss: 0.004865897104663904, Avg. Test Loss: 0.004748229868710041\n",
      "Epoch: 83, Avg. Train Loss: 0.0048499353078388895, Avg. Test Loss: 0.004771137144416571\n",
      "Epoch: 84, Avg. Train Loss: 0.004854128901781731, Avg. Test Loss: 0.00476856017485261\n",
      "Epoch: 85, Avg. Train Loss: 0.004851776186030271, Avg. Test Loss: 0.004747385159134865\n",
      "Epoch: 86, Avg. Train Loss: 0.004852081150856129, Avg. Test Loss: 0.004762132186442614\n",
      "Epoch: 87, Avg. Train Loss: 0.004852994182688552, Avg. Test Loss: 0.0047487011179327965\n",
      "Epoch: 88, Avg. Train Loss: 0.004850142472965079, Avg. Test Loss: 0.00474177673459053\n",
      "Epoch: 89, Avg. Train Loss: 0.00484619701151238, Avg. Test Loss: 0.0047367713414132595\n",
      "Epoch: 90, Avg. Train Loss: 0.004860268180193596, Avg. Test Loss: 0.004783321171998978\n",
      "Epoch: 91, Avg. Train Loss: 0.004870558417467184, Avg. Test Loss: 0.004728705622255802\n",
      "Epoch: 92, Avg. Train Loss: 0.004831004779525968, Avg. Test Loss: 0.004741573706269264\n",
      "Epoch: 93, Avg. Train Loss: 0.004831450525671244, Avg. Test Loss: 0.004742460325360298\n",
      "Epoch: 94, Avg. Train Loss: 0.0048351930237786715, Avg. Test Loss: 0.0047333636321127415\n",
      "Epoch: 95, Avg. Train Loss: 0.004833325960261877, Avg. Test Loss: 0.004742730874568224\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 96, Avg. Train Loss: 0.004841267217903636, Avg. Test Loss: 0.004729293752461672\n",
      "Epoch: 97, Avg. Train Loss: 0.0048586429898128955, Avg. Test Loss: 0.004752685781568289\n",
      "Epoch: 98, Avg. Train Loss: 0.004843827412831922, Avg. Test Loss: 0.0047727059572935104\n",
      "Epoch: 99, Avg. Train Loss: 0.004834066275074039, Avg. Test Loss: 0.004717978648841381\n",
      "Epoch: 100, Avg. Train Loss: 0.004828475653951944, Avg. Test Loss: 0.00473083695396781\n",
      "Epoch: 101, Avg. Train Loss: 0.004820217638341493, Avg. Test Loss: 0.004734464921057224\n",
      "Epoch: 102, Avg. Train Loss: 0.004834024766243474, Avg. Test Loss: 0.004728785250335932\n",
      "Epoch: 103, Avg. Train Loss: 0.00484351213848175, Avg. Test Loss: 0.004753440152853727\n",
      "Epoch: 104, Avg. Train Loss: 0.0048390799093731614, Avg. Test Loss: 0.004725950304418802\n",
      "Epoch: 105, Avg. Train Loss: 0.0048243804986393725, Avg. Test Loss: 0.004732129629701376\n",
      "Epoch: 106, Avg. Train Loss: 0.0048285919284924515, Avg. Test Loss: 0.004730836488306522\n",
      "Epoch: 107, Avg. Train Loss: 0.004824351010367621, Avg. Test Loss: 0.00473133334890008\n",
      "Epoch: 108, Avg. Train Loss: 0.004829003562241099, Avg. Test Loss: 0.004738313145935535\n",
      "Epoch: 109, Avg. Train Loss: 0.004830379732126413, Avg. Test Loss: 0.00477066682651639\n",
      "Epoch: 110, Avg. Train Loss: 0.004836799501073222, Avg. Test Loss: 0.004716000519692898\n",
      "Epoch: 111, Avg. Train Loss: 0.004815463290744742, Avg. Test Loss: 0.004775603301823139\n",
      "Epoch: 112, Avg. Train Loss: 0.004836913880480583, Avg. Test Loss: 0.004750220105051994\n",
      "Epoch: 113, Avg. Train Loss: 0.004828664669117262, Avg. Test Loss: 0.004716275259852409\n",
      "Epoch: 114, Avg. Train Loss: 0.004813239043361919, Avg. Test Loss: 0.004710003267973661\n",
      "Epoch: 115, Avg. Train Loss: 0.004829390115256227, Avg. Test Loss: 0.004761123564094305\n",
      "Epoch: 116, Avg. Train Loss: 0.004828942928809759, Avg. Test Loss: 0.004712192807346582\n",
      "Epoch: 117, Avg. Train Loss: 0.004815512553377207, Avg. Test Loss: 0.00474891159683466\n",
      "Epoch: 118, Avg. Train Loss: 0.004818992537641248, Avg. Test Loss: 0.0047137802466750145\n",
      "Epoch: 119, Avg. Train Loss: 0.004821371915208739, Avg. Test Loss: 0.004757064860314131\n",
      "Epoch: 120, Avg. Train Loss: 0.00482294078223234, Avg. Test Loss: 0.004754040855914354\n",
      "Epoch: 121, Avg. Train Loss: 0.004831352617678254, Avg. Test Loss: 0.004731020890176296\n",
      "Epoch: 122, Avg. Train Loss: 0.004831785628528789, Avg. Test Loss: 0.00474927481263876\n",
      "Epoch: 123, Avg. Train Loss: 0.00482285947560571, Avg. Test Loss: 0.004715760704129934\n",
      "Epoch: 124, Avg. Train Loss: 0.004821010161364494, Avg. Test Loss: 0.004726589657366276\n",
      "Epoch: 125, Avg. Train Loss: 0.00481285602070911, Avg. Test Loss: 0.004715810529887676\n",
      "Epoch: 126, Avg. Train Loss: 0.00482758597015988, Avg. Test Loss: 0.004705161787569523\n",
      "Epoch: 127, Avg. Train Loss: 0.004820855637622434, Avg. Test Loss: 0.004723864141851664\n",
      "Epoch: 128, Avg. Train Loss: 0.004809712947801102, Avg. Test Loss: 0.004706951789557934\n",
      "Epoch: 129, Avg. Train Loss: 0.00482462253421545, Avg. Test Loss: 0.0047055864706635475\n",
      "Epoch: 130, Avg. Train Loss: 0.004808030502740727, Avg. Test Loss: 0.004709702916443348\n",
      "Epoch: 131, Avg. Train Loss: 0.004811450654944015, Avg. Test Loss: 0.004749009385704994\n",
      "Epoch: 132, Avg. Train Loss: 0.004836700650928325, Avg. Test Loss: 0.004730934277176857\n",
      "Epoch: 133, Avg. Train Loss: 0.004811632306163394, Avg. Test Loss: 0.0047149951569736\n",
      "Epoch: 134, Avg. Train Loss: 0.00481128936286929, Avg. Test Loss: 0.00470707705244422\n",
      "Epoch: 135, Avg. Train Loss: 0.004806270996151969, Avg. Test Loss: 0.004713791888207197\n",
      "Epoch: 136, Avg. Train Loss: 0.0048302815750587815, Avg. Test Loss: 0.004698840901255608\n",
      "Epoch: 137, Avg. Train Loss: 0.004807703651834366, Avg. Test Loss: 0.0047484212554991245\n",
      "Epoch: 138, Avg. Train Loss: 0.0048174910940403165, Avg. Test Loss: 0.004725191742181778\n",
      "Epoch: 139, Avg. Train Loss: 0.004820413855012766, Avg. Test Loss: 0.004766449797898531\n",
      "Epoch: 140, Avg. Train Loss: 0.004839531059355237, Avg. Test Loss: 0.004729304928332567\n",
      "Epoch: 141, Avg. Train Loss: 0.004806279107321834, Avg. Test Loss: 0.0047131916508078575\n",
      "Epoch: 142, Avg. Train Loss: 0.004813174792933602, Avg. Test Loss: 0.004753901623189449\n",
      "Epoch: 143, Avg. Train Loss: 0.004830729411265185, Avg. Test Loss: 0.004715661518275738\n",
      "Epoch: 144, Avg. Train Loss: 0.004821346877792547, Avg. Test Loss: 0.004712649155408144\n",
      "Epoch: 145, Avg. Train Loss: 0.0048080570887514325, Avg. Test Loss: 0.00470123253762722\n",
      "Epoch: 146, Avg. Train Loss: 0.004814972797798556, Avg. Test Loss: 0.004735927097499371\n",
      "Epoch: 147, Avg. Train Loss: 0.004803778278793014, Avg. Test Loss: 0.004754992201924324\n",
      "Epoch: 148, Avg. Train Loss: 0.004809484438061021, Avg. Test Loss: 0.00472577940672636\n",
      "Epoch: 149, Avg. Train Loss: 0.004806193414815637, Avg. Test Loss: 0.00471146684139967\n",
      "Epoch: 150, Avg. Train Loss: 0.004801423451321763, Avg. Test Loss: 0.004696973133832216\n",
      "Epoch: 151, Avg. Train Loss: 0.0048095185937749784, Avg. Test Loss: 0.004714698530733585\n",
      "Epoch: 152, Avg. Train Loss: 0.004815432264707809, Avg. Test Loss: 0.004711465444415808\n",
      "Epoch: 153, Avg. Train Loss: 0.004802493443496005, Avg. Test Loss: 0.004704059101641178\n",
      "Epoch: 154, Avg. Train Loss: 0.00480999226876816, Avg. Test Loss: 0.0047189341858029366\n",
      "Epoch: 155, Avg. Train Loss: 0.004814057340195706, Avg. Test Loss: 0.00473155127838254\n",
      "Epoch: 156, Avg. Train Loss: 0.004812763202502284, Avg. Test Loss: 0.004720476921647787\n",
      "Epoch: 157, Avg. Train Loss: 0.004813038863155038, Avg. Test Loss: 0.0047147395089268684\n",
      "Epoch: 158, Avg. Train Loss: 0.004818745737158975, Avg. Test Loss: 0.004791537765413523\n",
      "Epoch: 159, Avg. Train Loss: 0.004809117984286574, Avg. Test Loss: 0.004701470956206322\n",
      "Epoch: 160, Avg. Train Loss: 0.004805507203347461, Avg. Test Loss: 0.004697671625763178\n",
      "Epoch: 161, Avg. Train Loss: 0.004804079886525869, Avg. Test Loss: 0.004724068101495504\n",
      "Epoch: 162, Avg. Train Loss: 0.004797013368197652, Avg. Test Loss: 0.004693422466516495\n",
      "Epoch: 163, Avg. Train Loss: 0.004804827586942634, Avg. Test Loss: 0.004720743745565414\n",
      "Epoch: 164, Avg. Train Loss: 0.004800331432285697, Avg. Test Loss: 0.004693059250712395\n",
      "Epoch: 165, Avg. Train Loss: 0.004798544971488936, Avg. Test Loss: 0.004709106404334307\n",
      "Epoch: 166, Avg. Train Loss: 0.004800493190021709, Avg. Test Loss: 0.004738351330161095\n",
      "Epoch: 167, Avg. Train Loss: 0.0048101359631779585, Avg. Test Loss: 0.004761672578752041\n",
      "Epoch: 168, Avg. Train Loss: 0.004816662466023551, Avg. Test Loss: 0.004693187307566404\n",
      "Epoch: 169, Avg. Train Loss: 0.004812138988961314, Avg. Test Loss: 0.004710664507001638\n",
      "Epoch: 170, Avg. Train Loss: 0.004814554818061202, Avg. Test Loss: 0.004733630456030369\n",
      "Epoch: 171, Avg. Train Loss: 0.004824093857043704, Avg. Test Loss: 0.004694212693721056\n",
      "Epoch: 172, Avg. Train Loss: 0.004812243751921626, Avg. Test Loss: 0.0047393785789608955\n",
      "Epoch: 173, Avg. Train Loss: 0.004796460823177598, Avg. Test Loss: 0.004698638804256916\n",
      "Epoch: 174, Avg. Train Loss: 0.004803718609172244, Avg. Test Loss: 0.004702353850007057\n",
      "Epoch: 175, Avg. Train Loss: 0.004800566017281177, Avg. Test Loss: 0.004733719862997532\n",
      "Epoch: 176, Avg. Train Loss: 0.004801245482075353, Avg. Test Loss: 0.004705151543021202\n",
      "Epoch: 177, Avg. Train Loss: 0.004796269468876512, Avg. Test Loss: 0.004689654801040888\n",
      "Epoch: 178, Avg. Train Loss: 0.004794635550054007, Avg. Test Loss: 0.00473290029913187\n",
      "Epoch: 179, Avg. Train Loss: 0.004804427735507488, Avg. Test Loss: 0.004732758272439241\n",
      "Epoch: 180, Avg. Train Loss: 0.0048009709585024865, Avg. Test Loss: 0.004692165181040764\n",
      "Epoch: 181, Avg. Train Loss: 0.004803541549589745, Avg. Test Loss: 0.004716080147773027\n",
      "Epoch: 182, Avg. Train Loss: 0.004789056180608134, Avg. Test Loss: 0.004717736504971981\n",
      "Epoch: 183, Avg. Train Loss: 0.00480642064669451, Avg. Test Loss: 0.0046923342160880566\n",
      "Epoch: 184, Avg. Train Loss: 0.004804143942026205, Avg. Test Loss: 0.004711439833045006\n",
      "Epoch: 185, Avg. Train Loss: 0.004802531595233568, Avg. Test Loss: 0.004694056231528521\n",
      "Epoch: 186, Avg. Train Loss: 0.004802404209798159, Avg. Test Loss: 0.004704578779637814\n",
      "Epoch: 187, Avg. Train Loss: 0.004803301474122807, Avg. Test Loss: 0.004703278187662363\n",
      "Epoch: 188, Avg. Train Loss: 0.004812550167878007, Avg. Test Loss: 0.004692661575973034\n",
      "Epoch: 189, Avg. Train Loss: 0.004801351652848859, Avg. Test Loss: 0.004748191684484482\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 190, Avg. Train Loss: 0.004796946540388257, Avg. Test Loss: 0.004683453589677811\n",
      "Epoch: 191, Avg. Train Loss: 0.004791648527823909, Avg. Test Loss: 0.004693989176303148\n",
      "Epoch: 192, Avg. Train Loss: 0.004797939752596755, Avg. Test Loss: 0.004699797369539738\n",
      "Epoch: 193, Avg. Train Loss: 0.0047965363036234715, Avg. Test Loss: 0.004718336742371321\n",
      "Epoch: 194, Avg. Train Loss: 0.004788167460626641, Avg. Test Loss: 0.004710289649665356\n",
      "Epoch: 195, Avg. Train Loss: 0.004798805048732564, Avg. Test Loss: 0.004732468631118536\n",
      "Epoch: 196, Avg. Train Loss: 0.004792374255525512, Avg. Test Loss: 0.004679928999394178\n",
      "Epoch: 197, Avg. Train Loss: 0.0047996923609008625, Avg. Test Loss: 0.0047360979951918125\n",
      "Epoch: 198, Avg. Train Loss: 0.004795410605364068, Avg. Test Loss: 0.004686560481786728\n",
      "Epoch: 199, Avg. Train Loss: 0.004783271519510552, Avg. Test Loss: 0.004702477715909481\n",
      "Epoch: 200, Avg. Train Loss: 0.004792285086803658, Avg. Test Loss: 0.004732533358037472\n",
      "Epoch: 201, Avg. Train Loss: 0.004787042953593786, Avg. Test Loss: 0.004674812778830528\n",
      "Epoch: 202, Avg. Train Loss: 0.004789871196154245, Avg. Test Loss: 0.004677953198552132\n",
      "Epoch: 203, Avg. Train Loss: 0.004803399804459755, Avg. Test Loss: 0.004709243308752775\n",
      "Epoch: 204, Avg. Train Loss: 0.004792538698935925, Avg. Test Loss: 0.0047503248788416386\n",
      "Epoch: 205, Avg. Train Loss: 0.004787260720636262, Avg. Test Loss: 0.0046927896328270435\n",
      "Epoch: 206, Avg. Train Loss: 0.004784832968441553, Avg. Test Loss: 0.0046808915212750435\n",
      "Epoch: 207, Avg. Train Loss: 0.004783639261975538, Avg. Test Loss: 0.00468695443123579\n",
      "Epoch: 208, Avg. Train Loss: 0.0047892447084535, Avg. Test Loss: 0.004710864741355181\n",
      "Epoch: 209, Avg. Train Loss: 0.004791219556314307, Avg. Test Loss: 0.0046721212565898895\n",
      "Epoch: 210, Avg. Train Loss: 0.004788502974998813, Avg. Test Loss: 0.004689221736043692\n",
      "Epoch: 211, Avg. Train Loss: 0.004792888952029306, Avg. Test Loss: 0.00468375813215971\n",
      "Epoch: 212, Avg. Train Loss: 0.004786393388585989, Avg. Test Loss: 0.004707684740424156\n",
      "Epoch: 213, Avg. Train Loss: 0.004791663320691779, Avg. Test Loss: 0.004705679137259722\n",
      "Epoch: 214, Avg. Train Loss: 0.004790185084349887, Avg. Test Loss: 0.004679887089878321\n",
      "Epoch: 215, Avg. Train Loss: 0.004788492416399856, Avg. Test Loss: 0.004679576959460974\n",
      "Epoch: 216, Avg. Train Loss: 0.004778377170306306, Avg. Test Loss: 0.00467548705637455\n",
      "Epoch: 217, Avg. Train Loss: 0.004780145708558171, Avg. Test Loss: 0.004667241126298904\n",
      "Epoch: 218, Avg. Train Loss: 0.0047781355570741865, Avg. Test Loss: 0.004732724744826555\n",
      "Epoch: 219, Avg. Train Loss: 0.004798446056368046, Avg. Test Loss: 0.004728458356112242\n",
      "Epoch: 220, Avg. Train Loss: 0.0047890019148241645, Avg. Test Loss: 0.004677293356508017\n",
      "Epoch: 221, Avg. Train Loss: 0.0047926685209710935, Avg. Test Loss: 0.004714594688266516\n",
      "Epoch: 222, Avg. Train Loss: 0.004782712195328501, Avg. Test Loss: 0.004666280001401901\n",
      "Epoch: 223, Avg. Train Loss: 0.004773858523126258, Avg. Test Loss: 0.004686726722866297\n",
      "Epoch: 224, Avg. Train Loss: 0.004787829477166714, Avg. Test Loss: 0.004695591516792774\n",
      "Epoch: 225, Avg. Train Loss: 0.004779578825502202, Avg. Test Loss: 0.0046797567047178745\n",
      "Epoch: 226, Avg. Train Loss: 0.004781212040418109, Avg. Test Loss: 0.0046622673980891705\n",
      "Epoch: 227, Avg. Train Loss: 0.004775370990987434, Avg. Test Loss: 0.0046774293296039104\n",
      "Epoch: 228, Avg. Train Loss: 0.004776797235705132, Avg. Test Loss: 0.004699676763266325\n",
      "Epoch: 229, Avg. Train Loss: 0.0047704426268505495, Avg. Test Loss: 0.004714464768767357\n",
      "Epoch: 230, Avg. Train Loss: 0.004770395725012519, Avg. Test Loss: 0.004668917041271925\n",
      "Epoch: 231, Avg. Train Loss: 0.004767187914356243, Avg. Test Loss: 0.004664586391299963\n",
      "Epoch: 232, Avg. Train Loss: 0.004778830605277488, Avg. Test Loss: 0.004672315437346697\n",
      "Epoch: 233, Avg. Train Loss: 0.004765446016261744, Avg. Test Loss: 0.004668070934712887\n",
      "Epoch: 234, Avg. Train Loss: 0.004764937817357307, Avg. Test Loss: 0.004657270852476358\n",
      "Epoch: 235, Avg. Train Loss: 0.00477676703269745, Avg. Test Loss: 0.004696651361882687\n",
      "Epoch: 236, Avg. Train Loss: 0.004782111892953168, Avg. Test Loss: 0.004692344460636377\n",
      "Epoch: 237, Avg. Train Loss: 0.004785167096659194, Avg. Test Loss: 0.004688440356403589\n",
      "Epoch: 238, Avg. Train Loss: 0.004762808846439733, Avg. Test Loss: 0.004652316682040691\n",
      "Epoch: 239, Avg. Train Loss: 0.004765908688653347, Avg. Test Loss: 0.004663625732064247\n",
      "Epoch: 240, Avg. Train Loss: 0.004771364636199419, Avg. Test Loss: 0.004663383588194847\n",
      "Epoch: 241, Avg. Train Loss: 0.004763967130159916, Avg. Test Loss: 0.00466324295848608\n",
      "Epoch: 242, Avg. Train Loss: 0.004765459758684386, Avg. Test Loss: 0.004700404591858387\n",
      "Epoch: 243, Avg. Train Loss: 0.004767362634802974, Avg. Test Loss: 0.004665058571845293\n",
      "Epoch: 244, Avg. Train Loss: 0.004764034380313269, Avg. Test Loss: 0.004652136471122503\n",
      "Epoch: 245, Avg. Train Loss: 0.004776440355060405, Avg. Test Loss: 0.004666752181947231\n",
      "Epoch: 246, Avg. Train Loss: 0.004762900690006656, Avg. Test Loss: 0.004675989970564842\n",
      "Epoch: 247, Avg. Train Loss: 0.004770956543642421, Avg. Test Loss: 0.004648510832339525\n",
      "Epoch: 248, Avg. Train Loss: 0.004755567607664784, Avg. Test Loss: 0.004650707356631756\n",
      "Epoch: 249, Avg. Train Loss: 0.0047677421054348, Avg. Test Loss: 0.0046607693657279015\n",
      "Epoch: 250, Avg. Train Loss: 0.004764838913065749, Avg. Test Loss: 0.004690627567470074\n",
      "Epoch: 251, Avg. Train Loss: 0.004776008665388407, Avg. Test Loss: 0.004644142463803291\n",
      "Epoch: 252, Avg. Train Loss: 0.004755844210469445, Avg. Test Loss: 0.004645364359021187\n",
      "Epoch: 253, Avg. Train Loss: 0.004758547839903554, Avg. Test Loss: 0.004675490781664848\n",
      "Epoch: 254, Avg. Train Loss: 0.004767087006638217, Avg. Test Loss: 0.004677878227084875\n",
      "Epoch: 255, Avg. Train Loss: 0.004765787194374689, Avg. Test Loss: 0.004664813634008169\n",
      "Epoch: 256, Avg. Train Loss: 0.004751218244606672, Avg. Test Loss: 0.004663349129259586\n",
      "Epoch: 257, Avg. Train Loss: 0.004771314550537703, Avg. Test Loss: 0.004679012577980757\n",
      "Epoch: 258, Avg. Train Loss: 0.004763758069900579, Avg. Test Loss: 0.004655920900404453\n",
      "Epoch: 259, Avg. Train Loss: 0.004749398191221232, Avg. Test Loss: 0.004647596273571253\n",
      "Epoch: 260, Avg. Train Loss: 0.004755055596835391, Avg. Test Loss: 0.0046455394476652145\n",
      "Epoch: 261, Avg. Train Loss: 0.004762485894092987, Avg. Test Loss: 0.004672525450587273\n",
      "Epoch: 262, Avg. Train Loss: 0.00476042103282241, Avg. Test Loss: 0.004643908701837063\n",
      "Epoch: 263, Avg. Train Loss: 0.004741265362691741, Avg. Test Loss: 0.004648139234632254\n",
      "Epoch: 264, Avg. Train Loss: 0.004744137962197148, Avg. Test Loss: 0.004722945857793093\n",
      "Epoch: 265, Avg. Train Loss: 0.004776178415171629, Avg. Test Loss: 0.004671711008995771\n",
      "Epoch: 266, Avg. Train Loss: 0.004759092479511056, Avg. Test Loss: 0.004644772969186306\n",
      "Epoch: 267, Avg. Train Loss: 0.004753836235681245, Avg. Test Loss: 0.004661369137465954\n",
      "Epoch: 268, Avg. Train Loss: 0.004757938689963762, Avg. Test Loss: 0.004667950328439474\n",
      "Epoch: 269, Avg. Train Loss: 0.004743811165437449, Avg. Test Loss: 0.004647192545235157\n",
      "Epoch: 270, Avg. Train Loss: 0.004742085197290709, Avg. Test Loss: 0.004647149704396725\n",
      "Epoch: 271, Avg. Train Loss: 0.004762479515616284, Avg. Test Loss: 0.00466719688847661\n",
      "Epoch: 272, Avg. Train Loss: 0.004755404712848885, Avg. Test Loss: 0.004652734380215406\n",
      "Epoch: 273, Avg. Train Loss: 0.004753380461574294, Avg. Test Loss: 0.0046727415174245834\n",
      "Epoch: 274, Avg. Train Loss: 0.004738134072097235, Avg. Test Loss: 0.004649605602025986\n",
      "Epoch: 275, Avg. Train Loss: 0.0047447001128349195, Avg. Test Loss: 0.004655815195292234\n",
      "Epoch: 276, Avg. Train Loss: 0.004743820868519156, Avg. Test Loss: 0.004634321201592684\n",
      "Epoch: 277, Avg. Train Loss: 0.0047460352503802886, Avg. Test Loss: 0.00464315852150321\n",
      "Epoch: 278, Avg. Train Loss: 0.004742230927614972, Avg. Test Loss: 0.004634304903447628\n",
      "Epoch: 279, Avg. Train Loss: 0.004742469129607428, Avg. Test Loss: 0.00463013956323266\n",
      "Epoch: 280, Avg. Train Loss: 0.004735316972919675, Avg. Test Loss: 0.004630547482520342\n",
      "Epoch: 281, Avg. Train Loss: 0.0047448283862755744, Avg. Test Loss: 0.004672550596296787\n",
      "Epoch: 282, Avg. Train Loss: 0.004745287593280853, Avg. Test Loss: 0.004635028075426817\n",
      "Epoch: 283, Avg. Train Loss: 0.0047405054901055125, Avg. Test Loss: 0.004638275597244501\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 284, Avg. Train Loss: 0.004731473902803521, Avg. Test Loss: 0.00463883439078927\n",
      "Epoch: 285, Avg. Train Loss: 0.004737713222586831, Avg. Test Loss: 0.0046505858190357685\n",
      "Epoch: 286, Avg. Train Loss: 0.004749660098622012, Avg. Test Loss: 0.004667548928409815\n",
      "Epoch: 287, Avg. Train Loss: 0.004730436398626067, Avg. Test Loss: 0.004634839948266745\n",
      "Epoch: 288, Avg. Train Loss: 0.00473141532694531, Avg. Test Loss: 0.004626092035323381\n",
      "Epoch: 289, Avg. Train Loss: 0.00472781881906612, Avg. Test Loss: 0.004620905499905348\n",
      "Epoch: 290, Avg. Train Loss: 0.004732980620289265, Avg. Test Loss: 0.004640879575163126\n",
      "Epoch: 291, Avg. Train Loss: 0.004732711370601211, Avg. Test Loss: 0.0046623037196695805\n",
      "Epoch: 292, Avg. Train Loss: 0.004724245431811311, Avg. Test Loss: 0.004632582422345877\n",
      "Epoch: 293, Avg. Train Loss: 0.004729486233013314, Avg. Test Loss: 0.004629478789865971\n",
      "Epoch: 294, Avg. Train Loss: 0.004748670330141173, Avg. Test Loss: 0.004633899312466383\n",
      "Epoch: 295, Avg. Train Loss: 0.004731992432890937, Avg. Test Loss: 0.004624871537089348\n",
      "Epoch: 296, Avg. Train Loss: 0.004720388413515202, Avg. Test Loss: 0.004647222813218832\n",
      "Epoch: 297, Avg. Train Loss: 0.004731479035907014, Avg. Test Loss: 0.004661012440919876\n",
      "Epoch: 298, Avg. Train Loss: 0.0047366511683131374, Avg. Test Loss: 0.004649925511330366\n",
      "Epoch: 299, Avg. Train Loss: 0.0047401241135112075, Avg. Test Loss: 0.004628420807421207\n",
      "Epoch: 300, Avg. Train Loss: 0.004719171586424806, Avg. Test Loss: 0.004626987501978874\n",
      "Epoch: 301, Avg. Train Loss: 0.004715906412795533, Avg. Test Loss: 0.0046422965824604034\n",
      "Epoch: 302, Avg. Train Loss: 0.004725387568997089, Avg. Test Loss: 0.0046610101126134396\n",
      "Epoch: 303, Avg. Train Loss: 0.004726430975160626, Avg. Test Loss: 0.004623089451342821\n",
      "Epoch: 304, Avg. Train Loss: 0.004712201189249754, Avg. Test Loss: 0.004607899114489555\n",
      "Epoch: 305, Avg. Train Loss: 0.0047114806379689724, Avg. Test Loss: 0.004612406250089407\n",
      "Epoch: 306, Avg. Train Loss: 0.004722695267044528, Avg. Test Loss: 0.0046124570071697235\n",
      "Epoch: 307, Avg. Train Loss: 0.004733617688247631, Avg. Test Loss: 0.004635708872228861\n",
      "Epoch: 308, Avg. Train Loss: 0.004723380807094103, Avg. Test Loss: 0.004601983819156885\n",
      "Epoch: 309, Avg. Train Loss: 0.004743687678561654, Avg. Test Loss: 0.004622757900506258\n",
      "Epoch: 310, Avg. Train Loss: 0.004724327052488576, Avg. Test Loss: 0.004634610842913389\n",
      "Epoch: 311, Avg. Train Loss: 0.004721812784758418, Avg. Test Loss: 0.004642243031412363\n",
      "Epoch: 312, Avg. Train Loss: 0.004725284094727317, Avg. Test Loss: 0.004601779393851757\n",
      "Epoch: 313, Avg. Train Loss: 0.004718381077657605, Avg. Test Loss: 0.004645838402211666\n",
      "Epoch: 314, Avg. Train Loss: 0.004703824213424394, Avg. Test Loss: 0.004613850265741348\n",
      "Epoch: 315, Avg. Train Loss: 0.004704092650912529, Avg. Test Loss: 0.0046207415871322155\n",
      "Epoch: 316, Avg. Train Loss: 0.004697516733823821, Avg. Test Loss: 0.0046176002360880375\n",
      "Epoch: 317, Avg. Train Loss: 0.004706956142949504, Avg. Test Loss: 0.004629063419997692\n",
      "Epoch: 318, Avg. Train Loss: 0.004708199891759906, Avg. Test Loss: 0.004600632470101118\n",
      "Epoch: 319, Avg. Train Loss: 0.004706297091446644, Avg. Test Loss: 0.0046431259252130985\n",
      "Epoch: 320, Avg. Train Loss: 0.004710359553005113, Avg. Test Loss: 0.00467181159183383\n",
      "Epoch: 321, Avg. Train Loss: 0.004703733312009379, Avg. Test Loss: 0.0046149627305567265\n",
      "Epoch: 322, Avg. Train Loss: 0.00470290390428069, Avg. Test Loss: 0.004592103883624077\n",
      "Epoch: 323, Avg. Train Loss: 0.004714880171123632, Avg. Test Loss: 0.004631298594176769\n",
      "Epoch: 324, Avg. Train Loss: 0.0047142862905423305, Avg. Test Loss: 0.0046233986504375935\n",
      "Epoch: 325, Avg. Train Loss: 0.004698149914051904, Avg. Test Loss: 0.0046166968531906605\n",
      "Epoch: 326, Avg. Train Loss: 0.004700278451796188, Avg. Test Loss: 0.0046098013408482075\n",
      "Epoch: 327, Avg. Train Loss: 0.004701974899183179, Avg. Test Loss: 0.004587366245687008\n",
      "Epoch: 328, Avg. Train Loss: 0.004691756514529156, Avg. Test Loss: 0.004586886614561081\n",
      "Epoch: 329, Avg. Train Loss: 0.004690355956987586, Avg. Test Loss: 0.004592979792505503\n",
      "Epoch: 330, Avg. Train Loss: 0.004697783698522767, Avg. Test Loss: 0.00460056634619832\n",
      "Epoch: 331, Avg. Train Loss: 0.004689467486080735, Avg. Test Loss: 0.004600028973072767\n",
      "Epoch: 332, Avg. Train Loss: 0.004694382194429636, Avg. Test Loss: 0.004609824623912573\n",
      "Epoch: 333, Avg. Train Loss: 0.004691911796324475, Avg. Test Loss: 0.004590495489537716\n",
      "Epoch: 334, Avg. Train Loss: 0.004701129085016112, Avg. Test Loss: 0.004603994078934193\n",
      "Epoch: 335, Avg. Train Loss: 0.00469443968735462, Avg. Test Loss: 0.004588758572936058\n",
      "Epoch: 336, Avg. Train Loss: 0.004694924170021401, Avg. Test Loss: 0.004605335183441639\n",
      "Epoch: 337, Avg. Train Loss: 0.004685670505602693, Avg. Test Loss: 0.004628185648471117\n",
      "Epoch: 338, Avg. Train Loss: 0.004689484379839065, Avg. Test Loss: 0.004589622840285301\n",
      "Epoch: 339, Avg. Train Loss: 0.004688148581704428, Avg. Test Loss: 0.004630740731954575\n",
      "Epoch: 340, Avg. Train Loss: 0.004704521871496772, Avg. Test Loss: 0.004598069936037064\n",
      "Epoch: 341, Avg. Train Loss: 0.00468584923290236, Avg. Test Loss: 0.004580907989293337\n",
      "Epoch: 342, Avg. Train Loss: 0.004685512884671605, Avg. Test Loss: 0.004575439728796482\n",
      "Epoch: 343, Avg. Train Loss: 0.004676451776609864, Avg. Test Loss: 0.004601520951837301\n",
      "Epoch: 344, Avg. Train Loss: 0.00468224243715752, Avg. Test Loss: 0.004593431018292904\n",
      "Epoch: 345, Avg. Train Loss: 0.0046780056666669454, Avg. Test Loss: 0.004581310320645571\n",
      "Epoch: 346, Avg. Train Loss: 0.0046974820474725825, Avg. Test Loss: 0.00459283497184515\n",
      "Epoch: 347, Avg. Train Loss: 0.0046865621603332285, Avg. Test Loss: 0.004611117299646139\n",
      "Epoch: 348, Avg. Train Loss: 0.004689819926699233, Avg. Test Loss: 0.004578324966132641\n",
      "Epoch: 349, Avg. Train Loss: 0.004699712792454764, Avg. Test Loss: 0.00458167539909482\n",
      "Epoch: 350, Avg. Train Loss: 0.004675019315855448, Avg. Test Loss: 0.004598306957632303\n",
      "Epoch: 351, Avg. Train Loss: 0.0046909453975426596, Avg. Test Loss: 0.0045847585424780846\n",
      "Epoch: 352, Avg. Train Loss: 0.004685044277805922, Avg. Test Loss: 0.00457738945260644\n",
      "Epoch: 353, Avg. Train Loss: 0.0046740003623241605, Avg. Test Loss: 0.00461503816768527\n",
      "Epoch: 354, Avg. Train Loss: 0.004691186555942824, Avg. Test Loss: 0.004611491225659847\n",
      "Epoch: 355, Avg. Train Loss: 0.004672964038543923, Avg. Test Loss: 0.004578066524118185\n",
      "Epoch: 356, Avg. Train Loss: 0.004678032675021609, Avg. Test Loss: 0.0046053556725382805\n",
      "Epoch: 357, Avg. Train Loss: 0.004683729098719913, Avg. Test Loss: 0.0045765298418700695\n",
      "Epoch: 358, Avg. Train Loss: 0.004678237739257341, Avg. Test Loss: 0.0045646075159311295\n",
      "Epoch: 359, Avg. Train Loss: 0.004684687548771847, Avg. Test Loss: 0.004578682594001293\n",
      "Epoch: 360, Avg. Train Loss: 0.004682182594267435, Avg. Test Loss: 0.004582503344863653\n",
      "Epoch: 361, Avg. Train Loss: 0.004665377105824476, Avg. Test Loss: 0.0045652627013623714\n",
      "Epoch: 362, Avg. Train Loss: 0.004670096095651388, Avg. Test Loss: 0.004588051233440638\n",
      "Epoch: 363, Avg. Train Loss: 0.004671783673815256, Avg. Test Loss: 0.0045932019129395485\n",
      "Epoch: 364, Avg. Train Loss: 0.004667216662837322, Avg. Test Loss: 0.004578671883791685\n",
      "Epoch: 365, Avg. Train Loss: 0.004685062373620133, Avg. Test Loss: 0.0046039302833378315\n",
      "Epoch: 366, Avg. Train Loss: 0.004668479265515195, Avg. Test Loss: 0.004570479039102793\n",
      "Epoch: 367, Avg. Train Loss: 0.004665862952987122, Avg. Test Loss: 0.004585424903780222\n",
      "Epoch: 368, Avg. Train Loss: 0.004668525030273337, Avg. Test Loss: 0.004618276376277208\n",
      "Epoch: 369, Avg. Train Loss: 0.0046771966505709086, Avg. Test Loss: 0.004587314557284117\n",
      "Epoch: 370, Avg. Train Loss: 0.004657395942093328, Avg. Test Loss: 0.004561631940305233\n",
      "Epoch: 371, Avg. Train Loss: 0.004656999588532503, Avg. Test Loss: 0.004581289365887642\n",
      "Epoch: 372, Avg. Train Loss: 0.00467196520591198, Avg. Test Loss: 0.0045689065009355545\n",
      "Epoch: 373, Avg. Train Loss: 0.004655993088733318, Avg. Test Loss: 0.004592160694301128\n",
      "Epoch: 374, Avg. Train Loss: 0.004661119867895924, Avg. Test Loss: 0.004578057676553726\n",
      "Epoch: 375, Avg. Train Loss: 0.004678188920627499, Avg. Test Loss: 0.004563539754599333\n",
      "Epoch: 376, Avg. Train Loss: 0.004661033698899108, Avg. Test Loss: 0.0045556919649243355\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 377, Avg. Train Loss: 0.004669777280109567, Avg. Test Loss: 0.004587383475154638\n",
      "Epoch: 378, Avg. Train Loss: 0.004669100760893766, Avg. Test Loss: 0.0045984769240021706\n",
      "Epoch: 379, Avg. Train Loss: 0.004656566458559314, Avg. Test Loss: 0.004573761951178312\n",
      "Epoch: 380, Avg. Train Loss: 0.004655620353946159, Avg. Test Loss: 0.004546681419014931\n",
      "Epoch: 381, Avg. Train Loss: 0.00465494244857583, Avg. Test Loss: 0.004566809628158808\n",
      "Epoch: 382, Avg. Train Loss: 0.004659463239963664, Avg. Test Loss: 0.004553096368908882\n",
      "Epoch: 383, Avg. Train Loss: 0.004646543640816628, Avg. Test Loss: 0.00459141144528985\n",
      "Epoch: 384, Avg. Train Loss: 0.004660057932744885, Avg. Test Loss: 0.00455568078905344\n",
      "Epoch: 385, Avg. Train Loss: 0.004657006876673116, Avg. Test Loss: 0.0045978473499417305\n",
      "Epoch: 386, Avg. Train Loss: 0.004649644587622132, Avg. Test Loss: 0.004575944039970636\n",
      "Epoch: 387, Avg. Train Loss: 0.004647155303161505, Avg. Test Loss: 0.004557832609862089\n",
      "Epoch: 388, Avg. Train Loss: 0.004651722476579422, Avg. Test Loss: 0.004550717305392027\n",
      "Epoch: 389, Avg. Train Loss: 0.004644948101147663, Avg. Test Loss: 0.004557858686894178\n",
      "Epoch: 390, Avg. Train Loss: 0.004643906492653282, Avg. Test Loss: 0.004589186515659094\n",
      "Epoch: 391, Avg. Train Loss: 0.004661837679355643, Avg. Test Loss: 0.004587381612509489\n",
      "Epoch: 392, Avg. Train Loss: 0.004648997513360755, Avg. Test Loss: 0.004536016378551722\n",
      "Epoch: 393, Avg. Train Loss: 0.004649057821912128, Avg. Test Loss: 0.004553921986371279\n",
      "Epoch: 394, Avg. Train Loss: 0.0046491624332617885, Avg. Test Loss: 0.004572055768221617\n",
      "Epoch: 395, Avg. Train Loss: 0.004633536833056877, Avg. Test Loss: 0.004586639814078808\n",
      "Epoch: 396, Avg. Train Loss: 0.004659354101953118, Avg. Test Loss: 0.004549482837319374\n",
      "Epoch: 397, Avg. Train Loss: 0.004656525588659353, Avg. Test Loss: 0.004571156110614538\n",
      "Epoch: 398, Avg. Train Loss: 0.0046523977829100085, Avg. Test Loss: 0.004555712454020977\n",
      "Epoch: 399, Avg. Train Loss: 0.00463817615148633, Avg. Test Loss: 0.004607873503118753\n",
      "Epoch: 400, Avg. Train Loss: 0.004649013205063205, Avg. Test Loss: 0.0045449575409293175\n",
      "Epoch: 401, Avg. Train Loss: 0.004654043635656667, Avg. Test Loss: 0.004541680682450533\n",
      "Epoch: 402, Avg. Train Loss: 0.0046332401526702005, Avg. Test Loss: 0.0045588938519358635\n",
      "Epoch: 403, Avg. Train Loss: 0.004641622272428385, Avg. Test Loss: 0.004534661304205656\n",
      "Epoch: 404, Avg. Train Loss: 0.00465078700637055, Avg. Test Loss: 0.0045500691048800945\n",
      "Epoch: 405, Avg. Train Loss: 0.00463797094646928, Avg. Test Loss: 0.0045350645668804646\n",
      "Epoch: 406, Avg. Train Loss: 0.004632244092347317, Avg. Test Loss: 0.00457864860072732\n",
      "Epoch: 407, Avg. Train Loss: 0.004646698771001294, Avg. Test Loss: 0.004555943422019482\n",
      "Epoch: 408, Avg. Train Loss: 0.004629929279258778, Avg. Test Loss: 0.004538512788712978\n",
      "Epoch: 409, Avg. Train Loss: 0.004633234109902798, Avg. Test Loss: 0.004551615100353956\n",
      "Epoch: 410, Avg. Train Loss: 0.004631292941265328, Avg. Test Loss: 0.004525604657828808\n",
      "Epoch: 411, Avg. Train Loss: 0.004631491258827059, Avg. Test Loss: 0.004627247340977192\n",
      "Epoch: 412, Avg. Train Loss: 0.004636667387256789, Avg. Test Loss: 0.004561115056276321\n",
      "Epoch: 413, Avg. Train Loss: 0.0046288616695376325, Avg. Test Loss: 0.004542646463960409\n",
      "Epoch: 414, Avg. Train Loss: 0.004629089605323104, Avg. Test Loss: 0.004530480597168207\n",
      "Epoch: 415, Avg. Train Loss: 0.004633190511011107, Avg. Test Loss: 0.0045452178455889225\n",
      "Epoch: 416, Avg. Train Loss: 0.004631542405763338, Avg. Test Loss: 0.004546035081148148\n",
      "Epoch: 417, Avg. Train Loss: 0.004627828432117091, Avg. Test Loss: 0.0045591616071760654\n",
      "Epoch: 418, Avg. Train Loss: 0.004638747875253821, Avg. Test Loss: 0.004528927616775036\n",
      "Epoch: 419, Avg. Train Loss: 0.004627357020454351, Avg. Test Loss: 0.004536372609436512\n",
      "Epoch: 420, Avg. Train Loss: 0.00463669472049142, Avg. Test Loss: 0.004526222124695778\n",
      "Epoch: 421, Avg. Train Loss: 0.004619613777153021, Avg. Test Loss: 0.004519369453191757\n",
      "Epoch: 422, Avg. Train Loss: 0.0046119630163492156, Avg. Test Loss: 0.004570284858345985\n",
      "Epoch: 423, Avg. Train Loss: 0.004627967361620692, Avg. Test Loss: 0.004534469917416573\n",
      "Epoch: 424, Avg. Train Loss: 0.004630525282389203, Avg. Test Loss: 0.004545206669718027\n",
      "Epoch: 425, Avg. Train Loss: 0.00462279585731584, Avg. Test Loss: 0.004558136221021414\n",
      "Epoch: 426, Avg. Train Loss: 0.004633759235053561, Avg. Test Loss: 0.004541752394288778\n",
      "Epoch: 427, Avg. Train Loss: 0.004619837630280229, Avg. Test Loss: 0.004527123179286718\n",
      "Epoch: 428, Avg. Train Loss: 0.004610599191902682, Avg. Test Loss: 0.004563699942082167\n",
      "Epoch: 429, Avg. Train Loss: 0.004617342682078827, Avg. Test Loss: 0.004518412984907627\n",
      "Epoch: 430, Avg. Train Loss: 0.004612939681338016, Avg. Test Loss: 0.004528761841356754\n",
      "Epoch: 431, Avg. Train Loss: 0.004631170169125462, Avg. Test Loss: 0.004512233193963766\n",
      "Epoch: 432, Avg. Train Loss: 0.004624547750884017, Avg. Test Loss: 0.004534328822046518\n",
      "Epoch: 433, Avg. Train Loss: 0.004618893778168185, Avg. Test Loss: 0.004550231620669365\n",
      "Epoch: 434, Avg. Train Loss: 0.004610657583662244, Avg. Test Loss: 0.004576720762997866\n",
      "Epoch: 435, Avg. Train Loss: 0.004623327642505945, Avg. Test Loss: 0.004511167760938406\n",
      "Epoch: 436, Avg. Train Loss: 0.004606165587468896, Avg. Test Loss: 0.004514476750046015\n",
      "Epoch: 437, Avg. Train Loss: 0.004610332075593083, Avg. Test Loss: 0.0045104133896529675\n",
      "Epoch: 438, Avg. Train Loss: 0.004613214161593554, Avg. Test Loss: 0.004506718832999468\n",
      "Epoch: 439, Avg. Train Loss: 0.004607569794495439, Avg. Test Loss: 0.004523957148194313\n",
      "Epoch: 440, Avg. Train Loss: 0.0046035668184590895, Avg. Test Loss: 0.004564189352095127\n",
      "Epoch: 441, Avg. Train Loss: 0.004621265380275111, Avg. Test Loss: 0.0045316098257899284\n",
      "Epoch: 442, Avg. Train Loss: 0.004614325142790412, Avg. Test Loss: 0.004561637062579393\n",
      "Epoch: 443, Avg. Train Loss: 0.004610334024872891, Avg. Test Loss: 0.004525322932749987\n",
      "Epoch: 444, Avg. Train Loss: 0.0046039004160394505, Avg. Test Loss: 0.004518553148955107\n",
      "Epoch: 445, Avg. Train Loss: 0.004623933781891368, Avg. Test Loss: 0.00452993530780077\n",
      "Epoch: 446, Avg. Train Loss: 0.004607124481523453, Avg. Test Loss: 0.004505308344960213\n",
      "Epoch: 447, Avg. Train Loss: 0.004609331401974656, Avg. Test Loss: 0.004513678140938282\n",
      "Epoch: 448, Avg. Train Loss: 0.00459899035347409, Avg. Test Loss: 0.004536620806902647\n",
      "Epoch: 449, Avg. Train Loss: 0.004601967087838539, Avg. Test Loss: 0.004502068739384413\n",
      "Epoch: 450, Avg. Train Loss: 0.004600173003191865, Avg. Test Loss: 0.0045152525417506695\n",
      "Epoch: 451, Avg. Train Loss: 0.0046120763344820155, Avg. Test Loss: 0.004560171160846949\n",
      "Epoch: 452, Avg. Train Loss: 0.004617401084667722, Avg. Test Loss: 0.004510319791734219\n",
      "Epoch: 453, Avg. Train Loss: 0.004614921492459469, Avg. Test Loss: 0.004508725367486477\n",
      "Epoch: 454, Avg. Train Loss: 0.004592284192006255, Avg. Test Loss: 0.004524674266576767\n",
      "Epoch: 455, Avg. Train Loss: 0.004594169329678596, Avg. Test Loss: 0.004562367219477892\n",
      "Epoch: 456, Avg. Train Loss: 0.004608709451764129, Avg. Test Loss: 0.004530793987214565\n",
      "Epoch: 457, Avg. Train Loss: 0.004605996162565642, Avg. Test Loss: 0.004510081838816404\n",
      "Epoch: 458, Avg. Train Loss: 0.0045992987078809465, Avg. Test Loss: 0.004515479784458876\n",
      "Epoch: 459, Avg. Train Loss: 0.004593016937115165, Avg. Test Loss: 0.004497778136283159\n",
      "Epoch: 460, Avg. Train Loss: 0.004586216430504655, Avg. Test Loss: 0.00451283436268568\n",
      "Epoch: 461, Avg. Train Loss: 0.004600153131367162, Avg. Test Loss: 0.004492361564189196\n",
      "Epoch: 462, Avg. Train Loss: 0.004590305088217868, Avg. Test Loss: 0.004500648472458124\n",
      "Epoch: 463, Avg. Train Loss: 0.0045962561636643355, Avg. Test Loss: 0.004502948373556137\n",
      "Epoch: 464, Avg. Train Loss: 0.004606138059306283, Avg. Test Loss: 0.004497464280575514\n",
      "Epoch: 465, Avg. Train Loss: 0.004592129050992256, Avg. Test Loss: 0.004525982774794102\n",
      "Epoch: 466, Avg. Train Loss: 0.0045921375411887505, Avg. Test Loss: 0.0045091016218066216\n",
      "Epoch: 467, Avg. Train Loss: 0.004595975045028121, Avg. Test Loss: 0.004511790815740824\n",
      "Epoch: 468, Avg. Train Loss: 0.0045925747429908705, Avg. Test Loss: 0.0045010182075202465\n",
      "Epoch: 469, Avg. Train Loss: 0.00458724528204563, Avg. Test Loss: 0.004510827828198671\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 470, Avg. Train Loss: 0.0045960903665873895, Avg. Test Loss: 0.004507877863943577\n",
      "Epoch: 471, Avg. Train Loss: 0.004593250818204048, Avg. Test Loss: 0.004526094067841768\n",
      "Epoch: 472, Avg. Train Loss: 0.004603022991051507, Avg. Test Loss: 0.004496441222727299\n",
      "Epoch: 473, Avg. Train Loss: 0.004596592490236426, Avg. Test Loss: 0.004511498846113682\n",
      "Epoch: 474, Avg. Train Loss: 0.004597190626745307, Avg. Test Loss: 0.004484051838517189\n",
      "Epoch: 475, Avg. Train Loss: 0.004583390429615974, Avg. Test Loss: 0.004545670468360186\n",
      "Epoch: 476, Avg. Train Loss: 0.004590518090354149, Avg. Test Loss: 0.004501571878790855\n",
      "Epoch: 477, Avg. Train Loss: 0.004576720817144527, Avg. Test Loss: 0.004482440184801817\n",
      "Epoch: 478, Avg. Train Loss: 0.004579316250719997, Avg. Test Loss: 0.004491576459258795\n",
      "Epoch: 479, Avg. Train Loss: 0.004573483453240506, Avg. Test Loss: 0.004484514705836773\n",
      "Epoch: 480, Avg. Train Loss: 0.0045797833089911665, Avg. Test Loss: 0.004485268145799637\n",
      "Epoch: 481, Avg. Train Loss: 0.00460249760599677, Avg. Test Loss: 0.004477275535464287\n",
      "Epoch: 482, Avg. Train Loss: 0.004574989239403675, Avg. Test Loss: 0.004516672808676958\n",
      "Epoch: 483, Avg. Train Loss: 0.004584067901813014, Avg. Test Loss: 0.004491025116294622\n",
      "Epoch: 484, Avg. Train Loss: 0.004567137226289095, Avg. Test Loss: 0.004476149566471577\n",
      "Epoch: 485, Avg. Train Loss: 0.004571761426970709, Avg. Test Loss: 0.004560769069939852\n",
      "Epoch: 486, Avg. Train Loss: 0.004599028017891701, Avg. Test Loss: 0.004507563542574644\n",
      "Epoch: 487, Avg. Train Loss: 0.00457575733145309, Avg. Test Loss: 0.004505947697907686\n",
      "Epoch: 488, Avg. Train Loss: 0.004582345030855301, Avg. Test Loss: 0.004473757464438677\n",
      "Epoch: 489, Avg. Train Loss: 0.004569998920656914, Avg. Test Loss: 0.004480194300413132\n",
      "Epoch: 490, Avg. Train Loss: 0.004571752341160941, Avg. Test Loss: 0.004488557111471891\n",
      "Epoch: 491, Avg. Train Loss: 0.0045702482443736045, Avg. Test Loss: 0.004481118638068438\n",
      "Epoch: 492, Avg. Train Loss: 0.00457273833020482, Avg. Test Loss: 0.004506209399551153\n",
      "Epoch: 493, Avg. Train Loss: 0.004600499074386303, Avg. Test Loss: 0.004473299719393253\n",
      "Epoch: 494, Avg. Train Loss: 0.004586566531987384, Avg. Test Loss: 0.00450233556330204\n",
      "Epoch: 495, Avg. Train Loss: 0.0045730514928352005, Avg. Test Loss: 0.004495738074183464\n",
      "Epoch: 496, Avg. Train Loss: 0.004573564099277868, Avg. Test Loss: 0.00447905482724309\n",
      "Epoch: 497, Avg. Train Loss: 0.004566585904983587, Avg. Test Loss: 0.004487466067075729\n",
      "Epoch: 498, Avg. Train Loss: 0.004594336675350056, Avg. Test Loss: 0.004572189413011074\n",
      "Epoch: 499, Avg. Train Loss: 0.0045973405480211555, Avg. Test Loss: 0.004486837889999151\n",
      "Epoch: 500, Avg. Train Loss: 0.004577882003125756, Avg. Test Loss: 0.004490724299103022\n",
      "Epoch: 501, Avg. Train Loss: 0.004571432919176512, Avg. Test Loss: 0.00452482420951128\n",
      "Epoch: 502, Avg. Train Loss: 0.004585410544085641, Avg. Test Loss: 0.004470022860914469\n",
      "Epoch: 503, Avg. Train Loss: 0.004558185862680507, Avg. Test Loss: 0.004477104637771845\n",
      "Epoch: 504, Avg. Train Loss: 0.004566267230223084, Avg. Test Loss: 0.004499088041484356\n",
      "Epoch: 505, Avg. Train Loss: 0.0045632399337063, Avg. Test Loss: 0.004490552004426718\n",
      "Epoch: 506, Avg. Train Loss: 0.004572567887344333, Avg. Test Loss: 0.004477037116885185\n",
      "Epoch: 507, Avg. Train Loss: 0.0045668618905163084, Avg. Test Loss: 0.004474502056837082\n",
      "Epoch: 508, Avg. Train Loss: 0.004563668634482595, Avg. Test Loss: 0.004473274573683739\n",
      "Epoch: 509, Avg. Train Loss: 0.004559289761494065, Avg. Test Loss: 0.004452595952898264\n",
      "Epoch: 510, Avg. Train Loss: 0.004555479298497356, Avg. Test Loss: 0.004471100401133299\n",
      "Epoch: 511, Avg. Train Loss: 0.004565582372421442, Avg. Test Loss: 0.004464063327759504\n",
      "Epoch: 512, Avg. Train Loss: 0.004550279193925996, Avg. Test Loss: 0.004468956962227821\n",
      "Epoch: 513, Avg. Train Loss: 0.004555454423521147, Avg. Test Loss: 0.004475539084523916\n",
      "Epoch: 514, Avg. Train Loss: 0.004554546546450881, Avg. Test Loss: 0.004523162264376879\n",
      "Epoch: 515, Avg. Train Loss: 0.0045553709293694, Avg. Test Loss: 0.004476088099181652\n",
      "Epoch: 516, Avg. Train Loss: 0.004551919848593169, Avg. Test Loss: 0.004457063972949982\n",
      "Epoch: 517, Avg. Train Loss: 0.0045799937770636965, Avg. Test Loss: 0.004451523069292307\n",
      "Epoch: 518, Avg. Train Loss: 0.004559509488645681, Avg. Test Loss: 0.004447413142770529\n",
      "Epoch: 519, Avg. Train Loss: 0.004541784113402976, Avg. Test Loss: 0.004482757765799761\n",
      "Epoch: 520, Avg. Train Loss: 0.004573848802423061, Avg. Test Loss: 0.004473153036087751\n",
      "Epoch: 521, Avg. Train Loss: 0.004558792662655198, Avg. Test Loss: 0.0044575887732207775\n",
      "Epoch: 522, Avg. Train Loss: 0.004554875400783711, Avg. Test Loss: 0.004455618094652891\n",
      "Epoch: 523, Avg. Train Loss: 0.004540857599051886, Avg. Test Loss: 0.0044814059510827065\n",
      "Epoch: 524, Avg. Train Loss: 0.00455722232284241, Avg. Test Loss: 0.004481864627450705\n",
      "Epoch: 525, Avg. Train Loss: 0.004558287907478421, Avg. Test Loss: 0.004479012452065945\n",
      "Epoch: 526, Avg. Train Loss: 0.004557089858450169, Avg. Test Loss: 0.004467194899916649\n",
      "Epoch: 527, Avg. Train Loss: 0.004548515756289626, Avg. Test Loss: 0.004441527184098959\n",
      "Epoch: 528, Avg. Train Loss: 0.004535924914011428, Avg. Test Loss: 0.0044579035602509975\n",
      "Epoch: 529, Avg. Train Loss: 0.0045598148974741615, Avg. Test Loss: 0.004533967934548855\n",
      "Epoch: 530, Avg. Train Loss: 0.004569654645354942, Avg. Test Loss: 0.004483881872147322\n",
      "Epoch: 531, Avg. Train Loss: 0.004561273760140636, Avg. Test Loss: 0.004445653408765793\n",
      "Epoch: 532, Avg. Train Loss: 0.0045540101263065675, Avg. Test Loss: 0.004549810197204351\n",
      "Epoch: 533, Avg. Train Loss: 0.004562187387586333, Avg. Test Loss: 0.004448239225894213\n",
      "Epoch: 534, Avg. Train Loss: 0.004541835931757855, Avg. Test Loss: 0.004466668237000704\n",
      "Epoch: 535, Avg. Train Loss: 0.004533774869213271, Avg. Test Loss: 0.004449102561920881\n",
      "Epoch: 536, Avg. Train Loss: 0.0045332367380344595, Avg. Test Loss: 0.004446540493518114\n",
      "Epoch: 537, Avg. Train Loss: 0.004545913294477518, Avg. Test Loss: 0.0044654132798314095\n",
      "Epoch: 538, Avg. Train Loss: 0.0045479179879780425, Avg. Test Loss: 0.004459119401872158\n",
      "Epoch: 539, Avg. Train Loss: 0.004538229894066273, Avg. Test Loss: 0.004446172155439854\n",
      "Epoch: 540, Avg. Train Loss: 0.0045419380090437654, Avg. Test Loss: 0.004462570883333683\n",
      "Epoch: 541, Avg. Train Loss: 0.004543228529740212, Avg. Test Loss: 0.004471407271921635\n",
      "Epoch: 542, Avg. Train Loss: 0.004539385275525409, Avg. Test Loss: 0.004447331186383963\n",
      "Epoch: 543, Avg. Train Loss: 0.004527286767179883, Avg. Test Loss: 0.004442290402948856\n",
      "Epoch: 544, Avg. Train Loss: 0.004545614968032338, Avg. Test Loss: 0.0044606709852814674\n",
      "Epoch: 545, Avg. Train Loss: 0.004538900976957277, Avg. Test Loss: 0.0044562239199876785\n",
      "Epoch: 546, Avg. Train Loss: 0.004547961088720449, Avg. Test Loss: 0.004504738375544548\n",
      "Epoch: 547, Avg. Train Loss: 0.004557535474643458, Avg. Test Loss: 0.004445408936589956\n",
      "Epoch: 548, Avg. Train Loss: 0.00454613974664447, Avg. Test Loss: 0.004429754335433245\n",
      "Epoch: 549, Avg. Train Loss: 0.00453740578188106, Avg. Test Loss: 0.004487179685384035\n",
      "Epoch: 550, Avg. Train Loss: 0.004546665608189827, Avg. Test Loss: 0.004431865178048611\n",
      "Epoch: 551, Avg. Train Loss: 0.004544036657831004, Avg. Test Loss: 0.004469213075935841\n",
      "Epoch: 552, Avg. Train Loss: 0.004539066340860932, Avg. Test Loss: 0.004445516970008612\n",
      "Epoch: 553, Avg. Train Loss: 0.004534622242804183, Avg. Test Loss: 0.004434168338775635\n",
      "Epoch: 554, Avg. Train Loss: 0.004525369812929353, Avg. Test Loss: 0.004458431154489517\n",
      "Epoch: 555, Avg. Train Loss: 0.004536160993454761, Avg. Test Loss: 0.004452731925994158\n",
      "Epoch: 556, Avg. Train Loss: 0.004542986873190763, Avg. Test Loss: 0.004447875078767538\n",
      "Epoch: 557, Avg. Train Loss: 0.004535485871222823, Avg. Test Loss: 0.004435406997799873\n",
      "Epoch: 558, Avg. Train Loss: 0.004526920887360046, Avg. Test Loss: 0.004452169872820377\n",
      "Epoch: 559, Avg. Train Loss: 0.0045161898962633555, Avg. Test Loss: 0.004444238729774952\n",
      "Epoch: 560, Avg. Train Loss: 0.00452295922522628, Avg. Test Loss: 0.004423986189067364\n",
      "Epoch: 561, Avg. Train Loss: 0.004526303767031709, Avg. Test Loss: 0.004470860585570335\n",
      "Epoch: 562, Avg. Train Loss: 0.0045401776252790935, Avg. Test Loss: 0.004424904007464647\n",
      "Epoch: 563, Avg. Train Loss: 0.00453848791373677, Avg. Test Loss: 0.004478067625313997\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 564, Avg. Train Loss: 0.004532039122179497, Avg. Test Loss: 0.004490784835070372\n",
      "Epoch: 565, Avg. Train Loss: 0.004524165482888388, Avg. Test Loss: 0.004440547898411751\n",
      "Epoch: 566, Avg. Train Loss: 0.00453029747315964, Avg. Test Loss: 0.00442981394007802\n",
      "Epoch: 567, Avg. Train Loss: 0.00451993620629574, Avg. Test Loss: 0.004439923912286758\n",
      "Epoch: 568, Avg. Train Loss: 0.00451366989981643, Avg. Test Loss: 0.004438743926584721\n",
      "Epoch: 569, Avg. Train Loss: 0.0045257209107106506, Avg. Test Loss: 0.004416755400598049\n",
      "Epoch: 570, Avg. Train Loss: 0.004519076108239418, Avg. Test Loss: 0.004423196893185377\n",
      "Epoch: 571, Avg. Train Loss: 0.004510663882937542, Avg. Test Loss: 0.004414383787661791\n",
      "Epoch: 572, Avg. Train Loss: 0.004513368422035561, Avg. Test Loss: 0.004417310003191233\n",
      "Epoch: 573, Avg. Train Loss: 0.004512284698268009, Avg. Test Loss: 0.00442184042185545\n",
      "Epoch: 574, Avg. Train Loss: 0.00451335362916769, Avg. Test Loss: 0.004465857520699501\n",
      "Epoch: 575, Avg. Train Loss: 0.004535658220045789, Avg. Test Loss: 0.004431914072483778\n",
      "Epoch: 576, Avg. Train Loss: 0.0045145632330934665, Avg. Test Loss: 0.004413890652358532\n",
      "Epoch: 577, Avg. Train Loss: 0.004512663594945226, Avg. Test Loss: 0.004463027697056532\n",
      "Epoch: 578, Avg. Train Loss: 0.004522740570178559, Avg. Test Loss: 0.004426928237080574\n",
      "Epoch: 579, Avg. Train Loss: 0.004512816180236811, Avg. Test Loss: 0.0044142017140984535\n",
      "Epoch: 580, Avg. Train Loss: 0.004501016799707052, Avg. Test Loss: 0.004457856994122267\n",
      "Epoch: 581, Avg. Train Loss: 0.004517101791015891, Avg. Test Loss: 0.004448616411536932\n",
      "Epoch: 582, Avg. Train Loss: 0.004521773879004772, Avg. Test Loss: 0.004439002834260464\n",
      "Epoch: 583, Avg. Train Loss: 0.0045062716032356715, Avg. Test Loss: 0.004433280322700739\n",
      "Epoch: 584, Avg. Train Loss: 0.004507024620854577, Avg. Test Loss: 0.004408347420394421\n",
      "Epoch: 585, Avg. Train Loss: 0.004501769319176674, Avg. Test Loss: 0.004425221122801304\n",
      "Epoch: 586, Avg. Train Loss: 0.004507761914283037, Avg. Test Loss: 0.004414726980030537\n",
      "Epoch: 587, Avg. Train Loss: 0.004508941141931817, Avg. Test Loss: 0.004450681619346142\n",
      "Epoch: 588, Avg. Train Loss: 0.004512169929004686, Avg. Test Loss: 0.004444635007530451\n",
      "Epoch: 589, Avg. Train Loss: 0.004547469058009081, Avg. Test Loss: 0.004440661519765854\n",
      "Epoch: 590, Avg. Train Loss: 0.00451066282166298, Avg. Test Loss: 0.004426008090376854\n",
      "Epoch: 591, Avg. Train Loss: 0.004506190589001012, Avg. Test Loss: 0.004441237077116966\n",
      "Epoch: 592, Avg. Train Loss: 0.004517429735684811, Avg. Test Loss: 0.004417738411575556\n",
      "Epoch: 593, Avg. Train Loss: 0.004490899214477733, Avg. Test Loss: 0.004417664837092161\n",
      "Epoch: 594, Avg. Train Loss: 0.00450446083058798, Avg. Test Loss: 0.004435093142092228\n",
      "Epoch: 595, Avg. Train Loss: 0.004510139894866666, Avg. Test Loss: 0.004418139345943928\n",
      "Epoch: 596, Avg. Train Loss: 0.004504467793848626, Avg. Test Loss: 0.004411453381180763\n",
      "Epoch: 597, Avg. Train Loss: 0.004493407212024511, Avg. Test Loss: 0.0044156406074762344\n",
      "Epoch: 598, Avg. Train Loss: 0.004498855070059382, Avg. Test Loss: 0.00444123474881053\n",
      "Epoch: 599, Avg. Train Loss: 0.004501997969698074, Avg. Test Loss: 0.004412828478962183\n",
      "Epoch: 600, Avg. Train Loss: 0.0045038437210889746, Avg. Test Loss: 0.004419978708028793\n",
      "Epoch: 601, Avg. Train Loss: 0.004509466061325267, Avg. Test Loss: 0.004522034898400307\n",
      "Epoch: 602, Avg. Train Loss: 0.0045221156852189885, Avg. Test Loss: 0.004473799839615822\n",
      "Epoch: 603, Avg. Train Loss: 0.004520755661868079, Avg. Test Loss: 0.004398752469569445\n",
      "Epoch: 604, Avg. Train Loss: 0.004495530833251948, Avg. Test Loss: 0.004400158300995827\n",
      "Epoch: 605, Avg. Train Loss: 0.004497162965234629, Avg. Test Loss: 0.004399850964546204\n",
      "Epoch: 606, Avg. Train Loss: 0.004503487988353469, Avg. Test Loss: 0.00440111244097352\n",
      "Epoch: 607, Avg. Train Loss: 0.004493192488024401, Avg. Test Loss: 0.004409534856677055\n",
      "Epoch: 608, Avg. Train Loss: 0.004487088231673074, Avg. Test Loss: 0.004401521757245064\n",
      "Epoch: 609, Avg. Train Loss: 0.004504787248321051, Avg. Test Loss: 0.004410337656736374\n",
      "Epoch: 610, Avg. Train Loss: 0.004485793097681085, Avg. Test Loss: 0.0043966579250991344\n",
      "Epoch: 611, Avg. Train Loss: 0.004486892827201721, Avg. Test Loss: 0.004402141086757183\n",
      "Epoch: 612, Avg. Train Loss: 0.004493617084483767, Avg. Test Loss: 0.004389456007629633\n",
      "Epoch: 613, Avg. Train Loss: 0.0044961685509702495, Avg. Test Loss: 0.004414688795804977\n",
      "Epoch: 614, Avg. Train Loss: 0.004508218857957874, Avg. Test Loss: 0.004405259620398283\n",
      "Epoch: 615, Avg. Train Loss: 0.004488721349124991, Avg. Test Loss: 0.00445568049326539\n",
      "Epoch: 616, Avg. Train Loss: 0.004502476420426785, Avg. Test Loss: 0.004400382749736309\n",
      "Epoch: 617, Avg. Train Loss: 0.004486629761062389, Avg. Test Loss: 0.004399631172418594\n",
      "Epoch: 618, Avg. Train Loss: 0.004502245961406896, Avg. Test Loss: 0.004403266590088606\n",
      "Epoch: 619, Avg. Train Loss: 0.004483818834604219, Avg. Test Loss: 0.0044200909323990345\n",
      "Epoch: 620, Avg. Train Loss: 0.004492274030696514, Avg. Test Loss: 0.004399911500513554\n",
      "Epoch: 621, Avg. Train Loss: 0.004483738740862802, Avg. Test Loss: 0.004461098928004503\n",
      "Epoch: 622, Avg. Train Loss: 0.004477757440749989, Avg. Test Loss: 0.0044366163201630116\n",
      "Epoch: 623, Avg. Train Loss: 0.004486631818635519, Avg. Test Loss: 0.00439991382881999\n",
      "Epoch: 624, Avg. Train Loss: 0.004501410868278769, Avg. Test Loss: 0.0044362181797623634\n",
      "Epoch: 625, Avg. Train Loss: 0.004492521859965352, Avg. Test Loss: 0.004406252410262823\n",
      "Epoch: 626, Avg. Train Loss: 0.004479855266507975, Avg. Test Loss: 0.004413906950503588\n",
      "Epoch: 627, Avg. Train Loss: 0.004469032204428384, Avg. Test Loss: 0.004387879744172096\n",
      "Epoch: 628, Avg. Train Loss: 0.004476082771150179, Avg. Test Loss: 0.004389909096062183\n",
      "Epoch: 629, Avg. Train Loss: 0.004470445616387351, Avg. Test Loss: 0.004391719587147236\n",
      "Epoch: 630, Avg. Train Loss: 0.004486990128752104, Avg. Test Loss: 0.004382267594337463\n",
      "Epoch: 631, Avg. Train Loss: 0.0044853398684672145, Avg. Test Loss: 0.004394606687128544\n",
      "Epoch: 632, Avg. Train Loss: 0.004474601318496604, Avg. Test Loss: 0.004380987491458654\n",
      "Epoch: 633, Avg. Train Loss: 0.004485126877160266, Avg. Test Loss: 0.004440641961991787\n",
      "Epoch: 634, Avg. Train Loss: 0.004474054946195941, Avg. Test Loss: 0.004379246849566698\n",
      "Epoch: 635, Avg. Train Loss: 0.004472686595088521, Avg. Test Loss: 0.004378444980829954\n",
      "Epoch: 636, Avg. Train Loss: 0.004469274380785781, Avg. Test Loss: 0.0043872809037566185\n",
      "Epoch: 637, Avg. Train Loss: 0.00450098161520653, Avg. Test Loss: 0.004387414548546076\n",
      "Epoch: 638, Avg. Train Loss: 0.004490331703320492, Avg. Test Loss: 0.004399085883051157\n",
      "Epoch: 639, Avg. Train Loss: 0.004479013957343129, Avg. Test Loss: 0.0043924907222390175\n",
      "Epoch: 640, Avg. Train Loss: 0.004467284902497087, Avg. Test Loss: 0.004398677963763475\n",
      "Epoch: 641, Avg. Train Loss: 0.004480405244976282, Avg. Test Loss: 0.004401794169098139\n",
      "Epoch: 642, Avg. Train Loss: 0.004464277835172969, Avg. Test Loss: 0.004372527357190847\n",
      "Epoch: 643, Avg. Train Loss: 0.004465162288397551, Avg. Test Loss: 0.004383440129458904\n",
      "Epoch: 644, Avg. Train Loss: 0.00447405279115882, Avg. Test Loss: 0.004375003278255463\n",
      "Epoch: 645, Avg. Train Loss: 0.00445859215417227, Avg. Test Loss: 0.004404062405228615\n",
      "Epoch: 646, Avg. Train Loss: 0.004468389851755874, Avg. Test Loss: 0.00442306837067008\n",
      "Epoch: 647, Avg. Train Loss: 0.0044737389354511745, Avg. Test Loss: 0.004395720083266497\n",
      "Epoch: 648, Avg. Train Loss: 0.004489133101996294, Avg. Test Loss: 0.004431661684066057\n",
      "Epoch: 649, Avg. Train Loss: 0.004495156842262246, Avg. Test Loss: 0.004423671867698431\n",
      "Epoch: 650, Avg. Train Loss: 0.00446300141426713, Avg. Test Loss: 0.004363515414297581\n",
      "Epoch: 651, Avg. Train Loss: 0.004466693664272857, Avg. Test Loss: 0.004367000423371792\n",
      "Epoch: 652, Avg. Train Loss: 0.004462441905986431, Avg. Test Loss: 0.004366343375295401\n",
      "Epoch: 653, Avg. Train Loss: 0.004470017966056286, Avg. Test Loss: 0.004389965441077948\n",
      "Epoch: 654, Avg. Train Loss: 0.004478808730667414, Avg. Test Loss: 0.004370056092739105\n",
      "Epoch: 655, Avg. Train Loss: 0.004471492639547864, Avg. Test Loss: 0.004396076779812574\n",
      "Epoch: 656, Avg. Train Loss: 0.004485449981117664, Avg. Test Loss: 0.004395243711769581\n",
      "Epoch: 657, Avg. Train Loss: 0.004468960947422094, Avg. Test Loss: 0.00437087332829833\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 658, Avg. Train Loss: 0.004463549995751575, Avg. Test Loss: 0.004391007125377655\n",
      "Epoch: 659, Avg. Train Loss: 0.004480138951695935, Avg. Test Loss: 0.00443349638953805\n",
      "Epoch: 660, Avg. Train Loss: 0.004459957310626673, Avg. Test Loss: 0.00439649960026145\n",
      "Epoch: 661, Avg. Train Loss: 0.004451787922271463, Avg. Test Loss: 0.004397593438625336\n",
      "Epoch: 662, Avg. Train Loss: 0.004458106144569641, Avg. Test Loss: 0.00441667390987277\n",
      "Epoch: 663, Avg. Train Loss: 0.004449025435416505, Avg. Test Loss: 0.004373465199023485\n",
      "Epoch: 664, Avg. Train Loss: 0.004469072197152432, Avg. Test Loss: 0.004359458573162556\n",
      "Epoch: 665, Avg. Train Loss: 0.004473647211006907, Avg. Test Loss: 0.004417655523866415\n",
      "Epoch: 666, Avg. Train Loss: 0.004457863199329654, Avg. Test Loss: 0.004389042034745216\n",
      "Epoch: 667, Avg. Train Loss: 0.004480685692193897, Avg. Test Loss: 0.004363937769085169\n",
      "Epoch: 668, Avg. Train Loss: 0.004452131331226853, Avg. Test Loss: 0.0044304803013801575\n",
      "Epoch: 669, Avg. Train Loss: 0.0044616751784328805, Avg. Test Loss: 0.004360147751867771\n",
      "Epoch: 670, Avg. Train Loss: 0.004442492380824893, Avg. Test Loss: 0.004365323111414909\n",
      "Epoch: 671, Avg. Train Loss: 0.004461811692995387, Avg. Test Loss: 0.00436833780258894\n",
      "Epoch: 672, Avg. Train Loss: 0.004449646118595157, Avg. Test Loss: 0.004385046660900116\n",
      "Epoch: 673, Avg. Train Loss: 0.004449673776709756, Avg. Test Loss: 0.00439288467168808\n",
      "Epoch: 674, Avg. Train Loss: 0.004465791894945987, Avg. Test Loss: 0.004399440251290798\n",
      "Epoch: 675, Avg. Train Loss: 0.004460210078071023, Avg. Test Loss: 0.004370288923382759\n",
      "Epoch: 676, Avg. Train Loss: 0.004463953355890374, Avg. Test Loss: 0.004383918363600969\n",
      "Epoch: 677, Avg. Train Loss: 0.004468555497222169, Avg. Test Loss: 0.004383076447993517\n",
      "Epoch: 678, Avg. Train Loss: 0.004441108262209698, Avg. Test Loss: 0.004374665208160877\n",
      "Epoch: 679, Avg. Train Loss: 0.004459336183445398, Avg. Test Loss: 0.004373037721961737\n",
      "Epoch: 680, Avg. Train Loss: 0.004451205553270356, Avg. Test Loss: 0.004363343119621277\n",
      "Epoch: 681, Avg. Train Loss: 0.004452653142601945, Avg. Test Loss: 0.004370886366814375\n",
      "Epoch: 682, Avg. Train Loss: 0.0044447333486967305, Avg. Test Loss: 0.004346448462456465\n",
      "Epoch: 683, Avg. Train Loss: 0.0044490116713351985, Avg. Test Loss: 0.004364963620901108\n",
      "Epoch: 684, Avg. Train Loss: 0.004436560365003209, Avg. Test Loss: 0.004391197115182877\n",
      "Epoch: 685, Avg. Train Loss: 0.004459744146050409, Avg. Test Loss: 0.004368660971522331\n",
      "Epoch: 686, Avg. Train Loss: 0.004443984511200079, Avg. Test Loss: 0.004361408296972513\n",
      "Epoch: 687, Avg. Train Loss: 0.00446414882533772, Avg. Test Loss: 0.0043606203980743885\n",
      "Epoch: 688, Avg. Train Loss: 0.004444458749318539, Avg. Test Loss: 0.0043748971074819565\n",
      "Epoch: 689, Avg. Train Loss: 0.004454627892998762, Avg. Test Loss: 0.00436547352001071\n",
      "Epoch: 690, Avg. Train Loss: 0.0044319961479929995, Avg. Test Loss: 0.004350601229816675\n",
      "Epoch: 691, Avg. Train Loss: 0.004434403389432403, Avg. Test Loss: 0.004345016088336706\n",
      "Epoch: 692, Avg. Train Loss: 0.004440813000465549, Avg. Test Loss: 0.0043480913154780865\n",
      "Epoch: 693, Avg. Train Loss: 0.0044421773988666926, Avg. Test Loss: 0.00441929092630744\n",
      "Epoch: 694, Avg. Train Loss: 0.004445208128281804, Avg. Test Loss: 0.0043726530857384205\n",
      "Epoch: 695, Avg. Train Loss: 0.004433571555933287, Avg. Test Loss: 0.004344166722148657\n",
      "Epoch: 696, Avg. Train Loss: 0.004426733525686486, Avg. Test Loss: 0.004350794479250908\n",
      "Epoch: 697, Avg. Train Loss: 0.004455604146472936, Avg. Test Loss: 0.004355467855930328\n",
      "Epoch: 698, Avg. Train Loss: 0.004442591794095067, Avg. Test Loss: 0.0043680425733327866\n",
      "Epoch: 699, Avg. Train Loss: 0.0044451010153563906, Avg. Test Loss: 0.00436039175838232\n",
      "Epoch: 700, Avg. Train Loss: 0.004446206062079169, Avg. Test Loss: 0.004353077616542578\n",
      "Epoch: 701, Avg. Train Loss: 0.004448263353646495, Avg. Test Loss: 0.004383084364235401\n",
      "Epoch: 702, Avg. Train Loss: 0.004445632497325193, Avg. Test Loss: 0.004369214177131653\n",
      "Epoch: 703, Avg. Train Loss: 0.004441905723408211, Avg. Test Loss: 0.004353822208940983\n",
      "Epoch: 704, Avg. Train Loss: 0.0044549980937221715, Avg. Test Loss: 0.004399708006531\n",
      "Epoch: 705, Avg. Train Loss: 0.004447156065251938, Avg. Test Loss: 0.004379082936793566\n",
      "Epoch: 706, Avg. Train Loss: 0.004423643516506566, Avg. Test Loss: 0.00435675447806716\n",
      "Epoch: 707, Avg. Train Loss: 0.004443786431883656, Avg. Test Loss: 0.004376502241939306\n",
      "Epoch: 708, Avg. Train Loss: 0.004479095166505769, Avg. Test Loss: 0.004399413242936134\n",
      "Epoch: 709, Avg. Train Loss: 0.004439774456672197, Avg. Test Loss: 0.0043631489388644695\n",
      "Epoch: 710, Avg. Train Loss: 0.0044285943406785645, Avg. Test Loss: 0.004359873477369547\n",
      "Epoch: 711, Avg. Train Loss: 0.004442338517672101, Avg. Test Loss: 0.004380545578896999\n",
      "Epoch: 712, Avg. Train Loss: 0.004443039836058783, Avg. Test Loss: 0.0044402130879461765\n",
      "Epoch: 713, Avg. Train Loss: 0.004450852192158616, Avg. Test Loss: 0.00438725296407938\n",
      "Epoch: 714, Avg. Train Loss: 0.004430343537743009, Avg. Test Loss: 0.004353954456746578\n",
      "Epoch: 715, Avg. Train Loss: 0.00444711601838123, Avg. Test Loss: 0.004340227227658033\n",
      "Epoch: 716, Avg. Train Loss: 0.0044215964153409, Avg. Test Loss: 0.004352983087301254\n",
      "Epoch: 717, Avg. Train Loss: 0.004426290021212988, Avg. Test Loss: 0.0043398551642894745\n",
      "Epoch: 718, Avg. Train Loss: 0.004434701867488234, Avg. Test Loss: 0.004364653490483761\n",
      "Epoch: 719, Avg. Train Loss: 0.00442433665874739, Avg. Test Loss: 0.004359439015388489\n",
      "Epoch: 720, Avg. Train Loss: 0.004425537480084702, Avg. Test Loss: 0.004341505467891693\n",
      "Epoch: 721, Avg. Train Loss: 0.0044315720930002455, Avg. Test Loss: 0.004334412049502134\n",
      "Epoch: 722, Avg. Train Loss: 0.004426216056873632, Avg. Test Loss: 0.004366540815681219\n",
      "Epoch: 723, Avg. Train Loss: 0.0044319627286736355, Avg. Test Loss: 0.0043497891165316105\n",
      "Epoch: 724, Avg. Train Loss: 0.004436971663042556, Avg. Test Loss: 0.004336660727858543\n",
      "Epoch: 725, Avg. Train Loss: 0.004418249382789052, Avg. Test Loss: 0.004355594515800476\n",
      "Epoch: 726, Avg. Train Loss: 0.00442088974726408, Avg. Test Loss: 0.004351356532424688\n",
      "Epoch: 727, Avg. Train Loss: 0.0044205424938957355, Avg. Test Loss: 0.004327793605625629\n",
      "Epoch: 728, Avg. Train Loss: 0.00443071810268732, Avg. Test Loss: 0.004341603722423315\n",
      "Epoch: 729, Avg. Train Loss: 0.004416983455506175, Avg. Test Loss: 0.004323178436607122\n",
      "Epoch: 730, Avg. Train Loss: 0.004421090891281533, Avg. Test Loss: 0.004346680361777544\n",
      "Epoch: 731, Avg. Train Loss: 0.004421025287186684, Avg. Test Loss: 0.00433688098564744\n",
      "Epoch: 732, Avg. Train Loss: 0.004419478392878244, Avg. Test Loss: 0.004341829102486372\n",
      "Epoch: 733, Avg. Train Loss: 0.004414928297317306, Avg. Test Loss: 0.004334942903369665\n",
      "Epoch: 734, Avg. Train Loss: 0.004437866631548765, Avg. Test Loss: 0.004346327390521765\n",
      "Epoch: 735, Avg. Train Loss: 0.004419263528096814, Avg. Test Loss: 0.004333457909524441\n",
      "Epoch: 736, Avg. Train Loss: 0.004414578130858582, Avg. Test Loss: 0.004353807773441076\n",
      "Epoch: 737, Avg. Train Loss: 0.004438690104803374, Avg. Test Loss: 0.004352015908807516\n",
      "Epoch: 738, Avg. Train Loss: 0.004436483996552091, Avg. Test Loss: 0.004372855182737112\n",
      "Epoch: 739, Avg. Train Loss: 0.004424385455718567, Avg. Test Loss: 0.004399062599986792\n",
      "Epoch: 740, Avg. Train Loss: 0.004416742470375327, Avg. Test Loss: 0.004319816827774048\n",
      "Epoch: 741, Avg. Train Loss: 0.004408375154314346, Avg. Test Loss: 0.004327268805354834\n",
      "Epoch: 742, Avg. Train Loss: 0.004411441588037929, Avg. Test Loss: 0.004373942036181688\n",
      "Epoch: 743, Avg. Train Loss: 0.004410614075442386, Avg. Test Loss: 0.004329610150307417\n",
      "Epoch: 744, Avg. Train Loss: 0.004418173187607249, Avg. Test Loss: 0.004324766341596842\n",
      "Epoch: 745, Avg. Train Loss: 0.004418770836796178, Avg. Test Loss: 0.0043894946575164795\n",
      "Epoch: 746, Avg. Train Loss: 0.004429548220752284, Avg. Test Loss: 0.004316107369959354\n",
      "Epoch: 747, Avg. Train Loss: 0.004427880806805089, Avg. Test Loss: 0.00437512993812561\n",
      "Epoch: 748, Avg. Train Loss: 0.0044198248232173365, Avg. Test Loss: 0.004347045440226793\n",
      "Epoch: 749, Avg. Train Loss: 0.004402264075483693, Avg. Test Loss: 0.004362383857369423\n",
      "Epoch: 750, Avg. Train Loss: 0.004412057560457047, Avg. Test Loss: 0.004358968697488308\n",
      "Epoch: 751, Avg. Train Loss: 0.004419132406541774, Avg. Test Loss: 0.004356096964329481\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 752, Avg. Train Loss: 0.00441235130609468, Avg. Test Loss: 0.00441744364798069\n",
      "Epoch: 753, Avg. Train Loss: 0.004416009346239789, Avg. Test Loss: 0.004426189698278904\n",
      "Epoch: 754, Avg. Train Loss: 0.0044117662297605085, Avg. Test Loss: 0.004350198898464441\n",
      "Epoch: 755, Avg. Train Loss: 0.004412592648593492, Avg. Test Loss: 0.00435327272862196\n",
      "Epoch: 756, Avg. Train Loss: 0.004418250292452962, Avg. Test Loss: 0.004383506253361702\n",
      "Epoch: 757, Avg. Train Loss: 0.004413325025505105, Avg. Test Loss: 0.004390026442706585\n",
      "Epoch: 758, Avg. Train Loss: 0.004400559495268173, Avg. Test Loss: 0.0043279025703668594\n",
      "Epoch: 759, Avg. Train Loss: 0.004407590276799923, Avg. Test Loss: 0.004352192860096693\n",
      "Epoch: 760, Avg. Train Loss: 0.004401659712108762, Avg. Test Loss: 0.004359080456197262\n",
      "Epoch: 761, Avg. Train Loss: 0.004409609990584296, Avg. Test Loss: 0.004385325592011213\n",
      "Epoch: 762, Avg. Train Loss: 0.0044003081789543465, Avg. Test Loss: 0.004313688259571791\n",
      "Epoch: 763, Avg. Train Loss: 0.004428608743690474, Avg. Test Loss: 0.004372539464384317\n",
      "Epoch: 764, Avg. Train Loss: 0.00440796199362985, Avg. Test Loss: 0.0044004907831549644\n",
      "Epoch: 765, Avg. Train Loss: 0.004404756922794636, Avg. Test Loss: 0.0043259188532829285\n",
      "Epoch: 766, Avg. Train Loss: 0.004394548847664928, Avg. Test Loss: 0.004319088999181986\n",
      "Epoch: 767, Avg. Train Loss: 0.004414884373545647, Avg. Test Loss: 0.004332888871431351\n",
      "Epoch: 768, Avg. Train Loss: 0.004412849563672099, Avg. Test Loss: 0.004458850249648094\n",
      "Epoch: 769, Avg. Train Loss: 0.004415916105689004, Avg. Test Loss: 0.004319170024245977\n",
      "Epoch: 770, Avg. Train Loss: 0.004393353690068389, Avg. Test Loss: 0.004313242621719837\n",
      "Epoch: 771, Avg. Train Loss: 0.004402341137012077, Avg. Test Loss: 0.004332942888140678\n",
      "Epoch: 772, Avg. Train Loss: 0.004407621649375489, Avg. Test Loss: 0.0044336626306176186\n",
      "Epoch: 773, Avg. Train Loss: 0.004410902298120565, Avg. Test Loss: 0.004310407675802708\n",
      "Epoch: 774, Avg. Train Loss: 0.004404848636409571, Avg. Test Loss: 0.004311415832489729\n",
      "Epoch: 775, Avg. Train Loss: 0.004407321828482456, Avg. Test Loss: 0.004381067585200071\n",
      "Epoch: 776, Avg. Train Loss: 0.004409937361298606, Avg. Test Loss: 0.0043910532258450985\n",
      "Epoch: 777, Avg. Train Loss: 0.004407851101267476, Avg. Test Loss: 0.004364216234534979\n",
      "Epoch: 778, Avg. Train Loss: 0.00442517066894229, Avg. Test Loss: 0.004313893616199493\n",
      "Epoch: 779, Avg. Train Loss: 0.004419459506522777, Avg. Test Loss: 0.004323227796703577\n",
      "Epoch: 780, Avg. Train Loss: 0.004406770128150319, Avg. Test Loss: 0.004328887443989515\n",
      "Epoch: 781, Avg. Train Loss: 0.004385433549624543, Avg. Test Loss: 0.004325023386627436\n",
      "Epoch: 782, Avg. Train Loss: 0.0044122492612967655, Avg. Test Loss: 0.0043547023087739944\n",
      "Epoch: 783, Avg. Train Loss: 0.004396504560095626, Avg. Test Loss: 0.004322069697082043\n",
      "Epoch: 784, Avg. Train Loss: 0.004400158073579849, Avg. Test Loss: 0.004309899639338255\n",
      "Epoch: 785, Avg. Train Loss: 0.004395549911139316, Avg. Test Loss: 0.0043204170651733875\n",
      "Epoch: 786, Avg. Train Loss: 0.004418615533342195, Avg. Test Loss: 0.004371659830212593\n",
      "Epoch: 787, Avg. Train Loss: 0.004400794426802286, Avg. Test Loss: 0.004338087979704142\n",
      "Epoch: 788, Avg. Train Loss: 0.004400910322316164, Avg. Test Loss: 0.004337746184319258\n",
      "Epoch: 789, Avg. Train Loss: 0.004388117285575284, Avg. Test Loss: 0.0043021258898079395\n",
      "Epoch: 790, Avg. Train Loss: 0.004408341236845698, Avg. Test Loss: 0.004342209082096815\n",
      "Epoch: 791, Avg. Train Loss: 0.004403674552693616, Avg. Test Loss: 0.004321897868067026\n",
      "Epoch: 792, Avg. Train Loss: 0.0043937451162830345, Avg. Test Loss: 0.004328917246311903\n",
      "Epoch: 793, Avg. Train Loss: 0.0044028237137163796, Avg. Test Loss: 0.004317977465689182\n",
      "Epoch: 794, Avg. Train Loss: 0.004390179147120825, Avg. Test Loss: 0.0043110474944114685\n",
      "Epoch: 795, Avg. Train Loss: 0.004402015574796255, Avg. Test Loss: 0.004315774887800217\n",
      "Epoch: 796, Avg. Train Loss: 0.004392159084767797, Avg. Test Loss: 0.004320432897657156\n",
      "Epoch: 797, Avg. Train Loss: 0.00438752047024494, Avg. Test Loss: 0.004326633643358946\n",
      "Epoch: 798, Avg. Train Loss: 0.004380091245091239, Avg. Test Loss: 0.004297031555324793\n",
      "Epoch: 799, Avg. Train Loss: 0.0043772489893748314, Avg. Test Loss: 0.004339392296969891\n",
      "Epoch: 800, Avg. Train Loss: 0.0043967918081339015, Avg. Test Loss: 0.004315318539738655\n",
      "Epoch: 801, Avg. Train Loss: 0.0043971041369056975, Avg. Test Loss: 0.004341157153248787\n",
      "Epoch: 802, Avg. Train Loss: 0.004389650004287792, Avg. Test Loss: 0.004323683679103851\n",
      "Epoch: 803, Avg. Train Loss: 0.004397108566102593, Avg. Test Loss: 0.004325261805206537\n",
      "Epoch: 804, Avg. Train Loss: 0.004386216737763133, Avg. Test Loss: 0.0043016583658754826\n",
      "Epoch: 805, Avg. Train Loss: 0.004372822424007016, Avg. Test Loss: 0.004338239319622517\n",
      "Epoch: 806, Avg. Train Loss: 0.004376157630928034, Avg. Test Loss: 0.004308792762458324\n",
      "Epoch: 807, Avg. Train Loss: 0.0043864127919944216, Avg. Test Loss: 0.004299536347389221\n",
      "Epoch: 808, Avg. Train Loss: 0.004377869975774787, Avg. Test Loss: 0.004366701934486628\n",
      "Epoch: 809, Avg. Train Loss: 0.004380039654152338, Avg. Test Loss: 0.00430875550955534\n",
      "Epoch: 810, Avg. Train Loss: 0.004375393448267565, Avg. Test Loss: 0.0043058148585259914\n",
      "Epoch: 811, Avg. Train Loss: 0.004397757297251807, Avg. Test Loss: 0.004332134034484625\n",
      "Epoch: 812, Avg. Train Loss: 0.004376421076093995, Avg. Test Loss: 0.004326328635215759\n",
      "Epoch: 813, Avg. Train Loss: 0.004375061247671066, Avg. Test Loss: 0.00431107310578227\n",
      "Epoch: 814, Avg. Train Loss: 0.004385252699775751, Avg. Test Loss: 0.004336113575845957\n",
      "Epoch: 815, Avg. Train Loss: 0.004386182322145202, Avg. Test Loss: 0.004309277981519699\n",
      "Epoch: 816, Avg. Train Loss: 0.0043774975875262604, Avg. Test Loss: 0.004309337120503187\n",
      "Epoch: 817, Avg. Train Loss: 0.004375987426312857, Avg. Test Loss: 0.004308945033699274\n",
      "Epoch: 818, Avg. Train Loss: 0.00441059035920473, Avg. Test Loss: 0.004305910784751177\n",
      "Epoch: 819, Avg. Train Loss: 0.004383688272778378, Avg. Test Loss: 0.004320914391428232\n",
      "Epoch: 820, Avg. Train Loss: 0.00438636263052738, Avg. Test Loss: 0.004306785296648741\n",
      "Epoch: 821, Avg. Train Loss: 0.004381735278510077, Avg. Test Loss: 0.004353275056928396\n",
      "Epoch: 822, Avg. Train Loss: 0.004389810581626587, Avg. Test Loss: 0.004336178302764893\n",
      "Epoch: 823, Avg. Train Loss: 0.004399102625198836, Avg. Test Loss: 0.0042959703132510185\n",
      "Epoch: 824, Avg. Train Loss: 0.004372016894955968, Avg. Test Loss: 0.004337402526289225\n",
      "Epoch: 825, Avg. Train Loss: 0.0043727168271881205, Avg. Test Loss: 0.004292304627597332\n",
      "Epoch: 826, Avg. Train Loss: 0.004369273521872454, Avg. Test Loss: 0.004340690560638905\n",
      "Epoch: 827, Avg. Train Loss: 0.004392171386889247, Avg. Test Loss: 0.004447346553206444\n",
      "Epoch: 828, Avg. Train Loss: 0.004408484671351521, Avg. Test Loss: 0.004300891887396574\n",
      "Epoch: 829, Avg. Train Loss: 0.004380528566016014, Avg. Test Loss: 0.0043312967754900455\n",
      "Epoch: 830, Avg. Train Loss: 0.00436660097262194, Avg. Test Loss: 0.004292900674045086\n",
      "Epoch: 831, Avg. Train Loss: 0.004373122937977314, Avg. Test Loss: 0.0042867339216172695\n",
      "Epoch: 832, Avg. Train Loss: 0.004378640721010608, Avg. Test Loss: 0.00431933905929327\n",
      "Epoch: 833, Avg. Train Loss: 0.004381877445984025, Avg. Test Loss: 0.004305969923734665\n",
      "Epoch: 834, Avg. Train Loss: 0.004372276679807624, Avg. Test Loss: 0.004366448149085045\n",
      "Epoch: 835, Avg. Train Loss: 0.0043972736917609395, Avg. Test Loss: 0.0042857518419623375\n",
      "Epoch: 836, Avg. Train Loss: 0.004356869507234457, Avg. Test Loss: 0.004291553981602192\n",
      "Epoch: 837, Avg. Train Loss: 0.004362504377008178, Avg. Test Loss: 0.004337530583143234\n",
      "Epoch: 838, Avg. Train Loss: 0.004367486422145089, Avg. Test Loss: 0.004295227117836475\n",
      "Epoch: 839, Avg. Train Loss: 0.004373464116090259, Avg. Test Loss: 0.004325880203396082\n",
      "Epoch: 840, Avg. Train Loss: 0.004381362099720295, Avg. Test Loss: 0.004293612204492092\n",
      "Epoch: 841, Avg. Train Loss: 0.0043715406317523745, Avg. Test Loss: 0.004308213014155626\n",
      "Epoch: 842, Avg. Train Loss: 0.004362759624369616, Avg. Test Loss: 0.004319595638662577\n",
      "Epoch: 843, Avg. Train Loss: 0.004377986120363307, Avg. Test Loss: 0.004359291400760412\n",
      "Epoch: 844, Avg. Train Loss: 0.004384299913464591, Avg. Test Loss: 0.004291210789233446\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 845, Avg. Train Loss: 0.004362740012448888, Avg. Test Loss: 0.004291233606636524\n",
      "Epoch: 846, Avg. Train Loss: 0.00436327465658271, Avg. Test Loss: 0.004344224464148283\n",
      "Epoch: 847, Avg. Train Loss: 0.004379987521746824, Avg. Test Loss: 0.004315725993365049\n",
      "Epoch: 848, Avg. Train Loss: 0.004377610970635054, Avg. Test Loss: 0.004292202182114124\n",
      "Epoch: 849, Avg. Train Loss: 0.004358235724963421, Avg. Test Loss: 0.004295570310205221\n",
      "Epoch: 850, Avg. Train Loss: 0.004355200988695372, Avg. Test Loss: 0.004303961060941219\n",
      "Epoch: 851, Avg. Train Loss: 0.004380747318527726, Avg. Test Loss: 0.004304195754230022\n",
      "Epoch: 852, Avg. Train Loss: 0.004371305418655623, Avg. Test Loss: 0.004339820239692926\n",
      "Epoch: 853, Avg. Train Loss: 0.004373113754703555, Avg. Test Loss: 0.004288812633603811\n",
      "Epoch: 854, Avg. Train Loss: 0.00436381192141494, Avg. Test Loss: 0.004334178753197193\n",
      "Epoch: 855, Avg. Train Loss: 0.004367153257738019, Avg. Test Loss: 0.004277529660612345\n",
      "Epoch: 856, Avg. Train Loss: 0.00436219391088153, Avg. Test Loss: 0.004318479914218187\n",
      "Epoch: 857, Avg. Train Loss: 0.004352702607595643, Avg. Test Loss: 0.004291526507586241\n",
      "Epoch: 858, Avg. Train Loss: 0.0043566012971623, Avg. Test Loss: 0.004269760567694902\n",
      "Epoch: 859, Avg. Train Loss: 0.004365747025626344, Avg. Test Loss: 0.004300943110138178\n",
      "Epoch: 860, Avg. Train Loss: 0.0043793993590529575, Avg. Test Loss: 0.004370349925011396\n",
      "Epoch: 861, Avg. Train Loss: 0.004364401426946008, Avg. Test Loss: 0.004284808412194252\n",
      "Epoch: 862, Avg. Train Loss: 0.004363765171187562, Avg. Test Loss: 0.0042719654738903046\n",
      "Epoch: 863, Avg. Train Loss: 0.004370562721390364, Avg. Test Loss: 0.004283244721591473\n",
      "Epoch: 864, Avg. Train Loss: 0.004370956367618123, Avg. Test Loss: 0.004297210369259119\n",
      "Epoch: 865, Avg. Train Loss: 0.004354073785158784, Avg. Test Loss: 0.004302106332033873\n",
      "Epoch: 866, Avg. Train Loss: 0.004364509676951308, Avg. Test Loss: 0.004300903063267469\n",
      "Epoch: 867, Avg. Train Loss: 0.0043617128394544125, Avg. Test Loss: 0.004307957831770182\n",
      "Epoch: 868, Avg. Train Loss: 0.0043628391008390935, Avg. Test Loss: 0.004352458752691746\n",
      "Epoch: 869, Avg. Train Loss: 0.004363787804491991, Avg. Test Loss: 0.004345492459833622\n",
      "Epoch: 870, Avg. Train Loss: 0.004350422123490378, Avg. Test Loss: 0.004305726382881403\n",
      "Epoch: 871, Avg. Train Loss: 0.004366970707684062, Avg. Test Loss: 0.004313900135457516\n",
      "Epoch: 872, Avg. Train Loss: 0.004355070657681587, Avg. Test Loss: 0.00434484239667654\n",
      "Epoch: 873, Avg. Train Loss: 0.004366274858110173, Avg. Test Loss: 0.004319052677601576\n",
      "Epoch: 874, Avg. Train Loss: 0.004349245256636032, Avg. Test Loss: 0.004292626399546862\n",
      "Epoch: 875, Avg. Train Loss: 0.004346088376329388, Avg. Test Loss: 0.004264047369360924\n",
      "Epoch: 876, Avg. Train Loss: 0.004357126920462348, Avg. Test Loss: 0.004268671851605177\n",
      "Epoch: 877, Avg. Train Loss: 0.004349237665274116, Avg. Test Loss: 0.004271864425390959\n",
      "Epoch: 878, Avg. Train Loss: 0.0043587406425801825, Avg. Test Loss: 0.00427552405744791\n",
      "Epoch: 879, Avg. Train Loss: 0.004357236816526153, Avg. Test Loss: 0.004268003161996603\n",
      "Epoch: 880, Avg. Train Loss: 0.004346863778178082, Avg. Test Loss: 0.004265065770596266\n",
      "Epoch: 881, Avg. Train Loss: 0.004335486893217231, Avg. Test Loss: 0.004281924571841955\n",
      "Epoch: 882, Avg. Train Loss: 0.004374077955130921, Avg. Test Loss: 0.004269476514309645\n",
      "Epoch: 883, Avg. Train Loss: 0.004363310609965823, Avg. Test Loss: 0.004275449551641941\n",
      "Epoch: 884, Avg. Train Loss: 0.004360753165687932, Avg. Test Loss: 0.004308861214667559\n",
      "Epoch: 885, Avg. Train Loss: 0.0043624894433589865, Avg. Test Loss: 0.004263062961399555\n",
      "Epoch: 886, Avg. Train Loss: 0.004353701028712961, Avg. Test Loss: 0.004266251344233751\n",
      "Epoch: 887, Avg. Train Loss: 0.004354596354587134, Avg. Test Loss: 0.00426168879494071\n",
      "Epoch: 888, Avg. Train Loss: 0.004354196156613355, Avg. Test Loss: 0.004268893040716648\n",
      "Epoch: 889, Avg. Train Loss: 0.004342856557043486, Avg. Test Loss: 0.004285698756575584\n",
      "Epoch: 890, Avg. Train Loss: 0.004352873180408117, Avg. Test Loss: 0.004298358224332333\n",
      "Epoch: 891, Avg. Train Loss: 0.004346915542386299, Avg. Test Loss: 0.004283245652914047\n",
      "Epoch: 892, Avg. Train Loss: 0.004345724662376004, Avg. Test Loss: 0.004266411066055298\n",
      "Epoch: 893, Avg. Train Loss: 0.004342370103438234, Avg. Test Loss: 0.004270478151738644\n",
      "Epoch: 894, Avg. Train Loss: 0.004343429103840229, Avg. Test Loss: 0.004265244584530592\n",
      "Epoch: 895, Avg. Train Loss: 0.004335227617344191, Avg. Test Loss: 0.004265658091753721\n",
      "Epoch: 896, Avg. Train Loss: 0.004342780302300356, Avg. Test Loss: 0.004294766113162041\n",
      "Epoch: 897, Avg. Train Loss: 0.004333913402068753, Avg. Test Loss: 0.004297791048884392\n",
      "Epoch: 898, Avg. Train Loss: 0.00436116719271901, Avg. Test Loss: 0.0043134926818311214\n",
      "Epoch: 899, Avg. Train Loss: 0.0043354883443477545, Avg. Test Loss: 0.004257781431078911\n",
      "Epoch: 900, Avg. Train Loss: 0.004344939714470922, Avg. Test Loss: 0.004304248373955488\n",
      "Epoch: 901, Avg. Train Loss: 0.004352724634457466, Avg. Test Loss: 0.004362589213997126\n",
      "Epoch: 902, Avg. Train Loss: 0.004356712514404641, Avg. Test Loss: 0.004312880337238312\n",
      "Epoch: 903, Avg. Train Loss: 0.004349934435341247, Avg. Test Loss: 0.004309162497520447\n",
      "Epoch: 904, Avg. Train Loss: 0.004362489465017652, Avg. Test Loss: 0.004273487254977226\n",
      "Epoch: 905, Avg. Train Loss: 0.004360822722489058, Avg. Test Loss: 0.0042612869292497635\n",
      "Epoch: 906, Avg. Train Loss: 0.0043640208517222905, Avg. Test Loss: 0.004289914853870869\n",
      "Epoch: 907, Avg. Train Loss: 0.004349929237261761, Avg. Test Loss: 0.004386588465422392\n",
      "Epoch: 908, Avg. Train Loss: 0.004353884921604117, Avg. Test Loss: 0.004291532561182976\n",
      "Epoch: 909, Avg. Train Loss: 0.004336182623668466, Avg. Test Loss: 0.004289256874471903\n",
      "Epoch: 910, Avg. Train Loss: 0.004343283600931944, Avg. Test Loss: 0.0043587409891188145\n",
      "Epoch: 911, Avg. Train Loss: 0.004354757365099219, Avg. Test Loss: 0.004298048559576273\n",
      "Epoch: 912, Avg. Train Loss: 0.004338445131082174, Avg. Test Loss: 0.004260094836354256\n",
      "Epoch: 913, Avg. Train Loss: 0.004354337511887384, Avg. Test Loss: 0.004274989943951368\n",
      "Epoch: 914, Avg. Train Loss: 0.004334795537816231, Avg. Test Loss: 0.004251236096024513\n",
      "Epoch: 915, Avg. Train Loss: 0.0043415183981144155, Avg. Test Loss: 0.0043142992071807384\n",
      "Epoch: 916, Avg. Train Loss: 0.004357567176136167, Avg. Test Loss: 0.004251577891409397\n",
      "Epoch: 917, Avg. Train Loss: 0.004341208246038403, Avg. Test Loss: 0.004257501568645239\n",
      "Epoch: 918, Avg. Train Loss: 0.004327838298279879, Avg. Test Loss: 0.004266177304089069\n",
      "Epoch: 919, Avg. Train Loss: 0.004331118286435687, Avg. Test Loss: 0.004278598818928003\n",
      "Epoch: 920, Avg. Train Loss: 0.004327670313677815, Avg. Test Loss: 0.004268081393092871\n",
      "Epoch: 921, Avg. Train Loss: 0.004343718810136928, Avg. Test Loss: 0.0042569623328745365\n",
      "Epoch: 922, Avg. Train Loss: 0.004334200823376345, Avg. Test Loss: 0.0043004476465284824\n",
      "Epoch: 923, Avg. Train Loss: 0.004335472186984018, Avg. Test Loss: 0.0043188584968447685\n",
      "Epoch: 924, Avg. Train Loss: 0.004337245170676777, Avg. Test Loss: 0.0042671943083405495\n",
      "Epoch: 925, Avg. Train Loss: 0.0043672396433214805, Avg. Test Loss: 0.004288123920559883\n",
      "Epoch: 926, Avg. Train Loss: 0.004334617525252492, Avg. Test Loss: 0.004251211881637573\n",
      "Epoch: 927, Avg. Train Loss: 0.004348262776295806, Avg. Test Loss: 0.00435048621147871\n",
      "Epoch: 928, Avg. Train Loss: 0.0043464769652589805, Avg. Test Loss: 0.004255315754562616\n",
      "Epoch: 929, Avg. Train Loss: 0.00434873435039853, Avg. Test Loss: 0.004297747742384672\n",
      "Epoch: 930, Avg. Train Loss: 0.004351825745732978, Avg. Test Loss: 0.004382546525448561\n",
      "Epoch: 931, Avg. Train Loss: 0.004352361873485321, Avg. Test Loss: 0.004302717745304108\n",
      "Epoch: 932, Avg. Train Loss: 0.004355451319539963, Avg. Test Loss: 0.004268032498657703\n",
      "Epoch: 933, Avg. Train Loss: 0.004347883034930672, Avg. Test Loss: 0.0042501576244831085\n",
      "Epoch: 934, Avg. Train Loss: 0.004318712582421857, Avg. Test Loss: 0.004256177227944136\n",
      "Epoch: 935, Avg. Train Loss: 0.004323831217926602, Avg. Test Loss: 0.0042948173359036446\n",
      "Epoch: 936, Avg. Train Loss: 0.0043253948977000495, Avg. Test Loss: 0.004275805316865444\n",
      "Epoch: 937, Avg. Train Loss: 0.0043505515123522555, Avg. Test Loss: 0.004273993894457817\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 938, Avg. Train Loss: 0.004350565081505582, Avg. Test Loss: 0.004340776242315769\n",
      "Epoch: 939, Avg. Train Loss: 0.004345710974100025, Avg. Test Loss: 0.004279355052858591\n",
      "Epoch: 940, Avg. Train Loss: 0.0043339550408513046, Avg. Test Loss: 0.00430567329749465\n",
      "Epoch: 941, Avg. Train Loss: 0.004342459456258735, Avg. Test Loss: 0.004271433688700199\n",
      "Epoch: 942, Avg. Train Loss: 0.0043298136009726415, Avg. Test Loss: 0.004257781431078911\n",
      "Epoch: 943, Avg. Train Loss: 0.004324435570472201, Avg. Test Loss: 0.004276021849364042\n",
      "Epoch: 944, Avg. Train Loss: 0.004352138735094043, Avg. Test Loss: 0.00427241763100028\n",
      "Epoch: 945, Avg. Train Loss: 0.0043259229575998565, Avg. Test Loss: 0.00424497714266181\n",
      "Epoch: 946, Avg. Train Loss: 0.0043332556717444294, Avg. Test Loss: 0.004279250744730234\n",
      "Epoch: 947, Avg. Train Loss: 0.0043376623219702135, Avg. Test Loss: 0.004245045594871044\n",
      "Epoch: 948, Avg. Train Loss: 0.004344688338595767, Avg. Test Loss: 0.0042811245657503605\n",
      "Epoch: 949, Avg. Train Loss: 0.004318897709856892, Avg. Test Loss: 0.004279798828065395\n",
      "Epoch: 950, Avg. Train Loss: 0.00432977631558166, Avg. Test Loss: 0.0042452504858374596\n",
      "Epoch: 951, Avg. Train Loss: 0.004339121043855368, Avg. Test Loss: 0.004253025632351637\n",
      "Epoch: 952, Avg. Train Loss: 0.004323688335716724, Avg. Test Loss: 0.004292703699320555\n",
      "Epoch: 953, Avg. Train Loss: 0.004323956513300885, Avg. Test Loss: 0.004271374084055424\n",
      "Epoch: 954, Avg. Train Loss: 0.004320995546444211, Avg. Test Loss: 0.004265007097274065\n",
      "Epoch: 955, Avg. Train Loss: 0.00434411749200419, Avg. Test Loss: 0.004263763315975666\n",
      "Epoch: 956, Avg. Train Loss: 0.0043149826138518576, Avg. Test Loss: 0.004298732616007328\n",
      "Epoch: 957, Avg. Train Loss: 0.004348828803834527, Avg. Test Loss: 0.004325910471379757\n",
      "Epoch: 958, Avg. Train Loss: 0.0043384950109865775, Avg. Test Loss: 0.004253728780895472\n",
      "Epoch: 959, Avg. Train Loss: 0.004324751721998287, Avg. Test Loss: 0.004274324513971806\n",
      "Epoch: 960, Avg. Train Loss: 0.004329611471485953, Avg. Test Loss: 0.004257196560502052\n",
      "Epoch: 961, Avg. Train Loss: 0.004341394402260004, Avg. Test Loss: 0.004245787858963013\n",
      "Epoch: 962, Avg. Train Loss: 0.0043310377703503124, Avg. Test Loss: 0.004248436540365219\n",
      "Epoch: 963, Avg. Train Loss: 0.004326553333030884, Avg. Test Loss: 0.004262937698513269\n",
      "Epoch: 964, Avg. Train Loss: 0.004313728945373103, Avg. Test Loss: 0.004242810420691967\n",
      "Epoch: 965, Avg. Train Loss: 0.004326728075136279, Avg. Test Loss: 0.0042519536800682545\n",
      "Epoch: 966, Avg. Train Loss: 0.004314126685088457, Avg. Test Loss: 0.00425346102565527\n",
      "Epoch: 967, Avg. Train Loss: 0.0043177891652597935, Avg. Test Loss: 0.0042626867070794106\n",
      "Epoch: 968, Avg. Train Loss: 0.004328811627834342, Avg. Test Loss: 0.004251063801348209\n",
      "Epoch: 969, Avg. Train Loss: 0.0043037828101321705, Avg. Test Loss: 0.0042428988963365555\n",
      "Epoch: 970, Avg. Train Loss: 0.00432198392877052, Avg. Test Loss: 0.004278916399925947\n",
      "Epoch: 971, Avg. Train Loss: 0.004314802013077709, Avg. Test Loss: 0.00423761922866106\n",
      "Epoch: 972, Avg. Train Loss: 0.004329847702539937, Avg. Test Loss: 0.0042838891968131065\n",
      "Epoch: 973, Avg. Train Loss: 0.004328545009674028, Avg. Test Loss: 0.004252380691468716\n",
      "Epoch: 974, Avg. Train Loss: 0.004317645362556674, Avg. Test Loss: 0.0042359731160104275\n",
      "Epoch: 975, Avg. Train Loss: 0.004313173920435961, Avg. Test Loss: 0.004261315800249577\n",
      "Epoch: 976, Avg. Train Loss: 0.004304984183765428, Avg. Test Loss: 0.0042787580750882626\n",
      "Epoch: 977, Avg. Train Loss: 0.004308345283619886, Avg. Test Loss: 0.004260617773979902\n",
      "Epoch: 978, Avg. Train Loss: 0.00431352727071837, Avg. Test Loss: 0.004254097118973732\n",
      "Epoch: 979, Avg. Train Loss: 0.0043115172166983745, Avg. Test Loss: 0.004290148615837097\n",
      "Epoch: 980, Avg. Train Loss: 0.004329879356678142, Avg. Test Loss: 0.004264088813215494\n",
      "Epoch: 981, Avg. Train Loss: 0.00431904015889348, Avg. Test Loss: 0.004269727505743504\n",
      "Epoch: 982, Avg. Train Loss: 0.004343043579611667, Avg. Test Loss: 0.004286168143153191\n",
      "Epoch: 983, Avg. Train Loss: 0.004314790642278832, Avg. Test Loss: 0.004253752063959837\n",
      "Epoch: 984, Avg. Train Loss: 0.004326012971009626, Avg. Test Loss: 0.004237614572048187\n",
      "Epoch: 985, Avg. Train Loss: 0.004323403459302214, Avg. Test Loss: 0.004229925572872162\n",
      "Epoch: 986, Avg. Train Loss: 0.004304137470763783, Avg. Test Loss: 0.004243607632815838\n",
      "Epoch: 987, Avg. Train Loss: 0.004308963053708159, Avg. Test Loss: 0.004243545234203339\n",
      "Epoch: 988, Avg. Train Loss: 0.004308323180952737, Avg. Test Loss: 0.004255736246705055\n",
      "Epoch: 989, Avg. Train Loss: 0.004309984259740557, Avg. Test Loss: 0.004251474980264902\n",
      "Epoch: 990, Avg. Train Loss: 0.004308240412366252, Avg. Test Loss: 0.004242486786097288\n",
      "Epoch: 991, Avg. Train Loss: 0.0043084412098450715, Avg. Test Loss: 0.004260245710611343\n",
      "Epoch: 992, Avg. Train Loss: 0.004328843336119209, Avg. Test Loss: 0.004234393127262592\n",
      "Epoch: 993, Avg. Train Loss: 0.0043014877605750115, Avg. Test Loss: 0.00423904275521636\n",
      "Epoch: 994, Avg. Train Loss: 0.004299730322388715, Avg. Test Loss: 0.004252472426742315\n",
      "Epoch: 995, Avg. Train Loss: 0.004317286662584127, Avg. Test Loss: 0.004270253702998161\n",
      "Epoch: 996, Avg. Train Loss: 0.004317734563766524, Avg. Test Loss: 0.004237525165081024\n",
      "Epoch: 997, Avg. Train Loss: 0.004324465762650551, Avg. Test Loss: 0.004389760550111532\n",
      "Epoch: 998, Avg. Train Loss: 0.004333212430220704, Avg. Test Loss: 0.004275905899703503\n",
      "Epoch: 999, Avg. Train Loss: 0.004314211673688057, Avg. Test Loss: 0.004232814069837332\n",
      "Epoch: 1000, Avg. Train Loss: 0.004311852362873249, Avg. Test Loss: 0.004239941015839577\n",
      "Epoch: 1001, Avg. Train Loss: 0.004301544333006753, Avg. Test Loss: 0.004232135601341724\n",
      "Epoch: 1002, Avg. Train Loss: 0.004308392445361892, Avg. Test Loss: 0.004250972997397184\n",
      "Epoch: 1003, Avg. Train Loss: 0.004304877276597328, Avg. Test Loss: 0.004244706127792597\n",
      "Epoch: 1004, Avg. Train Loss: 0.0043065159711553605, Avg. Test Loss: 0.004246827680617571\n",
      "Epoch: 1005, Avg. Train Loss: 0.004321985921367656, Avg. Test Loss: 0.0042310128919780254\n",
      "Epoch: 1006, Avg. Train Loss: 0.004300086748201487, Avg. Test Loss: 0.004247794859111309\n",
      "Epoch: 1007, Avg. Train Loss: 0.0043238534830337344, Avg. Test Loss: 0.004232408013194799\n",
      "Epoch: 1008, Avg. Train Loss: 0.004304205056626436, Avg. Test Loss: 0.004226492252200842\n",
      "Epoch: 1009, Avg. Train Loss: 0.004304234761484834, Avg. Test Loss: 0.004238916095346212\n",
      "Epoch: 1010, Avg. Train Loss: 0.004312654015023348, Avg. Test Loss: 0.004232206381857395\n",
      "Epoch: 1011, Avg. Train Loss: 0.004300645021938308, Avg. Test Loss: 0.004246894735842943\n",
      "Epoch: 1012, Avg. Train Loss: 0.004316663856856352, Avg. Test Loss: 0.004224337637424469\n",
      "Epoch: 1013, Avg. Train Loss: 0.004297823515222516, Avg. Test Loss: 0.0043081725016236305\n",
      "Epoch: 1014, Avg. Train Loss: 0.004304740144762882, Avg. Test Loss: 0.0042993007227778435\n",
      "Epoch: 1015, Avg. Train Loss: 0.004303578980440317, Avg. Test Loss: 0.004253105726093054\n",
      "Epoch: 1016, Avg. Train Loss: 0.004294866024581499, Avg. Test Loss: 0.004232457373291254\n",
      "Epoch: 1017, Avg. Train Loss: 0.004310275352191787, Avg. Test Loss: 0.00431211618706584\n",
      "Epoch: 1018, Avg. Train Loss: 0.00430012083893945, Avg. Test Loss: 0.00422388780862093\n",
      "Epoch: 1019, Avg. Train Loss: 0.004321525230743858, Avg. Test Loss: 0.004243002273142338\n",
      "Epoch: 1020, Avg. Train Loss: 0.004322885687268058, Avg. Test Loss: 0.004224640782922506\n",
      "Epoch: 1021, Avg. Train Loss: 0.004292843354389418, Avg. Test Loss: 0.00422986363992095\n",
      "Epoch: 1022, Avg. Train Loss: 0.00430757288149623, Avg. Test Loss: 0.004215731285512447\n",
      "Epoch: 1023, Avg. Train Loss: 0.004310239940275287, Avg. Test Loss: 0.004226797726005316\n",
      "Epoch: 1024, Avg. Train Loss: 0.0043021810219384905, Avg. Test Loss: 0.004251810256391764\n",
      "Epoch: 1025, Avg. Train Loss: 0.004318768721680308, Avg. Test Loss: 0.004345513414591551\n",
      "Epoch: 1026, Avg. Train Loss: 0.004314715638323579, Avg. Test Loss: 0.004275617655366659\n",
      "Epoch: 1027, Avg. Train Loss: 0.004323121279391439, Avg. Test Loss: 0.004236356820911169\n",
      "Epoch: 1028, Avg. Train Loss: 0.004306937719500342, Avg. Test Loss: 0.004254275932908058\n",
      "Epoch: 1029, Avg. Train Loss: 0.004300403397876856, Avg. Test Loss: 0.004217734560370445\n",
      "Epoch: 1030, Avg. Train Loss: 0.004292615039577318, Avg. Test Loss: 0.0042214300483465195\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1031, Avg. Train Loss: 0.004298103583413501, Avg. Test Loss: 0.004220339469611645\n",
      "Epoch: 1032, Avg. Train Loss: 0.004293441263482321, Avg. Test Loss: 0.004235203377902508\n",
      "Epoch: 1033, Avg. Train Loss: 0.004285164588932381, Avg. Test Loss: 0.004219162277877331\n",
      "Epoch: 1034, Avg. Train Loss: 0.004300901937016914, Avg. Test Loss: 0.004266755655407906\n",
      "Epoch: 1035, Avg. Train Loss: 0.004299225924579903, Avg. Test Loss: 0.0042258938774466515\n",
      "Epoch: 1036, Avg. Train Loss: 0.004287995993657861, Avg. Test Loss: 0.004225269891321659\n",
      "Epoch: 1037, Avg. Train Loss: 0.004292169564165348, Avg. Test Loss: 0.004214762710034847\n",
      "Epoch: 1038, Avg. Train Loss: 0.004293366573577703, Avg. Test Loss: 0.004253235179930925\n",
      "Epoch: 1039, Avg. Train Loss: 0.004290995772841365, Avg. Test Loss: 0.0042166998609900475\n",
      "Epoch: 1040, Avg. Train Loss: 0.004306167656512454, Avg. Test Loss: 0.004247575998306274\n",
      "Epoch: 1041, Avg. Train Loss: 0.004297810487535803, Avg. Test Loss: 0.0042148781940341\n",
      "Epoch: 1042, Avg. Train Loss: 0.004297779049984244, Avg. Test Loss: 0.004288670606911182\n",
      "Epoch: 1043, Avg. Train Loss: 0.004289864670745162, Avg. Test Loss: 0.004230906255543232\n",
      "Epoch: 1044, Avg. Train Loss: 0.004288754176868256, Avg. Test Loss: 0.0042069233022630215\n",
      "Epoch: 1045, Avg. Train Loss: 0.004315583825891101, Avg. Test Loss: 0.0042317952029407024\n",
      "Epoch: 1046, Avg. Train Loss: 0.004324368580222823, Avg. Test Loss: 0.004224075004458427\n",
      "Epoch: 1047, Avg. Train Loss: 0.004289956146114787, Avg. Test Loss: 0.004220596514642239\n",
      "Epoch: 1048, Avg. Train Loss: 0.004293237455449132, Avg. Test Loss: 0.004251091741025448\n",
      "Epoch: 1049, Avg. Train Loss: 0.004293811962355015, Avg. Test Loss: 0.00421038968488574\n",
      "Epoch: 1050, Avg. Train Loss: 0.004301502380173567, Avg. Test Loss: 0.004225404467433691\n",
      "Epoch: 1051, Avg. Train Loss: 0.004285002289729756, Avg. Test Loss: 0.004270309116691351\n",
      "Epoch: 1052, Avg. Train Loss: 0.004293340160836314, Avg. Test Loss: 0.004224608652293682\n",
      "Epoch: 1053, Avg. Train Loss: 0.004288309058824251, Avg. Test Loss: 0.0042363665997982025\n",
      "Epoch: 1054, Avg. Train Loss: 0.004299829410778922, Avg. Test Loss: 0.004221406299620867\n",
      "Epoch: 1055, Avg. Train Loss: 0.004293837768653798, Avg. Test Loss: 0.004236148204654455\n",
      "Epoch: 1056, Avg. Train Loss: 0.004292114930184081, Avg. Test Loss: 0.004228898789733648\n",
      "Epoch: 1057, Avg. Train Loss: 0.004284540851882031, Avg. Test Loss: 0.004296636208891869\n",
      "Epoch: 1058, Avg. Train Loss: 0.004303687452446929, Avg. Test Loss: 0.0042233215644955635\n",
      "Epoch: 1059, Avg. Train Loss: 0.004285096970581731, Avg. Test Loss: 0.0042121633887290955\n",
      "Epoch: 1060, Avg. Train Loss: 0.004292361210858406, Avg. Test Loss: 0.004280621651560068\n",
      "Epoch: 1061, Avg. Train Loss: 0.004291272603062003, Avg. Test Loss: 0.004238113760948181\n",
      "Epoch: 1062, Avg. Train Loss: 0.004282196106519117, Avg. Test Loss: 0.004254133440554142\n",
      "Epoch: 1063, Avg. Train Loss: 0.004297248640119336, Avg. Test Loss: 0.004233312793076038\n",
      "Epoch: 1064, Avg. Train Loss: 0.0043079832373836705, Avg. Test Loss: 0.004221009556204081\n",
      "Epoch: 1065, Avg. Train Loss: 0.004279267356925925, Avg. Test Loss: 0.004232770763337612\n",
      "Epoch: 1066, Avg. Train Loss: 0.004280385052308787, Avg. Test Loss: 0.004243159666657448\n",
      "Epoch: 1067, Avg. Train Loss: 0.004300315745261519, Avg. Test Loss: 0.004231771919876337\n",
      "Epoch: 1068, Avg. Train Loss: 0.004279565412637799, Avg. Test Loss: 0.004292474593967199\n",
      "Epoch: 1069, Avg. Train Loss: 0.0043254410739728185, Avg. Test Loss: 0.004200808238238096\n",
      "Epoch: 1070, Avg. Train Loss: 0.004304730398363845, Avg. Test Loss: 0.004277731291949749\n",
      "Epoch: 1071, Avg. Train Loss: 0.004285216678020566, Avg. Test Loss: 0.004236492328345776\n",
      "Epoch: 1072, Avg. Train Loss: 0.004277071471564298, Avg. Test Loss: 0.004225879907608032\n",
      "Epoch: 1073, Avg. Train Loss: 0.0042820420051210145, Avg. Test Loss: 0.004208861850202084\n",
      "Epoch: 1074, Avg. Train Loss: 0.0042660530916480135, Avg. Test Loss: 0.004226000513881445\n",
      "Epoch: 1075, Avg. Train Loss: 0.004281493201635258, Avg. Test Loss: 0.004212244413793087\n",
      "Epoch: 1076, Avg. Train Loss: 0.004284772810764437, Avg. Test Loss: 0.004210050217807293\n",
      "Epoch: 1077, Avg. Train Loss: 0.004277178898540347, Avg. Test Loss: 0.004208457190543413\n",
      "Epoch: 1078, Avg. Train Loss: 0.004293055804229753, Avg. Test Loss: 0.004349003080278635\n",
      "Epoch: 1079, Avg. Train Loss: 0.0042819723183679026, Avg. Test Loss: 0.004221056587994099\n",
      "Epoch: 1080, Avg. Train Loss: 0.004278883836123832, Avg. Test Loss: 0.0042275781743228436\n",
      "Epoch: 1081, Avg. Train Loss: 0.004288196341719392, Avg. Test Loss: 0.004243809729814529\n",
      "Epoch: 1082, Avg. Train Loss: 0.004277292238331811, Avg. Test Loss: 0.004252079874277115\n",
      "Epoch: 1083, Avg. Train Loss: 0.004278427823771571, Avg. Test Loss: 0.004216661676764488\n",
      "Epoch: 1084, Avg. Train Loss: 0.004283835255909104, Avg. Test Loss: 0.004202378913760185\n",
      "Epoch: 1085, Avg. Train Loss: 0.004272380432243957, Avg. Test Loss: 0.004195408895611763\n",
      "Epoch: 1086, Avg. Train Loss: 0.004267713109161271, Avg. Test Loss: 0.004205676726996899\n",
      "Epoch: 1087, Avg. Train Loss: 0.004286773264581381, Avg. Test Loss: 0.004231064114719629\n",
      "Epoch: 1088, Avg. Train Loss: 0.004279013235815043, Avg. Test Loss: 0.004231171682476997\n",
      "Epoch: 1089, Avg. Train Loss: 0.0042848054828598745, Avg. Test Loss: 0.004289552103728056\n",
      "Epoch: 1090, Avg. Train Loss: 0.004304056185795818, Avg. Test Loss: 0.004235559608787298\n",
      "Epoch: 1091, Avg. Train Loss: 0.004270727616236653, Avg. Test Loss: 0.004214037675410509\n",
      "Epoch: 1092, Avg. Train Loss: 0.004263129637598298, Avg. Test Loss: 0.004220202565193176\n",
      "Epoch: 1093, Avg. Train Loss: 0.0042965135342159936, Avg. Test Loss: 0.004262289963662624\n",
      "Epoch: 1094, Avg. Train Loss: 0.004285522899048966, Avg. Test Loss: 0.004199751652777195\n",
      "Epoch: 1095, Avg. Train Loss: 0.0042763468051372575, Avg. Test Loss: 0.004236111883074045\n",
      "Epoch: 1096, Avg. Train Loss: 0.004278816369383834, Avg. Test Loss: 0.004211036488413811\n",
      "Epoch: 1097, Avg. Train Loss: 0.004264550283551216, Avg. Test Loss: 0.004214209038764238\n",
      "Epoch: 1098, Avg. Train Loss: 0.004280692719053044, Avg. Test Loss: 0.004196141380816698\n",
      "Epoch: 1099, Avg. Train Loss: 0.0042903676607407805, Avg. Test Loss: 0.004222583957016468\n",
      "Epoch: 1100, Avg. Train Loss: 0.004282136891730303, Avg. Test Loss: 0.0042253462597727776\n",
      "Epoch: 1101, Avg. Train Loss: 0.004307900198063878, Avg. Test Loss: 0.004206411074846983\n",
      "Epoch: 1102, Avg. Train Loss: 0.004296400540963162, Avg. Test Loss: 0.004214536398649216\n",
      "Epoch: 1103, Avg. Train Loss: 0.0042651560114220135, Avg. Test Loss: 0.004258211236447096\n",
      "Epoch: 1104, Avg. Train Loss: 0.004267434335075492, Avg. Test Loss: 0.004200558178126812\n",
      "Epoch: 1105, Avg. Train Loss: 0.004273855647202148, Avg. Test Loss: 0.004219401627779007\n",
      "Epoch: 1106, Avg. Train Loss: 0.004259922043528668, Avg. Test Loss: 0.004226379096508026\n",
      "Epoch: 1107, Avg. Train Loss: 0.004277983734514131, Avg. Test Loss: 0.00422371132299304\n",
      "Epoch: 1108, Avg. Train Loss: 0.004279787836293149, Avg. Test Loss: 0.0042210533283650875\n",
      "Epoch: 1109, Avg. Train Loss: 0.004298316174035155, Avg. Test Loss: 0.004271454643458128\n",
      "Epoch: 1110, Avg. Train Loss: 0.0043089928885185445, Avg. Test Loss: 0.00423271581530571\n",
      "Epoch: 1111, Avg. Train Loss: 0.004267892399586217, Avg. Test Loss: 0.004240102134644985\n",
      "Epoch: 1112, Avg. Train Loss: 0.004274937546227214, Avg. Test Loss: 0.004251620266586542\n",
      "Epoch: 1113, Avg. Train Loss: 0.004272282892448264, Avg. Test Loss: 0.004199261777102947\n",
      "Epoch: 1114, Avg. Train Loss: 0.0042667734588301455, Avg. Test Loss: 0.0042104958556592464\n",
      "Epoch: 1115, Avg. Train Loss: 0.0042721774418253535, Avg. Test Loss: 0.0041982149705290794\n",
      "Epoch: 1116, Avg. Train Loss: 0.004293385178370531, Avg. Test Loss: 0.004222665913403034\n",
      "Epoch: 1117, Avg. Train Loss: 0.004296428004149781, Avg. Test Loss: 0.004204669501632452\n",
      "Epoch: 1118, Avg. Train Loss: 0.004269761542334806, Avg. Test Loss: 0.004204417113214731\n",
      "Epoch: 1119, Avg. Train Loss: 0.004266046691512646, Avg. Test Loss: 0.0042285555973649025\n",
      "Epoch: 1120, Avg. Train Loss: 0.004273486626875955, Avg. Test Loss: 0.004235010594129562\n",
      "Epoch: 1121, Avg. Train Loss: 0.004272321650628434, Avg. Test Loss: 0.004250547848641872\n",
      "Epoch: 1122, Avg. Train Loss: 0.004272623334166615, Avg. Test Loss: 0.004207597114145756\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1123, Avg. Train Loss: 0.004271781364412502, Avg. Test Loss: 0.004197285510599613\n",
      "Epoch: 1124, Avg. Train Loss: 0.004266586208845987, Avg. Test Loss: 0.00424571568146348\n",
      "Epoch: 1125, Avg. Train Loss: 0.004276172842743785, Avg. Test Loss: 0.0042252386920154095\n",
      "Epoch: 1126, Avg. Train Loss: 0.0042933795362884225, Avg. Test Loss: 0.004197397734969854\n",
      "Epoch: 1127, Avg. Train Loss: 0.004274291246263094, Avg. Test Loss: 0.004230318125337362\n",
      "Epoch: 1128, Avg. Train Loss: 0.004286622238713641, Avg. Test Loss: 0.004234388004988432\n",
      "Epoch: 1129, Avg. Train Loss: 0.004285474459445754, Avg. Test Loss: 0.004197308793663979\n",
      "Epoch: 1130, Avg. Train Loss: 0.004272389095709767, Avg. Test Loss: 0.0042199338786304\n",
      "Epoch: 1131, Avg. Train Loss: 0.0042872310637734655, Avg. Test Loss: 0.004229107405990362\n",
      "Epoch: 1132, Avg. Train Loss: 0.004264985925929491, Avg. Test Loss: 0.004217822570353746\n",
      "Epoch: 1133, Avg. Train Loss: 0.004276037086234536, Avg. Test Loss: 0.004261640831828117\n",
      "Epoch: 1134, Avg. Train Loss: 0.00427623177596996, Avg. Test Loss: 0.004225298762321472\n",
      "Epoch: 1135, Avg. Train Loss: 0.004281897834220598, Avg. Test Loss: 0.004248315468430519\n",
      "Epoch: 1136, Avg. Train Loss: 0.004273208789527416, Avg. Test Loss: 0.004228645004332066\n",
      "Epoch: 1137, Avg. Train Loss: 0.004270921970262777, Avg. Test Loss: 0.004203157499432564\n",
      "Epoch: 1138, Avg. Train Loss: 0.004254415804563567, Avg. Test Loss: 0.004241023678332567\n",
      "Epoch: 1139, Avg. Train Loss: 0.004258330223735335, Avg. Test Loss: 0.004203364253044128\n",
      "Epoch: 1140, Avg. Train Loss: 0.004255101041391839, Avg. Test Loss: 0.004256810527294874\n",
      "Epoch: 1141, Avg. Train Loss: 0.004284879809981862, Avg. Test Loss: 0.004300609230995178\n",
      "Epoch: 1142, Avg. Train Loss: 0.004277729375157939, Avg. Test Loss: 0.004224954638630152\n",
      "Epoch: 1143, Avg. Train Loss: 0.004259178501575492, Avg. Test Loss: 0.004219545051455498\n",
      "Epoch: 1144, Avg. Train Loss: 0.004257322927980229, Avg. Test Loss: 0.004225069656968117\n",
      "Epoch: 1145, Avg. Train Loss: 0.004273784899174474, Avg. Test Loss: 0.0042088995687663555\n",
      "Epoch: 1146, Avg. Train Loss: 0.004282291188056386, Avg. Test Loss: 0.004246982745826244\n",
      "Epoch: 1147, Avg. Train Loss: 0.004257829773218133, Avg. Test Loss: 0.004191117826849222\n",
      "Epoch: 1148, Avg. Train Loss: 0.004248274457749239, Avg. Test Loss: 0.004222072195261717\n",
      "Epoch: 1149, Avg. Train Loss: 0.004261336939106154, Avg. Test Loss: 0.004186967387795448\n",
      "Epoch: 1150, Avg. Train Loss: 0.0042944584193444525, Avg. Test Loss: 0.004219654481858015\n",
      "Epoch: 1151, Avg. Train Loss: 0.00426155528010324, Avg. Test Loss: 0.004228990990668535\n",
      "Epoch: 1152, Avg. Train Loss: 0.0042775919292728564, Avg. Test Loss: 0.004219449125230312\n",
      "Epoch: 1153, Avg. Train Loss: 0.004305683152187009, Avg. Test Loss: 0.004217485431581736\n",
      "Epoch: 1154, Avg. Train Loss: 0.0042610041645550455, Avg. Test Loss: 0.004200822673738003\n",
      "Epoch: 1155, Avg. Train Loss: 0.0042528512584435385, Avg. Test Loss: 0.004189265891909599\n",
      "Epoch: 1156, Avg. Train Loss: 0.00425500476862802, Avg. Test Loss: 0.004248595330864191\n",
      "Epoch: 1157, Avg. Train Loss: 0.004255433826772279, Avg. Test Loss: 0.004197629634290934\n",
      "Epoch: 1158, Avg. Train Loss: 0.004281866223399722, Avg. Test Loss: 0.004235630854964256\n",
      "Epoch: 1159, Avg. Train Loss: 0.004255943747540546, Avg. Test Loss: 0.004234993364661932\n",
      "Epoch: 1160, Avg. Train Loss: 0.004254104450431674, Avg. Test Loss: 0.004219525959342718\n",
      "Epoch: 1161, Avg. Train Loss: 0.00425213280263855, Avg. Test Loss: 0.004177852533757687\n",
      "Epoch: 1162, Avg. Train Loss: 0.004260354003933973, Avg. Test Loss: 0.004208123777061701\n",
      "Epoch: 1163, Avg. Train Loss: 0.004254644991136914, Avg. Test Loss: 0.0041924635879695415\n",
      "Epoch: 1164, Avg. Train Loss: 0.0042572148295855795, Avg. Test Loss: 0.004182293079793453\n",
      "Epoch: 1165, Avg. Train Loss: 0.004251116128681704, Avg. Test Loss: 0.004226595163345337\n",
      "Epoch: 1166, Avg. Train Loss: 0.004252938997693533, Avg. Test Loss: 0.004178458824753761\n",
      "Epoch: 1167, Avg. Train Loss: 0.004251509255101514, Avg. Test Loss: 0.004214717540889978\n",
      "Epoch: 1168, Avg. Train Loss: 0.004254535512002402, Avg. Test Loss: 0.004237465560436249\n",
      "Epoch: 1169, Avg. Train Loss: 0.004321194492107214, Avg. Test Loss: 0.004205840174108744\n",
      "Epoch: 1170, Avg. Train Loss: 0.004281539903130642, Avg. Test Loss: 0.004204470198601484\n",
      "Epoch: 1171, Avg. Train Loss: 0.0042804581719602264, Avg. Test Loss: 0.004227927420288324\n",
      "Epoch: 1172, Avg. Train Loss: 0.004255315505487974, Avg. Test Loss: 0.004178996197879314\n",
      "Epoch: 1173, Avg. Train Loss: 0.004248028664394866, Avg. Test Loss: 0.004188701510429382\n",
      "Epoch: 1174, Avg. Train Loss: 0.004267932121576958, Avg. Test Loss: 0.00421824911609292\n",
      "Epoch: 1175, Avg. Train Loss: 0.004244436185027278, Avg. Test Loss: 0.004199897404760122\n",
      "Epoch: 1176, Avg. Train Loss: 0.004252682050126929, Avg. Test Loss: 0.004187798593193293\n",
      "Epoch: 1177, Avg. Train Loss: 0.004239562292431676, Avg. Test Loss: 0.004216289147734642\n",
      "Epoch: 1178, Avg. Train Loss: 0.004250828414982141, Avg. Test Loss: 0.004176567308604717\n",
      "Epoch: 1179, Avg. Train Loss: 0.004270226001566233, Avg. Test Loss: 0.004211158957332373\n",
      "Epoch: 1180, Avg. Train Loss: 0.004249187186360359, Avg. Test Loss: 0.004167529754340649\n",
      "Epoch: 1181, Avg. Train Loss: 0.004237497950969047, Avg. Test Loss: 0.004222736693918705\n",
      "Epoch: 1182, Avg. Train Loss: 0.004249757458997327, Avg. Test Loss: 0.004166687838733196\n",
      "Epoch: 1183, Avg. Train Loss: 0.004239463902533401, Avg. Test Loss: 0.004174669738858938\n",
      "Epoch: 1184, Avg. Train Loss: 0.004248920579029377, Avg. Test Loss: 0.004203182179480791\n",
      "Epoch: 1185, Avg. Train Loss: 0.004250592703736106, Avg. Test Loss: 0.0041771335527300835\n",
      "Epoch: 1186, Avg. Train Loss: 0.004251585666869962, Avg. Test Loss: 0.004209845792502165\n",
      "Epoch: 1187, Avg. Train Loss: 0.00423757242428702, Avg. Test Loss: 0.0042268261313438416\n",
      "Epoch: 1188, Avg. Train Loss: 0.004242169638272635, Avg. Test Loss: 0.00419660983607173\n",
      "Epoch: 1189, Avg. Train Loss: 0.004242063175107158, Avg. Test Loss: 0.004197719506919384\n",
      "Epoch: 1190, Avg. Train Loss: 0.004269928292392991, Avg. Test Loss: 0.004203873686492443\n",
      "Epoch: 1191, Avg. Train Loss: 0.004240840489348007, Avg. Test Loss: 0.004162179306149483\n",
      "Epoch: 1192, Avg. Train Loss: 0.004247781160005996, Avg. Test Loss: 0.004284733906388283\n",
      "Epoch: 1193, Avg. Train Loss: 0.004243269302817278, Avg. Test Loss: 0.0042199306190013885\n",
      "Epoch: 1194, Avg. Train Loss: 0.004241023331793935, Avg. Test Loss: 0.004217005800455809\n",
      "Epoch: 1195, Avg. Train Loss: 0.004251421163898221, Avg. Test Loss: 0.004192715045064688\n",
      "Epoch: 1196, Avg. Train Loss: 0.004246815465130779, Avg. Test Loss: 0.004259820096194744\n",
      "Epoch: 1197, Avg. Train Loss: 0.0042585062924339325, Avg. Test Loss: 0.004182138480246067\n",
      "Epoch: 1198, Avg. Train Loss: 0.00423352824264141, Avg. Test Loss: 0.0042646839283406734\n",
      "Epoch: 1199, Avg. Train Loss: 0.004240220986566571, Avg. Test Loss: 0.004187144339084625\n",
      "Epoch: 1200, Avg. Train Loss: 0.004236666101225933, Avg. Test Loss: 0.004157301504164934\n",
      "Epoch: 1201, Avg. Train Loss: 0.004235562835928313, Avg. Test Loss: 0.004208667203783989\n",
      "Epoch: 1202, Avg. Train Loss: 0.004255829216522533, Avg. Test Loss: 0.0041636205278337\n",
      "Epoch: 1203, Avg. Train Loss: 0.004238015046169938, Avg. Test Loss: 0.004164526239037514\n",
      "Epoch: 1204, Avg. Train Loss: 0.004238069382344567, Avg. Test Loss: 0.004180389456450939\n",
      "Epoch: 1205, Avg. Train Loss: 0.004242103373588517, Avg. Test Loss: 0.004185786936432123\n",
      "Epoch: 1206, Avg. Train Loss: 0.004242142456648655, Avg. Test Loss: 0.004268229939043522\n",
      "Epoch: 1207, Avg. Train Loss: 0.004249939759976642, Avg. Test Loss: 0.004164827521890402\n",
      "Epoch: 1208, Avg. Train Loss: 0.00424558604352696, Avg. Test Loss: 0.004175799898803234\n",
      "Epoch: 1209, Avg. Train Loss: 0.004232814665450607, Avg. Test Loss: 0.00416445080190897\n",
      "Epoch: 1210, Avg. Train Loss: 0.004233400738083346, Avg. Test Loss: 0.004190579056739807\n",
      "Epoch: 1211, Avg. Train Loss: 0.004264168657882269, Avg. Test Loss: 0.004180604591965675\n",
      "Epoch: 1212, Avg. Train Loss: 0.00423368070881034, Avg. Test Loss: 0.004193437285721302\n",
      "Epoch: 1213, Avg. Train Loss: 0.004231883202094671, Avg. Test Loss: 0.00418295431882143\n",
      "Epoch: 1214, Avg. Train Loss: 0.004260452561686898, Avg. Test Loss: 0.004210027866065502\n",
      "Epoch: 1215, Avg. Train Loss: 0.004241554932885392, Avg. Test Loss: 0.004247779492288828\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1216, Avg. Train Loss: 0.004230684145938518, Avg. Test Loss: 0.004176536574959755\n",
      "Epoch: 1217, Avg. Train Loss: 0.004260509513145269, Avg. Test Loss: 0.004162495490163565\n",
      "Epoch: 1218, Avg. Train Loss: 0.004245805965606557, Avg. Test Loss: 0.004178538452833891\n",
      "Epoch: 1219, Avg. Train Loss: 0.0042383040864627025, Avg. Test Loss: 0.004218478221446276\n",
      "Epoch: 1220, Avg. Train Loss: 0.004241734450726315, Avg. Test Loss: 0.00416740495711565\n",
      "Epoch: 1221, Avg. Train Loss: 0.004245009803927915, Avg. Test Loss: 0.0041892798617482185\n",
      "Epoch: 1222, Avg. Train Loss: 0.004236408162775428, Avg. Test Loss: 0.004168618004769087\n",
      "Epoch: 1223, Avg. Train Loss: 0.004247164851877578, Avg. Test Loss: 0.004180481191724539\n",
      "Epoch: 1224, Avg. Train Loss: 0.004239449320837509, Avg. Test Loss: 0.004300934728235006\n",
      "Epoch: 1225, Avg. Train Loss: 0.00423226124325464, Avg. Test Loss: 0.0042119696736335754\n",
      "Epoch: 1226, Avg. Train Loss: 0.004257349199940299, Avg. Test Loss: 0.004199828952550888\n",
      "Epoch: 1227, Avg. Train Loss: 0.004239291147610476, Avg. Test Loss: 0.004153748042881489\n",
      "Epoch: 1228, Avg. Train Loss: 0.004224177255013654, Avg. Test Loss: 0.004182595293968916\n",
      "Epoch: 1229, Avg. Train Loss: 0.0042233947058056675, Avg. Test Loss: 0.0041658030822873116\n",
      "Epoch: 1230, Avg. Train Loss: 0.0042204038987239435, Avg. Test Loss: 0.004178861156105995\n",
      "Epoch: 1231, Avg. Train Loss: 0.004222808329951625, Avg. Test Loss: 0.004302770830690861\n",
      "Epoch: 1232, Avg. Train Loss: 0.004234632390529611, Avg. Test Loss: 0.004203549586236477\n",
      "Epoch: 1233, Avg. Train Loss: 0.004222683705995942, Avg. Test Loss: 0.004184406250715256\n",
      "Epoch: 1234, Avg. Train Loss: 0.00422873561335511, Avg. Test Loss: 0.004175399895757437\n",
      "Epoch: 1235, Avg. Train Loss: 0.004224946094286996, Avg. Test Loss: 0.00416548503562808\n",
      "Epoch: 1236, Avg. Train Loss: 0.004236149547491656, Avg. Test Loss: 0.004194660112261772\n",
      "Epoch: 1237, Avg. Train Loss: 0.004240981227350097, Avg. Test Loss: 0.004157212562859058\n",
      "Epoch: 1238, Avg. Train Loss: 0.004255523493643417, Avg. Test Loss: 0.004219782073050737\n",
      "Epoch: 1239, Avg. Train Loss: 0.004240995608703341, Avg. Test Loss: 0.004170997999608517\n",
      "Epoch: 1240, Avg. Train Loss: 0.004247102301654427, Avg. Test Loss: 0.004153984598815441\n",
      "Epoch: 1241, Avg. Train Loss: 0.004235942463585457, Avg. Test Loss: 0.004165728576481342\n",
      "Epoch: 1242, Avg. Train Loss: 0.004237613651554945, Avg. Test Loss: 0.004206271842122078\n",
      "Epoch: 1243, Avg. Train Loss: 0.004235340531395618, Avg. Test Loss: 0.004176882095634937\n",
      "Epoch: 1244, Avg. Train Loss: 0.004228439723509688, Avg. Test Loss: 0.004162783734500408\n",
      "Epoch: 1245, Avg. Train Loss: 0.004229404876918294, Avg. Test Loss: 0.004151298198848963\n",
      "Epoch: 1246, Avg. Train Loss: 0.0042405879384903025, Avg. Test Loss: 0.004164912737905979\n",
      "Epoch: 1247, Avg. Train Loss: 0.004238488970237763, Avg. Test Loss: 0.004175979644060135\n",
      "Epoch: 1248, Avg. Train Loss: 0.004237348495354486, Avg. Test Loss: 0.004177683033049107\n",
      "Epoch: 1249, Avg. Train Loss: 0.004232216171573761, Avg. Test Loss: 0.004152979236096144\n",
      "Epoch: 1250, Avg. Train Loss: 0.00424331319410094, Avg. Test Loss: 0.004152799490839243\n",
      "Epoch: 1251, Avg. Train Loss: 0.00422042046218764, Avg. Test Loss: 0.004180826246738434\n",
      "Epoch: 1252, Avg. Train Loss: 0.004225057116601356, Avg. Test Loss: 0.004168127663433552\n",
      "Epoch: 1253, Avg. Train Loss: 0.0042144984689129646, Avg. Test Loss: 0.004146828316152096\n",
      "Epoch: 1254, Avg. Train Loss: 0.004225163406497518, Avg. Test Loss: 0.004158236552029848\n",
      "Epoch: 1255, Avg. Train Loss: 0.004218278815536652, Avg. Test Loss: 0.004243840463459492\n",
      "Epoch: 1256, Avg. Train Loss: 0.00423725878516602, Avg. Test Loss: 0.004198768176138401\n",
      "Epoch: 1257, Avg. Train Loss: 0.004221275091431168, Avg. Test Loss: 0.0041617900133132935\n",
      "Epoch: 1258, Avg. Train Loss: 0.004252125205861968, Avg. Test Loss: 0.004187764134258032\n",
      "Epoch: 1259, Avg. Train Loss: 0.004226950766128856, Avg. Test Loss: 0.004143508151173592\n",
      "Epoch: 1260, Avg. Train Loss: 0.0042201011160085365, Avg. Test Loss: 0.0041701034642755985\n",
      "Epoch: 1261, Avg. Train Loss: 0.004246609258400493, Avg. Test Loss: 0.00415393803268671\n",
      "Epoch: 1262, Avg. Train Loss: 0.004233884690112846, Avg. Test Loss: 0.0041749137453734875\n",
      "Epoch: 1263, Avg. Train Loss: 0.004236024262946706, Avg. Test Loss: 0.00421511335298419\n",
      "Epoch: 1264, Avg. Train Loss: 0.004245884185873492, Avg. Test Loss: 0.00415708776563406\n",
      "Epoch: 1265, Avg. Train Loss: 0.004219982134134963, Avg. Test Loss: 0.004173289984464645\n",
      "Epoch: 1266, Avg. Train Loss: 0.004220157580146956, Avg. Test Loss: 0.004183235578238964\n",
      "Epoch: 1267, Avg. Train Loss: 0.004211782954286697, Avg. Test Loss: 0.004228418692946434\n",
      "Epoch: 1268, Avg. Train Loss: 0.004231267522067525, Avg. Test Loss: 0.004256758838891983\n",
      "Epoch: 1269, Avg. Train Loss: 0.004234583923853067, Avg. Test Loss: 0.004151447210460901\n",
      "Epoch: 1270, Avg. Train Loss: 0.004243583418428898, Avg. Test Loss: 0.0041987355798482895\n",
      "Epoch: 1271, Avg. Train Loss: 0.004231663182551085, Avg. Test Loss: 0.004180024843662977\n",
      "Epoch: 1272, Avg. Train Loss: 0.0042167905133304205, Avg. Test Loss: 0.004182314034551382\n",
      "Epoch: 1273, Avg. Train Loss: 0.004227285170494471, Avg. Test Loss: 0.004207972437143326\n",
      "Epoch: 1274, Avg. Train Loss: 0.00421234296071668, Avg. Test Loss: 0.004195633810013533\n",
      "Epoch: 1275, Avg. Train Loss: 0.004217474775518789, Avg. Test Loss: 0.004175488371402025\n",
      "Epoch: 1276, Avg. Train Loss: 0.004209777009998297, Avg. Test Loss: 0.00419998774304986\n",
      "Epoch: 1277, Avg. Train Loss: 0.004274011957784032, Avg. Test Loss: 0.004294647369533777\n",
      "Epoch: 1278, Avg. Train Loss: 0.004239955949488767, Avg. Test Loss: 0.004151578061282635\n",
      "Epoch: 1279, Avg. Train Loss: 0.00422303968780609, Avg. Test Loss: 0.004236882086843252\n",
      "Epoch: 1280, Avg. Train Loss: 0.004242927301675081, Avg. Test Loss: 0.004174484871327877\n",
      "Epoch: 1281, Avg. Train Loss: 0.0042152849112659, Avg. Test Loss: 0.004152669105678797\n",
      "Epoch: 1282, Avg. Train Loss: 0.004215743002849956, Avg. Test Loss: 0.004169815219938755\n",
      "Epoch: 1283, Avg. Train Loss: 0.004222388108542492, Avg. Test Loss: 0.004189636092633009\n",
      "Epoch: 1284, Avg. Train Loss: 0.00423942492235192, Avg. Test Loss: 0.004142514429986477\n",
      "Epoch: 1285, Avg. Train Loss: 0.004222795226459586, Avg. Test Loss: 0.004160456359386444\n",
      "Epoch: 1286, Avg. Train Loss: 0.004229758032272721, Avg. Test Loss: 0.004163892474025488\n",
      "Epoch: 1287, Avg. Train Loss: 0.004216516715322816, Avg. Test Loss: 0.004145960323512554\n",
      "Epoch: 1288, Avg. Train Loss: 0.0042169899842160385, Avg. Test Loss: 0.004162676632404327\n",
      "Epoch: 1289, Avg. Train Loss: 0.004205803863357666, Avg. Test Loss: 0.00413859635591507\n",
      "Epoch: 1290, Avg. Train Loss: 0.004215800604068263, Avg. Test Loss: 0.004141016863286495\n",
      "Epoch: 1291, Avg. Train Loss: 0.004212814745991383, Avg. Test Loss: 0.004172957967966795\n",
      "Epoch: 1292, Avg. Train Loss: 0.0042066935688083945, Avg. Test Loss: 0.004145076498389244\n",
      "Epoch: 1293, Avg. Train Loss: 0.004217954991428658, Avg. Test Loss: 0.004143340513110161\n",
      "Epoch: 1294, Avg. Train Loss: 0.004215776584609304, Avg. Test Loss: 0.004134630784392357\n",
      "Epoch: 1295, Avg. Train Loss: 0.004227201118632112, Avg. Test Loss: 0.004185757599771023\n",
      "Epoch: 1296, Avg. Train Loss: 0.004240899563355501, Avg. Test Loss: 0.004138022195547819\n",
      "Epoch: 1297, Avg. Train Loss: 0.004217419968268206, Avg. Test Loss: 0.004154193215072155\n",
      "Epoch: 1298, Avg. Train Loss: 0.004220849861455865, Avg. Test Loss: 0.004140939563512802\n",
      "Epoch: 1299, Avg. Train Loss: 0.004226787335261009, Avg. Test Loss: 0.004141421057283878\n",
      "Epoch: 1300, Avg. Train Loss: 0.0042155443820669205, Avg. Test Loss: 0.004209291189908981\n",
      "Epoch: 1301, Avg. Train Loss: 0.004214718033624596, Avg. Test Loss: 0.004161846823990345\n",
      "Epoch: 1302, Avg. Train Loss: 0.004216830321955819, Avg. Test Loss: 0.0041770655661821365\n",
      "Epoch: 1303, Avg. Train Loss: 0.004219498799377402, Avg. Test Loss: 0.004135969094932079\n",
      "Epoch: 1304, Avg. Train Loss: 0.00421026028519453, Avg. Test Loss: 0.004136417992413044\n",
      "Epoch: 1305, Avg. Train Loss: 0.0042027670045404935, Avg. Test Loss: 0.004130967892706394\n",
      "Epoch: 1306, Avg. Train Loss: 0.004200939949991745, Avg. Test Loss: 0.004133566748350859\n",
      "Epoch: 1307, Avg. Train Loss: 0.0042003103055406445, Avg. Test Loss: 0.00414819223806262\n",
      "Epoch: 1308, Avg. Train Loss: 0.004216985105601854, Avg. Test Loss: 0.004182299133390188\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1309, Avg. Train Loss: 0.004194336878352387, Avg. Test Loss: 0.004171110689640045\n",
      "Epoch: 1310, Avg. Train Loss: 0.004232228008033924, Avg. Test Loss: 0.004126101732254028\n",
      "Epoch: 1311, Avg. Train Loss: 0.004200695347863921, Avg. Test Loss: 0.004145466722548008\n",
      "Epoch: 1312, Avg. Train Loss: 0.004193984345684565, Avg. Test Loss: 0.004143440630286932\n",
      "Epoch: 1313, Avg. Train Loss: 0.004201230982881646, Avg. Test Loss: 0.004129920154809952\n",
      "Epoch: 1314, Avg. Train Loss: 0.004204484991469356, Avg. Test Loss: 0.004132350906729698\n",
      "Epoch: 1315, Avg. Train Loss: 0.0041931146149371944, Avg. Test Loss: 0.00418024742975831\n",
      "Epoch: 1316, Avg. Train Loss: 0.00420404116211589, Avg. Test Loss: 0.004152514971792698\n",
      "Epoch: 1317, Avg. Train Loss: 0.004204813715850198, Avg. Test Loss: 0.0041175903752446175\n",
      "Epoch: 1318, Avg. Train Loss: 0.004214250699205454, Avg. Test Loss: 0.0042535909451544285\n",
      "Epoch: 1319, Avg. Train Loss: 0.004216229250697896, Avg. Test Loss: 0.004159275442361832\n",
      "Epoch: 1320, Avg. Train Loss: 0.004186345237242275, Avg. Test Loss: 0.004144595470279455\n",
      "Epoch: 1321, Avg. Train Loss: 0.004185031991192075, Avg. Test Loss: 0.004124159924685955\n",
      "Epoch: 1322, Avg. Train Loss: 0.004186308184681937, Avg. Test Loss: 0.00417537335306406\n",
      "Epoch: 1323, Avg. Train Loss: 0.004189025242488051, Avg. Test Loss: 0.00412024836987257\n",
      "Epoch: 1324, Avg. Train Loss: 0.0041830014589047705, Avg. Test Loss: 0.004127830732613802\n",
      "Epoch: 1325, Avg. Train Loss: 0.004178899139988907, Avg. Test Loss: 0.004122884012758732\n",
      "Epoch: 1326, Avg. Train Loss: 0.004171104744336632, Avg. Test Loss: 0.004105062689632177\n",
      "Epoch: 1327, Avg. Train Loss: 0.004167256611507646, Avg. Test Loss: 0.004125603940337896\n",
      "Epoch: 1328, Avg. Train Loss: 0.004170838873400245, Avg. Test Loss: 0.004187738057225943\n",
      "Epoch: 1329, Avg. Train Loss: 0.0041928255529857655, Avg. Test Loss: 0.004109799861907959\n",
      "Epoch: 1330, Avg. Train Loss: 0.004189074743365826, Avg. Test Loss: 0.004157440271228552\n",
      "Epoch: 1331, Avg. Train Loss: 0.00417331044107329, Avg. Test Loss: 0.004115378018468618\n",
      "Epoch: 1332, Avg. Train Loss: 0.004166612499068642, Avg. Test Loss: 0.00412621907889843\n",
      "Epoch: 1333, Avg. Train Loss: 0.004186023551927403, Avg. Test Loss: 0.0040946477092802525\n",
      "Epoch: 1334, Avg. Train Loss: 0.004174887603365405, Avg. Test Loss: 0.0040963152423501015\n",
      "Epoch: 1335, Avg. Train Loss: 0.004152447721639345, Avg. Test Loss: 0.004170156084001064\n",
      "Epoch: 1336, Avg. Train Loss: 0.0041641833715487355, Avg. Test Loss: 0.004146978724747896\n",
      "Epoch: 1337, Avg. Train Loss: 0.004171544685959816, Avg. Test Loss: 0.004155932459980249\n",
      "Epoch: 1338, Avg. Train Loss: 0.00415520507539081, Avg. Test Loss: 0.004136587958782911\n",
      "Epoch: 1339, Avg. Train Loss: 0.004171511521129761, Avg. Test Loss: 0.004123055841773748\n",
      "Epoch: 1340, Avg. Train Loss: 0.0041529692676957955, Avg. Test Loss: 0.004120697733014822\n",
      "Epoch: 1341, Avg. Train Loss: 0.004159336606430453, Avg. Test Loss: 0.004102548584342003\n",
      "Epoch: 1342, Avg. Train Loss: 0.004146416086790173, Avg. Test Loss: 0.00414346344769001\n",
      "Epoch: 1343, Avg. Train Loss: 0.004139571694310668, Avg. Test Loss: 0.004111160058528185\n",
      "Epoch: 1344, Avg. Train Loss: 0.004143169279708419, Avg. Test Loss: 0.004113740753382444\n",
      "Epoch: 1345, Avg. Train Loss: 0.0041341724978803205, Avg. Test Loss: 0.004095170646905899\n",
      "Epoch: 1346, Avg. Train Loss: 0.004168058669757705, Avg. Test Loss: 0.004100417252629995\n",
      "Epoch: 1347, Avg. Train Loss: 0.0041188984936059905, Avg. Test Loss: 0.004067147150635719\n",
      "Epoch: 1348, Avg. Train Loss: 0.004121363774851658, Avg. Test Loss: 0.004134669899940491\n",
      "Epoch: 1349, Avg. Train Loss: 0.004115231351407115, Avg. Test Loss: 0.004087578039616346\n",
      "Epoch: 1350, Avg. Train Loss: 0.004116168083233195, Avg. Test Loss: 0.004092944320291281\n",
      "Epoch: 1351, Avg. Train Loss: 0.004151848328927922, Avg. Test Loss: 0.004049533046782017\n",
      "Epoch: 1352, Avg. Train Loss: 0.004117261493838457, Avg. Test Loss: 0.004100368358194828\n",
      "Epoch: 1353, Avg. Train Loss: 0.004104006217879264, Avg. Test Loss: 0.0040666088461875916\n",
      "Epoch: 1354, Avg. Train Loss: 0.004129502321268583, Avg. Test Loss: 0.004035371355712414\n",
      "Epoch: 1355, Avg. Train Loss: 0.004101104877326031, Avg. Test Loss: 0.004063477274030447\n",
      "Epoch: 1356, Avg. Train Loss: 0.004111592338398792, Avg. Test Loss: 0.0040557123720645905\n",
      "Epoch: 1357, Avg. Train Loss: 0.0041037359664779765, Avg. Test Loss: 0.004134313203394413\n",
      "Epoch: 1358, Avg. Train Loss: 0.00410675902331118, Avg. Test Loss: 0.0040474035777151585\n",
      "Epoch: 1359, Avg. Train Loss: 0.004114674171432853, Avg. Test Loss: 0.00406506797298789\n",
      "Epoch: 1360, Avg. Train Loss: 0.004103873666852366, Avg. Test Loss: 0.004141781944781542\n",
      "Epoch: 1361, Avg. Train Loss: 0.004122989273868328, Avg. Test Loss: 0.004093302879482508\n",
      "Epoch: 1362, Avg. Train Loss: 0.004100044934772128, Avg. Test Loss: 0.004058054648339748\n",
      "Epoch: 1363, Avg. Train Loss: 0.004101519299627736, Avg. Test Loss: 0.0040553417056798935\n",
      "Epoch: 1364, Avg. Train Loss: 0.004120060870813769, Avg. Test Loss: 0.004058509133756161\n",
      "Epoch: 1365, Avg. Train Loss: 0.00410774640933892, Avg. Test Loss: 0.0040711890906095505\n",
      "Epoch: 1366, Avg. Train Loss: 0.004101965056602345, Avg. Test Loss: 0.0040700859390199184\n",
      "Epoch: 1367, Avg. Train Loss: 0.004100829622773237, Avg. Test Loss: 0.004047504160553217\n",
      "Epoch: 1368, Avg. Train Loss: 0.004089661169970451, Avg. Test Loss: 0.004030878655612469\n",
      "Epoch: 1369, Avg. Train Loss: 0.004096255513168005, Avg. Test Loss: 0.004052709322422743\n",
      "Epoch: 1370, Avg. Train Loss: 0.004087221305167606, Avg. Test Loss: 0.004044301807880402\n",
      "Epoch: 1371, Avg. Train Loss: 0.0040967272334667135, Avg. Test Loss: 0.0040315426886081696\n",
      "Epoch: 1372, Avg. Train Loss: 0.0040828969903550175, Avg. Test Loss: 0.004043554421514273\n",
      "Epoch: 1373, Avg. Train Loss: 0.004085698506123451, Avg. Test Loss: 0.0040133739821612835\n",
      "Epoch: 1374, Avg. Train Loss: 0.004099405105334035, Avg. Test Loss: 0.004032286815345287\n",
      "Epoch: 1375, Avg. Train Loss: 0.004073105351782815, Avg. Test Loss: 0.004004699178040028\n",
      "Epoch: 1376, Avg. Train Loss: 0.0040795523185976025, Avg. Test Loss: 0.0040108272805809975\n",
      "Epoch: 1377, Avg. Train Loss: 0.0040663138660060804, Avg. Test Loss: 0.004032004624605179\n",
      "Epoch: 1378, Avg. Train Loss: 0.004064675680426664, Avg. Test Loss: 0.004029724281281233\n",
      "Epoch: 1379, Avg. Train Loss: 0.004087263117219473, Avg. Test Loss: 0.004062693100422621\n",
      "Epoch: 1380, Avg. Train Loss: 0.004087815997948827, Avg. Test Loss: 0.003997625783085823\n",
      "Epoch: 1381, Avg. Train Loss: 0.004069263922310499, Avg. Test Loss: 0.004045425448566675\n",
      "Epoch: 1382, Avg. Train Loss: 0.004077270984389755, Avg. Test Loss: 0.004012329038232565\n",
      "Epoch: 1383, Avg. Train Loss: 0.004065965177751211, Avg. Test Loss: 0.0040354616940021515\n",
      "Epoch: 1384, Avg. Train Loss: 0.0040803087691148356, Avg. Test Loss: 0.004029158502817154\n",
      "Epoch: 1385, Avg. Train Loss: 0.00407173439080632, Avg. Test Loss: 0.004049136769026518\n",
      "Epoch: 1386, Avg. Train Loss: 0.0040661607284185495, Avg. Test Loss: 0.004050882998853922\n",
      "Epoch: 1387, Avg. Train Loss: 0.0040687560212127, Avg. Test Loss: 0.004028975963592529\n",
      "Epoch: 1388, Avg. Train Loss: 0.0040872750728022916, Avg. Test Loss: 0.004027106333523989\n",
      "Epoch: 1389, Avg. Train Loss: 0.004078106981767125, Avg. Test Loss: 0.004045574925839901\n",
      "Epoch: 1390, Avg. Train Loss: 0.004084433824213785, Avg. Test Loss: 0.004005966242402792\n",
      "Epoch: 1391, Avg. Train Loss: 0.004075921904079096, Avg. Test Loss: 0.0040310341864824295\n",
      "Epoch: 1392, Avg. Train Loss: 0.004055233628943909, Avg. Test Loss: 0.003994257189333439\n",
      "Epoch: 1393, Avg. Train Loss: 0.004061738814248941, Avg. Test Loss: 0.004072242416441441\n",
      "Epoch: 1394, Avg. Train Loss: 0.004056625615068993, Avg. Test Loss: 0.004036962054669857\n",
      "Epoch: 1395, Avg. Train Loss: 0.004059267046233249, Avg. Test Loss: 0.0039891586638987064\n",
      "Epoch: 1396, Avg. Train Loss: 0.004062372438479648, Avg. Test Loss: 0.0040851254016160965\n",
      "Epoch: 1397, Avg. Train Loss: 0.004078506340467652, Avg. Test Loss: 0.004014575853943825\n",
      "Epoch: 1398, Avg. Train Loss: 0.004045858990054491, Avg. Test Loss: 0.003980319015681744\n",
      "Epoch: 1399, Avg. Train Loss: 0.004076481136211822, Avg. Test Loss: 0.004073050804436207\n",
      "Epoch: 1400, Avg. Train Loss: 0.004078242824911032, Avg. Test Loss: 0.004138269927352667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1401, Avg. Train Loss: 0.004048952838232697, Avg. Test Loss: 0.00398632325232029\n",
      "Epoch: 1402, Avg. Train Loss: 0.004051032118759183, Avg. Test Loss: 0.0040370998904109\n",
      "Epoch: 1403, Avg. Train Loss: 0.004073740362168052, Avg. Test Loss: 0.004103043582290411\n",
      "Epoch: 1404, Avg. Train Loss: 0.004068085891302935, Avg. Test Loss: 0.004023688845336437\n",
      "Epoch: 1405, Avg. Train Loss: 0.00404369926383329, Avg. Test Loss: 0.004020633175969124\n",
      "Epoch: 1406, Avg. Train Loss: 0.0040452207958455695, Avg. Test Loss: 0.003972465638071299\n",
      "Epoch: 1407, Avg. Train Loss: 0.004047528672746794, Avg. Test Loss: 0.003984788432717323\n",
      "Epoch: 1408, Avg. Train Loss: 0.0040537558257753075, Avg. Test Loss: 0.004030910786241293\n",
      "Epoch: 1409, Avg. Train Loss: 0.004038171420350324, Avg. Test Loss: 0.003972378093749285\n",
      "Epoch: 1410, Avg. Train Loss: 0.004036032589325725, Avg. Test Loss: 0.003970677498728037\n",
      "Epoch: 1411, Avg. Train Loss: 0.004046925982503697, Avg. Test Loss: 0.004071634262800217\n",
      "Epoch: 1412, Avg. Train Loss: 0.004055332392454147, Avg. Test Loss: 0.003984472248703241\n",
      "Epoch: 1413, Avg. Train Loss: 0.004038502272694956, Avg. Test Loss: 0.0039753057062625885\n",
      "Epoch: 1414, Avg. Train Loss: 0.004043133642394529, Avg. Test Loss: 0.004055474419146776\n",
      "Epoch: 1415, Avg. Train Loss: 0.0040854604015949855, Avg. Test Loss: 0.00409347377717495\n",
      "Epoch: 1416, Avg. Train Loss: 0.004031344961245046, Avg. Test Loss: 0.003963274881243706\n",
      "Epoch: 1417, Avg. Train Loss: 0.004033335219245664, Avg. Test Loss: 0.003977316431701183\n",
      "Epoch: 1418, Avg. Train Loss: 0.004029634868899404, Avg. Test Loss: 0.003958424553275108\n",
      "Epoch: 1419, Avg. Train Loss: 0.004021028278742072, Avg. Test Loss: 0.003990874160081148\n",
      "Epoch: 1420, Avg. Train Loss: 0.004028064929771908, Avg. Test Loss: 0.003977541346102953\n",
      "Epoch: 1421, Avg. Train Loss: 0.004043816139401738, Avg. Test Loss: 0.004031111486256123\n",
      "Epoch: 1422, Avg. Train Loss: 0.004043844344397617, Avg. Test Loss: 0.003974806517362595\n",
      "Epoch: 1423, Avg. Train Loss: 0.004050135915709096, Avg. Test Loss: 0.004056442063301802\n",
      "Epoch: 1424, Avg. Train Loss: 0.004040825164465364, Avg. Test Loss: 0.00404000747948885\n",
      "Epoch: 1425, Avg. Train Loss: 0.004041452442707364, Avg. Test Loss: 0.003950935322791338\n",
      "Epoch: 1426, Avg. Train Loss: 0.004022931209007321, Avg. Test Loss: 0.003962608985602856\n",
      "Epoch: 1427, Avg. Train Loss: 0.004024043078209425, Avg. Test Loss: 0.003981942776590586\n",
      "Epoch: 1428, Avg. Train Loss: 0.0040458300540786845, Avg. Test Loss: 0.0040312414057552814\n",
      "Epoch: 1429, Avg. Train Loss: 0.004020902176582536, Avg. Test Loss: 0.004047249909490347\n",
      "Epoch: 1430, Avg. Train Loss: 0.004052817556184045, Avg. Test Loss: 0.004002279601991177\n",
      "Epoch: 1431, Avg. Train Loss: 0.00402122083509904, Avg. Test Loss: 0.003955186810344458\n",
      "Epoch: 1432, Avg. Train Loss: 0.004019841059046083, Avg. Test Loss: 0.003951302729547024\n",
      "Epoch: 1433, Avg. Train Loss: 0.003999862126832785, Avg. Test Loss: 0.003969220910221338\n",
      "Epoch: 1434, Avg. Train Loss: 0.004017414741737898, Avg. Test Loss: 0.003973044455051422\n",
      "Epoch: 1435, Avg. Train Loss: 0.0040047527074294036, Avg. Test Loss: 0.003956865519285202\n",
      "Epoch: 1436, Avg. Train Loss: 0.004041012360302861, Avg. Test Loss: 0.00397591944783926\n",
      "Epoch: 1437, Avg. Train Loss: 0.004049120438393465, Avg. Test Loss: 0.003988585434854031\n",
      "Epoch: 1438, Avg. Train Loss: 0.004017035200715412, Avg. Test Loss: 0.00396594125777483\n",
      "Epoch: 1439, Avg. Train Loss: 0.004007862761703341, Avg. Test Loss: 0.003944018390029669\n",
      "Epoch: 1440, Avg. Train Loss: 0.004003749867944524, Avg. Test Loss: 0.004011337645351887\n",
      "Epoch: 1441, Avg. Train Loss: 0.004009632545328418, Avg. Test Loss: 0.003972742706537247\n",
      "Epoch: 1442, Avg. Train Loss: 0.004029537583593019, Avg. Test Loss: 0.003938282374292612\n",
      "Epoch: 1443, Avg. Train Loss: 0.004022524210212882, Avg. Test Loss: 0.00408664857968688\n",
      "Epoch: 1444, Avg. Train Loss: 0.004027496194900121, Avg. Test Loss: 0.003954073879867792\n",
      "Epoch: 1445, Avg. Train Loss: 0.004023272278826944, Avg. Test Loss: 0.003972902894020081\n",
      "Epoch: 1446, Avg. Train Loss: 0.0040372217312281905, Avg. Test Loss: 0.004038154613226652\n",
      "Epoch: 1447, Avg. Train Loss: 0.004008079808595222, Avg. Test Loss: 0.003930732142180204\n",
      "Epoch: 1448, Avg. Train Loss: 0.004006808899819504, Avg. Test Loss: 0.003979275468736887\n",
      "Epoch: 1449, Avg. Train Loss: 0.004015314165329517, Avg. Test Loss: 0.003984498791396618\n",
      "Epoch: 1450, Avg. Train Loss: 0.004019121076305246, Avg. Test Loss: 0.0039346530102193356\n",
      "Epoch: 1451, Avg. Train Loss: 0.004012376026705254, Avg. Test Loss: 0.003949832171201706\n",
      "Epoch: 1452, Avg. Train Loss: 0.004014961470221711, Avg. Test Loss: 0.003958709537982941\n",
      "Epoch: 1453, Avg. Train Loss: 0.004022159797767567, Avg. Test Loss: 0.004048448521643877\n",
      "Epoch: 1454, Avg. Train Loss: 0.003998194566689605, Avg. Test Loss: 0.003995334729552269\n",
      "Epoch: 1455, Avg. Train Loss: 0.004007031783721474, Avg. Test Loss: 0.003934040199965239\n",
      "Epoch: 1456, Avg. Train Loss: 0.004003174971182679, Avg. Test Loss: 0.00401479983702302\n",
      "Epoch: 1457, Avg. Train Loss: 0.004003518158136759, Avg. Test Loss: 0.003959925379604101\n",
      "Epoch: 1458, Avg. Train Loss: 0.003995738013885742, Avg. Test Loss: 0.003938664216548204\n",
      "Epoch: 1459, Avg. Train Loss: 0.0039848117049523565, Avg. Test Loss: 0.003936531953513622\n",
      "Epoch: 1460, Avg. Train Loss: 0.004002320699307115, Avg. Test Loss: 0.003955849912017584\n",
      "Epoch: 1461, Avg. Train Loss: 0.003997479987785567, Avg. Test Loss: 0.00393980136141181\n",
      "Epoch: 1462, Avg. Train Loss: 0.0039977935023692455, Avg. Test Loss: 0.00393895385786891\n",
      "Epoch: 1463, Avg. Train Loss: 0.003998210280050718, Avg. Test Loss: 0.00396901136264205\n",
      "Epoch: 1464, Avg. Train Loss: 0.00399376364793022, Avg. Test Loss: 0.003954841755330563\n",
      "Epoch: 1465, Avg. Train Loss: 0.003984318575063764, Avg. Test Loss: 0.003914519678801298\n",
      "Epoch: 1466, Avg. Train Loss: 0.003986031688793108, Avg. Test Loss: 0.003926201723515987\n",
      "Epoch: 1467, Avg. Train Loss: 0.003986681827755515, Avg. Test Loss: 0.0039625647477805614\n",
      "Epoch: 1468, Avg. Train Loss: 0.0039914233480082, Avg. Test Loss: 0.003974324092268944\n",
      "Epoch: 1469, Avg. Train Loss: 0.0040361274326176835, Avg. Test Loss: 0.00398791441693902\n",
      "Epoch: 1470, Avg. Train Loss: 0.004003187116278812, Avg. Test Loss: 0.003918208181858063\n",
      "Epoch: 1471, Avg. Train Loss: 0.003989445933595646, Avg. Test Loss: 0.003907708916813135\n",
      "Epoch: 1472, Avg. Train Loss: 0.003972114101702044, Avg. Test Loss: 0.003915327601134777\n",
      "Epoch: 1473, Avg. Train Loss: 0.003976739114583578, Avg. Test Loss: 0.00396747374907136\n",
      "Epoch: 1474, Avg. Train Loss: 0.003994507292762052, Avg. Test Loss: 0.003993435762822628\n",
      "Epoch: 1475, Avg. Train Loss: 0.0039919894351082485, Avg. Test Loss: 0.003950232174247503\n",
      "Epoch: 1476, Avg. Train Loss: 0.003985385773270283, Avg. Test Loss: 0.003922858741134405\n",
      "Epoch: 1477, Avg. Train Loss: 0.003974880216383311, Avg. Test Loss: 0.0039918445982038975\n",
      "Epoch: 1478, Avg. Train Loss: 0.003987157051343211, Avg. Test Loss: 0.00392997357994318\n",
      "Epoch: 1479, Avg. Train Loss: 0.0039769109490132605, Avg. Test Loss: 0.003926738165318966\n",
      "Epoch: 1480, Avg. Train Loss: 0.003978298024036164, Avg. Test Loss: 0.00395951047539711\n",
      "Epoch: 1481, Avg. Train Loss: 0.003970027820012251, Avg. Test Loss: 0.003903007600456476\n",
      "Epoch: 1482, Avg. Train Loss: 0.003976623408583014, Avg. Test Loss: 0.003960627596825361\n",
      "Epoch: 1483, Avg. Train Loss: 0.00398754404836096, Avg. Test Loss: 0.00393261993303895\n",
      "Epoch: 1484, Avg. Train Loss: 0.0040101262166836234, Avg. Test Loss: 0.003954166080802679\n",
      "Epoch: 1485, Avg. Train Loss: 0.003976488967837636, Avg. Test Loss: 0.003925956320017576\n",
      "Epoch: 1486, Avg. Train Loss: 0.003979762945714039, Avg. Test Loss: 0.0039276788011193275\n",
      "Epoch: 1487, Avg. Train Loss: 0.003960625853302867, Avg. Test Loss: 0.003915469162166119\n",
      "Epoch: 1488, Avg. Train Loss: 0.003967631564930428, Avg. Test Loss: 0.003909154329448938\n",
      "Epoch: 1489, Avg. Train Loss: 0.00396607352723909, Avg. Test Loss: 0.004024388734251261\n",
      "Epoch: 1490, Avg. Train Loss: 0.003963721428759569, Avg. Test Loss: 0.003918859641999006\n",
      "Epoch: 1491, Avg. Train Loss: 0.003969373928686214, Avg. Test Loss: 0.003898987779393792\n",
      "Epoch: 1492, Avg. Train Loss: 0.003973004624767359, Avg. Test Loss: 0.003908991813659668\n",
      "Epoch: 1493, Avg. Train Loss: 0.003950144516217501, Avg. Test Loss: 0.003918712493032217\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1494, Avg. Train Loss: 0.003964047981859293, Avg. Test Loss: 0.003907025791704655\n",
      "Epoch: 1495, Avg. Train Loss: 0.0039530245771328375, Avg. Test Loss: 0.003883958561345935\n",
      "Epoch: 1496, Avg. Train Loss: 0.00395633855856262, Avg. Test Loss: 0.003926047123968601\n",
      "Epoch: 1497, Avg. Train Loss: 0.00395857451245362, Avg. Test Loss: 0.003943081479519606\n",
      "Epoch: 1498, Avg. Train Loss: 0.003986798140198686, Avg. Test Loss: 0.00402613403275609\n",
      "Epoch: 1499, Avg. Train Loss: 0.003958371440815025, Avg. Test Loss: 0.003891075262799859\n",
      "Epoch: 1500, Avg. Train Loss: 0.003960976279665565, Avg. Test Loss: 0.003895742120221257\n",
      "Epoch: 1501, Avg. Train Loss: 0.003953935432269476, Avg. Test Loss: 0.0039041077252477407\n",
      "Epoch: 1502, Avg. Train Loss: 0.0039487455560024394, Avg. Test Loss: 0.003927209880203009\n",
      "Epoch: 1503, Avg. Train Loss: 0.003962224029914238, Avg. Test Loss: 0.004073488526046276\n",
      "Epoch: 1504, Avg. Train Loss: 0.003964354592743654, Avg. Test Loss: 0.0039017805829644203\n",
      "Epoch: 1505, Avg. Train Loss: 0.0039451175239370315, Avg. Test Loss: 0.003920757211744785\n",
      "Epoch: 1506, Avg. Train Loss: 0.003988267783465427, Avg. Test Loss: 0.0038780695758759975\n",
      "Epoch: 1507, Avg. Train Loss: 0.003974087530920325, Avg. Test Loss: 0.003915856592357159\n",
      "Epoch: 1508, Avg. Train Loss: 0.003942855763747249, Avg. Test Loss: 0.003965785261243582\n",
      "Epoch: 1509, Avg. Train Loss: 0.00395746678005644, Avg. Test Loss: 0.0038772886618971825\n",
      "Epoch: 1510, Avg. Train Loss: 0.003943349093978488, Avg. Test Loss: 0.0038785203360021114\n",
      "Epoch: 1511, Avg. Train Loss: 0.003940696692700649, Avg. Test Loss: 0.003921201452612877\n",
      "Epoch: 1512, Avg. Train Loss: 0.003954887823310009, Avg. Test Loss: 0.0039543346501886845\n",
      "Epoch: 1513, Avg. Train Loss: 0.003959190392823413, Avg. Test Loss: 0.0039404104463756084\n",
      "Epoch: 1514, Avg. Train Loss: 0.003953355364501476, Avg. Test Loss: 0.003916162997484207\n",
      "Epoch: 1515, Avg. Train Loss: 0.003952023405365126, Avg. Test Loss: 0.003896912094205618\n",
      "Epoch: 1516, Avg. Train Loss: 0.003946566098737855, Avg. Test Loss: 0.003920480143278837\n",
      "Epoch: 1517, Avg. Train Loss: 0.003997812794824672, Avg. Test Loss: 0.0038862202782183886\n",
      "Epoch: 1518, Avg. Train Loss: 0.003963697295592621, Avg. Test Loss: 0.0038871229626238346\n",
      "Epoch: 1519, Avg. Train Loss: 0.003938964004953241, Avg. Test Loss: 0.003944299649447203\n",
      "Epoch: 1520, Avg. Train Loss: 0.003961274524890753, Avg. Test Loss: 0.003917771391570568\n",
      "Epoch: 1521, Avg. Train Loss: 0.003937870605177311, Avg. Test Loss: 0.0038895171601325274\n",
      "Epoch: 1522, Avg. Train Loss: 0.003951183628550795, Avg. Test Loss: 0.0038761079777032137\n",
      "Epoch: 1523, Avg. Train Loss: 0.003938713674108649, Avg. Test Loss: 0.003927599173039198\n",
      "Epoch: 1524, Avg. Train Loss: 0.003929703702153855, Avg. Test Loss: 0.003898228518664837\n",
      "Epoch: 1525, Avg. Train Loss: 0.0039605785291208775, Avg. Test Loss: 0.003897701855748892\n",
      "Epoch: 1526, Avg. Train Loss: 0.0039551366218040845, Avg. Test Loss: 0.00387354358099401\n",
      "Epoch: 1527, Avg. Train Loss: 0.0039355159618047085, Avg. Test Loss: 0.0038870912976562977\n",
      "Epoch: 1528, Avg. Train Loss: 0.003936847753086409, Avg. Test Loss: 0.003997430205345154\n",
      "Epoch: 1529, Avg. Train Loss: 0.003929608669348581, Avg. Test Loss: 0.0039026245940476656\n",
      "Epoch: 1530, Avg. Train Loss: 0.003927352789486217, Avg. Test Loss: 0.00386974960565567\n",
      "Epoch: 1531, Avg. Train Loss: 0.003923070389604153, Avg. Test Loss: 0.003915475681424141\n",
      "Epoch: 1532, Avg. Train Loss: 0.003927489683075353, Avg. Test Loss: 0.003873100271448493\n",
      "Epoch: 1533, Avg. Train Loss: 0.003924311474398818, Avg. Test Loss: 0.003916056826710701\n",
      "Epoch: 1534, Avg. Train Loss: 0.003954707428293173, Avg. Test Loss: 0.00386380054987967\n",
      "Epoch: 1535, Avg. Train Loss: 0.003921621121726063, Avg. Test Loss: 0.0039058979600667953\n",
      "Epoch: 1536, Avg. Train Loss: 0.003926686471501409, Avg. Test Loss: 0.003906409256160259\n",
      "Epoch: 1537, Avg. Train Loss: 0.003921455351722448, Avg. Test Loss: 0.0038844789378345013\n",
      "Epoch: 1538, Avg. Train Loss: 0.003926432734831821, Avg. Test Loss: 0.003914962522685528\n",
      "Epoch: 1539, Avg. Train Loss: 0.003947572181607748, Avg. Test Loss: 0.0038842351641505957\n",
      "Epoch: 1540, Avg. Train Loss: 0.003938084749808145, Avg. Test Loss: 0.003986462950706482\n",
      "Epoch: 1541, Avg. Train Loss: 0.003926358445612497, Avg. Test Loss: 0.003890447784215212\n",
      "Epoch: 1542, Avg. Train Loss: 0.0039306107291215385, Avg. Test Loss: 0.00395680358633399\n",
      "Epoch: 1543, Avg. Train Loss: 0.003952626907808143, Avg. Test Loss: 0.0038769461680203676\n",
      "Epoch: 1544, Avg. Train Loss: 0.003935497681891849, Avg. Test Loss: 0.0038459862116724253\n",
      "Epoch: 1545, Avg. Train Loss: 0.003912429525625221, Avg. Test Loss: 0.003921062685549259\n",
      "Epoch: 1546, Avg. Train Loss: 0.003929735307560064, Avg. Test Loss: 0.0038438867777585983\n",
      "Epoch: 1547, Avg. Train Loss: 0.003928633076463675, Avg. Test Loss: 0.0038456961046904325\n",
      "Epoch: 1548, Avg. Train Loss: 0.003918939649105765, Avg. Test Loss: 0.0038466041442006826\n",
      "Epoch: 1549, Avg. Train Loss: 0.0039221243283083275, Avg. Test Loss: 0.0039050623308867216\n",
      "Epoch: 1550, Avg. Train Loss: 0.003952219546231073, Avg. Test Loss: 0.0038899185601621866\n",
      "Epoch: 1551, Avg. Train Loss: 0.003918550101780268, Avg. Test Loss: 0.0038391677662730217\n",
      "Epoch: 1552, Avg. Train Loss: 0.003926439129552523, Avg. Test Loss: 0.003891855012625456\n",
      "Epoch: 1553, Avg. Train Loss: 0.003914170449079816, Avg. Test Loss: 0.00384481530636549\n",
      "Epoch: 1554, Avg. Train Loss: 0.003915247047146739, Avg. Test Loss: 0.00389958661980927\n",
      "Epoch: 1555, Avg. Train Loss: 0.003920352064766163, Avg. Test Loss: 0.003919352311640978\n",
      "Epoch: 1556, Avg. Train Loss: 0.003940905065297387, Avg. Test Loss: 0.0038369749672710896\n",
      "Epoch: 1557, Avg. Train Loss: 0.003909485620381527, Avg. Test Loss: 0.003852551570162177\n",
      "Epoch: 1558, Avg. Train Loss: 0.003910351225153305, Avg. Test Loss: 0.0038515161722898483\n",
      "Epoch: 1559, Avg. Train Loss: 0.003933780729164218, Avg. Test Loss: 0.003930993378162384\n",
      "Epoch: 1560, Avg. Train Loss: 0.0039342714332823835, Avg. Test Loss: 0.003928178455680609\n",
      "Epoch: 1561, Avg. Train Loss: 0.003936342662200332, Avg. Test Loss: 0.003945914562791586\n",
      "Epoch: 1562, Avg. Train Loss: 0.003914240092515599, Avg. Test Loss: 0.003833794267848134\n",
      "Epoch: 1563, Avg. Train Loss: 0.003904568258846222, Avg. Test Loss: 0.0038818190805613995\n",
      "Epoch: 1564, Avg. Train Loss: 0.0039049400623108067, Avg. Test Loss: 0.003849225351586938\n",
      "Epoch: 1565, Avg. Train Loss: 0.003918183323125853, Avg. Test Loss: 0.003907049540430307\n",
      "Epoch: 1566, Avg. Train Loss: 0.00391194875200474, Avg. Test Loss: 0.0038977155927568674\n",
      "Epoch: 1567, Avg. Train Loss: 0.0039034645170579817, Avg. Test Loss: 0.003871385008096695\n",
      "Epoch: 1568, Avg. Train Loss: 0.0039205962283060305, Avg. Test Loss: 0.0038959765806794167\n",
      "Epoch: 1569, Avg. Train Loss: 0.003918011948942791, Avg. Test Loss: 0.003878355957567692\n",
      "Epoch: 1570, Avg. Train Loss: 0.003911018528607349, Avg. Test Loss: 0.0038620014674961567\n",
      "Epoch: 1571, Avg. Train Loss: 0.0038955490657150054, Avg. Test Loss: 0.0038511871825903654\n",
      "Epoch: 1572, Avg. Train Loss: 0.003912565915650407, Avg. Test Loss: 0.0038780630566179752\n",
      "Epoch: 1573, Avg. Train Loss: 0.0038883425945112873, Avg. Test Loss: 0.0038459207862615585\n",
      "Epoch: 1574, Avg. Train Loss: 0.003904355597833908, Avg. Test Loss: 0.003928139340132475\n",
      "Epoch: 1575, Avg. Train Loss: 0.003910300944563608, Avg. Test Loss: 0.00386038632132113\n",
      "Epoch: 1576, Avg. Train Loss: 0.003897337871062201, Avg. Test Loss: 0.003866414772346616\n",
      "Epoch: 1577, Avg. Train Loss: 0.00392795689837184, Avg. Test Loss: 0.0039304266683757305\n",
      "Epoch: 1578, Avg. Train Loss: 0.0038991449292489263, Avg. Test Loss: 0.003927756100893021\n",
      "Epoch: 1579, Avg. Train Loss: 0.003904328589479244, Avg. Test Loss: 0.0038383619394153357\n",
      "Epoch: 1580, Avg. Train Loss: 0.0038968558304098458, Avg. Test Loss: 0.0038479885552078485\n",
      "Epoch: 1581, Avg. Train Loss: 0.003920103748177373, Avg. Test Loss: 0.0038939237128943205\n",
      "Epoch: 1582, Avg. Train Loss: 0.0039005843261906573, Avg. Test Loss: 0.0038585085421800613\n",
      "Epoch: 1583, Avg. Train Loss: 0.003908035767719496, Avg. Test Loss: 0.0038267667405307293\n",
      "Epoch: 1584, Avg. Train Loss: 0.0038904486722204576, Avg. Test Loss: 0.0038834859151393175\n",
      "Epoch: 1585, Avg. Train Loss: 0.0038920908971408078, Avg. Test Loss: 0.0038335570134222507\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1586, Avg. Train Loss: 0.003903944294379894, Avg. Test Loss: 0.003854816546663642\n",
      "Epoch: 1587, Avg. Train Loss: 0.003894019352142201, Avg. Test Loss: 0.0038250659126788378\n",
      "Epoch: 1588, Avg. Train Loss: 0.003906250471075953, Avg. Test Loss: 0.003861464327201247\n",
      "Epoch: 1589, Avg. Train Loss: 0.0039061447551344023, Avg. Test Loss: 0.003824042621999979\n",
      "Epoch: 1590, Avg. Train Loss: 0.003875932315104576, Avg. Test Loss: 0.003826092230156064\n",
      "Epoch: 1591, Avg. Train Loss: 0.00388820706000335, Avg. Test Loss: 0.0038518039509654045\n",
      "Epoch: 1592, Avg. Train Loss: 0.0038877799565535647, Avg. Test Loss: 0.0038121570833027363\n",
      "Epoch: 1593, Avg. Train Loss: 0.003915710732080909, Avg. Test Loss: 0.0038541790563613176\n",
      "Epoch: 1594, Avg. Train Loss: 0.0038844123970024113, Avg. Test Loss: 0.00384820019826293\n",
      "Epoch: 1595, Avg. Train Loss: 0.003893848871379051, Avg. Test Loss: 0.003842491190880537\n",
      "Epoch: 1596, Avg. Train Loss: 0.0039051275126376125, Avg. Test Loss: 0.0038236980326473713\n",
      "Epoch: 1597, Avg. Train Loss: 0.0038826820917081, Avg. Test Loss: 0.00389531790278852\n",
      "Epoch: 1598, Avg. Train Loss: 0.003892550401952724, Avg. Test Loss: 0.003811711212620139\n",
      "Epoch: 1599, Avg. Train Loss: 0.0038949790800553424, Avg. Test Loss: 0.0038345856592059135\n",
      "Epoch: 1600, Avg. Train Loss: 0.003939975778637237, Avg. Test Loss: 0.0038991428446024656\n",
      "Epoch: 1601, Avg. Train Loss: 0.0039007907440929217, Avg. Test Loss: 0.003822841215878725\n",
      "Epoch: 1602, Avg. Train Loss: 0.003867884513077348, Avg. Test Loss: 0.0038458891212940216\n",
      "Epoch: 1603, Avg. Train Loss: 0.0038656124271192523, Avg. Test Loss: 0.0038264913018792868\n",
      "Epoch: 1604, Avg. Train Loss: 0.0038811341631984297, Avg. Test Loss: 0.0038256433326750994\n",
      "Epoch: 1605, Avg. Train Loss: 0.0038959864462011083, Avg. Test Loss: 0.003825254738330841\n",
      "Epoch: 1606, Avg. Train Loss: 0.003912271709766152, Avg. Test Loss: 0.003830058267340064\n",
      "Epoch: 1607, Avg. Train Loss: 0.0038699082174706596, Avg. Test Loss: 0.003819328499957919\n",
      "Epoch: 1608, Avg. Train Loss: 0.0038800172583568233, Avg. Test Loss: 0.003836209187284112\n",
      "Epoch: 1609, Avg. Train Loss: 0.0038903812271391235, Avg. Test Loss: 0.003835037350654602\n",
      "Epoch: 1610, Avg. Train Loss: 0.0038957442319410484, Avg. Test Loss: 0.003803400555625558\n",
      "Epoch: 1611, Avg. Train Loss: 0.0038732427692170753, Avg. Test Loss: 0.00385314435698092\n",
      "Epoch: 1612, Avg. Train Loss: 0.0038699622720826505, Avg. Test Loss: 0.0038714560214430094\n",
      "Epoch: 1613, Avg. Train Loss: 0.00388339483504032, Avg. Test Loss: 0.0038297364953905344\n",
      "Epoch: 1614, Avg. Train Loss: 0.003870938704240807, Avg. Test Loss: 0.003801055485382676\n",
      "Epoch: 1615, Avg. Train Loss: 0.0038670968849125295, Avg. Test Loss: 0.0038252747617661953\n",
      "Epoch: 1616, Avg. Train Loss: 0.003889780751494474, Avg. Test Loss: 0.0038022117223590612\n",
      "Epoch: 1617, Avg. Train Loss: 0.003884678408720119, Avg. Test Loss: 0.0038375414442270994\n",
      "Epoch: 1618, Avg. Train Loss: 0.0038778981854489377, Avg. Test Loss: 0.0038058371283113956\n",
      "Epoch: 1619, Avg. Train Loss: 0.003864024283884223, Avg. Test Loss: 0.0038024468813091516\n",
      "Epoch: 1620, Avg. Train Loss: 0.0038666102417939624, Avg. Test Loss: 0.0038132169283926487\n",
      "Epoch: 1621, Avg. Train Loss: 0.0038665761564706646, Avg. Test Loss: 0.0038335940334945917\n",
      "Epoch: 1622, Avg. Train Loss: 0.0038546072481589954, Avg. Test Loss: 0.003820582525804639\n",
      "Epoch: 1623, Avg. Train Loss: 0.0038884946329215933, Avg. Test Loss: 0.003910678438842297\n",
      "Epoch: 1624, Avg. Train Loss: 0.003918870000255315, Avg. Test Loss: 0.00389655283652246\n",
      "Epoch: 1625, Avg. Train Loss: 0.0038646337857773136, Avg. Test Loss: 0.003824961371719837\n",
      "Epoch: 1626, Avg. Train Loss: 0.003873337558362373, Avg. Test Loss: 0.003808156121522188\n",
      "Epoch: 1627, Avg. Train Loss: 0.003896118704836036, Avg. Test Loss: 0.003818454686552286\n",
      "Epoch: 1628, Avg. Train Loss: 0.0038704135736753772, Avg. Test Loss: 0.0038681658916175365\n",
      "Epoch: 1629, Avg. Train Loss: 0.0038680906223436426, Avg. Test Loss: 0.003844610648229718\n",
      "Epoch: 1630, Avg. Train Loss: 0.0038716127110515223, Avg. Test Loss: 0.003838647622615099\n",
      "Epoch: 1631, Avg. Train Loss: 0.0038625143609161295, Avg. Test Loss: 0.0038572747725993395\n",
      "Epoch: 1632, Avg. Train Loss: 0.003877773041685307, Avg. Test Loss: 0.0038116758223623037\n",
      "Epoch: 1633, Avg. Train Loss: 0.0038659056475342708, Avg. Test Loss: 0.0038168018218129873\n",
      "Epoch: 1634, Avg. Train Loss: 0.0038670141488140407, Avg. Test Loss: 0.003850206732749939\n",
      "Epoch: 1635, Avg. Train Loss: 0.0038718430022167604, Avg. Test Loss: 0.0038728949148207903\n",
      "Epoch: 1636, Avg. Train Loss: 0.0038697085245837305, Avg. Test Loss: 0.0037994161248207092\n",
      "Epoch: 1637, Avg. Train Loss: 0.003869838633596204, Avg. Test Loss: 0.0038600568659603596\n",
      "Epoch: 1638, Avg. Train Loss: 0.0038619244167971056, Avg. Test Loss: 0.0037975949235260487\n",
      "Epoch: 1639, Avg. Train Loss: 0.003877781412759146, Avg. Test Loss: 0.0038034149911254644\n",
      "Epoch: 1640, Avg. Train Loss: 0.0038736463351131873, Avg. Test Loss: 0.0037997765466570854\n",
      "Epoch: 1641, Avg. Train Loss: 0.0038581963162869215, Avg. Test Loss: 0.003908616490662098\n",
      "Epoch: 1642, Avg. Train Loss: 0.003873483218295976, Avg. Test Loss: 0.0037816213443875313\n",
      "Epoch: 1643, Avg. Train Loss: 0.0038497599524034316, Avg. Test Loss: 0.0038084436673671007\n",
      "Epoch: 1644, Avg. Train Loss: 0.0038566990961255722, Avg. Test Loss: 0.00380880618467927\n",
      "Epoch: 1645, Avg. Train Loss: 0.003864752556478908, Avg. Test Loss: 0.0038462160155177116\n",
      "Epoch: 1646, Avg. Train Loss: 0.0038601823779212873, Avg. Test Loss: 0.0038017225451767445\n",
      "Epoch: 1647, Avg. Train Loss: 0.0038447711389338556, Avg. Test Loss: 0.003805074840784073\n",
      "Epoch: 1648, Avg. Train Loss: 0.0038645418934783963, Avg. Test Loss: 0.003949047066271305\n",
      "Epoch: 1649, Avg. Train Loss: 0.003918680259524737, Avg. Test Loss: 0.0038790246471762657\n",
      "Epoch: 1650, Avg. Train Loss: 0.0038675504011037045, Avg. Test Loss: 0.003809591755270958\n",
      "Epoch: 1651, Avg. Train Loss: 0.0038599921986027515, Avg. Test Loss: 0.003853689879179001\n",
      "Epoch: 1652, Avg. Train Loss: 0.0038450196396212937, Avg. Test Loss: 0.0037866788916289806\n",
      "Epoch: 1653, Avg. Train Loss: 0.0038429152783612873, Avg. Test Loss: 0.0037925192154943943\n",
      "Epoch: 1654, Avg. Train Loss: 0.0038509564636665028, Avg. Test Loss: 0.0038384604267776012\n",
      "Epoch: 1655, Avg. Train Loss: 0.0038607285986112993, Avg. Test Loss: 0.0038326503708958626\n",
      "Epoch: 1656, Avg. Train Loss: 0.0038459855240098265, Avg. Test Loss: 0.0037843286991119385\n",
      "Epoch: 1657, Avg. Train Loss: 0.0038545048351637844, Avg. Test Loss: 0.0038421317003667355\n",
      "Epoch: 1658, Avg. Train Loss: 0.0038521328648595614, Avg. Test Loss: 0.0038021893706172705\n",
      "Epoch: 1659, Avg. Train Loss: 0.003846494421406194, Avg. Test Loss: 0.0038063672836869955\n",
      "Epoch: 1660, Avg. Train Loss: 0.003860794803734089, Avg. Test Loss: 0.0038892501033842564\n",
      "Epoch: 1661, Avg. Train Loss: 0.003849750547128361, Avg. Test Loss: 0.0037810851354151964\n",
      "Epoch: 1662, Avg. Train Loss: 0.0038605946072832096, Avg. Test Loss: 0.003779420629143715\n",
      "Epoch: 1663, Avg. Train Loss: 0.0038647885748380145, Avg. Test Loss: 0.0038611909840255976\n",
      "Epoch: 1664, Avg. Train Loss: 0.0038748749715904166, Avg. Test Loss: 0.003901367075741291\n",
      "Epoch: 1665, Avg. Train Loss: 0.003868361891702164, Avg. Test Loss: 0.0038222114089876413\n",
      "Epoch: 1666, Avg. Train Loss: 0.0038585279970754717, Avg. Test Loss: 0.0038020797073841095\n",
      "Epoch: 1667, Avg. Train Loss: 0.0038388080808312392, Avg. Test Loss: 0.003815974108874798\n",
      "Epoch: 1668, Avg. Train Loss: 0.003856323886835991, Avg. Test Loss: 0.003781096311286092\n",
      "Epoch: 1669, Avg. Train Loss: 0.0038425829803007978, Avg. Test Loss: 0.0037824390456080437\n",
      "Epoch: 1670, Avg. Train Loss: 0.003860524406136815, Avg. Test Loss: 0.0038668380584567785\n",
      "Epoch: 1671, Avg. Train Loss: 0.0038556170400751884, Avg. Test Loss: 0.0037743651773780584\n",
      "Epoch: 1672, Avg. Train Loss: 0.0038296728459901587, Avg. Test Loss: 0.003775432240217924\n",
      "Epoch: 1673, Avg. Train Loss: 0.003838362237221973, Avg. Test Loss: 0.003830335335806012\n",
      "Epoch: 1674, Avg. Train Loss: 0.0038552084493689064, Avg. Test Loss: 0.0038321909960359335\n",
      "Epoch: 1675, Avg. Train Loss: 0.003855642516079337, Avg. Test Loss: 0.0038427908439189196\n",
      "Epoch: 1676, Avg. Train Loss: 0.003889135729391561, Avg. Test Loss: 0.0037751798518002033\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1677, Avg. Train Loss: 0.003844228399874166, Avg. Test Loss: 0.0038248547352850437\n",
      "Epoch: 1678, Avg. Train Loss: 0.0038429884954767173, Avg. Test Loss: 0.003782459767535329\n",
      "Epoch: 1679, Avg. Train Loss: 0.0038485218294311402, Avg. Test Loss: 0.003832282265648246\n",
      "Epoch: 1680, Avg. Train Loss: 0.0038565590945180764, Avg. Test Loss: 0.0038949139416217804\n",
      "Epoch: 1681, Avg. Train Loss: 0.003830204744888253, Avg. Test Loss: 0.0037920838221907616\n",
      "Epoch: 1682, Avg. Train Loss: 0.003833678052868954, Avg. Test Loss: 0.00381589587777853\n",
      "Epoch: 1683, Avg. Train Loss: 0.0038377726342269155, Avg. Test Loss: 0.0038238263223320246\n",
      "Epoch: 1684, Avg. Train Loss: 0.003844788379230818, Avg. Test Loss: 0.003776423865929246\n",
      "Epoch: 1685, Avg. Train Loss: 0.003832581821222638, Avg. Test Loss: 0.003774787299335003\n",
      "Epoch: 1686, Avg. Train Loss: 0.0038267646125669397, Avg. Test Loss: 0.0038416972383856773\n",
      "Epoch: 1687, Avg. Train Loss: 0.003846606634947103, Avg. Test Loss: 0.0037698792293667793\n",
      "Epoch: 1688, Avg. Train Loss: 0.0038423969432018522, Avg. Test Loss: 0.0038130348548293114\n",
      "Epoch: 1689, Avg. Train Loss: 0.0038648830066153475, Avg. Test Loss: 0.003770803567022085\n",
      "Epoch: 1690, Avg. Train Loss: 0.00383921742959078, Avg. Test Loss: 0.003797676879912615\n",
      "Epoch: 1691, Avg. Train Loss: 0.003853337167827196, Avg. Test Loss: 0.0037646780256181955\n",
      "Epoch: 1692, Avg. Train Loss: 0.003832350907370795, Avg. Test Loss: 0.003777844598516822\n",
      "Epoch: 1693, Avg. Train Loss: 0.0038421068416345256, Avg. Test Loss: 0.0037911594845354557\n",
      "Epoch: 1694, Avg. Train Loss: 0.0038263533416009227, Avg. Test Loss: 0.0037863673642277718\n",
      "Epoch: 1695, Avg. Train Loss: 0.0038343395084835764, Avg. Test Loss: 0.0037883687764406204\n",
      "Epoch: 1696, Avg. Train Loss: 0.0038215368823689777, Avg. Test Loss: 0.00375530612654984\n",
      "Epoch: 1697, Avg. Train Loss: 0.0038180651338121227, Avg. Test Loss: 0.0038058869540691376\n",
      "Epoch: 1698, Avg. Train Loss: 0.003860437766064045, Avg. Test Loss: 0.003806930035352707\n",
      "Epoch: 1699, Avg. Train Loss: 0.003843152873911137, Avg. Test Loss: 0.003802693448960781\n",
      "Epoch: 1700, Avg. Train Loss: 0.003835870445770926, Avg. Test Loss: 0.003774113953113556\n",
      "Epoch: 1701, Avg. Train Loss: 0.00384211128707542, Avg. Test Loss: 0.0038488730788230896\n",
      "Epoch: 1702, Avg. Train Loss: 0.0038394244214476543, Avg. Test Loss: 0.003761684987694025\n",
      "Epoch: 1703, Avg. Train Loss: 0.00382133906295653, Avg. Test Loss: 0.0038158148527145386\n",
      "Epoch: 1704, Avg. Train Loss: 0.0038433739493146193, Avg. Test Loss: 0.003808520268648863\n",
      "Epoch: 1705, Avg. Train Loss: 0.003838869829683803, Avg. Test Loss: 0.00378946284763515\n",
      "Epoch: 1706, Avg. Train Loss: 0.0038300305875668, Avg. Test Loss: 0.0038814758881926537\n",
      "Epoch: 1707, Avg. Train Loss: 0.0038180698987183184, Avg. Test Loss: 0.0037474827840924263\n",
      "Epoch: 1708, Avg. Train Loss: 0.003869194889354498, Avg. Test Loss: 0.003821650519967079\n",
      "Epoch: 1709, Avg. Train Loss: 0.003831272430414724, Avg. Test Loss: 0.003777154954150319\n",
      "Epoch: 1710, Avg. Train Loss: 0.003811868665696577, Avg. Test Loss: 0.003753165015950799\n",
      "Epoch: 1711, Avg. Train Loss: 0.003817858255663237, Avg. Test Loss: 0.0037768573965877295\n",
      "Epoch: 1712, Avg. Train Loss: 0.00384338082052594, Avg. Test Loss: 0.003824233543127775\n",
      "Epoch: 1713, Avg. Train Loss: 0.0038244031792030084, Avg. Test Loss: 0.003765611443668604\n",
      "Epoch: 1714, Avg. Train Loss: 0.003816052561972377, Avg. Test Loss: 0.0037460518069565296\n",
      "Epoch: 1715, Avg. Train Loss: 0.0038332650762831055, Avg. Test Loss: 0.003763894783332944\n",
      "Epoch: 1716, Avg. Train Loss: 0.0038093028557595124, Avg. Test Loss: 0.0037489181850105524\n",
      "Epoch: 1717, Avg. Train Loss: 0.0038280677548501382, Avg. Test Loss: 0.0038689603097736835\n",
      "Epoch: 1718, Avg. Train Loss: 0.003852679973554819, Avg. Test Loss: 0.003747721668332815\n",
      "Epoch: 1719, Avg. Train Loss: 0.003838575152723595, Avg. Test Loss: 0.003762545296922326\n",
      "Epoch: 1720, Avg. Train Loss: 0.003844807520075593, Avg. Test Loss: 0.0038371626287698746\n",
      "Epoch: 1721, Avg. Train Loss: 0.00385001125247326, Avg. Test Loss: 0.003748829709365964\n",
      "Epoch: 1722, Avg. Train Loss: 0.0038037562558730672, Avg. Test Loss: 0.003775212448090315\n",
      "Epoch: 1723, Avg. Train Loss: 0.0038232188725973977, Avg. Test Loss: 0.0038346454966813326\n",
      "Epoch: 1724, Avg. Train Loss: 0.003815360860032744, Avg. Test Loss: 0.0037894188426434994\n",
      "Epoch: 1725, Avg. Train Loss: 0.0038119025939945565, Avg. Test Loss: 0.0037465225905179977\n",
      "Epoch: 1726, Avg. Train Loss: 0.003814761061221361, Avg. Test Loss: 0.003764441469684243\n",
      "Epoch: 1727, Avg. Train Loss: 0.0038065156238803336, Avg. Test Loss: 0.0037630023434758186\n",
      "Epoch: 1803, Avg. Train Loss: 0.0037765059251944687, Avg. Test Loss: 0.0037499701138585806\n",
      "Epoch: 1804, Avg. Train Loss: 0.003792071195189343, Avg. Test Loss: 0.003724220674484968\n",
      "Epoch: 1805, Avg. Train Loss: 0.0037744127939520187, Avg. Test Loss: 0.003830634756013751\n",
      "Epoch: 1806, Avg. Train Loss: 0.003803550623097392, Avg. Test Loss: 0.003717404557392001\n",
      "Epoch: 1807, Avg. Train Loss: 0.003807878473686964, Avg. Test Loss: 0.003771600080654025\n",
      "Epoch: 1808, Avg. Train Loss: 0.003803193211815385, Avg. Test Loss: 0.0037176955956965685\n",
      "Epoch: 1809, Avg. Train Loss: 0.003782929906751527, Avg. Test Loss: 0.0037472019903361797\n",
      "Epoch: 1810, Avg. Train Loss: 0.003766037225939853, Avg. Test Loss: 0.0037485393695533276\n",
      "Epoch: 1811, Avg. Train Loss: 0.003820390543402281, Avg. Test Loss: 0.0037207328714430332\n",
      "Epoch: 1812, Avg. Train Loss: 0.0037771282923342877, Avg. Test Loss: 0.003702760674059391\n",
      "Epoch: 1813, Avg. Train Loss: 0.00377646018209499, Avg. Test Loss: 0.0037027110811322927\n",
      "Epoch: 1814, Avg. Train Loss: 0.00378302687259261, Avg. Test Loss: 0.0037395847029983997\n",
      "Epoch: 1815, Avg. Train Loss: 0.003780758918024773, Avg. Test Loss: 0.003777415258809924\n",
      "Epoch: 1816, Avg. Train Loss: 0.0037852969821975673, Avg. Test Loss: 0.0037275173235684633\n",
      "Epoch: 1817, Avg. Train Loss: 0.0037829243134014133, Avg. Test Loss: 0.003789721056818962\n",
      "Epoch: 1818, Avg. Train Loss: 0.003776361288632764, Avg. Test Loss: 0.003703937167301774\n",
      "Epoch: 1819, Avg. Train Loss: 0.0037668630383302306, Avg. Test Loss: 0.0037241228856146336\n",
      "Epoch: 1820, Avg. Train Loss: 0.003790129934502549, Avg. Test Loss: 0.0037737286183983088\n",
      "Epoch: 1821, Avg. Train Loss: 0.003777687984713635, Avg. Test Loss: 0.0037385413888841867\n",
      "Epoch: 1822, Avg. Train Loss: 0.00378450931071542, Avg. Test Loss: 0.003740138839930296\n",
      "Epoch: 1823, Avg. Train Loss: 0.0037711813428634128, Avg. Test Loss: 0.0037238372024148703\n",
      "Epoch: 1824, Avg. Train Loss: 0.003777089501666122, Avg. Test Loss: 0.003701933193951845\n",
      "Epoch: 1825, Avg. Train Loss: 0.003759771980735105, Avg. Test Loss: 0.0037737046368420124\n",
      "Epoch: 1826, Avg. Train Loss: 0.003774715690375414, Avg. Test Loss: 0.003709356067702174\n",
      "Epoch: 1827, Avg. Train Loss: 0.0037848833937544463, Avg. Test Loss: 0.003696842584758997\n",
      "Epoch: 1828, Avg. Train Loss: 0.0037937110051685986, Avg. Test Loss: 0.003699178108945489\n",
      "Epoch: 1829, Avg. Train Loss: 0.0037668778961740955, Avg. Test Loss: 0.0037252497859299183\n",
      "Epoch: 1830, Avg. Train Loss: 0.003785066561080342, Avg. Test Loss: 0.0037497305311262608\n",
      "Epoch: 1831, Avg. Train Loss: 0.0037630330662914487, Avg. Test Loss: 0.003717967774719\n",
      "Epoch: 1832, Avg. Train Loss: 0.0037710513638029267, Avg. Test Loss: 0.003731776727363467\n",
      "Epoch: 1833, Avg. Train Loss: 0.0037654108248737664, Avg. Test Loss: 0.0037146343383938074\n",
      "Epoch: 1834, Avg. Train Loss: 0.0037739295295851176, Avg. Test Loss: 0.0037040780298411846\n",
      "Epoch: 1835, Avg. Train Loss: 0.0037568631083812823, Avg. Test Loss: 0.003797666635364294\n",
      "Epoch: 1836, Avg. Train Loss: 0.0037951041446175685, Avg. Test Loss: 0.003803413128480315\n",
      "Epoch: 1837, Avg. Train Loss: 0.003780619170906585, Avg. Test Loss: 0.0037294633220881224\n",
      "Epoch: 1838, Avg. Train Loss: 0.0037816588734384884, Avg. Test Loss: 0.0037222160026431084\n",
      "Epoch: 1839, Avg. Train Loss: 0.0037565451537713754, Avg. Test Loss: 0.0037141391076147556\n",
      "Epoch: 1840, Avg. Train Loss: 0.0037676785520256257, Avg. Test Loss: 0.0037237671203911304\n",
      "Epoch: 1841, Avg. Train Loss: 0.003756494402105725, Avg. Test Loss: 0.0036906669847667217\n",
      "Epoch: 1842, Avg. Train Loss: 0.0037649840896212777, Avg. Test Loss: 0.003701917128637433\n",
      "Epoch: 1843, Avg. Train Loss: 0.0037657357481589845, Avg. Test Loss: 0.0037309571634978056\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1844, Avg. Train Loss: 0.0037640232841895764, Avg. Test Loss: 0.0036964318715035915\n",
      "Epoch: 1845, Avg. Train Loss: 0.003765769086258356, Avg. Test Loss: 0.003781333565711975\n",
      "Epoch: 1846, Avg. Train Loss: 0.003766479658309457, Avg. Test Loss: 0.0037010405212640762\n",
      "Epoch: 1847, Avg. Train Loss: 0.0037669100592909164, Avg. Test Loss: 0.003724699607118964\n",
      "Epoch: 1848, Avg. Train Loss: 0.003764267967537392, Avg. Test Loss: 0.0037363055162131786\n",
      "Epoch: 1849, Avg. Train Loss: 0.0037726832304669673, Avg. Test Loss: 0.003696753876283765\n",
      "Epoch: 1850, Avg. Train Loss: 0.003781452330998903, Avg. Test Loss: 0.0038248226046562195\n",
      "Epoch: 1851, Avg. Train Loss: 0.0037681821755371813, Avg. Test Loss: 0.0037286831066012383\n",
      "Epoch: 1852, Avg. Train Loss: 0.0037613117872455784, Avg. Test Loss: 0.003782003652304411\n",
      "Epoch: 1853, Avg. Train Loss: 0.003782961328059088, Avg. Test Loss: 0.0036961694713681936\n",
      "Epoch: 1854, Avg. Train Loss: 0.003762623863727894, Avg. Test Loss: 0.003721364075317979\n",
      "Epoch: 1855, Avg. Train Loss: 0.003744091860256916, Avg. Test Loss: 0.003691998077556491\n",
      "Epoch: 1856, Avg. Train Loss: 0.003780056300118219, Avg. Test Loss: 0.003731001866981387\n",
      "Epoch: 1857, Avg. Train Loss: 0.0037516511077884326, Avg. Test Loss: 0.0037072147242724895\n",
      "Epoch: 1858, Avg. Train Loss: 0.003750695863218848, Avg. Test Loss: 0.0037511547561734915\n",
      "Epoch: 1859, Avg. Train Loss: 0.003745126288904007, Avg. Test Loss: 0.003711395664140582\n",
      "Epoch: 1860, Avg. Train Loss: 0.0037410769633255724, Avg. Test Loss: 0.0036932681687176228\n",
      "Epoch: 1861, Avg. Train Loss: 0.003761448242246758, Avg. Test Loss: 0.0036944521125406027\n",
      "Epoch: 1862, Avg. Train Loss: 0.0037720229011029005, Avg. Test Loss: 0.0037142601795494556\n",
      "Epoch: 1863, Avg. Train Loss: 0.0037673307734346667, Avg. Test Loss: 0.003713439917191863\n",
      "Epoch: 1864, Avg. Train Loss: 0.0037609353217534546, Avg. Test Loss: 0.003688844619318843\n",
      "Epoch: 1865, Avg. Train Loss: 0.003753428650630075, Avg. Test Loss: 0.0037065562792122364\n",
      "Epoch: 1866, Avg. Train Loss: 0.0037639761007889068, Avg. Test Loss: 0.003729943186044693\n",
      "Epoch: 1867, Avg. Train Loss: 0.003791802254137258, Avg. Test Loss: 0.003706237068399787\n",
      "Epoch: 1868, Avg. Train Loss: 0.0037645920677933584, Avg. Test Loss: 0.003682610346004367\n",
      "Epoch: 1869, Avg. Train Loss: 0.003743595357031323, Avg. Test Loss: 0.0036936679389327765\n",
      "Epoch: 1870, Avg. Train Loss: 0.0037766431869809018, Avg. Test Loss: 0.0037299266550689936\n",
      "Epoch: 1871, Avg. Train Loss: 0.003766417265111624, Avg. Test Loss: 0.0036868080496788025\n",
      "Epoch: 1872, Avg. Train Loss: 0.0037678322473237683, Avg. Test Loss: 0.0037175703328102827\n",
      "Epoch: 1873, Avg. Train Loss: 0.003758551347134418, Avg. Test Loss: 0.003733384422957897\n",
      "Epoch: 1874, Avg. Train Loss: 0.003739502925295816, Avg. Test Loss: 0.003700889879837632\n",
      "Epoch: 1875, Avg. Train Loss: 0.0037534011657847917, Avg. Test Loss: 0.0036993715912103653\n",
      "Epoch: 1876, Avg. Train Loss: 0.003754464514163691, Avg. Test Loss: 0.003680601017549634\n",
      "Epoch: 1877, Avg. Train Loss: 0.003742168148503054, Avg. Test Loss: 0.003754816483706236\n",
      "Epoch: 1878, Avg. Train Loss: 0.0037604386885758748, Avg. Test Loss: 0.003766401670873165\n",
      "Epoch: 1879, Avg. Train Loss: 0.003744146938240805, Avg. Test Loss: 0.003707542782649398\n",
      "Epoch: 1880, Avg. Train Loss: 0.003748921536688888, Avg. Test Loss: 0.003705358598381281\n",
      "Epoch: 1881, Avg. Train Loss: 0.003735671875738474, Avg. Test Loss: 0.003789553651586175\n",
      "Epoch: 1882, Avg. Train Loss: 0.0037676526645068513, Avg. Test Loss: 0.0037739649415016174\n",
      "Epoch: 1883, Avg. Train Loss: 0.003780648036491732, Avg. Test Loss: 0.0037038158625364304\n",
      "Epoch: 1884, Avg. Train Loss: 0.00374992290338458, Avg. Test Loss: 0.0037401909939944744\n",
      "Epoch: 1885, Avg. Train Loss: 0.0037425752664201483, Avg. Test Loss: 0.0036770091392099857\n",
      "Epoch: 1886, Avg. Train Loss: 0.003755857664441993, Avg. Test Loss: 0.003746860893443227\n",
      "Epoch: 1887, Avg. Train Loss: 0.003742334237971971, Avg. Test Loss: 0.003712514415383339\n",
      "Epoch: 1888, Avg. Train Loss: 0.003744787211681521, Avg. Test Loss: 0.0036705154925584793\n",
      "Epoch: 1889, Avg. Train Loss: 0.0037402870826596436, Avg. Test Loss: 0.003668318036943674\n",
      "Epoch: 1890, Avg. Train Loss: 0.0037290462466000123, Avg. Test Loss: 0.003727108472958207\n",
      "Epoch: 1891, Avg. Train Loss: 0.0037266234217514824, Avg. Test Loss: 0.003677823580801487\n",
      "Epoch: 1892, Avg. Train Loss: 0.003722035981238235, Avg. Test Loss: 0.0036669508554041386\n",
      "Epoch: 1893, Avg. Train Loss: 0.0037475153587238734, Avg. Test Loss: 0.003666484961286187\n",
      "Epoch: 1894, Avg. Train Loss: 0.00370543054305017, Avg. Test Loss: 0.003690190613269806\n",
      "Epoch: 1895, Avg. Train Loss: 0.003709404815941356, Avg. Test Loss: 0.003630853956565261\n",
      "Epoch: 1896, Avg. Train Loss: 0.0037156358025534904, Avg. Test Loss: 0.0036573768593370914\n",
      "Epoch: 1897, Avg. Train Loss: 0.003705705754285635, Avg. Test Loss: 0.003711634548380971\n",
      "Epoch: 1898, Avg. Train Loss: 0.0037449544977916534, Avg. Test Loss: 0.0036815304774791002\n",
      "Epoch: 1899, Avg. Train Loss: 0.0037032319286968126, Avg. Test Loss: 0.003651000326499343\n",
      "Epoch: 1900, Avg. Train Loss: 0.003713715166329991, Avg. Test Loss: 0.0036529935896396637\n",
      "Epoch: 1901, Avg. Train Loss: 0.003693212700877772, Avg. Test Loss: 0.003651723964139819\n",
      "Epoch: 1902, Avg. Train Loss: 0.003728020178197428, Avg. Test Loss: 0.0036885682493448257\n",
      "Epoch: 1903, Avg. Train Loss: 0.003736946769708464, Avg. Test Loss: 0.0036459616385400295\n",
      "Epoch: 1904, Avg. Train Loss: 0.0037164900744290547, Avg. Test Loss: 0.003650982165709138\n",
      "Epoch: 1905, Avg. Train Loss: 0.00369450916687763, Avg. Test Loss: 0.003668890567496419\n",
      "Epoch: 1906, Avg. Train Loss: 0.003708100796482244, Avg. Test Loss: 0.0036451739724725485\n",
      "Epoch: 1907, Avg. Train Loss: 0.0037029668374723474, Avg. Test Loss: 0.0036476231180131435\n",
      "Epoch: 1908, Avg. Train Loss: 0.003714227052622063, Avg. Test Loss: 0.0036692332942038774\n",
      "Epoch: 1909, Avg. Train Loss: 0.003702223934449775, Avg. Test Loss: 0.0036420931573957205\n",
      "Epoch: 1910, Avg. Train Loss: 0.0036995858333051896, Avg. Test Loss: 0.003624523524194956\n",
      "Epoch: 1911, Avg. Train Loss: 0.003688036003908099, Avg. Test Loss: 0.0036656789015978575\n",
      "Epoch: 1912, Avg. Train Loss: 0.0037189716808931077, Avg. Test Loss: 0.0036505565512925386\n",
      "Epoch: 1913, Avg. Train Loss: 0.0037009770288890186, Avg. Test Loss: 0.0036135504487901926\n",
      "Epoch: 1914, Avg. Train Loss: 0.003723201888808331, Avg. Test Loss: 0.003661287948489189\n",
      "Epoch: 1915, Avg. Train Loss: 0.0037046098366899545, Avg. Test Loss: 0.003618714166805148\n",
      "Epoch: 1916, Avg. Train Loss: 0.0037054639082228723, Avg. Test Loss: 0.0036232504062354565\n",
      "Epoch: 1917, Avg. Train Loss: 0.00370044661902411, Avg. Test Loss: 0.003630483290180564\n",
      "Epoch: 1918, Avg. Train Loss: 0.003683511048642009, Avg. Test Loss: 0.003688482567667961\n",
      "Epoch: 1919, Avg. Train Loss: 0.0036733103266289066, Avg. Test Loss: 0.003622393822297454\n",
      "Epoch: 1920, Avg. Train Loss: 0.0037455728255905386, Avg. Test Loss: 0.003603206481784582\n",
      "Epoch: 1921, Avg. Train Loss: 0.003696144970003949, Avg. Test Loss: 0.0036454375367611647\n",
      "Epoch: 1922, Avg. Train Loss: 0.0036871554492431324, Avg. Test Loss: 0.0036416545044630766\n",
      "Epoch: 1923, Avg. Train Loss: 0.0036855006081506956, Avg. Test Loss: 0.003699869615957141\n",
      "Epoch: 1924, Avg. Train Loss: 0.003698084270581603, Avg. Test Loss: 0.0036503367591649294\n",
      "Epoch: 1925, Avg. Train Loss: 0.0036775782801817323, Avg. Test Loss: 0.003630260704085231\n",
      "Epoch: 1926, Avg. Train Loss: 0.0036660445919043795, Avg. Test Loss: 0.003606715938076377\n",
      "Epoch: 1927, Avg. Train Loss: 0.003667822394649996, Avg. Test Loss: 0.0036389401648193598\n",
      "Epoch: 1928, Avg. Train Loss: 0.0036734595115101615, Avg. Test Loss: 0.0036649079993367195\n",
      "Epoch: 1929, Avg. Train Loss: 0.003686811125209165, Avg. Test Loss: 0.0036203868221491575\n",
      "Epoch: 1930, Avg. Train Loss: 0.00367645395183286, Avg. Test Loss: 0.003687115153297782\n",
      "Epoch: 1931, Avg. Train Loss: 0.0036865245648334886, Avg. Test Loss: 0.0036519705317914486\n",
      "Epoch: 1932, Avg. Train Loss: 0.003671516669740857, Avg. Test Loss: 0.0036236701998859644\n",
      "Epoch: 1933, Avg. Train Loss: 0.003672745474072736, Avg. Test Loss: 0.0036554131656885147\n",
      "Epoch: 1934, Avg. Train Loss: 0.003687468184114889, Avg. Test Loss: 0.003664877964183688\n",
      "Epoch: 1935, Avg. Train Loss: 0.003665768725494313, Avg. Test Loss: 0.0035903200041502714\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1936, Avg. Train Loss: 0.0036654536569014537, Avg. Test Loss: 0.0038066282868385315\n",
      "Epoch: 1937, Avg. Train Loss: 0.003690138518766955, Avg. Test Loss: 0.0036053324583917856\n",
      "Epoch: 1938, Avg. Train Loss: 0.003669852011858724, Avg. Test Loss: 0.003685900941491127\n",
      "Epoch: 1939, Avg. Train Loss: 0.0037221301855995905, Avg. Test Loss: 0.0036025741137564182\n",
      "Epoch: 1940, Avg. Train Loss: 0.00366916413267338, Avg. Test Loss: 0.0036249773111194372\n",
      "Epoch: 1941, Avg. Train Loss: 0.003656695174529802, Avg. Test Loss: 0.0036797926295548677\n",
      "Epoch: 1942, Avg. Train Loss: 0.0037009266237620006, Avg. Test Loss: 0.003603036282584071\n",
      "Epoch: 1943, Avg. Train Loss: 0.0036747108300238156, Avg. Test Loss: 0.0036347468849271536\n",
      "Epoch: 1944, Avg. Train Loss: 0.0036821600569542064, Avg. Test Loss: 0.0036279528867453337\n",
      "Epoch: 1945, Avg. Train Loss: 0.0036764892175533744, Avg. Test Loss: 0.003592572407796979\n",
      "Epoch: 1946, Avg. Train Loss: 0.0036546087304000245, Avg. Test Loss: 0.003632785752415657\n",
      "Epoch: 1947, Avg. Train Loss: 0.0036609336777135384, Avg. Test Loss: 0.0036718316841870546\n",
      "Epoch: 1948, Avg. Train Loss: 0.0036754295240741136, Avg. Test Loss: 0.0035920897498726845\n",
      "Epoch: 1949, Avg. Train Loss: 0.0036658731419159925, Avg. Test Loss: 0.0036059694830328226\n",
      "Epoch: 1950, Avg. Train Loss: 0.00367807432857537, Avg. Test Loss: 0.0036050823982805014\n",
      "Epoch: 1951, Avg. Train Loss: 0.00365799869583963, Avg. Test Loss: 0.0036149860825389624\n",
      "Epoch: 1952, Avg. Train Loss: 0.0036604587627618117, Avg. Test Loss: 0.0035976923536509275\n",
      "Epoch: 1953, Avg. Train Loss: 0.003690635579703159, Avg. Test Loss: 0.003624518634751439\n",
      "Epoch: 1954, Avg. Train Loss: 0.003676848789287168, Avg. Test Loss: 0.0036034942604601383\n",
      "Epoch: 1955, Avg. Train Loss: 0.0036604464660550274, Avg. Test Loss: 0.0036234117578715086\n",
      "Epoch: 1956, Avg. Train Loss: 0.003668365810542952, Avg. Test Loss: 0.003622850403189659\n",
      "Epoch: 1957, Avg. Train Loss: 0.003679359380459023, Avg. Test Loss: 0.003591660875827074\n",
      "Epoch: 1958, Avg. Train Loss: 0.0036582700734914737, Avg. Test Loss: 0.003658355213701725\n",
      "Epoch: 1959, Avg. Train Loss: 0.0036582428918674934, Avg. Test Loss: 0.0036102745216339827\n",
      "Epoch: 1960, Avg. Train Loss: 0.0036663281633843516, Avg. Test Loss: 0.0035825707018375397\n",
      "Epoch: 1961, Avg. Train Loss: 0.0036549175288095033, Avg. Test Loss: 0.003570789471268654\n",
      "Epoch: 1962, Avg. Train Loss: 0.0036428730480026366, Avg. Test Loss: 0.0035889665596187115\n",
      "Epoch: 1963, Avg. Train Loss: 0.0036719586797665025, Avg. Test Loss: 0.003615476656705141\n",
      "Epoch: 1964, Avg. Train Loss: 0.0036612454054573943, Avg. Test Loss: 0.0036005901638418436\n",
      "Epoch: 1965, Avg. Train Loss: 0.0036555133045239503, Avg. Test Loss: 0.003578820265829563\n",
      "Epoch: 1966, Avg. Train Loss: 0.003639006185843501, Avg. Test Loss: 0.003638436319306493\n",
      "Epoch: 1967, Avg. Train Loss: 0.0036748567715200573, Avg. Test Loss: 0.0035915051121264696\n",
      "Epoch: 1968, Avg. Train Loss: 0.0036577371620508128, Avg. Test Loss: 0.003693870035931468\n",
      "Epoch: 1969, Avg. Train Loss: 0.0036519078028843153, Avg. Test Loss: 0.0036044141743332148\n",
      "Epoch: 1970, Avg. Train Loss: 0.0036503655002127554, Avg. Test Loss: 0.0036177809815853834\n",
      "Epoch: 1971, Avg. Train Loss: 0.0036501318898571784, Avg. Test Loss: 0.0036332206800580025\n",
      "Epoch: 1972, Avg. Train Loss: 0.0036854898113064293, Avg. Test Loss: 0.003730315249413252\n",
      "Epoch: 1973, Avg. Train Loss: 0.003644742992121813, Avg. Test Loss: 0.003654001746326685\n",
      "Epoch: 1974, Avg. Train Loss: 0.0036626419832193574, Avg. Test Loss: 0.00364421377889812\n",
      "Epoch: 1975, Avg. Train Loss: 0.003647964637250055, Avg. Test Loss: 0.0036235456354916096\n",
      "Epoch: 1976, Avg. Train Loss: 0.0036662367800640505, Avg. Test Loss: 0.003586838487535715\n",
      "Epoch: 1977, Avg. Train Loss: 0.0036583399660018987, Avg. Test Loss: 0.003574197646230459\n",
      "Epoch: 1978, Avg. Train Loss: 0.0036509981173155613, Avg. Test Loss: 0.0035744011402130127\n",
      "Epoch: 1979, Avg. Train Loss: 0.0036563552147167366, Avg. Test Loss: 0.0036338118370622396\n",
      "Epoch: 1980, Avg. Train Loss: 0.003657681791674952, Avg. Test Loss: 0.0036110179498791695\n",
      "Epoch: 1981, Avg. Train Loss: 0.0036799407856495576, Avg. Test Loss: 0.003624299308285117\n",
      "Epoch: 1982, Avg. Train Loss: 0.0036574593734342692, Avg. Test Loss: 0.0035939926747232676\n",
      "Epoch: 1983, Avg. Train Loss: 0.0036347858651086342, Avg. Test Loss: 0.0035672783851623535\n",
      "Epoch: 1984, Avg. Train Loss: 0.0036264856800783513, Avg. Test Loss: 0.003599114716053009\n",
      "Epoch: 1985, Avg. Train Loss: 0.003642926387878698, Avg. Test Loss: 0.00358593906275928\n",
      "Epoch: 1986, Avg. Train Loss: 0.003655793610960245, Avg. Test Loss: 0.0035968220327049494\n",
      "Epoch: 1987, Avg. Train Loss: 0.0036426650598471943, Avg. Test Loss: 0.003564171027392149\n",
      "Epoch: 1988, Avg. Train Loss: 0.0036293262085162624, Avg. Test Loss: 0.00356203131377697\n",
      "Epoch: 1989, Avg. Train Loss: 0.0036483299918472767, Avg. Test Loss: 0.0037065651267766953\n",
      "Epoch: 1990, Avg. Train Loss: 0.0036415317810552066, Avg. Test Loss: 0.003601575968787074\n",
      "Epoch: 1991, Avg. Train Loss: 0.0036574676578734503, Avg. Test Loss: 0.003680581459775567\n",
      "Epoch: 1992, Avg. Train Loss: 0.0036455953851082298, Avg. Test Loss: 0.0036108095664530993\n",
      "Epoch: 1993, Avg. Train Loss: 0.003648316698841924, Avg. Test Loss: 0.0036287177354097366\n",
      "Epoch: 1994, Avg. Train Loss: 0.0036425813653528, Avg. Test Loss: 0.003606594866141677\n",
      "Epoch: 1995, Avg. Train Loss: 0.003687220945044659, Avg. Test Loss: 0.0036064840387552977\n",
      "Epoch: 1996, Avg. Train Loss: 0.003654955610156406, Avg. Test Loss: 0.0036561009474098682\n",
      "Epoch: 1997, Avg. Train Loss: 0.0036421193318918, Avg. Test Loss: 0.0036179234739392996\n",
      "Epoch: 1998, Avg. Train Loss: 0.003661125687189227, Avg. Test Loss: 0.003591150278225541\n",
      "Epoch: 1999, Avg. Train Loss: 0.0036229410122127033, Avg. Test Loss: 0.0036081101279705763\n",
      "Epoch: 2000, Avg. Train Loss: 0.003632019745012702, Avg. Test Loss: 0.0035516938660293818\n",
      "Epoch: 2001, Avg. Train Loss: 0.0036337819426905276, Avg. Test Loss: 0.0036781008820980787\n",
      "Epoch: 2002, Avg. Train Loss: 0.0036310122435002827, Avg. Test Loss: 0.0035697913262993097\n",
      "Epoch: 2003, Avg. Train Loss: 0.0036200367531544248, Avg. Test Loss: 0.0035578126553446054\n",
      "Epoch: 2004, Avg. Train Loss: 0.0036223180873622726, Avg. Test Loss: 0.00357389566488564\n",
      "Epoch: 2005, Avg. Train Loss: 0.0036323816558822644, Avg. Test Loss: 0.0035947225987911224\n",
      "Epoch: 2006, Avg. Train Loss: 0.00362760707367818, Avg. Test Loss: 0.003595424350351095\n",
      "Epoch: 2007, Avg. Train Loss: 0.0036185383092785296, Avg. Test Loss: 0.003558974014595151\n",
      "Epoch: 2008, Avg. Train Loss: 0.0036249651281206412, Avg. Test Loss: 0.0035608531907200813\n",
      "Epoch: 2009, Avg. Train Loss: 0.003620348415922287, Avg. Test Loss: 0.0035800884943455458\n",
      "Epoch: 2010, Avg. Train Loss: 0.0036396682695593943, Avg. Test Loss: 0.003557386575266719\n",
      "Epoch: 2011, Avg. Train Loss: 0.0036153029704596414, Avg. Test Loss: 0.0036091438960283995\n",
      "Epoch: 2012, Avg. Train Loss: 0.0036772817893083705, Avg. Test Loss: 0.0035832771100103855\n",
      "Epoch: 2013, Avg. Train Loss: 0.0036211472253726666, Avg. Test Loss: 0.0035465210676193237\n",
      "Epoch: 2014, Avg. Train Loss: 0.003640236858235196, Avg. Test Loss: 0.003607477992773056\n",
      "Epoch: 2015, Avg. Train Loss: 0.0036760655090992533, Avg. Test Loss: 0.003582755336537957\n",
      "Epoch: 2016, Avg. Train Loss: 0.0036347566746435193, Avg. Test Loss: 0.0035848882980644703\n",
      "Epoch: 2017, Avg. Train Loss: 0.0036255098489481347, Avg. Test Loss: 0.003554281312972307\n",
      "Epoch: 2018, Avg. Train Loss: 0.003606065457990003, Avg. Test Loss: 0.003549684304744005\n",
      "Epoch: 2019, Avg. Train Loss: 0.0036591667963495086, Avg. Test Loss: 0.0036046879831701517\n",
      "Epoch: 2020, Avg. Train Loss: 0.0036247813489374728, Avg. Test Loss: 0.003597208531573415\n",
      "Epoch: 2021, Avg. Train Loss: 0.003616029710703811, Avg. Test Loss: 0.003562566125765443\n",
      "Epoch: 2022, Avg. Train Loss: 0.003613038746596769, Avg. Test Loss: 0.0035742048639804125\n",
      "Epoch: 2023, Avg. Train Loss: 0.0036383864014994266, Avg. Test Loss: 0.003631778061389923\n",
      "Epoch: 2024, Avg. Train Loss: 0.0036329327010397993, Avg. Test Loss: 0.0035557555966079235\n",
      "Epoch: 2025, Avg. Train Loss: 0.0036201624275553363, Avg. Test Loss: 0.0035971205215901136\n",
      "Epoch: 2026, Avg. Train Loss: 0.003611867207773896, Avg. Test Loss: 0.0035597477108240128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2027, Avg. Train Loss: 0.0036208096588420313, Avg. Test Loss: 0.003596910974010825\n",
      "Epoch: 2028, Avg. Train Loss: 0.0036164114175927502, Avg. Test Loss: 0.0036258406471461058\n",
      "Epoch: 2029, Avg. Train Loss: 0.0036232273397577364, Avg. Test Loss: 0.0035863372031599283\n",
      "Epoch: 2030, Avg. Train Loss: 0.003608898221796682, Avg. Test Loss: 0.003597106784582138\n",
      "Epoch: 2031, Avg. Train Loss: 0.0036229815734766945, Avg. Test Loss: 0.0035917661152780056\n",
      "Epoch: 2032, Avg. Train Loss: 0.0036334328754090294, Avg. Test Loss: 0.003547456581145525\n",
      "Epoch: 2033, Avg. Train Loss: 0.0035992155100630467, Avg. Test Loss: 0.0035398025065660477\n",
      "Epoch: 2034, Avg. Train Loss: 0.0036089750883970843, Avg. Test Loss: 0.003543766215443611\n",
      "Epoch: 2035, Avg. Train Loss: 0.003634900141637339, Avg. Test Loss: 0.003662398084998131\n",
      "Epoch: 2036, Avg. Train Loss: 0.0036349486137285483, Avg. Test Loss: 0.003568565007299185\n",
      "Epoch: 2037, Avg. Train Loss: 0.0036046254491909993, Avg. Test Loss: 0.0036515698302537203\n",
      "Epoch: 2038, Avg. Train Loss: 0.003632934466220958, Avg. Test Loss: 0.0035520391538739204\n",
      "Epoch: 2039, Avg. Train Loss: 0.0036026163048349146, Avg. Test Loss: 0.003569030901417136\n",
      "Epoch: 2040, Avg. Train Loss: 0.0036184780386298203, Avg. Test Loss: 0.003546786028891802\n",
      "Epoch: 2041, Avg. Train Loss: 0.003627749511885435, Avg. Test Loss: 0.0036323692183941603\n",
      "Epoch: 2042, Avg. Train Loss: 0.003612535236793202, Avg. Test Loss: 0.0035371205303817987\n",
      "Epoch: 2043, Avg. Train Loss: 0.003610077151638824, Avg. Test Loss: 0.003559529548510909\n",
      "Epoch: 2044, Avg. Train Loss: 0.003602433976782269, Avg. Test Loss: 0.0036476547829806805\n",
      "Epoch: 2045, Avg. Train Loss: 0.0036139522170171487, Avg. Test Loss: 0.0035517055075615644\n",
      "Epoch: 2046, Avg. Train Loss: 0.003596935372496414, Avg. Test Loss: 0.003567465115338564\n",
      "Epoch: 2047, Avg. Train Loss: 0.003601299517593065, Avg. Test Loss: 0.0035551071632653475\n",
      "Epoch: 2048, Avg. Train Loss: 0.003607413179219462, Avg. Test Loss: 0.0035919155925512314\n",
      "Epoch: 2049, Avg. Train Loss: 0.0036085562585571477, Avg. Test Loss: 0.003556590061634779\n",
      "Epoch: 2050, Avg. Train Loss: 0.0036243144422769547, Avg. Test Loss: 0.0036095203831791878\n",
      "Epoch: 2051, Avg. Train Loss: 0.0036240419600332197, Avg. Test Loss: 0.0035921817179769278\n",
      "Epoch: 2052, Avg. Train Loss: 0.00366411775588816, Avg. Test Loss: 0.00361281493678689\n",
      "Epoch: 2053, Avg. Train Loss: 0.003610916782257169, Avg. Test Loss: 0.0036051820497959852\n",
      "Epoch: 2054, Avg. Train Loss: 0.003606360048315553, Avg. Test Loss: 0.0035752104595303535\n",
      "Epoch: 2055, Avg. Train Loss: 0.0035862622641806684, Avg. Test Loss: 0.003548411652445793\n",
      "Epoch: 2056, Avg. Train Loss: 0.0035916772172894587, Avg. Test Loss: 0.0035357738379389048\n",
      "Epoch: 2057, Avg. Train Loss: 0.003598420972784245, Avg. Test Loss: 0.003597763366997242\n",
      "Epoch: 2058, Avg. Train Loss: 0.003602604127250785, Avg. Test Loss: 0.0035241825971752405\n",
      "Epoch: 2059, Avg. Train Loss: 0.00359854900797959, Avg. Test Loss: 0.0035555227659642696\n",
      "Epoch: 2060, Avg. Train Loss: 0.003615883021983643, Avg. Test Loss: 0.0035406132228672504\n",
      "Epoch: 2061, Avg. Train Loss: 0.0036286176994529576, Avg. Test Loss: 0.0037863515317440033\n",
      "Epoch: 2062, Avg. Train Loss: 0.0036190213137414565, Avg. Test Loss: 0.0035262007731944323\n",
      "Epoch: 2063, Avg. Train Loss: 0.0036036806928297113, Avg. Test Loss: 0.0036193139385432005\n",
      "Epoch: 2064, Avg. Train Loss: 0.0036137686923232884, Avg. Test Loss: 0.0035873837769031525\n",
      "Epoch: 2065, Avg. Train Loss: 0.00360399886944093, Avg. Test Loss: 0.0035331789404153824\n",
      "Epoch: 2066, Avg. Train Loss: 0.0035909947581849126, Avg. Test Loss: 0.0035265886690467596\n",
      "Epoch: 2067, Avg. Train Loss: 0.003629499277489823, Avg. Test Loss: 0.003673139726743102\n",
      "Epoch: 2068, Avg. Train Loss: 0.0036154964418951855, Avg. Test Loss: 0.003526786807924509\n",
      "Epoch: 2069, Avg. Train Loss: 0.0035996115333292375, Avg. Test Loss: 0.003538477700203657\n",
      "Epoch: 2070, Avg. Train Loss: 0.003617015651015695, Avg. Test Loss: 0.003538492601364851\n",
      "Epoch: 2071, Avg. Train Loss: 0.0036036044218425833, Avg. Test Loss: 0.0035174668300896883\n",
      "Epoch: 2072, Avg. Train Loss: 0.0036012550252814625, Avg. Test Loss: 0.003544276114553213\n",
      "Epoch: 2073, Avg. Train Loss: 0.0036039749636899592, Avg. Test Loss: 0.003545329673215747\n",
      "Epoch: 2074, Avg. Train Loss: 0.003606142579079714, Avg. Test Loss: 0.0036294693127274513\n",
      "Epoch: 2075, Avg. Train Loss: 0.0036332018640931954, Avg. Test Loss: 0.0035404865629971027\n",
      "Epoch: 2076, Avg. Train Loss: 0.003590899649574313, Avg. Test Loss: 0.0036146375350654125\n",
      "Epoch: 2077, Avg. Train Loss: 0.0036078131930945916, Avg. Test Loss: 0.0035807203967124224\n",
      "Epoch: 2078, Avg. Train Loss: 0.003618301368903282, Avg. Test Loss: 0.003631383180618286\n",
      "Epoch: 2079, Avg. Train Loss: 0.0035961646380899257, Avg. Test Loss: 0.003575256559997797\n",
      "Epoch: 2080, Avg. Train Loss: 0.0036062523993381926, Avg. Test Loss: 0.003542775521054864\n",
      "Epoch: 2081, Avg. Train Loss: 0.0036177547258693116, Avg. Test Loss: 0.0035346224904060364\n",
      "Epoch: 2082, Avg. Train Loss: 0.0035971318328276622, Avg. Test Loss: 0.0035822452045977116\n",
      "Epoch: 2083, Avg. Train Loss: 0.003603934137107328, Avg. Test Loss: 0.003579248208552599\n",
      "Epoch: 2084, Avg. Train Loss: 0.0035830579134960507, Avg. Test Loss: 0.003544811625033617\n",
      "Epoch: 2085, Avg. Train Loss: 0.0035767875135291455, Avg. Test Loss: 0.0035643654409796\n",
      "Epoch: 2086, Avg. Train Loss: 0.0035973295168734566, Avg. Test Loss: 0.003737062681466341\n",
      "Epoch: 2087, Avg. Train Loss: 0.003617797398853094, Avg. Test Loss: 0.003548156935721636\n",
      "Epoch: 2088, Avg. Train Loss: 0.003599205065172079, Avg. Test Loss: 0.0035619500558823347\n",
      "Epoch: 2089, Avg. Train Loss: 0.003578533055693951, Avg. Test Loss: 0.003552729031071067\n",
      "Epoch: 2090, Avg. Train Loss: 0.0035787243341897116, Avg. Test Loss: 0.003583040088415146\n",
      "Epoch: 2091, Avg. Train Loss: 0.00359037495759684, Avg. Test Loss: 0.003520348109304905\n",
      "Epoch: 2092, Avg. Train Loss: 0.003582228457035367, Avg. Test Loss: 0.003516708267852664\n",
      "Epoch: 2093, Avg. Train Loss: 0.0035800863393084252, Avg. Test Loss: 0.0035223562736064196\n",
      "Epoch: 2094, Avg. Train Loss: 0.0035934082156610352, Avg. Test Loss: 0.0035551225300878286\n",
      "Epoch: 2095, Avg. Train Loss: 0.0035918216156058534, Avg. Test Loss: 0.0035601763520389795\n",
      "Epoch: 2096, Avg. Train Loss: 0.003580268337066437, Avg. Test Loss: 0.003605915466323495\n",
      "Epoch: 2097, Avg. Train Loss: 0.0036164296379442825, Avg. Test Loss: 0.0035448966082185507\n",
      "Epoch: 2098, Avg. Train Loss: 0.003585828744351517, Avg. Test Loss: 0.003564107697457075\n",
      "Epoch: 2099, Avg. Train Loss: 0.0035942941308454717, Avg. Test Loss: 0.0035338907036930323\n",
      "Epoch: 2100, Avg. Train Loss: 0.0035782855350610823, Avg. Test Loss: 0.003582865698263049\n",
      "Epoch: 2101, Avg. Train Loss: 0.0035981073174192464, Avg. Test Loss: 0.0036042334977537394\n",
      "Epoch: 2102, Avg. Train Loss: 0.0036325229191069685, Avg. Test Loss: 0.003514916403219104\n",
      "Epoch: 2103, Avg. Train Loss: 0.0035769553735938877, Avg. Test Loss: 0.0035466791596263647\n",
      "Epoch: 2104, Avg. Train Loss: 0.0035945063640991618, Avg. Test Loss: 0.0035236035473644733\n",
      "Epoch: 2105, Avg. Train Loss: 0.003566582129488504, Avg. Test Loss: 0.003520962316542864\n",
      "Epoch: 2106, Avg. Train Loss: 0.0035674218846441703, Avg. Test Loss: 0.0035098674707114697\n",
      "Epoch: 2107, Avg. Train Loss: 0.0035647579555421376, Avg. Test Loss: 0.0035664732567965984\n",
      "Epoch: 2108, Avg. Train Loss: 0.003579612442313932, Avg. Test Loss: 0.00350210047326982\n",
      "Epoch: 2109, Avg. Train Loss: 0.003577058420105036, Avg. Test Loss: 0.003584258258342743\n",
      "Epoch: 2110, Avg. Train Loss: 0.003599438101573046, Avg. Test Loss: 0.0035411687567830086\n",
      "Epoch: 2111, Avg. Train Loss: 0.0035891928980776736, Avg. Test Loss: 0.003670329926535487\n",
      "Epoch: 2112, Avg. Train Loss: 0.003607058691857166, Avg. Test Loss: 0.003577691037207842\n",
      "Epoch: 2113, Avg. Train Loss: 0.003585942798878911, Avg. Test Loss: 0.003518353682011366\n",
      "Epoch: 2114, Avg. Train Loss: 0.003618920178607453, Avg. Test Loss: 0.003516783006489277\n",
      "Epoch: 2115, Avg. Train Loss: 0.0035763742770393227, Avg. Test Loss: 0.0035141122061759233\n",
      "Epoch: 2116, Avg. Train Loss: 0.003579896901799149, Avg. Test Loss: 0.0035172486677765846\n",
      "Epoch: 2117, Avg. Train Loss: 0.0035957496743216073, Avg. Test Loss: 0.003497836645692587\n",
      "Epoch: 2118, Avg. Train Loss: 0.0035808735126412884, Avg. Test Loss: 0.00353641202673316\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2119, Avg. Train Loss: 0.0035899191239285606, Avg. Test Loss: 0.003500391962006688\n",
      "Epoch: 2120, Avg. Train Loss: 0.0035764430920311877, Avg. Test Loss: 0.0035383112262934446\n",
      "Epoch: 2121, Avg. Train Loss: 0.0035931625630879816, Avg. Test Loss: 0.0035981014370918274\n",
      "Epoch: 2122, Avg. Train Loss: 0.003588971400330233, Avg. Test Loss: 0.0035059608053416014\n",
      "Epoch: 2123, Avg. Train Loss: 0.003559887030183576, Avg. Test Loss: 0.00354561535641551\n",
      "Epoch: 2124, Avg. Train Loss: 0.003563913782018908, Avg. Test Loss: 0.0034991735592484474\n",
      "Epoch: 2125, Avg. Train Loss: 0.0035900769127142984, Avg. Test Loss: 0.0035002969671040773\n",
      "Epoch: 2126, Avg. Train Loss: 0.0035863985784005286, Avg. Test Loss: 0.00351147772744298\n",
      "Epoch: 2127, Avg. Train Loss: 0.003601881247663567, Avg. Test Loss: 0.0035440123174339533\n",
      "Epoch: 2128, Avg. Train Loss: 0.003580092214221178, Avg. Test Loss: 0.0035608436446636915\n",
      "Epoch: 2129, Avg. Train Loss: 0.0035902672436434863, Avg. Test Loss: 0.003520576748996973\n",
      "Epoch: 2130, Avg. Train Loss: 0.003581776045436083, Avg. Test Loss: 0.0035036634653806686\n",
      "Epoch: 2131, Avg. Train Loss: 0.0035659273609865544, Avg. Test Loss: 0.0035251574590802193\n",
      "Epoch: 2132, Avg. Train Loss: 0.0035667237609105056, Avg. Test Loss: 0.003590207314118743\n",
      "Epoch: 2133, Avg. Train Loss: 0.003611745296565946, Avg. Test Loss: 0.003492119489237666\n",
      "Epoch: 2134, Avg. Train Loss: 0.0035511515493136508, Avg. Test Loss: 0.003493123920634389\n",
      "Epoch: 2135, Avg. Train Loss: 0.0035805740057988917, Avg. Test Loss: 0.0035099408123642206\n",
      "Epoch: 2136, Avg. Train Loss: 0.0035723800023714472, Avg. Test Loss: 0.003613020060583949\n",
      "Epoch: 2137, Avg. Train Loss: 0.003578546132112658, Avg. Test Loss: 0.0034886167850345373\n",
      "Epoch: 2138, Avg. Train Loss: 0.003569518681615591, Avg. Test Loss: 0.0035651407670229673\n",
      "Epoch: 2139, Avg. Train Loss: 0.003575498254449908, Avg. Test Loss: 0.003515134332701564\n",
      "Epoch: 2140, Avg. Train Loss: 0.0035634293480841226, Avg. Test Loss: 0.0034933420829474926\n",
      "Epoch: 2141, Avg. Train Loss: 0.0035781360686171887, Avg. Test Loss: 0.0036230068653821945\n",
      "Epoch: 2142, Avg. Train Loss: 0.00358718880560509, Avg. Test Loss: 0.003567943349480629\n",
      "Epoch: 2143, Avg. Train Loss: 0.0035981004895252544, Avg. Test Loss: 0.0035622601862996817\n",
      "Epoch: 2144, Avg. Train Loss: 0.003581483009119713, Avg. Test Loss: 0.0034937227610498667\n",
      "Epoch: 2145, Avg. Train Loss: 0.0035614406061900217, Avg. Test Loss: 0.0035348644014447927\n",
      "Epoch: 2146, Avg. Train Loss: 0.0035603322619355694, Avg. Test Loss: 0.0035344967618584633\n",
      "Epoch: 2147, Avg. Train Loss: 0.0036072761556783387, Avg. Test Loss: 0.0035444756504148245\n",
      "Epoch: 2148, Avg. Train Loss: 0.0035605660076577996, Avg. Test Loss: 0.003543559229001403\n",
      "Epoch: 2149, Avg. Train Loss: 0.0035532822799977173, Avg. Test Loss: 0.0035494857002049685\n",
      "Epoch: 2150, Avg. Train Loss: 0.003570171148884435, Avg. Test Loss: 0.0035372425336390734\n",
      "Epoch: 2151, Avg. Train Loss: 0.003565778354789282, Avg. Test Loss: 0.003498306032270193\n",
      "Epoch: 2152, Avg. Train Loss: 0.0035645272041302783, Avg. Test Loss: 0.003621540265157819\n",
      "Epoch: 2153, Avg. Train Loss: 0.003580231159968778, Avg. Test Loss: 0.0035545865539461374\n",
      "Epoch: 2154, Avg. Train Loss: 0.0035727332822631957, Avg. Test Loss: 0.003495119046419859\n",
      "Epoch: 2155, Avg. Train Loss: 0.0035570601250456517, Avg. Test Loss: 0.0035652294754981995\n",
      "Epoch: 2156, Avg. Train Loss: 0.003558105144779696, Avg. Test Loss: 0.003590602660551667\n",
      "Epoch: 2157, Avg. Train Loss: 0.003596813044359171, Avg. Test Loss: 0.003485369961708784\n",
      "Epoch: 2158, Avg. Train Loss: 0.0035607375280368465, Avg. Test Loss: 0.003525105072185397\n",
      "Epoch: 2159, Avg. Train Loss: 0.003557126974513711, Avg. Test Loss: 0.003484489629045129\n",
      "Epoch: 2160, Avg. Train Loss: 0.0035727058136619107, Avg. Test Loss: 0.003484150394797325\n",
      "Epoch: 2161, Avg. Train Loss: 0.0035519094076440776, Avg. Test Loss: 0.0035033184103667736\n",
      "Epoch: 2162, Avg. Train Loss: 0.0036017521566083263, Avg. Test Loss: 0.0035675715189427137\n",
      "Epoch: 2163, Avg. Train Loss: 0.003556698696081375, Avg. Test Loss: 0.0035156668163836002\n",
      "Epoch: 2164, Avg. Train Loss: 0.0035554370193114112, Avg. Test Loss: 0.0035070034209638834\n",
      "Epoch: 2165, Avg. Train Loss: 0.0035512576713551615, Avg. Test Loss: 0.0035322168841958046\n",
      "Epoch: 2166, Avg. Train Loss: 0.003570315731299478, Avg. Test Loss: 0.003520750440657139\n",
      "Epoch: 2167, Avg. Train Loss: 0.003547409105352884, Avg. Test Loss: 0.0034763412550091743\n",
      "Epoch: 2168, Avg. Train Loss: 0.0035502725053405348, Avg. Test Loss: 0.0035229534842073917\n",
      "Epoch: 2169, Avg. Train Loss: 0.0035495448283591243, Avg. Test Loss: 0.00348403281532228\n",
      "Epoch: 2170, Avg. Train Loss: 0.003560229031325773, Avg. Test Loss: 0.0034946559462696314\n",
      "Epoch: 2171, Avg. Train Loss: 0.0035485479883243178, Avg. Test Loss: 0.0035262221936136484\n",
      "Epoch: 2172, Avg. Train Loss: 0.0035548654633985703, Avg. Test Loss: 0.003535754978656769\n",
      "Epoch: 2173, Avg. Train Loss: 0.0035663019800775274, Avg. Test Loss: 0.0034969558473676443\n",
      "Epoch: 2174, Avg. Train Loss: 0.0035624218953036984, Avg. Test Loss: 0.00349943689070642\n",
      "Epoch: 2175, Avg. Train Loss: 0.003544171416568895, Avg. Test Loss: 0.0034861082676798105\n",
      "Epoch: 2176, Avg. Train Loss: 0.0035635991628433384, Avg. Test Loss: 0.00351804681122303\n",
      "Epoch: 2177, Avg. Train Loss: 0.003554059988494183, Avg. Test Loss: 0.003571602050215006\n",
      "Epoch: 2178, Avg. Train Loss: 0.0035741564352065325, Avg. Test Loss: 0.0035222333390265703\n",
      "Epoch: 2179, Avg. Train Loss: 0.003548514628566282, Avg. Test Loss: 0.0034937825985252857\n",
      "Epoch: 2180, Avg. Train Loss: 0.0035683385443029017, Avg. Test Loss: 0.0035274773836135864\n",
      "Epoch: 2181, Avg. Train Loss: 0.0035425910866970934, Avg. Test Loss: 0.003497200785204768\n",
      "Epoch: 2182, Avg. Train Loss: 0.003556131136192139, Avg. Test Loss: 0.0035148304887115955\n",
      "Epoch: 2183, Avg. Train Loss: 0.0035621701133285843, Avg. Test Loss: 0.003547878237441182\n",
      "Epoch: 2184, Avg. Train Loss: 0.003564014126611657, Avg. Test Loss: 0.003547926899045706\n",
      "Epoch: 2185, Avg. Train Loss: 0.00356963969940363, Avg. Test Loss: 0.003557357471436262\n",
      "Epoch: 2186, Avg. Train Loss: 0.003577934626793099, Avg. Test Loss: 0.003510304493829608\n",
      "Epoch: 2187, Avg. Train Loss: 0.0035668617536768663, Avg. Test Loss: 0.0035508295986801386\n",
      "Epoch: 2188, Avg. Train Loss: 0.0036282001637182263, Avg. Test Loss: 0.003507699351757765\n",
      "Epoch: 2189, Avg. Train Loss: 0.003598297534640445, Avg. Test Loss: 0.0035402472130954266\n",
      "Epoch: 2190, Avg. Train Loss: 0.0035569539488574794, Avg. Test Loss: 0.0035055819898843765\n",
      "Epoch: 2191, Avg. Train Loss: 0.003553398836100864, Avg. Test Loss: 0.0035124809946864843\n",
      "Epoch: 2192, Avg. Train Loss: 0.00358199147334279, Avg. Test Loss: 0.0034907516092061996\n",
      "Epoch: 2193, Avg. Train Loss: 0.0035397349531913914, Avg. Test Loss: 0.0035113398917019367\n",
      "Epoch: 2194, Avg. Train Loss: 0.0035505932593328316, Avg. Test Loss: 0.003498992184177041\n",
      "Epoch: 2195, Avg. Train Loss: 0.003542787996445631, Avg. Test Loss: 0.0034775675740092993\n",
      "Epoch: 2196, Avg. Train Loss: 0.0035382172331040684, Avg. Test Loss: 0.003521661041304469\n",
      "Epoch: 2197, Avg. Train Loss: 0.003536446778060392, Avg. Test Loss: 0.0035002068616449833\n",
      "Epoch: 2198, Avg. Train Loss: 0.003533749565005649, Avg. Test Loss: 0.003486569272354245\n",
      "Epoch: 2199, Avg. Train Loss: 0.003526432158122229, Avg. Test Loss: 0.003463336266577244\n",
      "Epoch: 2200, Avg. Train Loss: 0.003538678920026435, Avg. Test Loss: 0.003497413592413068\n",
      "Epoch: 2201, Avg. Train Loss: 0.003550965977875992, Avg. Test Loss: 0.0035040671937167645\n",
      "Epoch: 2202, Avg. Train Loss: 0.0035512939550329087, Avg. Test Loss: 0.0035070995800197124\n",
      "Epoch: 2203, Avg. Train Loss: 0.0035420167043285315, Avg. Test Loss: 0.0035696576815098524\n",
      "Epoch: 2204, Avg. Train Loss: 0.0035505082274159025, Avg. Test Loss: 0.0035140039399266243\n",
      "Epoch: 2205, Avg. Train Loss: 0.0035573014837884625, Avg. Test Loss: 0.0035403487272560596\n",
      "Epoch: 2206, Avg. Train Loss: 0.00354743849074598, Avg. Test Loss: 0.003523177234455943\n",
      "Epoch: 2207, Avg. Train Loss: 0.003530968051013905, Avg. Test Loss: 0.0034641691017895937\n",
      "Epoch: 2208, Avg. Train Loss: 0.0035436668996374275, Avg. Test Loss: 0.003549670334905386\n",
      "Epoch: 2209, Avg. Train Loss: 0.00354689309308522, Avg. Test Loss: 0.0035200288984924555\n",
      "Epoch: 2210, Avg. Train Loss: 0.003551346932126339, Avg. Test Loss: 0.003452864708378911\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2211, Avg. Train Loss: 0.0035295306574986422, Avg. Test Loss: 0.0034769047051668167\n",
      "Epoch: 2212, Avg. Train Loss: 0.003549409532096497, Avg. Test Loss: 0.003471225965768099\n",
      "Epoch: 2213, Avg. Train Loss: 0.0035199318785047117, Avg. Test Loss: 0.003461896674707532\n",
      "Epoch: 2214, Avg. Train Loss: 0.0035425734240561724, Avg. Test Loss: 0.0034751337952911854\n",
      "Epoch: 2215, Avg. Train Loss: 0.003554057237843788, Avg. Test Loss: 0.003494434291496873\n",
      "Epoch: 2216, Avg. Train Loss: 0.0035302172967254424, Avg. Test Loss: 0.0034972033463418484\n",
      "Epoch: 2217, Avg. Train Loss: 0.003536744194841662, Avg. Test Loss: 0.003493618220090866\n",
      "Epoch: 2218, Avg. Train Loss: 0.0035250584302513404, Avg. Test Loss: 0.0034444911871105433\n",
      "Epoch: 2219, Avg. Train Loss: 0.0035224989446443183, Avg. Test Loss: 0.003446703776717186\n",
      "Epoch: 2220, Avg. Train Loss: 0.0035215338507970403, Avg. Test Loss: 0.0034733940847218037\n",
      "Epoch: 2221, Avg. Train Loss: 0.0035368415992707014, Avg. Test Loss: 0.0034517787862569094\n",
      "Epoch: 2222, Avg. Train Loss: 0.0035214041424698607, Avg. Test Loss: 0.0035846566315740347\n",
      "Epoch: 2223, Avg. Train Loss: 0.0035362324276722447, Avg. Test Loss: 0.003516022115945816\n",
      "Epoch: 2224, Avg. Train Loss: 0.0035231669574196257, Avg. Test Loss: 0.003496625227853656\n",
      "Epoch: 2225, Avg. Train Loss: 0.0035282841634525115, Avg. Test Loss: 0.0034468702506273985\n",
      "Epoch: 2226, Avg. Train Loss: 0.0035323608330949103, Avg. Test Loss: 0.0035174754448235035\n",
      "Epoch: 2227, Avg. Train Loss: 0.0035306244742038637, Avg. Test Loss: 0.0034850873053073883\n",
      "Epoch: 2228, Avg. Train Loss: 0.0035062740816799707, Avg. Test Loss: 0.003470928641036153\n",
      "Epoch: 2229, Avg. Train Loss: 0.003527932524204601, Avg. Test Loss: 0.0034843755420297384\n",
      "Epoch: 2230, Avg. Train Loss: 0.0035264446497569944, Avg. Test Loss: 0.003502131439745426\n",
      "Epoch: 2231, Avg. Train Loss: 0.0035297699045216623, Avg. Test Loss: 0.0034902540501207113\n",
      "Epoch: 2232, Avg. Train Loss: 0.003531845448928517, Avg. Test Loss: 0.003479250241070986\n",
      "Epoch: 2233, Avg. Train Loss: 0.0035304337425893823, Avg. Test Loss: 0.00349182216450572\n",
      "Epoch: 2234, Avg. Train Loss: 0.0035348420280443375, Avg. Test Loss: 0.0034669723827391863\n",
      "Epoch: 2235, Avg. Train Loss: 0.003539320915330981, Avg. Test Loss: 0.003486789995804429\n",
      "Epoch: 2236, Avg. Train Loss: 0.003526735769281554, Avg. Test Loss: 0.00344499247148633\n",
      "Epoch: 2237, Avg. Train Loss: 0.0035283943627376197, Avg. Test Loss: 0.003454802092164755\n",
      "Epoch: 2238, Avg. Train Loss: 0.003527505962221428, Avg. Test Loss: 0.003451899392530322\n",
      "Epoch: 2239, Avg. Train Loss: 0.0035166098238077273, Avg. Test Loss: 0.0035562091507017612\n",
      "Epoch: 2240, Avg. Train Loss: 0.0035108906314383413, Avg. Test Loss: 0.0034421770833432674\n",
      "Epoch: 2241, Avg. Train Loss: 0.0035287661066408767, Avg. Test Loss: 0.003456690814346075\n",
      "Epoch: 2242, Avg. Train Loss: 0.003516298675433148, Avg. Test Loss: 0.003616283880546689\n",
      "Epoch: 2243, Avg. Train Loss: 0.0035454462509775576, Avg. Test Loss: 0.0034632307942956686\n",
      "Epoch: 2244, Avg. Train Loss: 0.0035118451883453267, Avg. Test Loss: 0.0034441943280398846\n",
      "Epoch: 2245, Avg. Train Loss: 0.003515032786052934, Avg. Test Loss: 0.003453213954344392\n",
      "Epoch: 2246, Avg. Train Loss: 0.0035065944187429757, Avg. Test Loss: 0.0034844395704567432\n",
      "Epoch: 2247, Avg. Train Loss: 0.003519392723954001, Avg. Test Loss: 0.0035339167807251215\n",
      "Epoch: 2248, Avg. Train Loss: 0.0035137193721480843, Avg. Test Loss: 0.0034453689586371183\n",
      "Epoch: 2249, Avg. Train Loss: 0.0035023808717554394, Avg. Test Loss: 0.00354025443084538\n",
      "Epoch: 2250, Avg. Train Loss: 0.0035116066560582364, Avg. Test Loss: 0.003472042502835393\n",
      "Epoch: 2251, Avg. Train Loss: 0.0035106472205370665, Avg. Test Loss: 0.0034641604870557785\n",
      "Epoch: 2252, Avg. Train Loss: 0.0035073911435468948, Avg. Test Loss: 0.0034976424649357796\n",
      "Epoch: 2253, Avg. Train Loss: 0.0035258175989309718, Avg. Test Loss: 0.003435703692957759\n",
      "Epoch: 2254, Avg. Train Loss: 0.0035155236471964176, Avg. Test Loss: 0.0034219680819660425\n",
      "Epoch: 2255, Avg. Train Loss: 0.0035162597439836623, Avg. Test Loss: 0.0035136104561388493\n",
      "Epoch: 2256, Avg. Train Loss: 0.003520913524986353, Avg. Test Loss: 0.0034293641801923513\n",
      "Epoch: 2257, Avg. Train Loss: 0.003496260663797689, Avg. Test Loss: 0.0034937437158077955\n",
      "Epoch: 2258, Avg. Train Loss: 0.0035180091738787503, Avg. Test Loss: 0.003476725658401847\n",
      "Epoch: 2259, Avg. Train Loss: 0.0035145843325745923, Avg. Test Loss: 0.00346250063739717\n",
      "Epoch: 2260, Avg. Train Loss: 0.0034980251572939544, Avg. Test Loss: 0.003444921923801303\n",
      "Epoch: 2261, Avg. Train Loss: 0.0035137968506057595, Avg. Test Loss: 0.003438592189922929\n",
      "Epoch: 2262, Avg. Train Loss: 0.0035030522253797496, Avg. Test Loss: 0.0034642815589904785\n",
      "Epoch: 2263, Avg. Train Loss: 0.0034924916554848816, Avg. Test Loss: 0.0034420909360051155\n",
      "Epoch: 2264, Avg. Train Loss: 0.0035251735189799653, Avg. Test Loss: 0.003440259490162134\n",
      "Epoch: 2265, Avg. Train Loss: 0.0035154744278812823, Avg. Test Loss: 0.003515907097607851\n",
      "Epoch: 2266, Avg. Train Loss: 0.0035444619296508472, Avg. Test Loss: 0.0035071144811809063\n",
      "Epoch: 2267, Avg. Train Loss: 0.0035606971617008366, Avg. Test Loss: 0.003451670752838254\n",
      "Epoch: 2268, Avg. Train Loss: 0.0035140305800839913, Avg. Test Loss: 0.003486680332571268\n",
      "Epoch: 2269, Avg. Train Loss: 0.0035077087028861738, Avg. Test Loss: 0.003427851712331176\n",
      "Epoch: 2270, Avg. Train Loss: 0.003532949461450064, Avg. Test Loss: 0.003442562883719802\n",
      "Epoch: 2271, Avg. Train Loss: 0.0034976700039277245, Avg. Test Loss: 0.00346756586804986\n",
      "Epoch: 2272, Avg. Train Loss: 0.0035322828456586185, Avg. Test Loss: 0.0035635463427752256\n",
      "Epoch: 2273, Avg. Train Loss: 0.0035197667582610318, Avg. Test Loss: 0.003441569162532687\n",
      "Epoch: 2274, Avg. Train Loss: 0.0035098894488412974, Avg. Test Loss: 0.0034266675356775522\n",
      "Epoch: 2275, Avg. Train Loss: 0.0035047010995101096, Avg. Test Loss: 0.003481232328340411\n",
      "Epoch: 2276, Avg. Train Loss: 0.003508573955704653, Avg. Test Loss: 0.003444488625973463\n",
      "Epoch: 2277, Avg. Train Loss: 0.003495006009849698, Avg. Test Loss: 0.003430053126066923\n",
      "Epoch: 2278, Avg. Train Loss: 0.0034977985914190148, Avg. Test Loss: 0.003525008214637637\n",
      "Epoch: 2279, Avg. Train Loss: 0.003498746087601365, Avg. Test Loss: 0.003445468610152602\n",
      "Epoch: 2280, Avg. Train Loss: 0.003509668817440438, Avg. Test Loss: 0.003455141792073846\n",
      "Epoch: 2281, Avg. Train Loss: 0.0035032609336857878, Avg. Test Loss: 0.003444591537117958\n",
      "Epoch: 2282, Avg. Train Loss: 0.0035261505034340675, Avg. Test Loss: 0.003449904965236783\n",
      "Epoch: 2283, Avg. Train Loss: 0.003515324062602811, Avg. Test Loss: 0.0034117307513952255\n",
      "Epoch: 2284, Avg. Train Loss: 0.003490505117359896, Avg. Test Loss: 0.003455383237451315\n",
      "Epoch: 2285, Avg. Train Loss: 0.0034866855252360883, Avg. Test Loss: 0.0034069870598614216\n",
      "Epoch: 2286, Avg. Train Loss: 0.0034986776732947936, Avg. Test Loss: 0.003460399806499481\n",
      "Epoch: 2287, Avg. Train Loss: 0.0034919001356980136, Avg. Test Loss: 0.0034079269971698523\n",
      "Epoch: 2288, Avg. Train Loss: 0.003512009620926408, Avg. Test Loss: 0.0034938643220812082\n",
      "Epoch: 2289, Avg. Train Loss: 0.0035021410453631436, Avg. Test Loss: 0.003453428391367197\n",
      "Epoch: 2290, Avg. Train Loss: 0.003504504633764195, Avg. Test Loss: 0.003415877465158701\n",
      "Epoch: 2291, Avg. Train Loss: 0.0034788589123203313, Avg. Test Loss: 0.003454450285062194\n",
      "Epoch: 2292, Avg. Train Loss: 0.0034891413416453573, Avg. Test Loss: 0.003429953707382083\n",
      "Epoch: 2293, Avg. Train Loss: 0.00349531396357126, Avg. Test Loss: 0.0034224551636725664\n",
      "Epoch: 2294, Avg. Train Loss: 0.0034845784024963547, Avg. Test Loss: 0.0034102550707757473\n",
      "Epoch: 2295, Avg. Train Loss: 0.003479601100606974, Avg. Test Loss: 0.0034377207048237324\n",
      "Epoch: 2296, Avg. Train Loss: 0.003511456068778454, Avg. Test Loss: 0.003515851218253374\n",
      "Epoch: 2297, Avg. Train Loss: 0.003515694279570219, Avg. Test Loss: 0.003415796672925353\n",
      "Epoch: 2298, Avg. Train Loss: 0.003499721279800978, Avg. Test Loss: 0.0034197254572063684\n",
      "Epoch: 2299, Avg. Train Loss: 0.0034942701783810936, Avg. Test Loss: 0.0034839443396776915\n",
      "Epoch: 2300, Avg. Train Loss: 0.0034878894979090886, Avg. Test Loss: 0.0034337507095187902\n",
      "Epoch: 2301, Avg. Train Loss: 0.003494504021567314, Avg. Test Loss: 0.0034467217046767473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2302, Avg. Train Loss: 0.003516455424602988, Avg. Test Loss: 0.0034716923255473375\n",
      "Epoch: 2303, Avg. Train Loss: 0.0034799896841219, Avg. Test Loss: 0.0034083889331668615\n",
      "Epoch: 2304, Avg. Train Loss: 0.0034787748387993074, Avg. Test Loss: 0.003403801005333662\n",
      "Epoch: 2305, Avg. Train Loss: 0.0034931758851852526, Avg. Test Loss: 0.0034250004682689905\n",
      "Epoch: 2306, Avg. Train Loss: 0.00348738691401343, Avg. Test Loss: 0.0034475165884941816\n",
      "Epoch: 2307, Avg. Train Loss: 0.0034749560101434243, Avg. Test Loss: 0.003496526973322034\n",
      "Epoch: 2308, Avg. Train Loss: 0.0035012687101613643, Avg. Test Loss: 0.003436030587181449\n",
      "Epoch: 2309, Avg. Train Loss: 0.003488335168249039, Avg. Test Loss: 0.003499302314594388\n",
      "Epoch: 2310, Avg. Train Loss: 0.0035079423078270846, Avg. Test Loss: 0.0034604938700795174\n",
      "Epoch: 2311, Avg. Train Loss: 0.0034789298390319875, Avg. Test Loss: 0.0034101868513971567\n",
      "Epoch: 2312, Avg. Train Loss: 0.003473938881354623, Avg. Test Loss: 0.003412853926420212\n",
      "Epoch: 2313, Avg. Train Loss: 0.0034958860555360485, Avg. Test Loss: 0.0034479014575481415\n",
      "Epoch: 2314, Avg. Train Loss: 0.003476573300526239, Avg. Test Loss: 0.00346534070558846\n",
      "Epoch: 2315, Avg. Train Loss: 0.0034980835057361877, Avg. Test Loss: 0.0034370464272797108\n",
      "Epoch: 2316, Avg. Train Loss: 0.0035166519715688948, Avg. Test Loss: 0.0034430043306201696\n",
      "Epoch: 2317, Avg. Train Loss: 0.0034967761454280724, Avg. Test Loss: 0.0035486039705574512\n",
      "Epoch: 2318, Avg. Train Loss: 0.0035262867526779343, Avg. Test Loss: 0.0034253133926540613\n",
      "Epoch: 2319, Avg. Train Loss: 0.0034849349041144516, Avg. Test Loss: 0.003449897514656186\n",
      "Epoch: 2320, Avg. Train Loss: 0.0034879391124948513, Avg. Test Loss: 0.003392120823264122\n",
      "Epoch: 2321, Avg. Train Loss: 0.0034789178455465063, Avg. Test Loss: 0.0034048794768750668\n",
      "Epoch: 2322, Avg. Train Loss: 0.003488831741865291, Avg. Test Loss: 0.003387071890756488\n",
      "Epoch: 2323, Avg. Train Loss: 0.003479922439383213, Avg. Test Loss: 0.003403258044272661\n",
      "Epoch: 2324, Avg. Train Loss: 0.0034745685095617243, Avg. Test Loss: 0.003430632408708334\n",
      "Epoch: 2325, Avg. Train Loss: 0.003493579137030729, Avg. Test Loss: 0.0034416227135807276\n",
      "Epoch: 2326, Avg. Train Loss: 0.003498215174172507, Avg. Test Loss: 0.0034019690938293934\n",
      "Epoch: 2327, Avg. Train Loss: 0.0034618699587448394, Avg. Test Loss: 0.0033925711177289486\n",
      "Epoch: 2328, Avg. Train Loss: 0.003468968894679186, Avg. Test Loss: 0.00340006360784173\n",
      "Epoch: 2329, Avg. Train Loss: 0.003527557758917642, Avg. Test Loss: 0.003449796000495553\n",
      "Epoch: 2330, Avg. Train Loss: 0.003499890905046879, Avg. Test Loss: 0.003419385524466634\n",
      "Epoch: 2331, Avg. Train Loss: 0.003463106316535972, Avg. Test Loss: 0.003420084249228239\n",
      "Epoch: 2332, Avg. Train Loss: 0.003470540777671822, Avg. Test Loss: 0.003415792714804411\n",
      "Epoch: 2333, Avg. Train Loss: 0.003470505474048645, Avg. Test Loss: 0.003395207691937685\n",
      "Epoch: 2334, Avg. Train Loss: 0.0034825463378585354, Avg. Test Loss: 0.003434071084484458\n",
      "Epoch: 2335, Avg. Train Loss: 0.003509402334646777, Avg. Test Loss: 0.0034017327707260847\n",
      "Epoch: 2336, Avg. Train Loss: 0.003472086897683005, Avg. Test Loss: 0.003386693075299263\n",
      "Epoch: 2337, Avg. Train Loss: 0.003474844522167777, Avg. Test Loss: 0.003431239165365696\n",
      "Epoch: 2338, Avg. Train Loss: 0.0034838515052268673, Avg. Test Loss: 0.003398857545107603\n",
      "Epoch: 2339, Avg. Train Loss: 0.0034701529846981514, Avg. Test Loss: 0.0034341253340244293\n",
      "Epoch: 2340, Avg. Train Loss: 0.0035060407095697035, Avg. Test Loss: 0.003406389383599162\n",
      "Epoch: 2341, Avg. Train Loss: 0.0034720995734164187, Avg. Test Loss: 0.0033820844255387783\n",
      "Epoch: 2342, Avg. Train Loss: 0.0034889208726844815, Avg. Test Loss: 0.0033881121780723333\n",
      "Epoch: 2343, Avg. Train Loss: 0.0034673819751587023, Avg. Test Loss: 0.0034033122938126326\n",
      "Epoch: 2344, Avg. Train Loss: 0.0034668273563215205, Avg. Test Loss: 0.003391021629795432\n",
      "Epoch: 2345, Avg. Train Loss: 0.003481216208879338, Avg. Test Loss: 0.003427602583542466\n",
      "Epoch: 2346, Avg. Train Loss: 0.003467799732894745, Avg. Test Loss: 0.003491218900308013\n",
      "Epoch: 2347, Avg. Train Loss: 0.0034691367764025927, Avg. Test Loss: 0.003373872023075819\n",
      "Epoch: 2348, Avg. Train Loss: 0.003462614210019278, Avg. Test Loss: 0.0033949874341487885\n",
      "Epoch: 2349, Avg. Train Loss: 0.0034800682617568, Avg. Test Loss: 0.0034051144029945135\n",
      "Epoch: 2350, Avg. Train Loss: 0.0034662839458432307, Avg. Test Loss: 0.003384309820830822\n",
      "Epoch: 2351, Avg. Train Loss: 0.0034823792629203824, Avg. Test Loss: 0.0034458336886018515\n",
      "Epoch: 2352, Avg. Train Loss: 0.003469121144261471, Avg. Test Loss: 0.0034631011076271534\n",
      "Epoch: 2353, Avg. Train Loss: 0.0035014839323107587, Avg. Test Loss: 0.0034353004302829504\n",
      "Epoch: 2354, Avg. Train Loss: 0.0034806275588655194, Avg. Test Loss: 0.003426850074902177\n",
      "Epoch: 2355, Avg. Train Loss: 0.0034836057497751576, Avg. Test Loss: 0.003390669357031584\n",
      "Epoch: 2356, Avg. Train Loss: 0.003474738188954287, Avg. Test Loss: 0.003478837665170431\n",
      "Epoch: 2357, Avg. Train Loss: 0.0034747555158859077, Avg. Test Loss: 0.0034446946810930967\n",
      "Epoch: 2358, Avg. Train Loss: 0.003486154124487278, Avg. Test Loss: 0.003396526910364628\n",
      "Epoch: 2359, Avg. Train Loss: 0.0034608273864398863, Avg. Test Loss: 0.003408826654776931\n",
      "Epoch: 2360, Avg. Train Loss: 0.0034765363075272286, Avg. Test Loss: 0.0034484437201172113\n",
      "Epoch: 2361, Avg. Train Loss: 0.003467902508672587, Avg. Test Loss: 0.0034514006692916155\n",
      "Epoch: 2362, Avg. Train Loss: 0.0034622689221747395, Avg. Test Loss: 0.0034356883261352777\n",
      "Epoch: 2363, Avg. Train Loss: 0.003484574628474061, Avg. Test Loss: 0.0034121123608201742\n",
      "Epoch: 2364, Avg. Train Loss: 0.0034944700282933407, Avg. Test Loss: 0.003585632424801588\n",
      "Epoch: 2365, Avg. Train Loss: 0.0034929191921079573, Avg. Test Loss: 0.0033737446647137403\n",
      "Epoch: 2366, Avg. Train Loss: 0.0034627089179445837, Avg. Test Loss: 0.003421603702008724\n",
      "Epoch: 2367, Avg. Train Loss: 0.0035078332618658625, Avg. Test Loss: 0.0033817957155406475\n",
      "Epoch: 2368, Avg. Train Loss: 0.0034833799148801456, Avg. Test Loss: 0.0034042634069919586\n",
      "Epoch: 2369, Avg. Train Loss: 0.003478717735730285, Avg. Test Loss: 0.003475295612588525\n",
      "Epoch: 2370, Avg. Train Loss: 0.0034617157598827468, Avg. Test Loss: 0.0034041693434119225\n",
      "Epoch: 2371, Avg. Train Loss: 0.0034853979609473502, Avg. Test Loss: 0.003503878600895405\n",
      "Epoch: 2372, Avg. Train Loss: 0.0034547096583992243, Avg. Test Loss: 0.0033857212401926517\n",
      "Epoch: 2373, Avg. Train Loss: 0.0034631095220183216, Avg. Test Loss: 0.0033900528214871883\n",
      "Epoch: 2374, Avg. Train Loss: 0.0034488421204218337, Avg. Test Loss: 0.0034633376635611057\n",
      "Epoch: 2375, Avg. Train Loss: 0.0034764655053528934, Avg. Test Loss: 0.00339705403894186\n",
      "Epoch: 2376, Avg. Train Loss: 0.0034537219420768496, Avg. Test Loss: 0.003466085996478796\n",
      "Epoch: 2377, Avg. Train Loss: 0.0034617479121702354, Avg. Test Loss: 0.0033665718510746956\n",
      "Epoch: 2378, Avg. Train Loss: 0.0034581660184749338, Avg. Test Loss: 0.003372345119714737\n",
      "Epoch: 2379, Avg. Train Loss: 0.0034526807288530956, Avg. Test Loss: 0.0034715193323791027\n",
      "Epoch: 2380, Avg. Train Loss: 0.0034654156229090554, Avg. Test Loss: 0.00336767197586596\n",
      "Epoch: 2381, Avg. Train Loss: 0.0034651092340260052, Avg. Test Loss: 0.0033816916402429342\n",
      "Epoch: 2382, Avg. Train Loss: 0.003467091137196782, Avg. Test Loss: 0.003384173149242997\n",
      "Epoch: 2383, Avg. Train Loss: 0.0034625655213414235, Avg. Test Loss: 0.003446744754910469\n",
      "Epoch: 2384, Avg. Train Loss: 0.0034600962440721516, Avg. Test Loss: 0.003379212226718664\n",
      "Epoch: 2385, Avg. Train Loss: 0.003447371118073893, Avg. Test Loss: 0.0033930630888789892\n",
      "Epoch: 2386, Avg. Train Loss: 0.0034582664876050035, Avg. Test Loss: 0.003382206428796053\n",
      "Epoch: 2387, Avg. Train Loss: 0.0034524933543316153, Avg. Test Loss: 0.0033688233233988285\n",
      "Epoch: 2388, Avg. Train Loss: 0.003464799206487315, Avg. Test Loss: 0.003365774406120181\n",
      "Epoch: 2389, Avg. Train Loss: 0.0034436716286595477, Avg. Test Loss: 0.0033644535578787327\n",
      "Epoch: 2390, Avg. Train Loss: 0.0034574412275105715, Avg. Test Loss: 0.0033562900498509407\n",
      "Epoch: 2391, Avg. Train Loss: 0.003451192453720195, Avg. Test Loss: 0.003436977043747902\n",
      "Epoch: 2392, Avg. Train Loss: 0.003451694382441252, Avg. Test Loss: 0.00341735384427011\n",
      "Epoch: 2393, Avg. Train Loss: 0.0034632831811904907, Avg. Test Loss: 0.003435696242377162\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2394, Avg. Train Loss: 0.0034800738875949105, Avg. Test Loss: 0.003396894782781601\n",
      "Epoch: 2395, Avg. Train Loss: 0.0034370277954135523, Avg. Test Loss: 0.0033506816253066063\n",
      "Epoch: 2396, Avg. Train Loss: 0.0034423081182636496, Avg. Test Loss: 0.0033861214760690928\n",
      "Epoch: 2397, Avg. Train Loss: 0.0034455127992429014, Avg. Test Loss: 0.0033890921622514725\n",
      "Epoch: 2398, Avg. Train Loss: 0.0034508393741710937, Avg. Test Loss: 0.0033723304513841867\n",
      "Epoch: 2399, Avg. Train Loss: 0.003458044177657643, Avg. Test Loss: 0.0033789165318012238\n",
      "Epoch: 2400, Avg. Train Loss: 0.00346693423641629, Avg. Test Loss: 0.0033804597333073616\n",
      "Finished Training\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2af300cf6828>"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAD8CAYAAABzTgP2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4xLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvDW2N/gAAHm1JREFUeJzt3Xt0VPW99/H3dyYTEiAkEMAoodwVA2iMAeyReqHUSz08tlUfFZUutWV1tdrT4+Kp1LpOq55Trc86tvWyHostbRUrteXQQlul1VasWrkpVyMGFCTINUgIl1xm5vf8MZNIMGD2nklmsvN5reXKZGdm5/vLGD75XfZvm3MOERGRFqFMFyAiItlFwSAiIm0oGEREpA0Fg4iItKFgEBGRNhQMIiLShoJBRETaUDCIiEgbCgYREWkjJ9MFnMzAgQPd8OHDM12GiEi3sXr16n3OuUGpnCMrg8HMpgPTR48ezapVqzJdjohIt2Fm21I9R1YOJTnnljjnZhUWFma6FBGRHicrg0FERDJHwSAiIm1k/RyDiGSX5uZmampqaGhoyHQpPVpeXh6lpaVEIpG0n9uy+X4MlZWVTpPPItnlvffeo6CggOLiYsws0+X0SM45amtrqa+vZ8SIEW2+ZmarnXOVqZxfQ0ki4klDQ4NCIcPMjOLi4k7rtSkYRMQzhULmdeZ7EMhg+MWr77Fk7QeZLkNEpFvKymAws+lmNreurs7X6+e/vo3nN+xKc1Uikg1qa2spLy+nvLyckpIShgwZ0vp5U1NTh85x8803s2nTppM+57HHHuPpp59OR8lMmTKFNWvWpOVcXSErVyU555YASyorK7/q5/VTo6/S+9BgoCK9hYlIxhUXF7f+I/v973+fvn37Mnv27DbPcc7hnCMUav9v31/84hef+H2+8Y1vpF5sN5WVPYZUzWz8NVMO/jHTZYhIF9q8eTNlZWXccMMNjBs3jp07dzJr1iwqKysZN24c9957b+tzW/6Cj0ajFBUVMWfOHM4++2w+/elPs2fPHgDuvvtufvzjH7c+f86cOUyaNIkzzjiD1157DYDDhw9z1VVXUVZWxtVXX01lZeUn9gzmz5/PhAkTGD9+PHfddRcA0WiUm266qfX4ww8/DMCPfvQjysrKOOuss7jxxhvT/jM7kazsMaTMwLl4pqsQCbx7lmzkrQ8OpvWcZaf143vTx/l67dtvv82TTz5JZWViteYDDzzAgAEDiEajXHzxxVx99dWUlZW1eU1dXR0XXnghDzzwAHfccQfz5s1jzpw5Hzu3c44VK1awePFi7r33Xp5//nkeeeQRSkpKWLhwIWvXrqWi4uSjFDU1Ndx9992sWrWKwsJCpk2bxh//+EcGDRrEvn37WL9+PQAHDhwA4MEHH2Tbtm3k5ua2HusKgewxJJMh00WISBcbNWpUaygAPPPMM1RUVFBRUUFVVRVvvfXWx16Tn5/P5ZdfDsC5557L1q1b2z33l770pY8955VXXuG6664D4Oyzz2bcuJMH2vLly5k6dSoDBw4kEokwY8YMXn75ZUaPHs2mTZv45je/ydKlS2nZJ27cuHHceOONPP30051yIduJBLLH4CxENl+4JxIUfv+y7yx9+vRpfVxdXc1PfvITVqxYQVFRETfeeGO76/5zc3NbH4fDYaLRaLvn7tWr1yc+x6/i4mLWrVvHc889x2OPPcbChQuZO3cuS5cuZdmyZSxevJgf/OAHrFu3jnA4nNbv3Z6s7DGkuiop0WPQUJJIT3bw4EEKCgro168fO3fuZOnSpWn/Hueffz7PPvssAOvXr2+3R3KsyZMn8/e//53a2lqi0SgLFizgwgsvZO/evTjnuOaaa7j33nt54403iMVi1NTUMHXqVB588EH27dvHkSNH0t6G9mRljyHVVUmYAeoxiPRkFRUVlJWVMXbsWIYNG8b555+f9u9x++23M3PmTMrKylr/O9ntAkpLS7nvvvu46KKLcM4xffp0rrjiCt544w1uvfVWnHOYGT/84Q+JRqPMmDGD+vp64vE4s2fPpqCgIO1taE8g90p6/7/O4QMbzHl3pf8vBJGerqqqijPPPDPTZWSFaDRKNBolLy+P6upqLrnkEqqrq8nJ6Zq/udt7L9KxV1JW9hhS5QBTj0FEOtmhQ4f47Gc/SzQaxTnHT3/60y4Lhc7U/VvQHguhoSQR6WxFRUWsXr0602WkXVZOPqfKYVgWD5GJiGSzrAyGdKxK0lCSiIg/WRkMzrklzrlZJ5vdP+nrEydJa00iIj1FVgZD6rRXvIiIX8EMBtNQkkhQpWPbbYB58+axa9dH2/N3ZCvujmjZmK87C+SqJIcucBMJqo5su90R8+bNo6KigpKSEqBjW3H3FIHsMTiMENoSQ6Sn+dWvfsWkSZMoLy/n61//OvF4vN0trX/zm9+wZs0arr322taeRke24q6urmby5MlMmDCB7373u5/YM4jH49xxxx2MHz+eCRMm8Lvf/Q6AHTt2MGXKFMrLyxk/fjyvvfbaCbfezoRA9hgwU4dBpCs8Nwd2rU/vOUsmwOUPeH7Zhg0bWLRoEa+99ho5OTnMmjWLBQsWMGrUqI9taV1UVMQjjzzCo48+Snl5+cfOdaKtuG+//XZmz57NNddcw6OPPvqJNf32t7+lqqqKtWvXsnfvXiZOnMgFF1zA/PnzmT59OnfeeSexWIyjR4+yevXqdrfezoTA9hiUDCI9ywsvvMDKlSuprKykvLycZcuWsWXLlhNuaX0yJ9qKe/ny5Vx11VUAzJgx4xPP88orr3D99dcTDocpKSlhypQprFq1iokTJ/Kzn/2Me+65hw0bNtC3b19fdXaWwPYYNPks0gV8/GXfWZxz3HLLLdx3330f+1p7W1qfTEe34vZr6tSpvPTSS/zpT39i5syZfPvb3+aGG27wXGdnycoeQ1q23VYwiPQo06ZN49lnn2Xfvn1AYvXS+++/3+6W1gAFBQXU19d7+h6TJk1i0aJFACxYsOATn/+Zz3yGBQsWEI/H2b17N6+++iqVlZVs27aNkpISZs2axc0338ybb755wjozISt7DKluu53YEiPNRYlIVpswYQLf+973mDZtGvF4nEgkwuOPP044HP7YltaQWJ76la98hfz8fFasWNGh7/Hwww9z0003cc8993DppZd+4nDP1Vdfzeuvv85ZZ52FmfHQQw8xePBg5s2bx0MPPUQkEqGgoICnnnqK7du3t1tnJgRy2+3qH17IkcYmzv6Pf3ZCVSI9W0/edvvw4cP07t0bM2P+/PksWrSIhQsXZqwebbvtgdMcg4h0gpUrV/Ktb32LeDxO//79A3vtQyCDQXMMItIZLrrootaL64IsKyefU6e9kkQ6UzYPQfcUnfkeBDIYnKH7MYh0kry8PGpraxUOGeSco7a2lry8vE45f0CHkkKaYxDpJKWlpdTU1LB3795Ml9Kj5eXlUVpa2innDmYwaPJZpNNEIhFGjBiR6TKkEwVzKEmTzyIivmVlMOjWniIimZOVwZDqrT0xrUsSEfErK4MhVY6Q7vksIuJTIIMBM0IaShIR8SWYwaDJZxER3wIZDE6TzyIivgUyGDD1GERE/ApmMIB6DCIiPgUzGCyk5aoiIj4FMhgScwzxTJchItItBTIYMN3aU0TEr2AGg5arioj4Fthg0OSziIg/wQwGM00+i4j4FMhgcLqOQUTEt6wMhnRsux3SqiQREV+yMhhS3nYbDSWJiPiVlcGQMg0liYj4Fsxg0KokERHfghkMWpUkIuJbIIPBEVKPQUTEp0AGQ+KezwoGERE/ghkM6jGIiPgWzGBI9hicUziIiHgVzGBIXsegXBAR8S6YwWCJoSTlgoiId8EMhuR1DBpKEhHxLpjBYIlgiCsXREQ8C3QwaDBJRMS7QAaD0+SziIhvgQyGlh6DiIh4F8hgsJZVScoGERHPAhkMQHLyWckgIuJVMIMhubuqYkFExLtgBoOuYxAR8S2YwdC6XFVERLwKZjAQ0nJVERGfuiwYzGykmf3czH7X2d/LmYaSRET86lAwmNk8M9tjZhuOO36ZmW0ys81mNudk53DOveucuzWVYjvKzAhpuaqIiC85HXzeL4FHgSdbDphZGHgM+BxQA6w0s8VAGLj/uNff4pzbk3K1HZZYk6RcEBHxrkPB4Jx72cyGH3d4ErDZOfcugJktAK50zt0P/Gs6i/RMQ0kiIr6lMscwBNh+zOc1yWPtMrNiM3scOMfMvnOS580ys1Vmtmrv3r0+S0tcx6DdVUVEvOvoUFLKnHO1wNc68Ly5wFyAyspKf/+0a3dVERHfUukx7ACGHvN5afJY5iX3SlIuiIh4l0owrATGmNkIM8sFrgMWp6esVBlhU39BRMSPji5XfQb4J3CGmdWY2a3OuShwG7AUqAKedc5tTEdRZjbdzObW1dX5PQGgC9xERPzo6Kqk609w/M/An9NaUeK8S4AllZWVX/Xz+sTUM8Tj8XSWJSLSIwRzS4yWHoMGk0REPAtoMCSa5dRjEBHxLCuDIdU5BtfSY1AwiIh4lpXB4Jxb4pybVVhY6Ov1LXMMWq8qIuJdVgZDypI9hrhTj0FExKtAB4P2xBAR8S6QwfDRQJKCQUTEq6wMhpQvcAuFAXDqMYiIeJaVwZDq5HMLzTGIiHiXlcGQsuR1DCgYREQ8C2YwtMwyaLMkERHPghkMrZvoKRhERLwKZDCYgkFExLesDIaUVyUlm6XJZxER77IyGFLeEqPlQgYtVxUR8SwrgyFVrmV3VdRjEBHxKpDB0DrHoB6DiIhngQwGtLuqiIhvgQwG0/0YRER8C2QwtN7BTctVRUQ8y8pgSHm5qq5jEBHxLSuDIeVN9FrWq+o6BhERz7IyGFLVcmvPuHoMIiKeBTIY1GMQEfEvoMHQsu22egwiIl4FMhi0iZ6IiH8KBhERaSOQwdBy5bPTHIOIiGdZGQy6jkFEJHOyMhhSv45B93wWEfErK4MhZaZ7PouI+BXIYAhpuaqIiG+BDIaWHoNu7Ski4l0wgwFNPouI+BXIYDDTjXpERPwKZDBouaqIiH+BDAZrmXzWPZ9FRDwLZDC09hiIZbgQEZHuJ5DB0DrHoB6DiIhnWRkM2hJDRCRzsjIYUt0So3WOQUREPAvov6C6wE1ExK9gBkNIeyWJiPgVyGAwtLuqiIhfwQwG7a4qIuJboIPBaUsMERHPAhkMHy1X1VCSiIhXgQwGbYkhIuJfIIMB7a4qIuJbQIMh0SwNJYmIeBfIYAi1dhjUYxAR8SqQwfBRj0HBICLiVSCDQdcxiIj4F8hgUI9BRMS/rAyGVLfdDrWuStLks4iIV1kZDKluu637MYiI+JeVwZAyzTGIiPgWyGBovfJZ1zGIiHgW0GBo6TFktg4Rke4ooMGQXJWkZBAR8SygwdDSY4hlthARkW4okMHw0aqkDNchItINBTMYQpp8FhHxK6DBEEl8iDdnuBARke4nkMEQCucmHsSjmS1ERKQbCmQwhHMSwWAx9RhERLwKZjDk9gLAxZoyXImISPcTzGCIJOYYUI9BRMSzQAZDJJIHqMcgIuJHIIMhlJxjUI9BRMS7QAYDYQ0liYj4FdBgaFmuqmAQEfEqmMEQChPHMM0xiIh4FsxgAJrJwdRjEBHxLLDBECVHVz6LiPgQ6GAIaShJRMSznK76Rmb2BeAKoB/wc+fcXzrz+0UtB3PqMYiIeNWhHoOZzTOzPWa24bjjl5nZJjPbbGZzTnYO59zvnXNfBb4GXOu/5I6JEdbuqiIiPnS0x/BL4FHgyZYDZhYGHgM+B9QAK81sMRAG7j/u9bc45/YkH9+dfF2nilpEk88iIj50KBiccy+b2fDjDk8CNjvn3gUwswXAlc65+4F/Pf4clrjf5gPAc865N070vcxsFjAL4FOf+lRHymtXzHIIafJZRMSzVCafhwDbj/m8JnnsRG4HpgFXm9nXTvQk59xc51ylc65y0KBBvouLWQ4hpx6DiIhXXTb57Jx7GHi4q75fzCKENfksIuJZKj2GHcDQYz4vTR7LCnHL0eSziIgPqQTDSmCMmY0ws1zgOmBxOooys+lmNreurs73ORJDSeoxiIh41dHlqs8A/wTOMLMaM7vVORcFbgOWAlXAs865jekoyjm3xDk3q7Cw0Pc54qEIOQoGERHPOroq6foTHP8z8Oe0VpQm8VAOEU0+i4h4FtgtMeIWIeximS5DRKTbCWwwuFCEHNRjEBHxKiuDIR2Tz/GQegwiIn5kZTCkY/JZPQYREX+yMhjSwYVyiGhVkoiIZwEOhghhNJQkIuJVYIOBcIQI6jGIiHiVlcGQjslnF44QIUY87tJYmYhI8GVlMKRj8plQosfQHNNwkoiIF1kZDGkRziVkjqZmrUwSEfEisMHQp3c+ADX7Dma4EhGR7iWwwTB48KkAbKx6K8OViIh0L1kZDOmYfB447mIA3lv5JxqaNc8gItJRWRkMaZl8Lh7N0b5D+T/RJ5j7p1fTV5yISMBlZTCkhRn5F/47AANX/4g33/8wwwWJiHQPwQ0GgIm3Eh0ymRnhvxH75XT21DdkuiIRkawX7GAAcmb8GoDK+Hru+vkSDjfqamgRkZMJfDDQZyDc+gIAPzvwFRY+Oof9h5syXJSISPYKfjAADJ0I0+4BYGb9E9x2/6Os3qY5BxGR9phz2beXkJlNB6aPHj36q9XV1ek78Yv3wj/+G4BfR6fyVPgLjDh9PLWHmhg5qA+N0TilRfmEQsZ7+w6TEwrxubLB9MsLkx/Job4xxsC+vYjFHUW9I/TLjxCPO2LOMaB3Lmat9aevZhERD8xstXOuMqVzZGMwtKisrHSrVq1K70k3vwDzr0rb6Y66XPKtiaWxSlbEz2CP608DuYSJU2p7WdP/UgYX9qZXfh8a6EX1rgNMHDmYM4tiFA4YRF4kzPb9R9hZ18B5I4sp7ptLSb88TumXR8gg7iAcUtCISMcoGPxqrIeHK+DwnvSf24N6l0+BHT3h1/e7vgywQ+ykmJdC51HVOJBw38GEokfZOWAiY3Jr2TOgkv55YXZ/eIAdO7Zz+ikFNLkQFeMn8NbOg4w7tQ8DcpoYOXQIR5tiDB/Ym/xIGOcgFDKONsXIzw13YatFpDMpGDqDcxCPQqwJLAwNdRAKw8EPwMUBB0dq4ch+aDoEh/bCgfcTx2PN8O5LcPRDiLezeV+vQmj0fzV3OsSccZh8VsVPZz/9qIoP5Yrwcra6EuZHp3FxeA01Q6ezfp+jd14eMYvQK3qQLfubKC75FAeONPPZMwYw9rT+rHh7K2P6h/jShZUcboxxqLGZ0wrz6MNRXLSR3rtWEj/9Mnrl9vp4Ibs3woCREMnv+h+CSIApGIIgFoXGg4kgqquBUA7sWge7NoCF4J3n4cP3oOA0qP8g09X69qqdQ7mrIupCvBCv4KrwKwAcdr1YHj+TM3rtp8pGsa8xh//rZnDtpBE0vP0C/3H4P9nIaP4w/C7u2noLLwycyXN5l7P5oHFWvwYKh5ZRPrSIbfuPMOboGkZvXcDfx9/P8LzD5O2vYvjYCvqVjOTdvYcZ0j+fuHPs2H+YsbuW4MZfQzSUS1MsjgH5kTBmyTmieJw4RjTuaIjGaGiOMbgg7+MNcw7iMTBL/AEhkmEKBmmfc4neTEMdRBvh0O7E8S1/g+ajiaG0+l2Q2weaDsP216F0Emz+a2brzlKNLoc6+rLbFTEhtLX1+KuxcZwf3tj6+WPDfkL1B7UUH9nCtX3e5PSmt1gXH8GLU37DgKNb2Z1TQtnBVykv7Uffc75EYZ98LVSQtFMwSNdzLvHXccvH5qOJYbUj+wCDQ3tg6KTEJP/+d6HvKVC/MzEUd2BbYuit9FxY/cuPn3vUZ3GHdmO7N+AwjOz9fzOdDrre7Mk5lTcvXcjwwYX0yc3hlNgHFL54J6GrnuDgwTqKhoxJPLmhDnLyIKed4TkRFAwi7YtFwcWgIXkvjg+3JuaHikcn5o/2bUr0lo4eSAzTOQenng07VieG9E49OxFgW15M9K62/A169YNDuzLarOXxsUwOvd36+f1lv2fwvpUMGzOewftXMmb/MvJ3r2bPDS+yPXcU51IFg8YmwrtwSAYrl64U2GDotOsYRLJBrBnqtkNOHu6JqVj9zi4vYYcr5gvNP2BW6A/8JudKKkYMZOLhZWzrPY7LSpsYufI+3h91PacNKCA6/AJq6poZP3wI0cJh5MSOUr/vA/oNGITlFcLJhsOO7E8Ea14hjPlc1zWwBwtsMLRQj0F6FOcSPZZQDuxanxh62/wCrF0Ag87ANR7CPnwv01We1OL4+fyvUPvb3N/XfCMXjizg99HzmMxGzhw9kmGrf0DVJb/mjQP5XDaqN7nbXmLQ5GvoFYm0fXHDQVj7DEyadfIgOpHGeqjdAqeV+2hV96JgEJGP1NVAcwMc3Z9Y0bbtNajdDFtfgf1bMl2dJ0ddLnc2f5Ut7jQuC6/k9pzfA/DzyHXUn/sNxgzux5RXZrJr2HQKTz8f3nmeprFfpO9pZ7Bx12H+ZdRAwi4KGM2ECD31BcJbl8HszYmfz7Nfhpv/DL0HJBZi9D3FX+BkIQWDiKRfc0Oi5xJtTCylrqtJzs1UJ4Im1gjv/CUx51I0DKZ9L9Grqf5Lpiv3pNHl8Gp8PFPDa1gaq2R+zhf5t/iTFOfG2Zx/FkfII3zBvzPxU0WsqznAj/+xk8dvOIch+c1Y7/7YzrUw+EzY9w68uwz+5TYAmpqayQ0bhHM6VsjOdYn5r9zeaWmXgkFEup+WFW3xWKJnE48ml1Y3QDgXnrsTNv5Ppqv0ZWHsM1wV/gcA32y+jRF9owwP7eZo/QH+d3gZ34l+hUXuYoYP6MWMIbvZ3diL72y9BYC9X9tAQfFpfHDgKHEHowf39VWDgkFEegbnEivLWkLl/deheFQiUKqWwNgr4G//Ce8shXAk8byioYm/5ruhm5rm8KO77mBgX+/LkhUMIiLpEIsmhn7qdyUm//OKoGZl4mu9B0BhaWJ4bd1vE1viLHsg8bVBY2Hv2yc+bwqis98jp+8Az69LRzB0cBBMRCTAWuYDCko+Ojbs08c9qQ9MnpV4ePF3On7ueDzR24k1wY5V0HtgYtXZ7vUwelpi94HaLbBxUWIobfvrcNkD5OQXpNSkVKjHICISIOnoMfSMO7iJiEiHKRhERKSNrAwGM5tuZnPr6jJ77wIRkZ4oK4PBObfEOTersLAw06WIiPQ4WRkMIiKSOQoGERFpQ8EgIiJtKBhERKSNrL7Azcz2Att8vnwgsC+N5XQnPbnt0LPb35PbDj27/S1tH+acG5TKibI6GFJhZqtSvfqvu+rJbYee3f6e3Hbo2e1PZ9s1lCQiIm0oGEREpI0gB8PcTBeQQT257dCz29+T2w49u/1pa3tg5xhERMSfIPcYRETEh8AFg5ldZmabzGyzmc3JdD2dxcy2mtl6M1tjZquSxwaY2V/NrDr5sX/yuJnZw8mfyTozq8hs9d6Y2Twz22NmG4455rmtZvbl5POrzezLmWiLHydo//fNbEfy/V9jZp8/5mvfSbZ/k5ldeszxbve7YWZDzezvZvaWmW00s39LHg/8+3+Stnf+e++cC8x/QBjYAowEcoG1QFmm6+qktm4FBh537EFgTvLxHOCHycefB54DDDgPWJ7p+j229QKgAtjgt63AAODd5Mf+ycf9M922FNr/fWB2O88tS/5/3wsYkfx9CHfX3w3gVKAi+bgAeCfZxsC//ydpe6e/90HrMUwCNjvn3nXONQELgCszXFNXuhL4VfLxr4AvHHP8SZfwOlBkZqdmokA/nHMvA/uPO+y1rZcCf3XO7XfOfQj8Fbis86tP3QnafyJXAgucc43OufeAzSR+L7rl74Zzbqdz7o3k43qgChhCD3j/T9L2E0nbex+0YBgCbD/m8xpO/oPszhzwFzNbbWbJG9FyinNuZ/LxLuCU5OMg/ly8tjWIP4PbksMl81qGUghw+81sOHAOsJwe9v4f13bo5Pc+aMHQk0xxzlUAlwPfMLMLjv2iS/Qte8SSs57U1mP8P2AUUA7sBP47s+V0LjPrCywEvuWcO3js14L+/rfT9k5/74MWDDuAocd8Xpo8FjjOuR3Jj3uARSS6i7tbhoiSH/cknx7En4vXtgbqZ+Cc2+2ciznn4sATJN5/CGD7zSxC4h/Gp51z/5M83CPe//ba3hXvfdCCYSUwxsxGmFkucB2wOMM1pZ2Z9TGzgpbHwCXABhJtbVlt8WXgD8nHi4GZyRUb5wF1x3TDuyuvbV0KXGJm/ZNd70uSx7ql4+aIvkji/YdE+68zs15mNgIYA6ygm/5umJkBPweqnHMPHfOlwL//J2p7l7z3mZ5574SZ/M+TmL3fAnw30/V0UhtHklhZsBbY2NJOoBh4EagGXgAGJI8b8FjyZ7IeqMx0Gzy29xkSXeZmEuOjt/ppK3ALiQm5zcDNmW5Xiu1/Ktm+dclf8lOPef53k+3fBFx+zPFu97sBTCExTLQOWJP87/M94f0/Sds7/b3Xlc8iItJG0IaSREQkRQoGERFpQ8EgIiJtKBhERKQNBYOIiLShYBARkTYUDCIi0oaCQURE2vj/ldbx7cWA+z4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Now let's train the initial network \n",
    "\n",
    "model = offCenterLineNet()\n",
    "model = model.to(dev)\n",
    "model.apply(weights_init_uniform)\n",
    "\n",
    "model.train();\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=.01) \n",
    "# scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=500, gamma=0.1)\n",
    "\n",
    "n_epochs = 2400\n",
    "\n",
    "mse_loss = nn.MSELoss()\n",
    "ce_loss = nn.CrossEntropyLoss()\n",
    "\n",
    "for epoch in range(0,n_epochs):  # loop over the dataset multiple times\n",
    "    \n",
    "    if epoch == 0:\n",
    "        train_loss_over_time = [] # to track the loss as the network trains\n",
    "        test_loss_over_time = []\n",
    "        \n",
    "    if epoch == 10:\n",
    "        optimizer = torch.optim.Adam(model.parameters(),lr=.001) \n",
    "        \n",
    "        \n",
    "    running_loss = 0\n",
    "    num_batches = 0\n",
    "    \n",
    "    for batch_i, data in enumerate(train_loader):\n",
    "        \n",
    "        # get the input images and their corresponding labels\n",
    "        num_batches += 1\n",
    "\n",
    "        inputs, output_gt, _, _ = data\n",
    "        inputs, output_gt = inputs.to(dev), output_gt.to(dev)\n",
    "        \n",
    "        # zero the parameter (weight) gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # forward pass to get outputs\n",
    "        output_line_params = model(inputs)\n",
    "        \n",
    "\n",
    "        # make the ground truth\n",
    "        c = -output_gt[:,2]*torch.cos(output_gt[:,0]) + output_gt[:,1]*torch.sin(output_gt[:,0])\n",
    "        gt_line_params = torch.stack((-torch.sin(output_gt[:,0]),torch.cos(output_gt[:,0]),c),dim=1)\n",
    "        \n",
    "        # calculate the loss\n",
    "#         print(output_line_params[:,:,0,50])\n",
    "        \n",
    "        loss = mse_loss(output_line_params,gt_line_params)\n",
    "        \n",
    "        # backward pass to calculate the parameter gradients\n",
    "        loss.backward()\n",
    "\n",
    "        # update the parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        # to convert loss into a scalar and add it to running_loss, we use .item()\n",
    "        running_loss += loss.item()\n",
    "      \n",
    "\n",
    "#     scheduler.step()\n",
    "    \n",
    "    # Calculate test data loss after each epoch\n",
    "    with torch.no_grad():\n",
    "        test_loss = 0\n",
    "        num_batches_test = 0\n",
    "        for batch_i, data in enumerate(test_loader):\n",
    "            num_batches_test += 1\n",
    "\n",
    "            # Add code here\n",
    "            inputs, output_gt, _, _ = data\n",
    "            inputs, output_gt = inputs.to(dev), output_gt.to(dev)\n",
    "\n",
    "\n",
    "            # zero the parameter (weight) gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward pass to get outputs\n",
    "            output_line_params = model(inputs)\n",
    "\n",
    "            # make the ground truth\n",
    "            c = -output_gt[:,2]*torch.cos(output_gt[:,0]) + output_gt[:,1]*torch.sin(output_gt[:,0])\n",
    "            gt_line_params = torch.stack((-torch.sin(output_gt[:,0]),torch.cos(output_gt[:,0]),c),dim=1)\n",
    "    \n",
    "\n",
    "            # calculate the loss\n",
    "    #         print(output_line_params[:,:,0,50])\n",
    "\n",
    "            loss = mse_loss(output_line_params,gt_line_params)\n",
    "            \n",
    "            test_loss += loss\n",
    "                    \n",
    "        test_loss_over_time.append(test_loss/num_batches_test)\n",
    "\n",
    "    # Calculate model loss:\n",
    "    avg_loss = running_loss/num_batches\n",
    "    train_loss_over_time.append(avg_loss)\n",
    "    \n",
    "#     print('Epoch: {}, Avg. Train Loss: {},'.format(epoch + 1, train_loss_over_time[-1]))\n",
    "\n",
    "\n",
    "    print('Epoch: {}, Avg. Train Loss: {}, Avg. Test Loss: {}'.format(epoch + 1, train_loss_over_time[-1], test_loss_over_time[-1]))\n",
    "    \n",
    "print('Finished Training')\n",
    "\n",
    "plt.figure()\n",
    "plt.semilogy(np.arange(0,n_epochs),train_loss_over_time[0:])\n",
    "plt.semilogy(np.arange(0,n_epochs),test_loss_over_time[0:])\n",
    "plt.legend(['Training loss', 'Testing loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "36a289d6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor(3.6651), tensor(3.6877), tensor(3.6083), tensor(3.4280), tensor(3.6389), tensor(3.4745), tensor(3.4947), tensor(3.5486), tensor(3.7855), tensor(3.6254), tensor(3.9051), tensor(3.6045), tensor(3.5799), tensor(3.6642), tensor(3.9461)]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1080 with 9 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the Results\n",
    "\n",
    "model.eval();\n",
    "\n",
    "ang_loss_all = []\n",
    "\n",
    "for batch_i, data in enumerate(test_loader):\n",
    "    # get the input images and their corresponding labels\n",
    "    inputs, output_gt, _, _ = data\n",
    "    inputs, output_gt = inputs.to(dev), output_gt.to(dev)\n",
    "    \n",
    "\n",
    "    # forward pass to get outputs\n",
    "    outputs = model(inputs).squeeze().detach().cpu()\n",
    "    \n",
    "    gt = output_gt.cpu().squeeze()\n",
    "    \n",
    "    c = -output_gt[:,2]*torch.cos(output_gt[:,0]) + output_gt[:,1]*torch.sin(output_gt[:,0])\n",
    "    angle_params = torch.stack((-torch.sin(output_gt[:,0]),torch.cos(output_gt[:,0]),c),axis=1).detach().cpu()\n",
    "  \n",
    "    # Calculate angular loss\n",
    "    ang_loss = torch.mean(torch.abs(torch.rad2deg(torch.atan2(-angle_params[:,0]*outputs[:,1] + angle_params[:,1]*outputs[:,0]\n",
    "                                         ,angle_params[:,1]*outputs[:,1]+angle_params[:,0]*outputs[:,0]).cpu())))\n",
    "\n",
    "    ang_loss_all.append(ang_loss)\n",
    "\n",
    "    \n",
    "print(ang_loss_all)\n",
    "\n",
    "plt.figure(figsize=[15, 15])\n",
    "\n",
    "for ii in range(9):\n",
    "    \n",
    "    plt.subplot(3,3,ii+1)\n",
    "    plt.imshow(inputs[ii].cpu().squeeze(),cmap='gray', vmin=0, vmax=1)\n",
    "    \n",
    "    # Plot the ground truth lines\n",
    "    x_sample = torch.linspace(-1,1,inputs.shape[-1])\n",
    "    y_sample = -angle_params[ii,0]/angle_params[ii,1]*x_sample - angle_params[ii,2]/angle_params[ii,1]\n",
    "    \n",
    "    plt.plot(x_sample*W/2+W/2,y_sample*W/2+W/2,'b')\n",
    "    plt.xlim([0,W])\n",
    "    plt.ylim(([0,W]))\n",
    "    \n",
    "    # Plot the estimated lines\n",
    "    y_est = -outputs[ii,0]/outputs[ii,1]*x_sample - outputs[ii,2]/outputs[ii,1]\n",
    "    plt.plot(x_sample*W/2+W/2,y_est*W/2+W/2,'r')\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e57b273",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fb383b04",
   "metadata": {},
   "source": [
    "# 5x5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "b196d283",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1080 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load dataset \n",
    "\n",
    "data_folder = 'foj_data/grayscale_lines/'\n",
    "\n",
    "with open(data_folder + 'line_data_5_50000_grey_bicolor_noiseless_uncentered.pkl','rb') as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "# wedges = data['wedges']\n",
    "wedges_grey = data['wedges_grey']\n",
    "params = data['params']\n",
    "boundaries = data['boundaries']\n",
    "wedges = data['wedges']\n",
    "\n",
    "\n",
    "line_data = LineDataset(wedges_grey, params, boundaries, wedges)#, transform=trainTransform)\n",
    "data_size = len(line_data)\n",
    "\n",
    "print(data_size)\n",
    "\n",
    "train_proportion = .85\n",
    "# Split dataset into training and testing\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(line_data, [int(data_size*train_proportion), int(data_size*(1-train_proportion))], generator=torch.Generator().manual_seed(42))\n",
    "\n",
    "# Create loaders for the training and testing data\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=1000, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=500, shuffle=False) #len(test_dataset)\n",
    "\n",
    "\n",
    "W,H = 5,5\n",
    "\n",
    "img_show = 1\n",
    "plt.figure(figsize=[15, 15])\n",
    "plt.subplot(131)\n",
    "plt.imshow(wedges[img_show,:,:].squeeze().permute(1,2,0).cpu())\n",
    "plt.title('RGB Image')\n",
    "plt.axis('off');\n",
    "plt.subplot(132)\n",
    "plt.imshow(wedges_grey[img_show,:,:].squeeze().cpu(),cmap='gray', vmin=0, vmax=1)\n",
    "plt.title('Grayscale Image')\n",
    "plt.axis('off');\n",
    "plt.subplot(133)\n",
    "plt.imshow(boundaries[img_show,:,:].squeeze().cpu(),cmap='gray', vmin=0, vmax=1)\n",
    "plt.title('Boundaries')\n",
    "plt.axis('off');\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "67bd3181",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1              [-1, 2, 3, 3]              20\n",
      "              ReLU-2              [-1, 2, 3, 3]               0\n",
      "            Linear-3                    [-1, 3]              57\n",
      "================================================================\n",
      "Total params: 77\n",
      "Trainable params: 77\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.00\n",
      "Params size (MB): 0.00\n",
      "Estimated Total Size (MB): 0.00\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "class offCenterLineNet(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "                \n",
    "        self.conv1 = nn.Conv2d(1, 2, kernel_size=3) #64 is good\n",
    "#         self.conv2 = nn.Conv2d(1, 8, kernel_size=3)\n",
    "#         self.conv3 = nn.Conv2d(128, 8, kernel_size=3)\n",
    "        self.fc = nn.LazyLinear(3)\n",
    "#         self.fc2 = nn.LazyLinear(32)\n",
    "        self.maxpool = nn.MaxPool1d(1)\n",
    "#         self.avgpool = nn.AvgPool2d(2)\n",
    "        self.activate = nn.ReLU()\n",
    "#         self.batchnorm = nn.BatchNorm2d(128)\n",
    "    \n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.conv1(x)\n",
    "#         x = F.relu(x)\n",
    "        x = self.activate(x)\n",
    "#         x = self.maxpool(x)\n",
    "#         x = self.batchnorm(x)\n",
    "#         x = self.conv2(x)\n",
    "#         x = self.activate(x)\n",
    "#         x = F.relu(x)\n",
    "#         x = self.batchnorm(x)\n",
    "#         x = self.conv3(x)\n",
    "\n",
    "#         x = self.avgpool(x)\n",
    "        x = x.view(x.shape[0],-1)\n",
    "#         x = self.fc2(x)\n",
    "#         x = self.maxpool(x)\n",
    "        x = self.fc(x)\n",
    "         \n",
    "        # We're defining\n",
    "        # a = - sin(theta)\n",
    "        # b = cos(theta)\n",
    "        # c = -cy*cos(theta)+cx*sin(theta)\n",
    "        # Hence, we want to normalize the vector by 1/sqrt(a^2 + b^2)\n",
    "        norm_factor = (torch.norm(x[:,:2],p=2,dim=1)).unsqueeze(1)       \n",
    "        out = x/(norm_factor)#+eps)\n",
    "#         print('Output shape=',x.shape)\n",
    "\n",
    "#         out = x\n",
    "        \n",
    "        return out\n",
    "    \n",
    "model = offCenterLineNet()\n",
    "model = model.to(dev)\n",
    "summary(model, input_size=(1, H, W))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4949f902",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "391073e9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Avg. Train Loss: 0.5691371497719787, Avg. Test Loss: 0.4738861918449402\n",
      "Epoch: 2, Avg. Train Loss: 0.42374646039896235, Avg. Test Loss: 0.3095325827598572\n",
      "Epoch: 3, Avg. Train Loss: 0.4331767264493676, Avg. Test Loss: 0.4821835458278656\n",
      "Epoch: 4, Avg. Train Loss: 0.42934983899427015, Avg. Test Loss: 0.3648873269557953\n",
      "Epoch: 5, Avg. Train Loss: 0.304233715631241, Avg. Test Loss: 0.42176106572151184\n",
      "Epoch: 6, Avg. Train Loss: 0.404740747324256, Avg. Test Loss: 0.421425998210907\n",
      "Epoch: 7, Avg. Train Loss: 0.39754962782527126, Avg. Test Loss: 0.36875879764556885\n",
      "Epoch: 8, Avg. Train Loss: 0.33950644384982975, Avg. Test Loss: 0.30512550473213196\n",
      "Epoch: 9, Avg. Train Loss: 0.2677428916443226, Avg. Test Loss: 0.22458013892173767\n",
      "Epoch: 10, Avg. Train Loss: 0.18897357305815055, Avg. Test Loss: 0.21376310288906097\n",
      "Epoch: 11, Avg. Train Loss: 0.1993591750777045, Avg. Test Loss: 0.18776904046535492\n",
      "Epoch: 12, Avg. Train Loss: 0.19035639388616696, Avg. Test Loss: 0.18638110160827637\n",
      "Epoch: 13, Avg. Train Loss: 0.18722409910933915, Avg. Test Loss: 0.1838098019361496\n",
      "Epoch: 14, Avg. Train Loss: 0.1845992841692858, Avg. Test Loss: 0.1826220452785492\n",
      "Epoch: 15, Avg. Train Loss: 0.18727347913176515, Avg. Test Loss: 0.18071028590202332\n",
      "Epoch: 16, Avg. Train Loss: 0.1801113337278366, Avg. Test Loss: 0.1794198602437973\n",
      "Epoch: 17, Avg. Train Loss: 0.1782502639432286, Avg. Test Loss: 0.17613977193832397\n",
      "Epoch: 18, Avg. Train Loss: 0.17429910946724025, Avg. Test Loss: 0.17476993799209595\n",
      "Epoch: 19, Avg. Train Loss: 0.17374181782090387, Avg. Test Loss: 0.17301008105278015\n",
      "Epoch: 20, Avg. Train Loss: 0.17036131336245425, Avg. Test Loss: 0.16907663643360138\n",
      "Epoch: 21, Avg. Train Loss: 0.1657278045665386, Avg. Test Loss: 0.16601836681365967\n",
      "Epoch: 22, Avg. Train Loss: 0.16095179457997166, Avg. Test Loss: 0.16245508193969727\n",
      "Epoch: 23, Avg. Train Loss: 0.1605421970056933, Avg. Test Loss: 0.16068343818187714\n",
      "Epoch: 24, Avg. Train Loss: 0.16736168778219887, Avg. Test Loss: 0.16923436522483826\n",
      "Epoch: 25, Avg. Train Loss: 0.19707225089849428, Avg. Test Loss: 0.20439884066581726\n",
      "Epoch: 26, Avg. Train Loss: 0.22384907270586768, Avg. Test Loss: 0.22618649899959564\n",
      "Epoch: 27, Avg. Train Loss: 0.22851416537928027, Avg. Test Loss: 0.2260599285364151\n",
      "Epoch: 28, Avg. Train Loss: 0.2282976168532704, Avg. Test Loss: 0.2189842015504837\n",
      "Epoch: 29, Avg. Train Loss: 0.20558729247991428, Avg. Test Loss: 0.19871720671653748\n",
      "Epoch: 30, Avg. Train Loss: 0.1959607594234999, Avg. Test Loss: 0.1947944313287735\n",
      "Epoch: 31, Avg. Train Loss: 0.19298021807227023, Avg. Test Loss: 0.19211935997009277\n",
      "Epoch: 32, Avg. Train Loss: 0.1899213621089625, Avg. Test Loss: 0.18818342685699463\n",
      "Epoch: 33, Avg. Train Loss: 0.18536766323932383, Avg. Test Loss: 0.18395760655403137\n",
      "Epoch: 34, Avg. Train Loss: 0.18169336436792863, Avg. Test Loss: 0.18018539249897003\n",
      "Epoch: 35, Avg. Train Loss: 0.1781800805136215, Avg. Test Loss: 0.17733317613601685\n",
      "Epoch: 36, Avg. Train Loss: 0.17549653732499412, Avg. Test Loss: 0.1747940182685852\n",
      "Epoch: 37, Avg. Train Loss: 0.1731928898844608, Avg. Test Loss: 0.17243143916130066\n",
      "Epoch: 38, Avg. Train Loss: 0.17054655974687533, Avg. Test Loss: 0.17007941007614136\n",
      "Epoch: 39, Avg. Train Loss: 0.16849324938862822, Avg. Test Loss: 0.16802817583084106\n",
      "Epoch: 40, Avg. Train Loss: 0.16752710349338, Avg. Test Loss: 0.16752572357654572\n",
      "Epoch: 41, Avg. Train Loss: 0.16611014306545258, Avg. Test Loss: 0.1658937633037567\n",
      "Epoch: 42, Avg. Train Loss: 0.16413170896297277, Avg. Test Loss: 0.16385559737682343\n",
      "Epoch: 43, Avg. Train Loss: 0.16197715214518613, Avg. Test Loss: 0.1618901640176773\n",
      "Epoch: 44, Avg. Train Loss: 0.16072190639584563, Avg. Test Loss: 0.16067849099636078\n",
      "Epoch: 45, Avg. Train Loss: 0.1598894353522811, Avg. Test Loss: 0.15948282182216644\n",
      "Epoch: 46, Avg. Train Loss: 0.15995756311472073, Avg. Test Loss: 0.1597638726234436\n",
      "Epoch: 47, Avg. Train Loss: 0.15877047042514003, Avg. Test Loss: 0.1583942323923111\n",
      "Epoch: 48, Avg. Train Loss: 0.18458954019601956, Avg. Test Loss: 0.19132627546787262\n",
      "Epoch: 49, Avg. Train Loss: 0.18550639790157938, Avg. Test Loss: 0.18313106894493103\n",
      "Epoch: 50, Avg. Train Loss: 0.18059471007003342, Avg. Test Loss: 0.17971214652061462\n",
      "Epoch: 51, Avg. Train Loss: 0.17749954517497574, Avg. Test Loss: 0.17703421413898468\n",
      "Epoch: 52, Avg. Train Loss: 0.1753671235123346, Avg. Test Loss: 0.17492717504501343\n",
      "Epoch: 53, Avg. Train Loss: 0.17451737855756005, Avg. Test Loss: 0.17386998236179352\n",
      "Epoch: 54, Avg. Train Loss: 0.17496961667094119, Avg. Test Loss: 0.17593982815742493\n",
      "Epoch: 55, Avg. Train Loss: 0.1738552097664323, Avg. Test Loss: 0.17319759726524353\n",
      "Epoch: 56, Avg. Train Loss: 0.17549224301826122, Avg. Test Loss: 0.18071715533733368\n",
      "Epoch: 57, Avg. Train Loss: 0.18311699843683907, Avg. Test Loss: 0.18260888755321503\n",
      "Epoch: 58, Avg. Train Loss: 0.17942142070725906, Avg. Test Loss: 0.17818090319633484\n",
      "Epoch: 59, Avg. Train Loss: 0.17573380504929742, Avg. Test Loss: 0.17464911937713623\n",
      "Epoch: 60, Avg. Train Loss: 0.17236670886361322, Avg. Test Loss: 0.17144574224948883\n",
      "Epoch: 61, Avg. Train Loss: 0.16915504703688067, Avg. Test Loss: 0.16847436130046844\n",
      "Epoch: 62, Avg. Train Loss: 0.16646509392316952, Avg. Test Loss: 0.16567453742027283\n",
      "Epoch: 63, Avg. Train Loss: 0.16360487043857574, Avg. Test Loss: 0.16311758756637573\n",
      "Epoch: 64, Avg. Train Loss: 0.16072855681874032, Avg. Test Loss: 0.16154475510120392\n",
      "Epoch: 65, Avg. Train Loss: 0.1583289497120436, Avg. Test Loss: 0.21787238121032715\n",
      "Epoch: 66, Avg. Train Loss: 0.15588329351225563, Avg. Test Loss: 0.1574379950761795\n",
      "Epoch: 67, Avg. Train Loss: 0.1536568430967109, Avg. Test Loss: 0.1546601802110672\n",
      "Epoch: 68, Avg. Train Loss: 0.15115688117437584, Avg. Test Loss: 0.18184208869934082\n",
      "Epoch: 69, Avg. Train Loss: 0.14888402958248936, Avg. Test Loss: 0.15231427550315857\n",
      "Epoch: 70, Avg. Train Loss: 0.14664236958636795, Avg. Test Loss: 0.14743776619434357\n",
      "Epoch: 71, Avg. Train Loss: 0.144724111917407, Avg. Test Loss: 0.14633142948150635\n",
      "Epoch: 72, Avg. Train Loss: 0.14264627944591435, Avg. Test Loss: 0.15570290386676788\n",
      "Epoch: 73, Avg. Train Loss: 0.14102759610774906, Avg. Test Loss: 0.1447802037000656\n",
      "Epoch: 74, Avg. Train Loss: 0.13886508345603943, Avg. Test Loss: 0.1393369436264038\n",
      "Epoch: 75, Avg. Train Loss: 0.13687536640222683, Avg. Test Loss: 0.13671305775642395\n",
      "Epoch: 76, Avg. Train Loss: 0.13495164555172587, Avg. Test Loss: 0.13463549315929413\n",
      "Epoch: 77, Avg. Train Loss: 0.13324390802272532, Avg. Test Loss: 0.1327487677335739\n",
      "Epoch: 78, Avg. Train Loss: 0.13141191421553147, Avg. Test Loss: 0.130941703915596\n",
      "Epoch: 79, Avg. Train Loss: 0.129546114178591, Avg. Test Loss: 0.12919220328330994\n",
      "Epoch: 80, Avg. Train Loss: 0.12801939664885056, Avg. Test Loss: 0.1274982988834381\n",
      "Epoch: 81, Avg. Train Loss: 0.12624219683713692, Avg. Test Loss: 0.12583470344543457\n",
      "Epoch: 82, Avg. Train Loss: 0.12457126829513283, Avg. Test Loss: 0.12419898808002472\n",
      "Epoch: 83, Avg. Train Loss: 0.12302861605272737, Avg. Test Loss: 0.122589610517025\n",
      "Epoch: 84, Avg. Train Loss: 0.12144553644019504, Avg. Test Loss: 0.1210009828209877\n",
      "Epoch: 85, Avg. Train Loss: 0.1198848738919857, Avg. Test Loss: 0.11943317204713821\n",
      "Epoch: 86, Avg. Train Loss: 0.11821190943551618, Avg. Test Loss: 0.11788120120763779\n",
      "Epoch: 87, Avg. Train Loss: 0.11671230370222135, Avg. Test Loss: 0.11634809523820877\n",
      "Epoch: 88, Avg. Train Loss: 0.11520106778588406, Avg. Test Loss: 0.11482663452625275\n",
      "Epoch: 89, Avg. Train Loss: 0.11377652543921803, Avg. Test Loss: 0.11332366615533829\n",
      "Epoch: 90, Avg. Train Loss: 0.11217165183882381, Avg. Test Loss: 0.11182808876037598\n",
      "Epoch: 91, Avg. Train Loss: 0.11067787349917167, Avg. Test Loss: 0.11033248156309128\n",
      "Epoch: 92, Avg. Train Loss: 0.10927223188932551, Avg. Test Loss: 0.10885850340127945\n",
      "Epoch: 93, Avg. Train Loss: 0.10774567446043325, Avg. Test Loss: 0.10738285630941391\n",
      "Epoch: 94, Avg. Train Loss: 0.10628103898015133, Avg. Test Loss: 0.1059253141283989\n",
      "Epoch: 95, Avg. Train Loss: 0.10488605118075083, Avg. Test Loss: 0.1044699177145958\n",
      "Epoch: 96, Avg. Train Loss: 0.10331460556318593, Avg. Test Loss: 0.10301938652992249\n",
      "Epoch: 97, Avg. Train Loss: 0.10196676607741866, Avg. Test Loss: 0.1015840396285057\n",
      "Epoch: 98, Avg. Train Loss: 0.10049678835757943, Avg. Test Loss: 0.1001535952091217\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 99, Avg. Train Loss: 0.09909411034611769, Avg. Test Loss: 0.09872257709503174\n",
      "Epoch: 100, Avg. Train Loss: 0.09778685365305391, Avg. Test Loss: 0.09730557352304459\n",
      "Epoch: 101, Avg. Train Loss: 0.09630575204311415, Avg. Test Loss: 0.09589368104934692\n",
      "Epoch: 102, Avg. Train Loss: 0.09485447822615158, Avg. Test Loss: 0.09447738528251648\n",
      "Epoch: 103, Avg. Train Loss: 0.09366274659716806, Avg. Test Loss: 0.09308353811502457\n",
      "Epoch: 104, Avg. Train Loss: 0.09200715602830399, Avg. Test Loss: 0.09168058633804321\n",
      "Epoch: 105, Avg. Train Loss: 0.09064536836258201, Avg. Test Loss: 0.09029829502105713\n",
      "Epoch: 106, Avg. Train Loss: 0.08929582009481829, Avg. Test Loss: 0.08891608566045761\n",
      "Epoch: 107, Avg. Train Loss: 0.08794339590294417, Avg. Test Loss: 0.08754045516252518\n",
      "Epoch: 108, Avg. Train Loss: 0.08666375643292139, Avg. Test Loss: 0.08617030084133148\n",
      "Epoch: 109, Avg. Train Loss: 0.08527016778324925, Avg. Test Loss: 0.08480887860059738\n",
      "Epoch: 110, Avg. Train Loss: 0.08391137213207954, Avg. Test Loss: 0.08345510065555573\n",
      "Epoch: 111, Avg. Train Loss: 0.08251500406930613, Avg. Test Loss: 0.08211428672075272\n",
      "Epoch: 112, Avg. Train Loss: 0.08121123268853786, Avg. Test Loss: 0.08077874779701233\n",
      "Epoch: 113, Avg. Train Loss: 0.07985953657433044, Avg. Test Loss: 0.07944723963737488\n",
      "Epoch: 114, Avg. Train Loss: 0.07863396752712339, Avg. Test Loss: 0.07812975347042084\n",
      "Epoch: 115, Avg. Train Loss: 0.07733611398658087, Avg. Test Loss: 0.07682118564844131\n",
      "Epoch: 116, Avg. Train Loss: 0.07603128704913827, Avg. Test Loss: 0.07551337778568268\n",
      "Epoch: 117, Avg. Train Loss: 0.07467549935329792, Avg. Test Loss: 0.07422823458909988\n",
      "Epoch: 118, Avg. Train Loss: 0.07338370694670567, Avg. Test Loss: 0.07294901460409164\n",
      "Epoch: 119, Avg. Train Loss: 0.072164170617281, Avg. Test Loss: 0.07168062776327133\n",
      "Epoch: 120, Avg. Train Loss: 0.07085710902546727, Avg. Test Loss: 0.07042009383440018\n",
      "Epoch: 121, Avg. Train Loss: 0.06962636217128398, Avg. Test Loss: 0.06917911767959595\n",
      "Epoch: 122, Avg. Train Loss: 0.06842464849699376, Avg. Test Loss: 0.06794335693120956\n",
      "Epoch: 123, Avg. Train Loss: 0.0672108611568462, Avg. Test Loss: 0.06672371923923492\n",
      "Epoch: 124, Avg. Train Loss: 0.06601173170777254, Avg. Test Loss: 0.0655166283249855\n",
      "Epoch: 125, Avg. Train Loss: 0.06480631674098414, Avg. Test Loss: 0.06431829929351807\n",
      "Epoch: 126, Avg. Train Loss: 0.0635949113341265, Avg. Test Loss: 0.06313639134168625\n",
      "Epoch: 127, Avg. Train Loss: 0.06252223495827165, Avg. Test Loss: 0.06196647509932518\n",
      "Epoch: 128, Avg. Train Loss: 0.061260407573955004, Avg. Test Loss: 0.06080923229455948\n",
      "Epoch: 129, Avg. Train Loss: 0.060202675243449764, Avg. Test Loss: 0.05967271700501442\n",
      "Epoch: 130, Avg. Train Loss: 0.05902540363198103, Avg. Test Loss: 0.05853680521249771\n",
      "Epoch: 131, Avg. Train Loss: 0.057967302324466924, Avg. Test Loss: 0.05743120238184929\n",
      "Epoch: 132, Avg. Train Loss: 0.05686236207568368, Avg. Test Loss: 0.05632593110203743\n",
      "Epoch: 133, Avg. Train Loss: 0.055729010683852574, Avg. Test Loss: 0.055238381028175354\n",
      "Epoch: 134, Avg. Train Loss: 0.05468827589999798, Avg. Test Loss: 0.05416806787252426\n",
      "Epoch: 135, Avg. Train Loss: 0.05358859316207642, Avg. Test Loss: 0.053108081221580505\n",
      "Epoch: 136, Avg. Train Loss: 0.052676720934551814, Avg. Test Loss: 0.05206712707877159\n",
      "Epoch: 137, Avg. Train Loss: 0.05158439729102822, Avg. Test Loss: 0.05103382468223572\n",
      "Epoch: 138, Avg. Train Loss: 0.05058855381469394, Avg. Test Loss: 0.05001577362418175\n",
      "Epoch: 139, Avg. Train Loss: 0.04956604826242425, Avg. Test Loss: 0.04901101067662239\n",
      "Epoch: 140, Avg. Train Loss: 0.04857572618612023, Avg. Test Loss: 0.04802165925502777\n",
      "Epoch: 141, Avg. Train Loss: 0.047609479967937914, Avg. Test Loss: 0.047051746398210526\n",
      "Epoch: 142, Avg. Train Loss: 0.04666198296255843, Avg. Test Loss: 0.046082742512226105\n",
      "Epoch: 143, Avg. Train Loss: 0.045707786412433137, Avg. Test Loss: 0.04513806477189064\n",
      "Epoch: 144, Avg. Train Loss: 0.04477188545604085, Avg. Test Loss: 0.044201552867889404\n",
      "Epoch: 145, Avg. Train Loss: 0.043894832390685416, Avg. Test Loss: 0.04328291863203049\n",
      "Epoch: 146, Avg. Train Loss: 0.042984754800103435, Avg. Test Loss: 0.04237499088048935\n",
      "Epoch: 147, Avg. Train Loss: 0.0420710573536019, Avg. Test Loss: 0.0414823442697525\n",
      "Epoch: 148, Avg. Train Loss: 0.04123974461541619, Avg. Test Loss: 0.040596622973680496\n",
      "Epoch: 149, Avg. Train Loss: 0.04036821806153586, Avg. Test Loss: 0.03973397985100746\n",
      "Epoch: 150, Avg. Train Loss: 0.03947728586404822, Avg. Test Loss: 0.03887748345732689\n",
      "Epoch: 151, Avg. Train Loss: 0.03867119256147118, Avg. Test Loss: 0.03803623467683792\n",
      "Epoch: 152, Avg. Train Loss: 0.037822783253220624, Avg. Test Loss: 0.037210360169410706\n",
      "Epoch: 153, Avg. Train Loss: 0.037033895767012305, Avg. Test Loss: 0.03639419749379158\n",
      "Epoch: 154, Avg. Train Loss: 0.03623635755028835, Avg. Test Loss: 0.035589780658483505\n",
      "Epoch: 155, Avg. Train Loss: 0.035460162821204164, Avg. Test Loss: 0.034801218658685684\n",
      "Epoch: 156, Avg. Train Loss: 0.034649689183678736, Avg. Test Loss: 0.03402391076087952\n",
      "Epoch: 157, Avg. Train Loss: 0.03392366111971611, Avg. Test Loss: 0.03326074406504631\n",
      "Epoch: 158, Avg. Train Loss: 0.03314134114703467, Avg. Test Loss: 0.03250866010785103\n",
      "Epoch: 159, Avg. Train Loss: 0.032407994100520775, Avg. Test Loss: 0.03176867961883545\n",
      "Epoch: 160, Avg. Train Loss: 0.03168880073137061, Avg. Test Loss: 0.031042497605085373\n",
      "Epoch: 161, Avg. Train Loss: 0.030991746632512227, Avg. Test Loss: 0.030326202511787415\n",
      "Epoch: 162, Avg. Train Loss: 0.030278185599072034, Avg. Test Loss: 0.029621349647641182\n",
      "Epoch: 163, Avg. Train Loss: 0.02956141210919203, Avg. Test Loss: 0.028932036831974983\n",
      "Epoch: 164, Avg. Train Loss: 0.02889735355626705, Avg. Test Loss: 0.028255686163902283\n",
      "Epoch: 165, Avg. Train Loss: 0.028230537422174632, Avg. Test Loss: 0.027589429169893265\n",
      "Epoch: 166, Avg. Train Loss: 0.02756725771482601, Avg. Test Loss: 0.026934586465358734\n",
      "Epoch: 167, Avg. Train Loss: 0.02689821424699107, Avg. Test Loss: 0.02628941647708416\n",
      "Epoch: 168, Avg. Train Loss: 0.026289069678547772, Avg. Test Loss: 0.025661526247859\n",
      "Epoch: 169, Avg. Train Loss: 0.025654152858742448, Avg. Test Loss: 0.025040186941623688\n",
      "Epoch: 170, Avg. Train Loss: 0.025058029999220095, Avg. Test Loss: 0.024430448189377785\n",
      "Epoch: 171, Avg. Train Loss: 0.02445462913533976, Avg. Test Loss: 0.023835035040974617\n",
      "Epoch: 172, Avg. Train Loss: 0.023860452090238415, Avg. Test Loss: 0.023246539756655693\n",
      "Epoch: 173, Avg. Train Loss: 0.023265316995770433, Avg. Test Loss: 0.022668907418847084\n",
      "Epoch: 174, Avg. Train Loss: 0.022688619705826737, Avg. Test Loss: 0.02210618369281292\n",
      "Epoch: 175, Avg. Train Loss: 0.022132136490802434, Avg. Test Loss: 0.021551629528403282\n",
      "Epoch: 176, Avg. Train Loss: 0.02157047993048679, Avg. Test Loss: 0.0210091732442379\n",
      "Epoch: 177, Avg. Train Loss: 0.02102309980884541, Avg. Test Loss: 0.020477157086133957\n",
      "Epoch: 178, Avg. Train Loss: 0.020521006958429202, Avg. Test Loss: 0.019955839961767197\n",
      "Epoch: 179, Avg. Train Loss: 0.01998651647117249, Avg. Test Loss: 0.019445020705461502\n",
      "Epoch: 180, Avg. Train Loss: 0.019482843967717746, Avg. Test Loss: 0.01894412934780121\n",
      "Epoch: 181, Avg. Train Loss: 0.018989137915331265, Avg. Test Loss: 0.018455039709806442\n",
      "Epoch: 182, Avg. Train Loss: 0.01849942086914251, Avg. Test Loss: 0.01797398366034031\n",
      "Epoch: 183, Avg. Train Loss: 0.018006499900027763, Avg. Test Loss: 0.017504729330539703\n",
      "Epoch: 184, Avg. Train Loss: 0.0175559897149025, Avg. Test Loss: 0.01704513281583786\n",
      "Epoch: 185, Avg. Train Loss: 0.017079739766412003, Avg. Test Loss: 0.016596440225839615\n",
      "Epoch: 186, Avg. Train Loss: 0.016646589260808257, Avg. Test Loss: 0.016158511862158775\n",
      "Epoch: 187, Avg. Train Loss: 0.016194173979551293, Avg. Test Loss: 0.015728509053587914\n",
      "Epoch: 188, Avg. Train Loss: 0.015776747209561424, Avg. Test Loss: 0.015309019014239311\n",
      "Epoch: 189, Avg. Train Loss: 0.015349687358667685, Avg. Test Loss: 0.014900177717208862\n",
      "Epoch: 190, Avg. Train Loss: 0.014928591286027155, Avg. Test Loss: 0.014499537646770477\n",
      "Epoch: 191, Avg. Train Loss: 0.01453068213494018, Avg. Test Loss: 0.014109445735812187\n",
      "Epoch: 192, Avg. Train Loss: 0.014137691601591056, Avg. Test Loss: 0.013729384168982506\n",
      "Epoch: 193, Avg. Train Loss: 0.013756984866462475, Avg. Test Loss: 0.013359489850699902\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 194, Avg. Train Loss: 0.013400235299973987, Avg. Test Loss: 0.012995987199246883\n",
      "Epoch: 195, Avg. Train Loss: 0.013021849204114703, Avg. Test Loss: 0.012643600814044476\n",
      "Epoch: 196, Avg. Train Loss: 0.012674865940975588, Avg. Test Loss: 0.012300273403525352\n",
      "Epoch: 197, Avg. Train Loss: 0.012325146517088248, Avg. Test Loss: 0.011964837089180946\n",
      "Epoch: 198, Avg. Train Loss: 0.011985410026512867, Avg. Test Loss: 0.01163992565125227\n",
      "Epoch: 199, Avg. Train Loss: 0.011659979820251465, Avg. Test Loss: 0.011323296464979649\n",
      "Epoch: 200, Avg. Train Loss: 0.011334605536661869, Avg. Test Loss: 0.011015314608812332\n",
      "Epoch: 201, Avg. Train Loss: 0.011034215908757476, Avg. Test Loss: 0.01071541104465723\n",
      "Epoch: 202, Avg. Train Loss: 0.010731981005952802, Avg. Test Loss: 0.010424472391605377\n",
      "Epoch: 203, Avg. Train Loss: 0.01043581124395132, Avg. Test Loss: 0.010140936821699142\n",
      "Epoch: 204, Avg. Train Loss: 0.010159499661693739, Avg. Test Loss: 0.009865697473287582\n",
      "Epoch: 205, Avg. Train Loss: 0.009873700176560602, Avg. Test Loss: 0.009598715230822563\n",
      "Epoch: 206, Avg. Train Loss: 0.009600155813576178, Avg. Test Loss: 0.009339552372694016\n",
      "Epoch: 207, Avg. Train Loss: 0.009346978349048038, Avg. Test Loss: 0.009087525308132172\n",
      "Epoch: 208, Avg. Train Loss: 0.009082539851755597, Avg. Test Loss: 0.00884326547384262\n",
      "Epoch: 209, Avg. Train Loss: 0.008844671814247619, Avg. Test Loss: 0.008605657145380974\n",
      "Epoch: 210, Avg. Train Loss: 0.00859171136953803, Avg. Test Loss: 0.008375581353902817\n",
      "Epoch: 211, Avg. Train Loss: 0.008371163906832768, Avg. Test Loss: 0.008153331466019154\n",
      "Epoch: 212, Avg. Train Loss: 0.008145837795509155, Avg. Test Loss: 0.007936895824968815\n",
      "Epoch: 213, Avg. Train Loss: 0.007928419316750627, Avg. Test Loss: 0.007726543582975864\n",
      "Epoch: 214, Avg. Train Loss: 0.007713472828009101, Avg. Test Loss: 0.007522557862102985\n",
      "Epoch: 215, Avg. Train Loss: 0.00751041638296704, Avg. Test Loss: 0.007325092330574989\n",
      "Epoch: 216, Avg. Train Loss: 0.007302913197511157, Avg. Test Loss: 0.007133767940104008\n",
      "Epoch: 217, Avg. Train Loss: 0.007113857433026613, Avg. Test Loss: 0.006947721820324659\n",
      "Epoch: 218, Avg. Train Loss: 0.0069215657990859, Avg. Test Loss: 0.006767855491489172\n",
      "Epoch: 219, Avg. Train Loss: 0.00674160226616402, Avg. Test Loss: 0.006593667436391115\n",
      "Epoch: 220, Avg. Train Loss: 0.006560219375979762, Avg. Test Loss: 0.006424704100936651\n",
      "Epoch: 221, Avg. Train Loss: 0.006394864265741997, Avg. Test Loss: 0.0062607694417238235\n",
      "Epoch: 222, Avg. Train Loss: 0.0062303187997015405, Avg. Test Loss: 0.006101825274527073\n",
      "Epoch: 223, Avg. Train Loss: 0.006065597616915786, Avg. Test Loss: 0.00594803411513567\n",
      "Epoch: 224, Avg. Train Loss: 0.0059116942981301355, Avg. Test Loss: 0.005798791069537401\n",
      "Epoch: 225, Avg. Train Loss: 0.0057619111070972544, Avg. Test Loss: 0.00565419951453805\n",
      "Epoch: 226, Avg. Train Loss: 0.005616575284579465, Avg. Test Loss: 0.005514153745025396\n",
      "Epoch: 227, Avg. Train Loss: 0.005471017926411573, Avg. Test Loss: 0.005377835128456354\n",
      "Epoch: 228, Avg. Train Loss: 0.005338121313861636, Avg. Test Loss: 0.005245447624474764\n",
      "Epoch: 229, Avg. Train Loss: 0.005201556286666282, Avg. Test Loss: 0.005117753054946661\n",
      "Epoch: 230, Avg. Train Loss: 0.005072531376987002, Avg. Test Loss: 0.004993135575205088\n",
      "Epoch: 231, Avg. Train Loss: 0.004945614050294078, Avg. Test Loss: 0.00487282732501626\n",
      "Epoch: 232, Avg. Train Loss: 0.004826180030440175, Avg. Test Loss: 0.004756022244691849\n",
      "Epoch: 233, Avg. Train Loss: 0.004700641494330971, Avg. Test Loss: 0.00464347330853343\n",
      "Epoch: 234, Avg. Train Loss: 0.004591546552039163, Avg. Test Loss: 0.00453337375074625\n",
      "Epoch: 235, Avg. Train Loss: 0.0044831469286839625, Avg. Test Loss: 0.004426463041454554\n",
      "Epoch: 236, Avg. Train Loss: 0.004366844372693883, Avg. Test Loss: 0.004324016161262989\n",
      "Epoch: 237, Avg. Train Loss: 0.004271464671419803, Avg. Test Loss: 0.004224131815135479\n",
      "Epoch: 238, Avg. Train Loss: 0.004164402692600391, Avg. Test Loss: 0.004126366227865219\n",
      "Epoch: 239, Avg. Train Loss: 0.00407187558905503, Avg. Test Loss: 0.004032476805150509\n",
      "Epoch: 240, Avg. Train Loss: 0.003974695408413577, Avg. Test Loss: 0.003941726870834827\n",
      "Epoch: 241, Avg. Train Loss: 0.003879033884596686, Avg. Test Loss: 0.003852521302178502\n",
      "Epoch: 242, Avg. Train Loss: 0.003794213675698915, Avg. Test Loss: 0.0037666023708879948\n",
      "Epoch: 243, Avg. Train Loss: 0.0037051261034469272, Avg. Test Loss: 0.003684200579300523\n",
      "Epoch: 244, Avg. Train Loss: 0.003620829460276074, Avg. Test Loss: 0.003603216027840972\n",
      "Epoch: 245, Avg. Train Loss: 0.00354146713737485, Avg. Test Loss: 0.0035251197405159473\n",
      "Epoch: 246, Avg. Train Loss: 0.003461131452431166, Avg. Test Loss: 0.003449508221819997\n",
      "Epoch: 247, Avg. Train Loss: 0.0033835754242487427, Avg. Test Loss: 0.003376501379534602\n",
      "Epoch: 248, Avg. Train Loss: 0.0033152394949696783, Avg. Test Loss: 0.0033055467065423727\n",
      "Epoch: 249, Avg. Train Loss: 0.0032428687243440816, Avg. Test Loss: 0.0032373061403632164\n",
      "Epoch: 250, Avg. Train Loss: 0.003176781495080091, Avg. Test Loss: 0.0031706788577139378\n",
      "Epoch: 251, Avg. Train Loss: 0.0031127225835049567, Avg. Test Loss: 0.0031069875694811344\n",
      "Epoch: 252, Avg. Train Loss: 0.0030442541140283264, Avg. Test Loss: 0.0030444844160228968\n",
      "Epoch: 253, Avg. Train Loss: 0.0029853744009986174, Avg. Test Loss: 0.0029847631230950356\n",
      "Epoch: 254, Avg. Train Loss: 0.002921100115663437, Avg. Test Loss: 0.0029266681522130966\n",
      "Epoch: 255, Avg. Train Loss: 0.0028626092839552915, Avg. Test Loss: 0.002870753640308976\n",
      "Epoch: 256, Avg. Train Loss: 0.0028068073862773735, Avg. Test Loss: 0.0028169467113912106\n",
      "Epoch: 257, Avg. Train Loss: 0.00275082703744776, Avg. Test Loss: 0.0027645020745694637\n",
      "Epoch: 258, Avg. Train Loss: 0.002701495849895616, Avg. Test Loss: 0.0027144034393131733\n",
      "Epoch: 259, Avg. Train Loss: 0.0026547346686467874, Avg. Test Loss: 0.0026655634865164757\n",
      "Epoch: 260, Avg. Train Loss: 0.002605705662782109, Avg. Test Loss: 0.0026188178453594446\n",
      "Epoch: 261, Avg. Train Loss: 0.0025568644646122014, Avg. Test Loss: 0.002573244506493211\n",
      "Epoch: 262, Avg. Train Loss: 0.0025129759045274453, Avg. Test Loss: 0.0025295219384133816\n",
      "Epoch: 263, Avg. Train Loss: 0.002468773911079002, Avg. Test Loss: 0.002487356308847666\n",
      "Epoch: 264, Avg. Train Loss: 0.0024285397199957175, Avg. Test Loss: 0.0024463783483952284\n",
      "Epoch: 265, Avg. Train Loss: 0.0023849998048485017, Avg. Test Loss: 0.0024068523198366165\n",
      "Epoch: 266, Avg. Train Loss: 0.0023477090154449608, Avg. Test Loss: 0.0023690795060247183\n",
      "Epoch: 267, Avg. Train Loss: 0.0023096597504390533, Avg. Test Loss: 0.002333153737708926\n",
      "Epoch: 268, Avg. Train Loss: 0.0022731551922164682, Avg. Test Loss: 0.0022969890851527452\n",
      "Epoch: 269, Avg. Train Loss: 0.002239989013909254, Avg. Test Loss: 0.0022630724124610424\n",
      "Epoch: 270, Avg. Train Loss: 0.0022048256143407767, Avg. Test Loss: 0.0022318256087601185\n",
      "Epoch: 271, Avg. Train Loss: 0.0021725055804952633, Avg. Test Loss: 0.0021980491001158953\n",
      "Epoch: 272, Avg. Train Loss: 0.0021410714834928513, Avg. Test Loss: 0.002167325234040618\n",
      "Epoch: 273, Avg. Train Loss: 0.002113763042617329, Avg. Test Loss: 0.002137801144272089\n",
      "Epoch: 274, Avg. Train Loss: 0.002081915641441768, Avg. Test Loss: 0.002108945045620203\n",
      "Epoch: 275, Avg. Train Loss: 0.0020515036709649963, Avg. Test Loss: 0.0020811683498322964\n",
      "Epoch: 276, Avg. Train Loss: 0.0020274299787097546, Avg. Test Loss: 0.002054651966318488\n",
      "Epoch: 277, Avg. Train Loss: 0.001998673953917311, Avg. Test Loss: 0.0020295397844165564\n",
      "Epoch: 278, Avg. Train Loss: 0.001974243521798662, Avg. Test Loss: 0.0020039055962115526\n",
      "Epoch: 279, Avg. Train Loss: 0.0019497036971801588, Avg. Test Loss: 0.0019790418446063995\n",
      "Epoch: 280, Avg. Train Loss: 0.0019243905147494271, Avg. Test Loss: 0.0019555040635168552\n",
      "Epoch: 281, Avg. Train Loss: 0.0019003763756996325, Avg. Test Loss: 0.001932778861373663\n",
      "Epoch: 282, Avg. Train Loss: 0.0018782472714435222, Avg. Test Loss: 0.0019108984852209687\n",
      "Epoch: 283, Avg. Train Loss: 0.0018567053877293718, Avg. Test Loss: 0.0018896409310400486\n",
      "Epoch: 284, Avg. Train Loss: 0.0018364784367339208, Avg. Test Loss: 0.0018697758205235004\n",
      "Epoch: 285, Avg. Train Loss: 0.0018162509794671868, Avg. Test Loss: 0.001848081243224442\n",
      "Epoch: 286, Avg. Train Loss: 0.001797536764358885, Avg. Test Loss: 0.0018295318586751819\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 287, Avg. Train Loss: 0.0017809068085625768, Avg. Test Loss: 0.001811327296309173\n",
      "Epoch: 288, Avg. Train Loss: 0.0017595848794160194, Avg. Test Loss: 0.0017913366900756955\n",
      "Epoch: 289, Avg. Train Loss: 0.0017383016082783078, Avg. Test Loss: 0.0017733138520270586\n",
      "Epoch: 290, Avg. Train Loss: 0.0017253022429771548, Avg. Test Loss: 0.0017554013757035136\n",
      "Epoch: 291, Avg. Train Loss: 0.001706183384454181, Avg. Test Loss: 0.001738899271003902\n",
      "Epoch: 292, Avg. Train Loss: 0.0016899101224966174, Avg. Test Loss: 0.0017226337222382426\n",
      "Epoch: 293, Avg. Train Loss: 0.0016728487423469508, Avg. Test Loss: 0.00170534395147115\n",
      "Epoch: 294, Avg. Train Loss: 0.0016577646358285187, Avg. Test Loss: 0.0016898715402930975\n",
      "Epoch: 295, Avg. Train Loss: 0.001643682358959733, Avg. Test Loss: 0.0016744548920542002\n",
      "Epoch: 296, Avg. Train Loss: 0.0016267428764813515, Avg. Test Loss: 0.0016601551324129105\n",
      "Epoch: 297, Avg. Train Loss: 0.0016123418923640667, Avg. Test Loss: 0.0016448087990283966\n",
      "Epoch: 298, Avg. Train Loss: 0.0015975017734088522, Avg. Test Loss: 0.001631165505386889\n",
      "Epoch: 299, Avg. Train Loss: 0.0015842910736885874, Avg. Test Loss: 0.0016171577153727412\n",
      "Epoch: 300, Avg. Train Loss: 0.001570449175508043, Avg. Test Loss: 0.0016034014988690615\n",
      "Epoch: 301, Avg. Train Loss: 0.0015562924848826125, Avg. Test Loss: 0.0015904541360214353\n",
      "Epoch: 302, Avg. Train Loss: 0.0015463586084458025, Avg. Test Loss: 0.001577245770022273\n",
      "Epoch: 303, Avg. Train Loss: 0.0015313778191718252, Avg. Test Loss: 0.0015666544204577804\n",
      "Epoch: 304, Avg. Train Loss: 0.001519814095741441, Avg. Test Loss: 0.0015526916831731796\n",
      "Epoch: 305, Avg. Train Loss: 0.0015076807413120256, Avg. Test Loss: 0.0015404754085466266\n",
      "Epoch: 306, Avg. Train Loss: 0.0014952888934288261, Avg. Test Loss: 0.0015291369054466486\n",
      "Epoch: 307, Avg. Train Loss: 0.001484913894971616, Avg. Test Loss: 0.0015181376365944743\n",
      "Epoch: 308, Avg. Train Loss: 0.0014733141531821253, Avg. Test Loss: 0.001506358035840094\n",
      "Epoch: 309, Avg. Train Loss: 0.0014631775218646886, Avg. Test Loss: 0.001495029660873115\n",
      "Epoch: 310, Avg. Train Loss: 0.0014535502698489052, Avg. Test Loss: 0.0014849572908133268\n",
      "Epoch: 311, Avg. Train Loss: 0.00144346303111592, Avg. Test Loss: 0.0014734816504642367\n",
      "Epoch: 312, Avg. Train Loss: 0.0014309213837868599, Avg. Test Loss: 0.0014632587553933263\n",
      "Epoch: 313, Avg. Train Loss: 0.0014214028555596637, Avg. Test Loss: 0.0014533903449773788\n",
      "Epoch: 314, Avg. Train Loss: 0.0014115934189798873, Avg. Test Loss: 0.0014432346215471625\n",
      "Epoch: 315, Avg. Train Loss: 0.0014019296315043819, Avg. Test Loss: 0.0014330840203911066\n",
      "Epoch: 316, Avg. Train Loss: 0.0013915593492213724, Avg. Test Loss: 0.0014244724297896028\n",
      "Epoch: 317, Avg. Train Loss: 0.0013843563461113115, Avg. Test Loss: 0.0014145378954708576\n",
      "Epoch: 318, Avg. Train Loss: 0.0013731025202676308, Avg. Test Loss: 0.0014063951093703508\n",
      "Epoch: 319, Avg. Train Loss: 0.0013646102851516632, Avg. Test Loss: 0.0013963570818305016\n",
      "Epoch: 320, Avg. Train Loss: 0.001357286442937546, Avg. Test Loss: 0.001388081582263112\n",
      "Epoch: 321, Avg. Train Loss: 0.001347609294773361, Avg. Test Loss: 0.0013805299531668425\n",
      "Epoch: 322, Avg. Train Loss: 0.0013384552304308082, Avg. Test Loss: 0.0013706901809200644\n",
      "Epoch: 323, Avg. Train Loss: 0.00133071010824033, Avg. Test Loss: 0.0013621398247778416\n",
      "Epoch: 324, Avg. Train Loss: 0.0013223514800111567, Avg. Test Loss: 0.0013531161239370704\n",
      "Epoch: 325, Avg. Train Loss: 0.0013126335783623332, Avg. Test Loss: 0.001346461707726121\n",
      "Epoch: 326, Avg. Train Loss: 0.0013051765434833806, Avg. Test Loss: 0.0013372452231124043\n",
      "Epoch: 327, Avg. Train Loss: 0.0012988397570023703, Avg. Test Loss: 0.0013345532352104783\n",
      "Epoch: 328, Avg. Train Loss: 0.001291964901611209, Avg. Test Loss: 0.0013217753730714321\n",
      "Epoch: 329, Avg. Train Loss: 0.001284343832129136, Avg. Test Loss: 0.0013139016227796674\n",
      "Epoch: 330, Avg. Train Loss: 0.001276343519431214, Avg. Test Loss: 0.0013062182115390897\n",
      "Epoch: 331, Avg. Train Loss: 0.0012687140599239705, Avg. Test Loss: 0.0012981602922081947\n",
      "Epoch: 332, Avg. Train Loss: 0.0012612399877980351, Avg. Test Loss: 0.0012909742072224617\n",
      "Epoch: 333, Avg. Train Loss: 0.0012533344642454108, Avg. Test Loss: 0.0012832935899496078\n",
      "Epoch: 334, Avg. Train Loss: 0.0012468885993151817, Avg. Test Loss: 0.0012762960977852345\n",
      "Epoch: 335, Avg. Train Loss: 0.0012401055495882796, Avg. Test Loss: 0.0012686591362580657\n",
      "Epoch: 336, Avg. Train Loss: 0.0012330685845078077, Avg. Test Loss: 0.0012621356872841716\n",
      "Epoch: 337, Avg. Train Loss: 0.0012246004852661213, Avg. Test Loss: 0.0012550352839753032\n",
      "Epoch: 338, Avg. Train Loss: 0.0012186230647615915, Avg. Test Loss: 0.0012482150923460722\n",
      "Epoch: 339, Avg. Train Loss: 0.0012114356098653271, Avg. Test Loss: 0.00124121003318578\n",
      "Epoch: 340, Avg. Train Loss: 0.0012046979539919384, Avg. Test Loss: 0.0012358156964182854\n",
      "Epoch: 341, Avg. Train Loss: 0.0011993024882665554, Avg. Test Loss: 0.0012270112056285143\n",
      "Epoch: 342, Avg. Train Loss: 0.001191196454212416, Avg. Test Loss: 0.0012212565634399652\n",
      "Epoch: 343, Avg. Train Loss: 0.0011854748631459336, Avg. Test Loss: 0.0012145598884671926\n",
      "Epoch: 344, Avg. Train Loss: 0.0011791821953645626, Avg. Test Loss: 0.001206978689879179\n",
      "Epoch: 345, Avg. Train Loss: 0.0011731168163160598, Avg. Test Loss: 0.0012005328899249434\n",
      "Epoch: 346, Avg. Train Loss: 0.0011658290330710452, Avg. Test Loss: 0.0011946095619350672\n",
      "Epoch: 347, Avg. Train Loss: 0.0011593037106226696, Avg. Test Loss: 0.00118727283552289\n",
      "Epoch: 348, Avg. Train Loss: 0.0011533129213074612, Avg. Test Loss: 0.0011854032054543495\n",
      "Epoch: 349, Avg. Train Loss: 0.0011477259794510034, Avg. Test Loss: 0.001174314646050334\n",
      "Epoch: 350, Avg. Train Loss: 0.001138591613663837, Avg. Test Loss: 0.001168245100416243\n",
      "Epoch: 351, Avg. Train Loss: 0.0011341897337589152, Avg. Test Loss: 0.001161416876129806\n",
      "Epoch: 352, Avg. Train Loss: 0.0011277400785623941, Avg. Test Loss: 0.0011546866735443473\n",
      "Epoch: 353, Avg. Train Loss: 0.0011217610905120193, Avg. Test Loss: 0.0011492406483739614\n",
      "Epoch: 354, Avg. Train Loss: 0.001114697715397491, Avg. Test Loss: 0.0011426928685978055\n",
      "Epoch: 355, Avg. Train Loss: 0.0011096854618382315, Avg. Test Loss: 0.0011357550974935293\n",
      "Epoch: 356, Avg. Train Loss: 0.0011035367185899684, Avg. Test Loss: 0.0011299520265311003\n",
      "Epoch: 357, Avg. Train Loss: 0.0010967128341584358, Avg. Test Loss: 0.0011235277634114027\n",
      "Epoch: 358, Avg. Train Loss: 0.0010897938817262995, Avg. Test Loss: 0.00111696170642972\n",
      "Epoch: 359, Avg. Train Loss: 0.0010841068064490723, Avg. Test Loss: 0.001111192861571908\n",
      "Epoch: 360, Avg. Train Loss: 0.0010780555190691768, Avg. Test Loss: 0.00110485905315727\n",
      "Epoch: 361, Avg. Train Loss: 0.0010710765288189747, Avg. Test Loss: 0.0010994750773534179\n",
      "Epoch: 362, Avg. Train Loss: 0.0010654896248651798, Avg. Test Loss: 0.0010931480210274458\n",
      "Epoch: 363, Avg. Train Loss: 0.0010586165536065088, Avg. Test Loss: 0.0010866106022149324\n",
      "Epoch: 364, Avg. Train Loss: 0.001052386660756933, Avg. Test Loss: 0.0010798489674925804\n",
      "Epoch: 365, Avg. Train Loss: 0.001047015690981129, Avg. Test Loss: 0.0010733662638813257\n",
      "Epoch: 366, Avg. Train Loss: 0.0010399446324553601, Avg. Test Loss: 0.0010681322310119867\n",
      "Epoch: 367, Avg. Train Loss: 0.001035909551509851, Avg. Test Loss: 0.0010652202181518078\n",
      "Epoch: 368, Avg. Train Loss: 0.0010293186412106247, Avg. Test Loss: 0.0010558625217527151\n",
      "Epoch: 369, Avg. Train Loss: 0.0010226979285890107, Avg. Test Loss: 0.0010502783115953207\n",
      "Epoch: 370, Avg. Train Loss: 0.0010163362116314644, Avg. Test Loss: 0.001043794327415526\n",
      "Epoch: 371, Avg. Train Loss: 0.001010813137115694, Avg. Test Loss: 0.0010383924236521125\n",
      "Epoch: 372, Avg. Train Loss: 0.0010050032084786096, Avg. Test Loss: 0.0010312879458069801\n",
      "Epoch: 373, Avg. Train Loss: 0.0009991737180064584, Avg. Test Loss: 0.0010248011676594615\n",
      "Epoch: 374, Avg. Train Loss: 0.000993892474663119, Avg. Test Loss: 0.0010191705077886581\n",
      "Epoch: 375, Avg. Train Loss: 0.0009867283041848866, Avg. Test Loss: 0.0010126786073669791\n",
      "Epoch: 376, Avg. Train Loss: 0.000981348986347574, Avg. Test Loss: 0.0010072143049910665\n",
      "Epoch: 377, Avg. Train Loss: 0.0009752727752594753, Avg. Test Loss: 0.001001080614514649\n",
      "Epoch: 378, Avg. Train Loss: 0.000969536833974078, Avg. Test Loss: 0.0009944378398358822\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 379, Avg. Train Loss: 0.0009638089091018882, Avg. Test Loss: 0.000992300221696496\n",
      "Epoch: 380, Avg. Train Loss: 0.0009587979997334958, Avg. Test Loss: 0.0009825819870457053\n",
      "Epoch: 381, Avg. Train Loss: 0.0009512614504824025, Avg. Test Loss: 0.0009807719616219401\n",
      "Epoch: 382, Avg. Train Loss: 0.0009463754479859977, Avg. Test Loss: 0.0009710693266242743\n",
      "Epoch: 383, Avg. Train Loss: 0.0009399307593919857, Avg. Test Loss: 0.0009647971019148827\n",
      "Epoch: 384, Avg. Train Loss: 0.0009346495038656474, Avg. Test Loss: 0.0009597417083568871\n",
      "Epoch: 385, Avg. Train Loss: 0.0009281601226173861, Avg. Test Loss: 0.0009544985368847847\n",
      "Epoch: 386, Avg. Train Loss: 0.0009245689143426716, Avg. Test Loss: 0.0009485606569796801\n",
      "Epoch: 387, Avg. Train Loss: 0.0009158544951703313, Avg. Test Loss: 0.0009411536739207804\n",
      "Epoch: 388, Avg. Train Loss: 0.0009112931912505003, Avg. Test Loss: 0.000936292577534914\n",
      "Epoch: 389, Avg. Train Loss: 0.0009060837951120595, Avg. Test Loss: 0.0009319255477748811\n",
      "Epoch: 390, Avg. Train Loss: 0.0009006404529087418, Avg. Test Loss: 0.0009255821933038533\n",
      "Epoch: 391, Avg. Train Loss: 0.0008952861372922915, Avg. Test Loss: 0.0009185372618958354\n",
      "Epoch: 392, Avg. Train Loss: 0.0008864390249580665, Avg. Test Loss: 0.000912852119654417\n",
      "Epoch: 393, Avg. Train Loss: 0.000883270887560536, Avg. Test Loss: 0.0009068275685422122\n",
      "Epoch: 394, Avg. Train Loss: 0.0008763026427152719, Avg. Test Loss: 0.0009018847486004233\n",
      "Epoch: 395, Avg. Train Loss: 0.0008714251453056931, Avg. Test Loss: 0.0008975280215963721\n",
      "Epoch: 396, Avg. Train Loss: 0.0008652144474475536, Avg. Test Loss: 0.0008902999688871205\n",
      "Epoch: 397, Avg. Train Loss: 0.0008594240170232085, Avg. Test Loss: 0.000883763306774199\n",
      "Epoch: 398, Avg. Train Loss: 0.0008543427535441032, Avg. Test Loss: 0.000877929967828095\n",
      "Epoch: 399, Avg. Train Loss: 0.0008488868087053646, Avg. Test Loss: 0.0008729904657229781\n",
      "Epoch: 400, Avg. Train Loss: 0.0008431067744399919, Avg. Test Loss: 0.0008667987422086298\n",
      "Epoch: 401, Avg. Train Loss: 0.0008376068286706022, Avg. Test Loss: 0.0008617477724328637\n",
      "Epoch: 402, Avg. Train Loss: 0.0008322964138134794, Avg. Test Loss: 0.0008559223497286439\n",
      "Epoch: 403, Avg. Train Loss: 0.0008263631363745865, Avg. Test Loss: 0.0008502274286001921\n",
      "Epoch: 404, Avg. Train Loss: 0.0008210054663724677, Avg. Test Loss: 0.0008451549801975489\n",
      "Epoch: 405, Avg. Train Loss: 0.000816718787550493, Avg. Test Loss: 0.0008408906869590282\n",
      "Epoch: 406, Avg. Train Loss: 0.0008103041774268414, Avg. Test Loss: 0.0008333376026712358\n",
      "Epoch: 407, Avg. Train Loss: 0.0008037867373786867, Avg. Test Loss: 0.0008302959031425416\n",
      "Epoch: 408, Avg. Train Loss: 0.0007999047439350465, Avg. Test Loss: 0.0008229920640587807\n",
      "Epoch: 409, Avg. Train Loss: 0.0007943112530399027, Avg. Test Loss: 0.0008177222916856408\n",
      "Epoch: 410, Avg. Train Loss: 0.0007884104649514653, Avg. Test Loss: 0.0008121362770907581\n",
      "Epoch: 411, Avg. Train Loss: 0.0007840510861146762, Avg. Test Loss: 0.0008063956047408283\n",
      "Epoch: 412, Avg. Train Loss: 0.0007786739585098139, Avg. Test Loss: 0.0008008731529116631\n",
      "Epoch: 413, Avg. Train Loss: 0.000772960873883824, Avg. Test Loss: 0.0007952432497404516\n",
      "Epoch: 414, Avg. Train Loss: 0.0007674466036151835, Avg. Test Loss: 0.0007902105571702123\n",
      "Epoch: 415, Avg. Train Loss: 0.0007622331965628058, Avg. Test Loss: 0.000784761446993798\n",
      "Epoch: 416, Avg. Train Loss: 0.0007576139205200381, Avg. Test Loss: 0.000780040689278394\n",
      "Epoch: 417, Avg. Train Loss: 0.0007517965940953514, Avg. Test Loss: 0.0007760507287457585\n",
      "Epoch: 418, Avg. Train Loss: 0.0007472875593013542, Avg. Test Loss: 0.0007705909665673971\n",
      "Epoch: 419, Avg. Train Loss: 0.0007433795659846171, Avg. Test Loss: 0.0007643456920050085\n",
      "Epoch: 420, Avg. Train Loss: 0.0007362782408288399, Avg. Test Loss: 0.0007599337841384113\n",
      "Epoch: 421, Avg. Train Loss: 0.0007320174522329728, Avg. Test Loss: 0.0007553871255367994\n",
      "Epoch: 422, Avg. Train Loss: 0.000726626709450123, Avg. Test Loss: 0.0007486190879717469\n",
      "Epoch: 423, Avg. Train Loss: 0.0007227106794151803, Avg. Test Loss: 0.0007467343821190298\n",
      "Epoch: 424, Avg. Train Loss: 0.0007176173276939365, Avg. Test Loss: 0.0007382846088148654\n",
      "Epoch: 425, Avg. Train Loss: 0.0007116595570127978, Avg. Test Loss: 0.0007362409378401935\n",
      "Epoch: 426, Avg. Train Loss: 0.0007063811211738476, Avg. Test Loss: 0.0007286684704013169\n",
      "Epoch: 427, Avg. Train Loss: 0.0007021333372523619, Avg. Test Loss: 0.0007248466718010604\n",
      "Epoch: 428, Avg. Train Loss: 0.0006978780689086159, Avg. Test Loss: 0.0007195922662504017\n",
      "Epoch: 429, Avg. Train Loss: 0.0006930283636266235, Avg. Test Loss: 0.000714422669261694\n",
      "Epoch: 430, Avg. Train Loss: 0.0006868202553325614, Avg. Test Loss: 0.0007091356674209237\n",
      "Epoch: 431, Avg. Train Loss: 0.0006834808926552881, Avg. Test Loss: 0.0007056728354655206\n",
      "Epoch: 432, Avg. Train Loss: 0.0006787171235394686, Avg. Test Loss: 0.0007000325131230056\n",
      "Epoch: 433, Avg. Train Loss: 0.0006748696161044198, Avg. Test Loss: 0.0006954357959330082\n",
      "Epoch: 434, Avg. Train Loss: 0.0006695738533338488, Avg. Test Loss: 0.0006906272610649467\n",
      "Epoch: 435, Avg. Train Loss: 0.0006664890138064186, Avg. Test Loss: 0.0006859955610707402\n",
      "Epoch: 436, Avg. Train Loss: 0.0006612516062464132, Avg. Test Loss: 0.0006830352358520031\n",
      "Epoch: 437, Avg. Train Loss: 0.0006561989768754777, Avg. Test Loss: 0.000677326344884932\n",
      "Epoch: 438, Avg. Train Loss: 0.0006520037246911331, Avg. Test Loss: 0.0006728592561557889\n",
      "Epoch: 439, Avg. Train Loss: 0.0006474700897152341, Avg. Test Loss: 0.0006716444622725248\n",
      "Epoch: 440, Avg. Train Loss: 0.0006452889633798149, Avg. Test Loss: 0.0006644888198934495\n",
      "Epoch: 441, Avg. Train Loss: 0.0006392478799382441, Avg. Test Loss: 0.0006601337809115648\n",
      "Epoch: 442, Avg. Train Loss: 0.000634584238828528, Avg. Test Loss: 0.0006556269363500178\n",
      "Epoch: 443, Avg. Train Loss: 0.000632355865470112, Avg. Test Loss: 0.0006510110106319189\n",
      "Epoch: 444, Avg. Train Loss: 0.0006268514945648264, Avg. Test Loss: 0.00064786960138008\n",
      "Epoch: 445, Avg. Train Loss: 0.0006226980178833528, Avg. Test Loss: 0.0006436839466914535\n",
      "Epoch: 446, Avg. Train Loss: 0.0006195256719365716, Avg. Test Loss: 0.0006397308898158371\n",
      "Epoch: 447, Avg. Train Loss: 0.0006151178805699008, Avg. Test Loss: 0.0006372908246703446\n",
      "Epoch: 448, Avg. Train Loss: 0.0006116116311141225, Avg. Test Loss: 0.0006319118547253311\n",
      "Epoch: 449, Avg. Train Loss: 0.0006070190168873862, Avg. Test Loss: 0.0006273459875956178\n",
      "Epoch: 450, Avg. Train Loss: 0.0006039421274435034, Avg. Test Loss: 0.0006249485304579139\n",
      "Epoch: 451, Avg. Train Loss: 0.0006001994235787627, Avg. Test Loss: 0.0006210652063600719\n",
      "Epoch: 452, Avg. Train Loss: 0.0005963579007034558, Avg. Test Loss: 0.0006171829300001264\n",
      "Epoch: 453, Avg. Train Loss: 0.0005925177788730104, Avg. Test Loss: 0.0006133796414360404\n",
      "Epoch: 454, Avg. Train Loss: 0.0005903956426177607, Avg. Test Loss: 0.0006095814751461148\n",
      "Epoch: 455, Avg. Train Loss: 0.0005858563127667579, Avg. Test Loss: 0.0006063997861929238\n",
      "Epoch: 456, Avg. Train Loss: 0.0005826585097671595, Avg. Test Loss: 0.0006036084378138185\n",
      "Epoch: 457, Avg. Train Loss: 0.0005801584947919256, Avg. Test Loss: 0.000600501021835953\n",
      "Epoch: 458, Avg. Train Loss: 0.0005764989060523032, Avg. Test Loss: 0.0005964672891423106\n",
      "Epoch: 459, Avg. Train Loss: 0.0005742561161453121, Avg. Test Loss: 0.0005951901548542082\n",
      "Epoch: 460, Avg. Train Loss: 0.0005720200268876587, Avg. Test Loss: 0.000594169890973717\n",
      "Epoch: 461, Avg. Train Loss: 0.0005681345139110331, Avg. Test Loss: 0.000587375950999558\n",
      "Epoch: 462, Avg. Train Loss: 0.0005642632888846619, Avg. Test Loss: 0.0005852011381648481\n",
      "Epoch: 463, Avg. Train Loss: 0.0005617728416244824, Avg. Test Loss: 0.0005821888917125762\n",
      "Epoch: 464, Avg. Train Loss: 0.0005593452897724198, Avg. Test Loss: 0.0005811554146930575\n",
      "Epoch: 465, Avg. Train Loss: 0.0005564084614973602, Avg. Test Loss: 0.0005772706354036927\n",
      "Epoch: 466, Avg. Train Loss: 0.0005541812617678282, Avg. Test Loss: 0.000573804893065244\n",
      "Epoch: 467, Avg. Train Loss: 0.0005514784079846428, Avg. Test Loss: 0.0005723224603570998\n",
      "Epoch: 468, Avg. Train Loss: 0.0005480171652337492, Avg. Test Loss: 0.0005674994899891317\n",
      "Epoch: 469, Avg. Train Loss: 0.0005469831846502804, Avg. Test Loss: 0.0005666590295732021\n",
      "Epoch: 470, Avg. Train Loss: 0.0005441251099867702, Avg. Test Loss: 0.0005642693140543997\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 471, Avg. Train Loss: 0.0005413477957454445, Avg. Test Loss: 0.0005609704530797899\n",
      "Epoch: 472, Avg. Train Loss: 0.0005388871677284844, Avg. Test Loss: 0.0005590744549408555\n",
      "Epoch: 473, Avg. Train Loss: 0.0005359924493119294, Avg. Test Loss: 0.0005567939369939268\n",
      "Epoch: 474, Avg. Train Loss: 0.0005340160393199428, Avg. Test Loss: 0.0005545204039663076\n",
      "Epoch: 475, Avg. Train Loss: 0.0005326128015186378, Avg. Test Loss: 0.0005534025258384645\n",
      "Epoch: 476, Avg. Train Loss: 0.0005307684795995958, Avg. Test Loss: 0.0005503245047293603\n",
      "Epoch: 477, Avg. Train Loss: 0.0005279818555166901, Avg. Test Loss: 0.0005484120338223875\n",
      "Epoch: 478, Avg. Train Loss: 0.0005261655923975415, Avg. Test Loss: 0.0005489806644618511\n",
      "Epoch: 479, Avg. Train Loss: 0.0005260925201244305, Avg. Test Loss: 0.0005445986753329635\n",
      "Epoch: 480, Avg. Train Loss: 0.000522856448971948, Avg. Test Loss: 0.0005426177522167563\n",
      "Epoch: 481, Avg. Train Loss: 0.0005218480154601207, Avg. Test Loss: 0.0005431512254290283\n",
      "Epoch: 482, Avg. Train Loss: 0.0005197429611228493, Avg. Test Loss: 0.000539130880497396\n",
      "Epoch: 483, Avg. Train Loss: 0.000518404770382615, Avg. Test Loss: 0.0005379466456361115\n",
      "Epoch: 484, Avg. Train Loss: 0.0005170183356439825, Avg. Test Loss: 0.0005372824962250888\n",
      "Epoch: 485, Avg. Train Loss: 0.000515452975970368, Avg. Test Loss: 0.0005348613485693932\n",
      "Epoch: 486, Avg. Train Loss: 0.000512954136654518, Avg. Test Loss: 0.0005340236239135265\n",
      "Epoch: 487, Avg. Train Loss: 0.0005122280536154502, Avg. Test Loss: 0.0005332619184628129\n",
      "Epoch: 488, Avg. Train Loss: 0.0005101080487081564, Avg. Test Loss: 0.0005296316230669618\n",
      "Epoch: 489, Avg. Train Loss: 0.000508637499161671, Avg. Test Loss: 0.0005295042064972222\n",
      "Epoch: 490, Avg. Train Loss: 0.0005079473038528894, Avg. Test Loss: 0.0005275382427498698\n",
      "Epoch: 491, Avg. Train Loss: 0.000508116252265524, Avg. Test Loss: 0.0005260945181362331\n",
      "Epoch: 492, Avg. Train Loss: 0.0005058834321125475, Avg. Test Loss: 0.000526986550539732\n",
      "Epoch: 493, Avg. Train Loss: 0.0005036301025579316, Avg. Test Loss: 0.0005220581078901887\n",
      "Epoch: 494, Avg. Train Loss: 0.0005026966892453561, Avg. Test Loss: 0.0005210054805502295\n",
      "Epoch: 495, Avg. Train Loss: 0.0005009766643715286, Avg. Test Loss: 0.0005244992207735777\n",
      "Epoch: 496, Avg. Train Loss: 0.000500704517837094, Avg. Test Loss: 0.0005193442921154201\n",
      "Epoch: 497, Avg. Train Loss: 0.0004990439101252271, Avg. Test Loss: 0.0005206007044762373\n",
      "Epoch: 498, Avg. Train Loss: 0.0004983873710274523, Avg. Test Loss: 0.0005163361201994121\n",
      "Epoch: 499, Avg. Train Loss: 0.0004968787293047319, Avg. Test Loss: 0.0005162504385225475\n",
      "Epoch: 500, Avg. Train Loss: 0.0004965826628058282, Avg. Test Loss: 0.0005181861342862248\n",
      "Epoch: 501, Avg. Train Loss: 0.000495452354635047, Avg. Test Loss: 0.0005141118308529258\n",
      "Epoch: 502, Avg. Train Loss: 0.0004943540762449333, Avg. Test Loss: 0.0005120684509165585\n",
      "Epoch: 503, Avg. Train Loss: 0.0004932288504151497, Avg. Test Loss: 0.0005121863796375692\n",
      "Epoch: 504, Avg. Train Loss: 0.0004931154415866924, Avg. Test Loss: 0.000511067861225456\n",
      "Epoch: 505, Avg. Train Loss: 0.0004929002025164664, Avg. Test Loss: 0.0005104410229250789\n",
      "Epoch: 506, Avg. Train Loss: 0.0004922234504700227, Avg. Test Loss: 0.0005090509075671434\n",
      "Epoch: 507, Avg. Train Loss: 0.0004907251737719445, Avg. Test Loss: 0.0005077932728454471\n",
      "Epoch: 508, Avg. Train Loss: 0.00048801223043525634, Avg. Test Loss: 0.0005077456007711589\n",
      "Epoch: 509, Avg. Train Loss: 0.0004888003398285269, Avg. Test Loss: 0.0005059746908955276\n",
      "Epoch: 510, Avg. Train Loss: 0.0004887008588750262, Avg. Test Loss: 0.0005064117722213268\n",
      "Epoch: 511, Avg. Train Loss: 0.0004874013038081399, Avg. Test Loss: 0.0005046103033237159\n",
      "Epoch: 512, Avg. Train Loss: 0.00048711159548094107, Avg. Test Loss: 0.000503707502502948\n",
      "Epoch: 513, Avg. Train Loss: 0.00048512783846384736, Avg. Test Loss: 0.0005023476551286876\n",
      "Epoch: 514, Avg. Train Loss: 0.00048437890214953833, Avg. Test Loss: 0.0005029426538385451\n",
      "Epoch: 515, Avg. Train Loss: 0.00048526541700824924, Avg. Test Loss: 0.0005039918469265103\n",
      "Epoch: 516, Avg. Train Loss: 0.0004835545997741784, Avg. Test Loss: 0.0005008557927794755\n",
      "Epoch: 517, Avg. Train Loss: 0.0004837862980757775, Avg. Test Loss: 0.0005023395642638206\n",
      "Epoch: 518, Avg. Train Loss: 0.0004815644202862195, Avg. Test Loss: 0.0004994558985345066\n",
      "Epoch: 519, Avg. Train Loss: 0.0004804510715265953, Avg. Test Loss: 0.0004987862193956971\n",
      "Epoch: 520, Avg. Train Loss: 0.0004799250468644205, Avg. Test Loss: 0.0004988081054762006\n",
      "Epoch: 521, Avg. Train Loss: 0.0004800685043825746, Avg. Test Loss: 0.0004976456402800977\n",
      "Epoch: 522, Avg. Train Loss: 0.0004792956514879628, Avg. Test Loss: 0.000495888467412442\n",
      "Epoch: 523, Avg. Train Loss: 0.0004779351685672652, Avg. Test Loss: 0.000496952619869262\n",
      "Epoch: 524, Avg. Train Loss: 0.000477601348985593, Avg. Test Loss: 0.0004956769989803433\n",
      "Epoch: 525, Avg. Train Loss: 0.0004769692252942383, Avg. Test Loss: 0.0004980614176020026\n",
      "Epoch: 526, Avg. Train Loss: 0.0004769333186126206, Avg. Test Loss: 0.0004930460709147155\n",
      "Epoch: 527, Avg. Train Loss: 0.00047591467100996956, Avg. Test Loss: 0.0004923765081912279\n",
      "Epoch: 528, Avg. Train Loss: 0.00047612289199605584, Avg. Test Loss: 0.0004926988040097058\n",
      "Epoch: 529, Avg. Train Loss: 0.00047367721184178493, Avg. Test Loss: 0.0004901603097096086\n",
      "Epoch: 530, Avg. Train Loss: 0.00047347323053927964, Avg. Test Loss: 0.0004895419697277248\n",
      "Epoch: 531, Avg. Train Loss: 0.0004733190533358517, Avg. Test Loss: 0.00048773863818496466\n",
      "Epoch: 532, Avg. Train Loss: 0.0004726046240119653, Avg. Test Loss: 0.000487856799736619\n",
      "Epoch: 533, Avg. Train Loss: 0.0004718528998214318, Avg. Test Loss: 0.00048623571638017893\n",
      "Epoch: 534, Avg. Train Loss: 0.0004702379695562169, Avg. Test Loss: 0.0004885069793090224\n",
      "Epoch: 535, Avg. Train Loss: 0.0004697847301898481, Avg. Test Loss: 0.00048532552318647504\n",
      "Epoch: 536, Avg. Train Loss: 0.00046967436305009, Avg. Test Loss: 0.0004845276416745037\n",
      "Epoch: 537, Avg. Train Loss: 0.0004685214615080419, Avg. Test Loss: 0.00048363039968535304\n",
      "Epoch: 538, Avg. Train Loss: 0.0004681335988205446, Avg. Test Loss: 0.00048563507152721286\n",
      "Epoch: 539, Avg. Train Loss: 0.00046806100303805324, Avg. Test Loss: 0.00048473841161467135\n",
      "Epoch: 540, Avg. Train Loss: 0.000468346560346829, Avg. Test Loss: 0.0004885807866230607\n",
      "Epoch: 541, Avg. Train Loss: 0.0004696707501141138, Avg. Test Loss: 0.00048371960292570293\n",
      "Epoch: 542, Avg. Train Loss: 0.0004669035728046194, Avg. Test Loss: 0.0004832391277886927\n",
      "Epoch: 543, Avg. Train Loss: 0.0004677889296016114, Avg. Test Loss: 0.0004803290939889848\n",
      "Epoch: 544, Avg. Train Loss: 0.00046521374552380726, Avg. Test Loss: 0.0004822283808607608\n",
      "Epoch: 545, Avg. Train Loss: 0.00046680590305693965, Avg. Test Loss: 0.0004810763639397919\n",
      "Epoch: 546, Avg. Train Loss: 0.0004647622550945989, Avg. Test Loss: 0.0004813354171346873\n",
      "Epoch: 547, Avg. Train Loss: 0.0004645558872779961, Avg. Test Loss: 0.00048127496847882867\n",
      "Epoch: 548, Avg. Train Loss: 0.00046336930854310994, Avg. Test Loss: 0.00047681928845122457\n",
      "Epoch: 549, Avg. Train Loss: 0.0004640122473532291, Avg. Test Loss: 0.00047723110765218735\n",
      "Epoch: 550, Avg. Train Loss: 0.0004642244921130843, Avg. Test Loss: 0.0004765467019751668\n",
      "Epoch: 551, Avg. Train Loss: 0.00046216273276936695, Avg. Test Loss: 0.0004760574665851891\n",
      "Epoch: 552, Avg. Train Loss: 0.0004617685173248309, Avg. Test Loss: 0.00047538045328110456\n",
      "Epoch: 553, Avg. Train Loss: 0.00046075502110017074, Avg. Test Loss: 0.0004756356938742101\n",
      "Epoch: 554, Avg. Train Loss: 0.00046283285726446573, Avg. Test Loss: 0.000474432046758011\n",
      "Epoch: 555, Avg. Train Loss: 0.0004622073421731245, Avg. Test Loss: 0.0004752835084218532\n",
      "Epoch: 556, Avg. Train Loss: 0.00046056661305429286, Avg. Test Loss: 0.0004748067876789719\n",
      "Epoch: 557, Avg. Train Loss: 0.00045955561163705275, Avg. Test Loss: 0.00047928281128406525\n",
      "Epoch: 558, Avg. Train Loss: 0.0004594329999066716, Avg. Test Loss: 0.0004764008044730872\n",
      "Epoch: 559, Avg. Train Loss: 0.00046038006968406395, Avg. Test Loss: 0.00047232088400051\n",
      "Epoch: 560, Avg. Train Loss: 0.0004591833134073504, Avg. Test Loss: 0.0004762774333357811\n",
      "Epoch: 561, Avg. Train Loss: 0.000458203955975816, Avg. Test Loss: 0.0004705995670519769\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 562, Avg. Train Loss: 0.00045744774844172563, Avg. Test Loss: 0.00047194925718940794\n",
      "Epoch: 563, Avg. Train Loss: 0.00045932466055937976, Avg. Test Loss: 0.0004717414849437773\n",
      "Epoch: 564, Avg. Train Loss: 0.00045756253665638004, Avg. Test Loss: 0.00047163479030132294\n",
      "Epoch: 565, Avg. Train Loss: 0.00045766843737341293, Avg. Test Loss: 0.0004729311622213572\n",
      "Epoch: 566, Avg. Train Loss: 0.0004577876629069621, Avg. Test Loss: 0.00047157815424725413\n",
      "Epoch: 567, Avg. Train Loss: 0.00045591402260131787, Avg. Test Loss: 0.00047126031131483614\n",
      "Epoch: 568, Avg. Train Loss: 0.0004572965357680047, Avg. Test Loss: 0.0004708192136604339\n",
      "Epoch: 569, Avg. Train Loss: 0.0004559880322885028, Avg. Test Loss: 0.00046999097685329616\n",
      "Epoch: 570, Avg. Train Loss: 0.00045574508501801554, Avg. Test Loss: 0.0004686130560003221\n",
      "Epoch: 571, Avg. Train Loss: 0.0004559222007776762, Avg. Test Loss: 0.0004723567981272936\n",
      "Epoch: 572, Avg. Train Loss: 0.00045486652701118486, Avg. Test Loss: 0.00047020817873999476\n",
      "Epoch: 573, Avg. Train Loss: 0.00045701087151957286, Avg. Test Loss: 0.00047058967174962163\n",
      "Epoch: 574, Avg. Train Loss: 0.0004538542193057405, Avg. Test Loss: 0.0004669638001359999\n",
      "Epoch: 575, Avg. Train Loss: 0.0004533590156000194, Avg. Test Loss: 0.0004662671126425266\n",
      "Epoch: 576, Avg. Train Loss: 0.000453499527539798, Avg. Test Loss: 0.000473113264888525\n",
      "Epoch: 577, Avg. Train Loss: 0.0004542938827504512, Avg. Test Loss: 0.00046608640695922077\n",
      "Epoch: 578, Avg. Train Loss: 0.0004535751007118284, Avg. Test Loss: 0.00046689968439750373\n",
      "Epoch: 579, Avg. Train Loss: 0.00045355331547948166, Avg. Test Loss: 0.00046591710997745395\n",
      "Epoch: 580, Avg. Train Loss: 0.0004532878330453884, Avg. Test Loss: 0.00046616262989118695\n",
      "Epoch: 581, Avg. Train Loss: 0.00045256655078467937, Avg. Test Loss: 0.00046869978541508317\n",
      "Epoch: 582, Avg. Train Loss: 0.00045386804497887404, Avg. Test Loss: 0.0004665522719733417\n",
      "Epoch: 583, Avg. Train Loss: 0.00045338195889408505, Avg. Test Loss: 0.00046641076914966106\n",
      "Epoch: 584, Avg. Train Loss: 0.0004521223775999144, Avg. Test Loss: 0.00046365702291950583\n",
      "Epoch: 585, Avg. Train Loss: 0.0004536566834864315, Avg. Test Loss: 0.0004709913919214159\n",
      "Epoch: 586, Avg. Train Loss: 0.00045152323734729964, Avg. Test Loss: 0.00046421695151366293\n",
      "Epoch: 587, Avg. Train Loss: 0.00045110782483852535, Avg. Test Loss: 0.00046506841317750514\n",
      "Epoch: 588, Avg. Train Loss: 0.00045248676906339824, Avg. Test Loss: 0.00046497557195834816\n",
      "Epoch: 589, Avg. Train Loss: 0.0004506782556851503, Avg. Test Loss: 0.00046431642840616405\n",
      "Epoch: 590, Avg. Train Loss: 0.00045065442438583906, Avg. Test Loss: 0.00046263248077593744\n",
      "Epoch: 591, Avg. Train Loss: 0.00045094586946719953, Avg. Test Loss: 0.00046265884884633124\n",
      "Epoch: 592, Avg. Train Loss: 0.0004507207797656139, Avg. Test Loss: 0.00046356217353604734\n",
      "Epoch: 593, Avg. Train Loss: 0.00045089586028764243, Avg. Test Loss: 0.0004651109629776329\n",
      "Epoch: 594, Avg. Train Loss: 0.00044958144805372455, Avg. Test Loss: 0.00046296865912154317\n",
      "Epoch: 595, Avg. Train Loss: 0.00045042424286759, Avg. Test Loss: 0.0004634281212929636\n",
      "Epoch: 596, Avg. Train Loss: 0.00044961413368582726, Avg. Test Loss: 0.00046234947512857616\n",
      "Epoch: 597, Avg. Train Loss: 0.00044963833250560213, Avg. Test Loss: 0.00046536276931874454\n",
      "Epoch: 598, Avg. Train Loss: 0.00045121012683308056, Avg. Test Loss: 0.0004625163273885846\n",
      "Epoch: 599, Avg. Train Loss: 0.00044787915959564403, Avg. Test Loss: 0.00046182257938198745\n",
      "Epoch: 600, Avg. Train Loss: 0.00044756320773537247, Avg. Test Loss: 0.00046046433271840215\n",
      "Epoch: 601, Avg. Train Loss: 0.0004490353539315334, Avg. Test Loss: 0.00046469707740470767\n",
      "Epoch: 602, Avg. Train Loss: 0.0004517384973993568, Avg. Test Loss: 0.000461489224107936\n",
      "Epoch: 603, Avg. Train Loss: 0.00044831906737716394, Avg. Test Loss: 0.00046042140456847847\n",
      "Epoch: 604, Avg. Train Loss: 0.00044860142258775615, Avg. Test Loss: 0.00046575217857025564\n",
      "Epoch: 605, Avg. Train Loss: 0.00044725493590217516, Avg. Test Loss: 0.00045899979886598885\n",
      "Epoch: 606, Avg. Train Loss: 0.00044803939513363985, Avg. Test Loss: 0.0004620831459760666\n",
      "Epoch: 607, Avg. Train Loss: 0.00044921177593709597, Avg. Test Loss: 0.0004604255373124033\n",
      "Epoch: 608, Avg. Train Loss: 0.00044840625974587925, Avg. Test Loss: 0.0004588150477502495\n",
      "Epoch: 609, Avg. Train Loss: 0.00044687321683023733, Avg. Test Loss: 0.00045951965148560703\n",
      "Epoch: 610, Avg. Train Loss: 0.0004470606759558757, Avg. Test Loss: 0.00046659435611218214\n",
      "Epoch: 611, Avg. Train Loss: 0.00044637605436904313, Avg. Test Loss: 0.00045896790106780827\n",
      "Epoch: 612, Avg. Train Loss: 0.00044584145558304914, Avg. Test Loss: 0.00045820308150723577\n",
      "Epoch: 613, Avg. Train Loss: 0.00044614501056521266, Avg. Test Loss: 0.00045867759035900235\n",
      "Epoch: 614, Avg. Train Loss: 0.00044636519051828355, Avg. Test Loss: 0.0004605515277944505\n",
      "Epoch: 615, Avg. Train Loss: 0.00044560277033164056, Avg. Test Loss: 0.00045828791917301714\n",
      "Epoch: 616, Avg. Train Loss: 0.0004467493509278135, Avg. Test Loss: 0.0004674142983276397\n",
      "Epoch: 617, Avg. Train Loss: 0.0004487937082114175, Avg. Test Loss: 0.0004602050466928631\n",
      "Epoch: 618, Avg. Train Loss: 0.00044529956391860926, Avg. Test Loss: 0.0004577483341563493\n",
      "Epoch: 619, Avg. Train Loss: 0.00044528207793117087, Avg. Test Loss: 0.00045809944276697934\n",
      "Epoch: 620, Avg. Train Loss: 0.00044601457734960454, Avg. Test Loss: 0.0004604517307598144\n",
      "Epoch: 621, Avg. Train Loss: 0.000445916255134656, Avg. Test Loss: 0.0004566004208754748\n",
      "Epoch: 622, Avg. Train Loss: 0.00044437510646381525, Avg. Test Loss: 0.0004574818885885179\n",
      "Epoch: 623, Avg. Train Loss: 0.00044509272637971957, Avg. Test Loss: 0.00046060423483140767\n",
      "Epoch: 624, Avg. Train Loss: 0.0004454177071957654, Avg. Test Loss: 0.0004561494861263782\n",
      "Epoch: 625, Avg. Train Loss: 0.000442776296336507, Avg. Test Loss: 0.0004568690783344209\n",
      "Epoch: 626, Avg. Train Loss: 0.00044434227395889373, Avg. Test Loss: 0.00045639093150384724\n",
      "Epoch: 627, Avg. Train Loss: 0.0004452119065654399, Avg. Test Loss: 0.00045785310794599354\n",
      "Epoch: 628, Avg. Train Loss: 0.0004441484255272202, Avg. Test Loss: 0.0004570090095512569\n",
      "Epoch: 629, Avg. Train Loss: 0.00044477062413555594, Avg. Test Loss: 0.00045785107067786157\n",
      "Epoch: 630, Avg. Train Loss: 0.0004427029201652595, Avg. Test Loss: 0.0004575476050376892\n",
      "Epoch: 631, Avg. Train Loss: 0.0004436879907463959, Avg. Test Loss: 0.0004564209084492177\n",
      "Epoch: 632, Avg. Train Loss: 0.00044374824447427377, Avg. Test Loss: 0.0004566087736748159\n",
      "Epoch: 633, Avg. Train Loss: 0.00044293956408753644, Avg. Test Loss: 0.00045438893721438944\n",
      "Epoch: 634, Avg. Train Loss: 0.0004457845778995042, Avg. Test Loss: 0.0004609064490068704\n",
      "Epoch: 635, Avg. Train Loss: 0.00044432904728320104, Avg. Test Loss: 0.0004565319686662406\n",
      "Epoch: 636, Avg. Train Loss: 0.00044465022903412234, Avg. Test Loss: 0.000455344415968284\n",
      "Epoch: 637, Avg. Train Loss: 0.0004436707551872661, Avg. Test Loss: 0.0004557879001367837\n",
      "Epoch: 638, Avg. Train Loss: 0.00044225900959180193, Avg. Test Loss: 0.00045899918768554926\n",
      "Epoch: 639, Avg. Train Loss: 0.00044302099389782133, Avg. Test Loss: 0.00045439813402481377\n",
      "Epoch: 640, Avg. Train Loss: 0.000443369165052075, Avg. Test Loss: 0.00045548329944722354\n",
      "Epoch: 641, Avg. Train Loss: 0.00044162346383145207, Avg. Test Loss: 0.00045727010001428425\n",
      "Epoch: 642, Avg. Train Loss: 0.00044200627937328156, Avg. Test Loss: 0.00045584686449728906\n",
      "Epoch: 643, Avg. Train Loss: 0.00044185245276948565, Avg. Test Loss: 0.0004543070972431451\n",
      "Epoch: 644, Avg. Train Loss: 0.00044395754636308653, Avg. Test Loss: 0.00045599541044794023\n",
      "Epoch: 645, Avg. Train Loss: 0.0004406823549246372, Avg. Test Loss: 0.00045595155097544193\n",
      "Epoch: 646, Avg. Train Loss: 0.0004410826821735692, Avg. Test Loss: 0.0004547065182123333\n",
      "Epoch: 647, Avg. Train Loss: 0.0004424638497957223, Avg. Test Loss: 0.0004578819789458066\n",
      "Epoch: 648, Avg. Train Loss: 0.0004413826986714158, Avg. Test Loss: 0.00045445660362020135\n",
      "Epoch: 649, Avg. Train Loss: 0.0004419120892254246, Avg. Test Loss: 0.0004536541528068483\n",
      "Epoch: 650, Avg. Train Loss: 0.0004426134021974407, Avg. Test Loss: 0.0004537935310509056\n",
      "Epoch: 651, Avg. Train Loss: 0.0004411599027577701, Avg. Test Loss: 0.00045530969509854913\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 652, Avg. Train Loss: 0.0004402932421260968, Avg. Test Loss: 0.00045424854033626616\n",
      "Epoch: 653, Avg. Train Loss: 0.0004416896384967448, Avg. Test Loss: 0.00045536342076957226\n",
      "Epoch: 654, Avg. Train Loss: 0.0004411604936332117, Avg. Test Loss: 0.0004578126536216587\n",
      "Epoch: 655, Avg. Train Loss: 0.00044259687392907436, Avg. Test Loss: 0.0004537251079455018\n",
      "Epoch: 656, Avg. Train Loss: 0.0004406537066029688, Avg. Test Loss: 0.00045863163541071117\n",
      "Epoch: 657, Avg. Train Loss: 0.0004413375024532163, Avg. Test Loss: 0.00045251118717715144\n",
      "Epoch: 658, Avg. Train Loss: 0.00044056952884962216, Avg. Test Loss: 0.0004518204659689218\n",
      "Epoch: 659, Avg. Train Loss: 0.000439599116446537, Avg. Test Loss: 0.0004532747552730143\n",
      "Epoch: 660, Avg. Train Loss: 0.00044009040737914487, Avg. Test Loss: 0.00045185236376710236\n",
      "Epoch: 661, Avg. Train Loss: 0.0004389968911878938, Avg. Test Loss: 0.00045455372310243547\n",
      "Epoch: 662, Avg. Train Loss: 0.00043985805931760996, Avg. Test Loss: 0.0004511172301135957\n",
      "Epoch: 663, Avg. Train Loss: 0.0004395981594042982, Avg. Test Loss: 0.00045190477976575494\n",
      "Epoch: 664, Avg. Train Loss: 0.00043929625048063866, Avg. Test Loss: 0.0004517857450991869\n",
      "Epoch: 665, Avg. Train Loss: 0.00043941843648289525, Avg. Test Loss: 0.0004576425417326391\n",
      "Epoch: 666, Avg. Train Loss: 0.0004388626264191644, Avg. Test Loss: 0.0004502168158069253\n",
      "Epoch: 667, Avg. Train Loss: 0.0004407253412822218, Avg. Test Loss: 0.00045410270104184747\n",
      "Epoch: 668, Avg. Train Loss: 0.0004386202395666217, Avg. Test Loss: 0.00045231959666125476\n",
      "Epoch: 669, Avg. Train Loss: 0.0004397717427711414, Avg. Test Loss: 0.0004511414736043662\n",
      "Epoch: 670, Avg. Train Loss: 0.0004385444173199493, Avg. Test Loss: 0.0004524870018940419\n",
      "Epoch: 671, Avg. Train Loss: 0.00043919397149841453, Avg. Test Loss: 0.0004495181783568114\n",
      "Epoch: 672, Avg. Train Loss: 0.0004388202410895204, Avg. Test Loss: 0.00045790401054546237\n",
      "Epoch: 673, Avg. Train Loss: 0.00043893229219044535, Avg. Test Loss: 0.0004503671661950648\n",
      "Epoch: 674, Avg. Train Loss: 0.0004385363514979132, Avg. Test Loss: 0.00046002474846318364\n",
      "Epoch: 675, Avg. Train Loss: 0.00044224538290764875, Avg. Test Loss: 0.0004526230040937662\n",
      "Epoch: 676, Avg. Train Loss: 0.00043823114707307933, Avg. Test Loss: 0.00045187401701696217\n",
      "Epoch: 677, Avg. Train Loss: 0.0004383615863801868, Avg. Test Loss: 0.00045031020999886096\n",
      "Epoch: 678, Avg. Train Loss: 0.0004375815461931187, Avg. Test Loss: 0.0004514461033977568\n",
      "Epoch: 679, Avg. Train Loss: 0.00043719897972593127, Avg. Test Loss: 0.00044914535828866065\n",
      "Epoch: 680, Avg. Train Loss: 0.00043760575178122623, Avg. Test Loss: 0.0004489095008466393\n",
      "Epoch: 681, Avg. Train Loss: 0.0004381828563731857, Avg. Test Loss: 0.0004503904783632606\n",
      "Epoch: 682, Avg. Train Loss: 0.000437965898146463, Avg. Test Loss: 0.0004522472736425698\n",
      "Epoch: 683, Avg. Train Loss: 0.0004381861329230285, Avg. Test Loss: 0.0004582356777973473\n",
      "Epoch: 684, Avg. Train Loss: 0.0004379138171802773, Avg. Test Loss: 0.0004505318938754499\n",
      "Epoch: 685, Avg. Train Loss: 0.0004372499385025612, Avg. Test Loss: 0.0004528537392616272\n",
      "Epoch: 686, Avg. Train Loss: 0.00043702118848667066, Avg. Test Loss: 0.0004487778933253139\n",
      "Epoch: 687, Avg. Train Loss: 0.0004370474618004072, Avg. Test Loss: 0.00044882914517074823\n",
      "Epoch: 688, Avg. Train Loss: 0.0004381027172839399, Avg. Test Loss: 0.0004492976295296103\n",
      "Epoch: 689, Avg. Train Loss: 0.00043671496610460413, Avg. Test Loss: 0.0004474680172279477\n",
      "Epoch: 690, Avg. Train Loss: 0.0004370509434307297, Avg. Test Loss: 0.0004514448519330472\n",
      "Epoch: 691, Avg. Train Loss: 0.000436364225691271, Avg. Test Loss: 0.00044831394916400313\n",
      "Epoch: 692, Avg. Train Loss: 0.00043660734149324166, Avg. Test Loss: 0.00044828918180428445\n",
      "Epoch: 693, Avg. Train Loss: 0.00043654269850163093, Avg. Test Loss: 0.0004487638361752033\n",
      "Epoch: 694, Avg. Train Loss: 0.0004358412988949567, Avg. Test Loss: 0.00044997254735790193\n",
      "Epoch: 695, Avg. Train Loss: 0.00043694364572983497, Avg. Test Loss: 0.0004497973422985524\n",
      "Epoch: 696, Avg. Train Loss: 0.00043909425568377033, Avg. Test Loss: 0.0004484771634452045\n",
      "Epoch: 697, Avg. Train Loss: 0.0004375761680759836, Avg. Test Loss: 0.00044796778820455074\n",
      "Epoch: 698, Avg. Train Loss: 0.0004385040827951026, Avg. Test Loss: 0.0004515080654527992\n",
      "Epoch: 699, Avg. Train Loss: 0.00043680222412614627, Avg. Test Loss: 0.0004473758745007217\n",
      "Epoch: 700, Avg. Train Loss: 0.0004355213895905763, Avg. Test Loss: 0.00045313319424167275\n",
      "Epoch: 701, Avg. Train Loss: 0.00043550097088459447, Avg. Test Loss: 0.0004532644816208631\n",
      "Epoch: 702, Avg. Train Loss: 0.00043709810314223517, Avg. Test Loss: 0.0004489514685701579\n",
      "Epoch: 703, Avg. Train Loss: 0.00043517644557733697, Avg. Test Loss: 0.00045088963815942407\n",
      "Epoch: 704, Avg. Train Loss: 0.0004362407868706383, Avg. Test Loss: 0.0004493494052439928\n",
      "Epoch: 705, Avg. Train Loss: 0.0004359930320534595, Avg. Test Loss: 0.0004478688060771674\n",
      "Epoch: 706, Avg. Train Loss: 0.00043536461808523814, Avg. Test Loss: 0.0004537854983936995\n",
      "Epoch: 707, Avg. Train Loss: 0.0004357557119747494, Avg. Test Loss: 0.00045147008495405316\n",
      "Epoch: 708, Avg. Train Loss: 0.00043516303751032885, Avg. Test Loss: 0.0004470286366995424\n",
      "Epoch: 709, Avg. Train Loss: 0.00043490852383615145, Avg. Test Loss: 0.0004618545644916594\n",
      "Epoch: 710, Avg. Train Loss: 0.0004378590349725253, Avg. Test Loss: 0.0004524241085164249\n",
      "Epoch: 711, Avg. Train Loss: 0.00043458843923195503, Avg. Test Loss: 0.00044805504148826003\n",
      "Epoch: 712, Avg. Train Loss: 0.00043540224189285274, Avg. Test Loss: 0.0004466800601221621\n",
      "Epoch: 713, Avg. Train Loss: 0.00043309720904501374, Avg. Test Loss: 0.000446075398940593\n",
      "Epoch: 714, Avg. Train Loss: 0.00043507477236088627, Avg. Test Loss: 0.000450612889835611\n",
      "Epoch: 715, Avg. Train Loss: 0.00043481031262185857, Avg. Test Loss: 0.00044668163172900677\n",
      "Epoch: 716, Avg. Train Loss: 0.00043306756916261, Avg. Test Loss: 0.0004464054072741419\n",
      "Epoch: 717, Avg. Train Loss: 0.0004347793339632538, Avg. Test Loss: 0.00044691350194625556\n",
      "Epoch: 718, Avg. Train Loss: 0.00043576328303166775, Avg. Test Loss: 0.0004463885852601379\n",
      "Epoch: 719, Avg. Train Loss: 0.00043572172073127574, Avg. Test Loss: 0.00044870926649309695\n",
      "Epoch: 720, Avg. Train Loss: 0.00043464196794449765, Avg. Test Loss: 0.00044656655518338084\n",
      "Epoch: 721, Avg. Train Loss: 0.00043431224997242005, Avg. Test Loss: 0.0004460762720555067\n",
      "Epoch: 722, Avg. Train Loss: 0.00043354756171750124, Avg. Test Loss: 0.00044626431190408766\n",
      "Epoch: 723, Avg. Train Loss: 0.0004328280960772793, Avg. Test Loss: 0.0004464551748242229\n",
      "Epoch: 724, Avg. Train Loss: 0.00043314034633641673, Avg. Test Loss: 0.0004468261613510549\n",
      "Epoch: 725, Avg. Train Loss: 0.0004356369581939869, Avg. Test Loss: 0.0004470376006793231\n",
      "Epoch: 726, Avg. Train Loss: 0.0004340766260378756, Avg. Test Loss: 0.0004482231452129781\n",
      "Epoch: 727, Avg. Train Loss: 0.00043345635572751594, Avg. Test Loss: 0.00044760905439034104\n",
      "Epoch: 728, Avg. Train Loss: 0.00043422728912298415, Avg. Test Loss: 0.00044796979636885226\n",
      "Epoch: 729, Avg. Train Loss: 0.0004337324048825648, Avg. Test Loss: 0.00044824820361100137\n",
      "Epoch: 730, Avg. Train Loss: 0.0004336212878115475, Avg. Test Loss: 0.0004503006348386407\n",
      "Epoch: 731, Avg. Train Loss: 0.0004334318394729391, Avg. Test Loss: 0.00044683218584395945\n",
      "Epoch: 732, Avg. Train Loss: 0.00043316210246493303, Avg. Test Loss: 0.00044571043690666556\n",
      "Epoch: 733, Avg. Train Loss: 0.00043385149234212764, Avg. Test Loss: 0.00044666146277450025\n",
      "Epoch: 734, Avg. Train Loss: 0.0004331764668973466, Avg. Test Loss: 0.0004464444937184453\n",
      "Epoch: 735, Avg. Train Loss: 0.0004343566299297002, Avg. Test Loss: 0.0004458596231415868\n",
      "Epoch: 736, Avg. Train Loss: 0.0004325361555539678, Avg. Test Loss: 0.0004460249620024115\n",
      "Epoch: 737, Avg. Train Loss: 0.0004318111439419607, Avg. Test Loss: 0.0004437686293385923\n",
      "Epoch: 738, Avg. Train Loss: 0.0004329390547693122, Avg. Test Loss: 0.0004465342790354043\n",
      "Epoch: 739, Avg. Train Loss: 0.0004321471300669188, Avg. Test Loss: 0.00044511054875329137\n",
      "Epoch: 740, Avg. Train Loss: 0.0004329645179136288, Avg. Test Loss: 0.00044468158739618957\n",
      "Epoch: 741, Avg. Train Loss: 0.00043242105531917757, Avg. Test Loss: 0.0004427174280863255\n",
      "Epoch: 742, Avg. Train Loss: 0.00043312182614774723, Avg. Test Loss: 0.0004442846402525902\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 743, Avg. Train Loss: 0.0004328363094489675, Avg. Test Loss: 0.0004442546924110502\n",
      "Epoch: 744, Avg. Train Loss: 0.0004327623363107789, Avg. Test Loss: 0.0004455205053091049\n",
      "Epoch: 745, Avg. Train Loss: 0.0004315928922868659, Avg. Test Loss: 0.0004466130631044507\n",
      "Epoch: 746, Avg. Train Loss: 0.00043392112494857854, Avg. Test Loss: 0.0004477675538510084\n",
      "Epoch: 747, Avg. Train Loss: 0.00043269885611871994, Avg. Test Loss: 0.0004446303064469248\n",
      "Epoch: 748, Avg. Train Loss: 0.00043137403283549777, Avg. Test Loss: 0.00044450981658883393\n",
      "Epoch: 749, Avg. Train Loss: 0.0004316842688388343, Avg. Test Loss: 0.000444375560618937\n",
      "Epoch: 750, Avg. Train Loss: 0.0004326454411141661, Avg. Test Loss: 0.000446115096565336\n",
      "Epoch: 751, Avg. Train Loss: 0.00043169571273570315, Avg. Test Loss: 0.00044410739792510867\n",
      "Epoch: 752, Avg. Train Loss: 0.00043117429053974015, Avg. Test Loss: 0.0004425194929353893\n",
      "Epoch: 753, Avg. Train Loss: 0.000431421565482133, Avg. Test Loss: 0.0004485609824769199\n",
      "Epoch: 754, Avg. Train Loss: 0.0004303768557377246, Avg. Test Loss: 0.00044529122533276677\n",
      "Epoch: 755, Avg. Train Loss: 0.00043211413782934634, Avg. Test Loss: 0.000443176191765815\n",
      "Epoch: 756, Avg. Train Loss: 0.00043443033504191525, Avg. Test Loss: 0.0004499028145801276\n",
      "Epoch: 757, Avg. Train Loss: 0.0004317110897106833, Avg. Test Loss: 0.0004435477021615952\n",
      "Epoch: 758, Avg. Train Loss: 0.00043102253639940605, Avg. Test Loss: 0.0004428703396115452\n",
      "Epoch: 759, Avg. Train Loss: 0.00043044507850048156, Avg. Test Loss: 0.0004421185585670173\n",
      "Epoch: 760, Avg. Train Loss: 0.00043234397619312933, Avg. Test Loss: 0.00044185135629959404\n",
      "Epoch: 761, Avg. Train Loss: 0.0004329470508775219, Avg. Test Loss: 0.0004422775818966329\n",
      "Epoch: 762, Avg. Train Loss: 0.0004312827415645209, Avg. Test Loss: 0.0004431127163115889\n",
      "Epoch: 763, Avg. Train Loss: 0.0004296145391065714, Avg. Test Loss: 0.0004457642789930105\n",
      "Epoch: 764, Avg. Train Loss: 0.0004318962652008807, Avg. Test Loss: 0.0004423975187819451\n",
      "Epoch: 765, Avg. Train Loss: 0.0004294105740480645, Avg. Test Loss: 0.0004426511295605451\n",
      "Epoch: 766, Avg. Train Loss: 0.0004299432749935794, Avg. Test Loss: 0.00044736373820342124\n",
      "Epoch: 767, Avg. Train Loss: 0.0004317344072935453, Avg. Test Loss: 0.00044348082155920565\n",
      "Epoch: 768, Avg. Train Loss: 0.0004318302455304061, Avg. Test Loss: 0.00044413484283722937\n",
      "Epoch: 769, Avg. Train Loss: 0.00042984205796275026, Avg. Test Loss: 0.00044225851888768375\n",
      "Epoch: 770, Avg. Train Loss: 0.0004292222621125104, Avg. Test Loss: 0.0004450409905984998\n",
      "Epoch: 771, Avg. Train Loss: 0.0004295115365895854, Avg. Test Loss: 0.00044030393473803997\n",
      "Epoch: 772, Avg. Train Loss: 0.0004295046423659335, Avg. Test Loss: 0.00044071435695514083\n",
      "Epoch: 773, Avg. Train Loss: 0.00042843281935770497, Avg. Test Loss: 0.00043996874592266977\n",
      "Epoch: 774, Avg. Train Loss: 0.00042819875823117275, Avg. Test Loss: 0.00043971234117634594\n",
      "Epoch: 775, Avg. Train Loss: 0.0004283356206859787, Avg. Test Loss: 0.000442131218733266\n",
      "Epoch: 776, Avg. Train Loss: 0.00042859451482505647, Avg. Test Loss: 0.0004386969667393714\n",
      "Epoch: 777, Avg. Train Loss: 0.0004283647407604338, Avg. Test Loss: 0.0004406188672874123\n",
      "Epoch: 778, Avg. Train Loss: 0.0004275885531083183, Avg. Test Loss: 0.00044052008888684213\n",
      "Epoch: 779, Avg. Train Loss: 0.00042825308493013646, Avg. Test Loss: 0.00044209713814780116\n",
      "Epoch: 780, Avg. Train Loss: 0.0004280620203136878, Avg. Test Loss: 0.0004391757247503847\n",
      "Epoch: 781, Avg. Train Loss: 0.0004266314878572472, Avg. Test Loss: 0.00044033510494045913\n",
      "Epoch: 782, Avg. Train Loss: 0.00042660555634431023, Avg. Test Loss: 0.0004393631243146956\n",
      "Epoch: 783, Avg. Train Loss: 0.0004271735920473327, Avg. Test Loss: 0.00043833121890202165\n",
      "Epoch: 784, Avg. Train Loss: 0.00042634739386199346, Avg. Test Loss: 0.00043983012437820435\n",
      "Epoch: 785, Avg. Train Loss: 0.00042671514309531206, Avg. Test Loss: 0.00043800732237286866\n",
      "Epoch: 786, Avg. Train Loss: 0.0004273025849617498, Avg. Test Loss: 0.00043860028381459415\n",
      "Epoch: 787, Avg. Train Loss: 0.0004257383799656879, Avg. Test Loss: 0.00043904941412620246\n",
      "Epoch: 788, Avg. Train Loss: 0.0004257726581864665, Avg. Test Loss: 0.000436712201917544\n",
      "Epoch: 789, Avg. Train Loss: 0.0004258302844476041, Avg. Test Loss: 0.0004392013361211866\n",
      "Epoch: 790, Avg. Train Loss: 0.00042560490979921334, Avg. Test Loss: 0.0004368936934042722\n",
      "Epoch: 791, Avg. Train Loss: 0.0004252614825693241, Avg. Test Loss: 0.00043827309855259955\n",
      "Epoch: 792, Avg. Train Loss: 0.00042593967220962565, Avg. Test Loss: 0.00044703882304020226\n",
      "Epoch: 793, Avg. Train Loss: 0.0004252361771271586, Avg. Test Loss: 0.0004368551599327475\n",
      "Epoch: 794, Avg. Train Loss: 0.00042529272722340256, Avg. Test Loss: 0.00043759492109529674\n",
      "Epoch: 795, Avg. Train Loss: 0.0004260542790329647, Avg. Test Loss: 0.0004380375612527132\n",
      "Epoch: 796, Avg. Train Loss: 0.0004246161003911131, Avg. Test Loss: 0.00043609258136712015\n",
      "Epoch: 797, Avg. Train Loss: 0.00042519517389104464, Avg. Test Loss: 0.00043676525820046663\n",
      "Epoch: 798, Avg. Train Loss: 0.0004266563276381254, Avg. Test Loss: 0.000438669347204268\n",
      "Epoch: 799, Avg. Train Loss: 0.0004250892521921805, Avg. Test Loss: 0.00043622689554467797\n",
      "Epoch: 800, Avg. Train Loss: 0.0004239081348249212, Avg. Test Loss: 0.00043612290755845606\n",
      "Epoch: 801, Avg. Train Loss: 0.0004251390732120896, Avg. Test Loss: 0.0004360922903288156\n",
      "Epoch: 802, Avg. Train Loss: 0.00042505607179496005, Avg. Test Loss: 0.0004363415646366775\n",
      "Epoch: 803, Avg. Train Loss: 0.00042421721344337214, Avg. Test Loss: 0.0004349737719167024\n",
      "Epoch: 804, Avg. Train Loss: 0.000427236209276977, Avg. Test Loss: 0.00043702381663024426\n",
      "Epoch: 805, Avg. Train Loss: 0.0004226630079819886, Avg. Test Loss: 0.0004369382804725319\n",
      "Epoch: 806, Avg. Train Loss: 0.0004249875755915635, Avg. Test Loss: 0.00043828372145071626\n",
      "Epoch: 807, Avg. Train Loss: 0.00042497348392295627, Avg. Test Loss: 0.0004381602047942579\n",
      "Epoch: 808, Avg. Train Loss: 0.00042571219937810893, Avg. Test Loss: 0.0004366047214716673\n",
      "Epoch: 809, Avg. Train Loss: 0.00042467082845220385, Avg. Test Loss: 0.00043597634066827595\n",
      "Epoch: 810, Avg. Train Loss: 0.00042283825500500066, Avg. Test Loss: 0.0004358584701549262\n",
      "Epoch: 811, Avg. Train Loss: 0.0004240460355419579, Avg. Test Loss: 0.0004342885222285986\n",
      "Epoch: 812, Avg. Train Loss: 0.00042365893564555186, Avg. Test Loss: 0.0004349741793703288\n",
      "Epoch: 813, Avg. Train Loss: 0.0004227619508530425, Avg. Test Loss: 0.0004389601235743612\n",
      "Epoch: 814, Avg. Train Loss: 0.000423912470618826, Avg. Test Loss: 0.00043985864613205194\n",
      "Epoch: 815, Avg. Train Loss: 0.0004243166192683803, Avg. Test Loss: 0.0004375508869998157\n",
      "Epoch: 816, Avg. Train Loss: 0.00042472653656786436, Avg. Test Loss: 0.00043674782500602305\n",
      "Epoch: 817, Avg. Train Loss: 0.0004242100146447503, Avg. Test Loss: 0.000434225337812677\n",
      "Epoch: 818, Avg. Train Loss: 0.00042294532528991787, Avg. Test Loss: 0.0004346646892372519\n",
      "Epoch: 819, Avg. Train Loss: 0.0004242004949848579, Avg. Test Loss: 0.0004355895216576755\n",
      "Epoch: 820, Avg. Train Loss: 0.00042207815026496214, Avg. Test Loss: 0.0004367336805444211\n",
      "Epoch: 821, Avg. Train Loss: 0.00042307719406888407, Avg. Test Loss: 0.00043543713400140405\n",
      "Epoch: 822, Avg. Train Loss: 0.0004231697577864018, Avg. Test Loss: 0.0004346036002971232\n",
      "Epoch: 823, Avg. Train Loss: 0.00042256846994183264, Avg. Test Loss: 0.00043884554179385304\n",
      "Epoch: 824, Avg. Train Loss: 0.0004223804619044152, Avg. Test Loss: 0.0004340941086411476\n",
      "Epoch: 825, Avg. Train Loss: 0.0004229922460792803, Avg. Test Loss: 0.0004392147820908576\n",
      "Epoch: 826, Avg. Train Loss: 0.0004225684645271665, Avg. Test Loss: 0.0004338280123192817\n",
      "Epoch: 827, Avg. Train Loss: 0.0004224387460474878, Avg. Test Loss: 0.000434499786933884\n",
      "Epoch: 828, Avg. Train Loss: 0.00042216720798615975, Avg. Test Loss: 0.00043419533176347613\n",
      "Epoch: 829, Avg. Train Loss: 0.0004216585481582686, Avg. Test Loss: 0.00043365772580727935\n",
      "Epoch: 830, Avg. Train Loss: 0.0004211617965348671, Avg. Test Loss: 0.0004324979381635785\n",
      "Epoch: 831, Avg. Train Loss: 0.00042291977889510955, Avg. Test Loss: 0.0004349823866505176\n",
      "Epoch: 832, Avg. Train Loss: 0.0004211331867926949, Avg. Test Loss: 0.0004333788820076734\n",
      "Epoch: 833, Avg. Train Loss: 0.00042071694922416885, Avg. Test Loss: 0.0004338311846368015\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 834, Avg. Train Loss: 0.00042203477405141607, Avg. Test Loss: 0.00043735982035286725\n",
      "Epoch: 835, Avg. Train Loss: 0.0004216150413159021, Avg. Test Loss: 0.00043352972716093063\n",
      "Epoch: 836, Avg. Train Loss: 0.0004234697776684148, Avg. Test Loss: 0.00043287983862683177\n",
      "Epoch: 837, Avg. Train Loss: 0.00042124423008888613, Avg. Test Loss: 0.0004349669616203755\n",
      "Epoch: 838, Avg. Train Loss: 0.0004206260667604849, Avg. Test Loss: 0.0004336766432970762\n",
      "Epoch: 839, Avg. Train Loss: 0.00042171282274107083, Avg. Test Loss: 0.00043200646177865565\n",
      "Epoch: 840, Avg. Train Loss: 0.0004221009737595396, Avg. Test Loss: 0.00043513556011021137\n",
      "Epoch: 841, Avg. Train Loss: 0.0004218212588755197, Avg. Test Loss: 0.0004332124372012913\n",
      "Epoch: 842, Avg. Train Loss: 0.0004196322298348816, Avg. Test Loss: 0.0004330635129008442\n",
      "Epoch: 843, Avg. Train Loss: 0.0004208588202451464, Avg. Test Loss: 0.0004341796156950295\n",
      "Epoch: 844, Avg. Train Loss: 0.00042265537804057603, Avg. Test Loss: 0.0004361892642918974\n",
      "Epoch: 845, Avg. Train Loss: 0.00042305928776798727, Avg. Test Loss: 0.00043473331606946886\n",
      "Epoch: 846, Avg. Train Loss: 0.00042194570820821924, Avg. Test Loss: 0.00043344407458789647\n",
      "Epoch: 847, Avg. Train Loss: 0.000422601820224203, Avg. Test Loss: 0.00043243152322247624\n",
      "Epoch: 848, Avg. Train Loss: 0.00042046142436109136, Avg. Test Loss: 0.0004319690924603492\n",
      "Epoch: 849, Avg. Train Loss: 0.0004202787910566427, Avg. Test Loss: 0.00043612788431346416\n",
      "Epoch: 850, Avg. Train Loss: 0.00042136079634453146, Avg. Test Loss: 0.0004334795521572232\n",
      "Epoch: 851, Avg. Train Loss: 0.0004201103143967948, Avg. Test Loss: 0.0004348252550698817\n",
      "Epoch: 852, Avg. Train Loss: 0.00042338982944615015, Avg. Test Loss: 0.00043295021168887615\n",
      "Epoch: 853, Avg. Train Loss: 0.00042067507558047425, Avg. Test Loss: 0.00043112965067848563\n",
      "Epoch: 854, Avg. Train Loss: 0.00042000734910563846, Avg. Test Loss: 0.0004316249687690288\n",
      "Epoch: 855, Avg. Train Loss: 0.0004197933005851282, Avg. Test Loss: 0.0004343014443293214\n",
      "Epoch: 856, Avg. Train Loss: 0.0004193667568764541, Avg. Test Loss: 0.00043414600077085197\n",
      "Epoch: 857, Avg. Train Loss: 0.00041989542998720046, Avg. Test Loss: 0.00043335629743523896\n",
      "Epoch: 858, Avg. Train Loss: 0.00042254366467945107, Avg. Test Loss: 0.0004389082605484873\n",
      "Epoch: 859, Avg. Train Loss: 0.00042309913632654865, Avg. Test Loss: 0.0004384900094009936\n",
      "Epoch: 860, Avg. Train Loss: 0.00042111212171094364, Avg. Test Loss: 0.0004320293664932251\n",
      "Epoch: 861, Avg. Train Loss: 0.00041997003731815966, Avg. Test Loss: 0.00043111026752740145\n",
      "Epoch: 862, Avg. Train Loss: 0.00042005756133517555, Avg. Test Loss: 0.0004358464211691171\n",
      "Epoch: 863, Avg. Train Loss: 0.00042032613418996334, Avg. Test Loss: 0.0004345100314822048\n",
      "Epoch: 864, Avg. Train Loss: 0.00042034022991957015, Avg. Test Loss: 0.0004378872399684042\n",
      "Epoch: 865, Avg. Train Loss: 0.0004207576878184756, Avg. Test Loss: 0.000432096014264971\n",
      "Epoch: 866, Avg. Train Loss: 0.00041848924457702007, Avg. Test Loss: 0.0004329177609179169\n",
      "Epoch: 867, Avg. Train Loss: 0.0004194572440695104, Avg. Test Loss: 0.00043379058479331434\n",
      "Epoch: 868, Avg. Train Loss: 0.00041861652171910674, Avg. Test Loss: 0.0004313077952247113\n",
      "Epoch: 869, Avg. Train Loss: 0.00041937757199521846, Avg. Test Loss: 0.00043213251046836376\n",
      "Epoch: 870, Avg. Train Loss: 0.0004208929069221106, Avg. Test Loss: 0.0004364360647741705\n",
      "Epoch: 871, Avg. Train Loss: 0.0004221749861540576, Avg. Test Loss: 0.00043350568739697337\n",
      "Epoch: 872, Avg. Train Loss: 0.00042049107371916087, Avg. Test Loss: 0.0004361241008155048\n",
      "Epoch: 873, Avg. Train Loss: 0.000420453832999175, Avg. Test Loss: 0.0004334983532316983\n",
      "Epoch: 874, Avg. Train Loss: 0.0004189444582660271, Avg. Test Loss: 0.0004330816154833883\n",
      "Epoch: 875, Avg. Train Loss: 0.00041930842467821964, Avg. Test Loss: 0.0004310989170335233\n",
      "Epoch: 876, Avg. Train Loss: 0.0004214169762129787, Avg. Test Loss: 0.0004350451345089823\n",
      "Epoch: 877, Avg. Train Loss: 0.0004204263684588896, Avg. Test Loss: 0.00043502813787199557\n",
      "Epoch: 878, Avg. Train Loss: 0.0004191176558379084, Avg. Test Loss: 0.0004311544180382043\n",
      "Epoch: 879, Avg. Train Loss: 0.000418897352701183, Avg. Test Loss: 0.0004321573651395738\n",
      "Epoch: 880, Avg. Train Loss: 0.00041898802466972104, Avg. Test Loss: 0.0004301573208067566\n",
      "Epoch: 881, Avg. Train Loss: 0.0004196829097562058, Avg. Test Loss: 0.0004343590117059648\n",
      "Epoch: 882, Avg. Train Loss: 0.000420127444369935, Avg. Test Loss: 0.00045128859346732497\n",
      "Epoch: 883, Avg. Train Loss: 0.00042120544618905284, Avg. Test Loss: 0.00043340257252566516\n",
      "Epoch: 884, Avg. Train Loss: 0.00041804399861152783, Avg. Test Loss: 0.00043134886072948575\n",
      "Epoch: 885, Avg. Train Loss: 0.0004186248460914506, Avg. Test Loss: 0.000432110478868708\n",
      "Epoch: 886, Avg. Train Loss: 0.0004185425830994148, Avg. Test Loss: 0.0004324094916228205\n",
      "Epoch: 887, Avg. Train Loss: 0.0004185847680864119, Avg. Test Loss: 0.0004314698453526944\n",
      "Epoch: 888, Avg. Train Loss: 0.00041811789932855685, Avg. Test Loss: 0.0004305366601329297\n",
      "Epoch: 889, Avg. Train Loss: 0.0004189614941593433, Avg. Test Loss: 0.0004318272112868726\n",
      "Epoch: 890, Avg. Train Loss: 0.0004183755541859238, Avg. Test Loss: 0.00043316217488609254\n",
      "Epoch: 891, Avg. Train Loss: 0.00041888185457304814, Avg. Test Loss: 0.0004309923679102212\n",
      "Epoch: 892, Avg. Train Loss: 0.0004180603915132409, Avg. Test Loss: 0.00043115197331644595\n",
      "Epoch: 893, Avg. Train Loss: 0.00041882708928612773, Avg. Test Loss: 0.0004334224504418671\n",
      "Epoch: 894, Avg. Train Loss: 0.00041900763929778235, Avg. Test Loss: 0.00043014594120904803\n",
      "Epoch: 895, Avg. Train Loss: 0.0004185461940048912, Avg. Test Loss: 0.00043220407678745687\n",
      "Epoch: 896, Avg. Train Loss: 0.00041787262172113325, Avg. Test Loss: 0.00043101527262479067\n",
      "Epoch: 897, Avg. Train Loss: 0.00041723752740857215, Avg. Test Loss: 0.0004334002442192286\n",
      "Epoch: 898, Avg. Train Loss: 0.00041904195406755737, Avg. Test Loss: 0.0004342447209637612\n",
      "Epoch: 899, Avg. Train Loss: 0.00041841472388071897, Avg. Test Loss: 0.00043019032455049455\n",
      "Epoch: 900, Avg. Train Loss: 0.00041926228630811323, Avg. Test Loss: 0.00043062283657491207\n",
      "Epoch: 901, Avg. Train Loss: 0.0004190197708572499, Avg. Test Loss: 0.00043293944327160716\n",
      "Epoch: 902, Avg. Train Loss: 0.00041781890078794297, Avg. Test Loss: 0.00043085156357847154\n",
      "Epoch: 903, Avg. Train Loss: 0.000418161854911379, Avg. Test Loss: 0.0004313755489420146\n",
      "Epoch: 904, Avg. Train Loss: 0.0004177812925474935, Avg. Test Loss: 0.00042917963583022356\n",
      "Epoch: 905, Avg. Train Loss: 0.00041782013194765463, Avg. Test Loss: 0.00042889121687039733\n",
      "Epoch: 906, Avg. Train Loss: 0.0004181245397397339, Avg. Test Loss: 0.000434169196523726\n",
      "Epoch: 907, Avg. Train Loss: 0.00041859036549752535, Avg. Test Loss: 0.00042877052328549325\n",
      "Epoch: 908, Avg. Train Loss: 0.00041725354737515537, Avg. Test Loss: 0.00043160453788004816\n",
      "Epoch: 909, Avg. Train Loss: 0.00041863982508847015, Avg. Test Loss: 0.0004312033124733716\n",
      "Epoch: 910, Avg. Train Loss: 0.00041942533611883086, Avg. Test Loss: 0.00043067525257356465\n",
      "Epoch: 911, Avg. Train Loss: 0.00041857597940644724, Avg. Test Loss: 0.0004293270467314869\n",
      "Epoch: 912, Avg. Train Loss: 0.00041664709190859697, Avg. Test Loss: 0.00043227997957728803\n",
      "Epoch: 913, Avg. Train Loss: 0.0004176928175797383, Avg. Test Loss: 0.00043223760440014303\n",
      "Epoch: 914, Avg. Train Loss: 0.0004172148643234788, Avg. Test Loss: 0.0004297507111914456\n",
      "Epoch: 915, Avg. Train Loss: 0.0004181549160167315, Avg. Test Loss: 0.00043464358896017075\n",
      "Epoch: 916, Avg. Train Loss: 0.00041840532672764776, Avg. Test Loss: 0.0004303243476897478\n",
      "Epoch: 917, Avg. Train Loss: 0.00041732031426955623, Avg. Test Loss: 0.0004292037629056722\n",
      "Epoch: 918, Avg. Train Loss: 0.00041606392492107006, Avg. Test Loss: 0.0004292544617783278\n",
      "Epoch: 919, Avg. Train Loss: 0.0004169946532360776, Avg. Test Loss: 0.00043045415077358484\n",
      "Epoch: 920, Avg. Train Loss: 0.000418749823354098, Avg. Test Loss: 0.00043304372229613364\n",
      "Epoch: 921, Avg. Train Loss: 0.0004176048786639301, Avg. Test Loss: 0.00042902081622742116\n",
      "Epoch: 922, Avg. Train Loss: 0.00041613082447479113, Avg. Test Loss: 0.0004313902463763952\n",
      "Epoch: 923, Avg. Train Loss: 0.00041616611050030345, Avg. Test Loss: 0.0004294823738746345\n",
      "Epoch: 924, Avg. Train Loss: 0.00041627248906162245, Avg. Test Loss: 0.00042962186853401363\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 925, Avg. Train Loss: 0.0004162149947829718, Avg. Test Loss: 0.00043214394827373326\n",
      "Epoch: 926, Avg. Train Loss: 0.0004175538765699711, Avg. Test Loss: 0.0004297918058000505\n",
      "Epoch: 927, Avg. Train Loss: 0.0004168675419181412, Avg. Test Loss: 0.0004299658176023513\n",
      "Epoch: 928, Avg. Train Loss: 0.0004174657420493489, Avg. Test Loss: 0.0004351501411292702\n",
      "Epoch: 929, Avg. Train Loss: 0.00041905058842953727, Avg. Test Loss: 0.0004309848591219634\n",
      "Epoch: 930, Avg. Train Loss: 0.00041675309279695324, Avg. Test Loss: 0.00042862887494266033\n",
      "Epoch: 931, Avg. Train Loss: 0.0004168329361100616, Avg. Test Loss: 0.00042844045674428344\n",
      "Epoch: 932, Avg. Train Loss: 0.00041788704977587383, Avg. Test Loss: 0.00042960798600688577\n",
      "Epoch: 933, Avg. Train Loss: 0.0004173042509856439, Avg. Test Loss: 0.00042898234096355736\n",
      "Epoch: 934, Avg. Train Loss: 0.00041857932093228366, Avg. Test Loss: 0.0004316361155360937\n",
      "Epoch: 935, Avg. Train Loss: 0.0004171521868556738, Avg. Test Loss: 0.00043103910866193473\n",
      "Epoch: 936, Avg. Train Loss: 0.00041727777259142765, Avg. Test Loss: 0.00042976776603609324\n",
      "Epoch: 937, Avg. Train Loss: 0.00041850095853036227, Avg. Test Loss: 0.0004310416697990149\n",
      "Epoch: 938, Avg. Train Loss: 0.00041640475649538255, Avg. Test Loss: 0.0004307013878133148\n",
      "Epoch: 939, Avg. Train Loss: 0.00041730532850420407, Avg. Test Loss: 0.00042796143679879606\n",
      "Epoch: 940, Avg. Train Loss: 0.000417621779190593, Avg. Test Loss: 0.00042803745600394905\n",
      "Epoch: 941, Avg. Train Loss: 0.00041640557478680166, Avg. Test Loss: 0.0004297005361877382\n",
      "Epoch: 942, Avg. Train Loss: 0.0004175274502919164, Avg. Test Loss: 0.0004316267149988562\n",
      "Epoch: 943, Avg. Train Loss: 0.0004180401900707376, Avg. Test Loss: 0.0004299111315049231\n",
      "Epoch: 944, Avg. Train Loss: 0.00041605771429901724, Avg. Test Loss: 0.0004289654898457229\n",
      "Epoch: 945, Avg. Train Loss: 0.0004176031168669376, Avg. Test Loss: 0.0004302116867620498\n",
      "Epoch: 946, Avg. Train Loss: 0.0004164798890489565, Avg. Test Loss: 0.00042745767859742045\n",
      "Epoch: 947, Avg. Train Loss: 0.00041595653110985145, Avg. Test Loss: 0.00043197834747843444\n",
      "Epoch: 948, Avg. Train Loss: 0.00041658960372144575, Avg. Test Loss: 0.0004292046942282468\n",
      "Epoch: 949, Avg. Train Loss: 0.00041468585584161067, Avg. Test Loss: 0.0004292842641007155\n",
      "Epoch: 950, Avg. Train Loss: 0.0004152240540269156, Avg. Test Loss: 0.00042874342761933804\n",
      "Epoch: 951, Avg. Train Loss: 0.00041851119427985055, Avg. Test Loss: 0.0004284656315576285\n",
      "Epoch: 952, Avg. Train Loss: 0.0004167415900155902, Avg. Test Loss: 0.0004287636838853359\n",
      "Epoch: 953, Avg. Train Loss: 0.0004161466217632297, Avg. Test Loss: 0.0004334792320150882\n",
      "Epoch: 954, Avg. Train Loss: 0.00041638427078290733, Avg. Test Loss: 0.0004294531245250255\n",
      "Epoch: 955, Avg. Train Loss: 0.0004165876693319703, Avg. Test Loss: 0.0004280954890418798\n",
      "Epoch: 956, Avg. Train Loss: 0.0004162591019764456, Avg. Test Loss: 0.0004301516164559871\n",
      "Epoch: 957, Avg. Train Loss: 0.0004156327652095189, Avg. Test Loss: 0.00042768780258484185\n",
      "Epoch: 958, Avg. Train Loss: 0.0004167590184722009, Avg. Test Loss: 0.00043133104918524623\n",
      "Epoch: 959, Avg. Train Loss: 0.0004152205710429265, Avg. Test Loss: 0.00042795133776962757\n",
      "Epoch: 960, Avg. Train Loss: 0.00041731137600943964, Avg. Test Loss: 0.0004330261144787073\n",
      "Epoch: 961, Avg. Train Loss: 0.00041601862785471384, Avg. Test Loss: 0.00042978845885954797\n",
      "Epoch: 962, Avg. Train Loss: 0.00041566562952560397, Avg. Test Loss: 0.00043213486787863076\n",
      "Epoch: 963, Avg. Train Loss: 0.0004166048812019357, Avg. Test Loss: 0.0004291656950954348\n",
      "Epoch: 964, Avg. Train Loss: 0.0004164286940575166, Avg. Test Loss: 0.0004304082540329546\n",
      "Epoch: 965, Avg. Train Loss: 0.00041496037806081044, Avg. Test Loss: 0.00042791757732629776\n",
      "Epoch: 966, Avg. Train Loss: 0.00041774245653149867, Avg. Test Loss: 0.00042808809666894376\n",
      "Epoch: 967, Avg. Train Loss: 0.0004166229012108213, Avg. Test Loss: 0.00042938411934301257\n",
      "Epoch: 968, Avg. Train Loss: 0.0004166026970609849, Avg. Test Loss: 0.0004294586833566427\n",
      "Epoch: 969, Avg. Train Loss: 0.0004158395012234186, Avg. Test Loss: 0.00043030924280174077\n",
      "Epoch: 970, Avg. Train Loss: 0.00041570890692149313, Avg. Test Loss: 0.00042765846592374146\n",
      "Epoch: 971, Avg. Train Loss: 0.00041615711470935926, Avg. Test Loss: 0.0004282923764549196\n",
      "Epoch: 972, Avg. Train Loss: 0.0004155334575253344, Avg. Test Loss: 0.00043070106767117977\n",
      "Epoch: 973, Avg. Train Loss: 0.0004173259651504977, Avg. Test Loss: 0.0004318899300415069\n",
      "Epoch: 974, Avg. Train Loss: 0.00041561584099369166, Avg. Test Loss: 0.00042858548113144934\n",
      "Epoch: 975, Avg. Train Loss: 0.00041434224586673946, Avg. Test Loss: 0.00042762147495523095\n",
      "Epoch: 976, Avg. Train Loss: 0.00041506670315230137, Avg. Test Loss: 0.0004282284644432366\n",
      "Epoch: 977, Avg. Train Loss: 0.00041435813588133557, Avg. Test Loss: 0.00043136897147633135\n",
      "Epoch: 978, Avg. Train Loss: 0.00041566390901544065, Avg. Test Loss: 0.0004300871805753559\n",
      "Epoch: 979, Avg. Train Loss: 0.0004146064971411211, Avg. Test Loss: 0.0004277832922525704\n",
      "Epoch: 980, Avg. Train Loss: 0.00041625135358921143, Avg. Test Loss: 0.00042767144623212516\n",
      "Epoch: 981, Avg. Train Loss: 0.00041717301775311485, Avg. Test Loss: 0.00042996846605092287\n",
      "Epoch: 982, Avg. Train Loss: 0.0004156197483521388, Avg. Test Loss: 0.00043058086885139346\n",
      "Epoch: 983, Avg. Train Loss: 0.0004179160202701771, Avg. Test Loss: 0.000429880601586774\n",
      "Epoch: 984, Avg. Train Loss: 0.00041478668843114444, Avg. Test Loss: 0.00043267395813018084\n",
      "Epoch: 985, Avg. Train Loss: 0.0004146179369769904, Avg. Test Loss: 0.0004282575682736933\n",
      "Epoch: 986, Avg. Train Loss: 0.00041485723814667136, Avg. Test Loss: 0.00043122979695908725\n",
      "Epoch: 987, Avg. Train Loss: 0.00041747375101739066, Avg. Test Loss: 0.00043106568045914173\n",
      "Epoch: 988, Avg. Train Loss: 0.0004160123569945003, Avg. Test Loss: 0.0004264999879524112\n",
      "Epoch: 989, Avg. Train Loss: 0.00041529055424900944, Avg. Test Loss: 0.00042679780744947493\n",
      "Epoch: 990, Avg. Train Loss: 0.0004142860280956293, Avg. Test Loss: 0.00042689352994784713\n",
      "Epoch: 991, Avg. Train Loss: 0.00041453790415056744, Avg. Test Loss: 0.00042785654659383\n",
      "Epoch: 992, Avg. Train Loss: 0.0004154575648880022, Avg. Test Loss: 0.0004308263014536351\n",
      "Epoch: 993, Avg. Train Loss: 0.00041433377529841, Avg. Test Loss: 0.0004269809287507087\n",
      "Epoch: 994, Avg. Train Loss: 0.00041571607052478507, Avg. Test Loss: 0.00042715264135040343\n",
      "Epoch: 995, Avg. Train Loss: 0.00041679685074446157, Avg. Test Loss: 0.00043065231875516474\n",
      "Epoch: 996, Avg. Train Loss: 0.0004146429412283523, Avg. Test Loss: 0.00042730060522444546\n",
      "Epoch: 997, Avg. Train Loss: 0.00041416094253965934, Avg. Test Loss: 0.0004294307727832347\n",
      "Epoch: 998, Avg. Train Loss: 0.0004152575782554354, Avg. Test Loss: 0.0004273763042874634\n",
      "Epoch: 999, Avg. Train Loss: 0.00041443168126089973, Avg. Test Loss: 0.0004295154649298638\n",
      "Epoch: 1000, Avg. Train Loss: 0.0004163575588812142, Avg. Test Loss: 0.00042658261372707784\n",
      "Epoch: 1001, Avg. Train Loss: 0.0004142824212511525, Avg. Test Loss: 0.00042827625293284655\n",
      "Epoch: 1002, Avg. Train Loss: 0.00041400465564693994, Avg. Test Loss: 0.00042616279097273946\n",
      "Epoch: 1003, Avg. Train Loss: 0.0004141773036302089, Avg. Test Loss: 0.00042875990038737655\n",
      "Epoch: 1004, Avg. Train Loss: 0.0004142108366575612, Avg. Test Loss: 0.00042603869223967195\n",
      "Epoch: 1005, Avg. Train Loss: 0.00041599887041483336, Avg. Test Loss: 0.000432114175055176\n",
      "Epoch: 1006, Avg. Train Loss: 0.0004150724325459017, Avg. Test Loss: 0.00043049099622294307\n",
      "Epoch: 1007, Avg. Train Loss: 0.0004148306264163017, Avg. Test Loss: 0.00042861589463427663\n",
      "Epoch: 1008, Avg. Train Loss: 0.0004147465312366136, Avg. Test Loss: 0.00042681649210862815\n",
      "Epoch: 1009, Avg. Train Loss: 0.0004137672875130679, Avg. Test Loss: 0.0004284956376068294\n",
      "Epoch: 1010, Avg. Train Loss: 0.0004154535065957367, Avg. Test Loss: 0.0004267360200174153\n",
      "Epoch: 1011, Avg. Train Loss: 0.0004139278939556937, Avg. Test Loss: 0.0004273313097655773\n",
      "Epoch: 1012, Avg. Train Loss: 0.0004149742280999415, Avg. Test Loss: 0.0004291082441341132\n",
      "Epoch: 1013, Avg. Train Loss: 0.00041453490036453096, Avg. Test Loss: 0.00042992053204216063\n",
      "Epoch: 1014, Avg. Train Loss: 0.0004142283828831603, Avg. Test Loss: 0.0004306807240936905\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1015, Avg. Train Loss: 0.0004144126811974444, Avg. Test Loss: 0.0004260750429239124\n",
      "Epoch: 1016, Avg. Train Loss: 0.00041429354229855327, Avg. Test Loss: 0.00042651593685150146\n",
      "Epoch: 1017, Avg. Train Loss: 0.0004135605041208395, Avg. Test Loss: 0.00042950251372531056\n",
      "Epoch: 1018, Avg. Train Loss: 0.00041545509647707954, Avg. Test Loss: 0.0004275238316040486\n",
      "Epoch: 1019, Avg. Train Loss: 0.0004139117961532848, Avg. Test Loss: 0.0004276412073522806\n",
      "Epoch: 1020, Avg. Train Loss: 0.0004141970394114249, Avg. Test Loss: 0.0004299420688766986\n",
      "Epoch: 1021, Avg. Train Loss: 0.00041347909461555266, Avg. Test Loss: 0.0004328830982558429\n",
      "Epoch: 1022, Avg. Train Loss: 0.0004138623433306727, Avg. Test Loss: 0.00042748445412144065\n",
      "Epoch: 1023, Avg. Train Loss: 0.0004141130755373905, Avg. Test Loss: 0.00042544209281913936\n",
      "Epoch: 1024, Avg. Train Loss: 0.00041456943172095125, Avg. Test Loss: 0.00042587690404616296\n",
      "Epoch: 1025, Avg. Train Loss: 0.0004144129059060888, Avg. Test Loss: 0.0004286601615604013\n",
      "Epoch: 1026, Avg. Train Loss: 0.0004149314217800058, Avg. Test Loss: 0.00042606511851772666\n",
      "Epoch: 1027, Avg. Train Loss: 0.0004151113375988897, Avg. Test Loss: 0.0004301966982893646\n",
      "Epoch: 1028, Avg. Train Loss: 0.0004129934836677167, Avg. Test Loss: 0.00042630400275811553\n",
      "Epoch: 1029, Avg. Train Loss: 0.0004146184080529438, Avg. Test Loss: 0.00043039332376793027\n",
      "Epoch: 1030, Avg. Train Loss: 0.0004163318446317558, Avg. Test Loss: 0.00042800212395377457\n",
      "Epoch: 1031, Avg. Train Loss: 0.00041304054253106547, Avg. Test Loss: 0.0004267625045031309\n",
      "Epoch: 1032, Avg. Train Loss: 0.00041360681914442846, Avg. Test Loss: 0.00042731541907414794\n",
      "Epoch: 1033, Avg. Train Loss: 0.00041404937672818645, Avg. Test Loss: 0.00042750846478156745\n",
      "Epoch: 1034, Avg. Train Loss: 0.00041373550409970933, Avg. Test Loss: 0.00042677513556554914\n",
      "Epoch: 1035, Avg. Train Loss: 0.0004123167688471027, Avg. Test Loss: 0.00042633802513591945\n",
      "Epoch: 1036, Avg. Train Loss: 0.000414747774579324, Avg. Test Loss: 0.00042945792665705085\n",
      "Epoch: 1037, Avg. Train Loss: 0.0004138594769417893, Avg. Test Loss: 0.00042855890933424234\n",
      "Epoch: 1038, Avg. Train Loss: 0.00041307739948658924, Avg. Test Loss: 0.00042707528336904943\n",
      "Epoch: 1039, Avg. Train Loss: 0.0004146165223954635, Avg. Test Loss: 0.00042595580453053117\n",
      "Epoch: 1040, Avg. Train Loss: 0.0004144075704294495, Avg. Test Loss: 0.00042843399569392204\n",
      "Epoch: 1041, Avg. Train Loss: 0.0004148051632719851, Avg. Test Loss: 0.00042560152360238135\n",
      "Epoch: 1042, Avg. Train Loss: 0.0004134370395805427, Avg. Test Loss: 0.00043339486001059413\n",
      "Epoch: 1043, Avg. Train Loss: 0.00041596263546908146, Avg. Test Loss: 0.000433347187936306\n",
      "Epoch: 1044, Avg. Train Loss: 0.0004134343051741463, Avg. Test Loss: 0.0004287574556656182\n",
      "Epoch: 1045, Avg. Train Loss: 0.0004137128112339523, Avg. Test Loss: 0.0004289337666705251\n",
      "Epoch: 1046, Avg. Train Loss: 0.00041250180220231414, Avg. Test Loss: 0.00042553950333967805\n",
      "Epoch: 1047, Avg. Train Loss: 0.00041319049426441105, Avg. Test Loss: 0.00042543202289380133\n",
      "Epoch: 1048, Avg. Train Loss: 0.00041356058127983193, Avg. Test Loss: 0.0004254576051607728\n",
      "Epoch: 1049, Avg. Train Loss: 0.000412502886489207, Avg. Test Loss: 0.00042536522960290313\n",
      "Epoch: 1050, Avg. Train Loss: 0.000413400485169489, Avg. Test Loss: 0.0004300346481613815\n",
      "Epoch: 1051, Avg. Train Loss: 0.0004152230996920099, Avg. Test Loss: 0.0004265909956302494\n",
      "Epoch: 1052, Avg. Train Loss: 0.0004125896585444638, Avg. Test Loss: 0.00042734621092677116\n",
      "Epoch: 1053, Avg. Train Loss: 0.00041284328692072874, Avg. Test Loss: 0.00042540638241916895\n",
      "Epoch: 1054, Avg. Train Loss: 0.0004135241087656035, Avg. Test Loss: 0.0004268887860234827\n",
      "Epoch: 1055, Avg. Train Loss: 0.00041249928370572974, Avg. Test Loss: 0.0004286635958123952\n",
      "Epoch: 1056, Avg. Train Loss: 0.0004145179145568765, Avg. Test Loss: 0.00042664213106036186\n",
      "Epoch: 1057, Avg. Train Loss: 0.0004121687860217292, Avg. Test Loss: 0.00042490335181355476\n",
      "Epoch: 1058, Avg. Train Loss: 0.0004120921461604709, Avg. Test Loss: 0.0004248314071446657\n",
      "Epoch: 1059, Avg. Train Loss: 0.00041274247057519335, Avg. Test Loss: 0.0004248716286383569\n",
      "Epoch: 1060, Avg. Train Loss: 0.0004117165639357598, Avg. Test Loss: 0.00042627405491657555\n",
      "Epoch: 1061, Avg. Train Loss: 0.00041261887879024236, Avg. Test Loss: 0.0004322270106058568\n",
      "Epoch: 1062, Avg. Train Loss: 0.00041315178549307033, Avg. Test Loss: 0.0004250881029292941\n",
      "Epoch: 1063, Avg. Train Loss: 0.00041211994437955667, Avg. Test Loss: 0.00042788084829226136\n",
      "Epoch: 1064, Avg. Train Loss: 0.0004123677431908978, Avg. Test Loss: 0.0004242709546815604\n",
      "Epoch: 1065, Avg. Train Loss: 0.00041187085349350997, Avg. Test Loss: 0.0004257301043253392\n",
      "Epoch: 1066, Avg. Train Loss: 0.00041338825885336414, Avg. Test Loss: 0.0004310451040510088\n",
      "Epoch: 1067, Avg. Train Loss: 0.000413164260207004, Avg. Test Loss: 0.0004289658390916884\n",
      "Epoch: 1068, Avg. Train Loss: 0.0004137075211051418, Avg. Test Loss: 0.00042694888543337584\n",
      "Epoch: 1069, Avg. Train Loss: 0.00041285843715656463, Avg. Test Loss: 0.00042827901779673994\n",
      "Epoch: 1070, Avg. Train Loss: 0.0004145340739511127, Avg. Test Loss: 0.0004303829337004572\n",
      "Epoch: 1071, Avg. Train Loss: 0.00041364837061548824, Avg. Test Loss: 0.0004283848684281111\n",
      "Epoch: 1072, Avg. Train Loss: 0.00041264535041612597, Avg. Test Loss: 0.000434417073847726\n",
      "Epoch: 1073, Avg. Train Loss: 0.00041276506326962695, Avg. Test Loss: 0.0004274689999874681\n",
      "Epoch: 1074, Avg. Train Loss: 0.0004133956803301306, Avg. Test Loss: 0.00042562733869999647\n",
      "Epoch: 1075, Avg. Train Loss: 0.0004120432165299737, Avg. Test Loss: 0.0004282148147467524\n",
      "Epoch: 1076, Avg. Train Loss: 0.0004151996061324987, Avg. Test Loss: 0.00042539171408861876\n",
      "Epoch: 1077, Avg. Train Loss: 0.0004139224258197342, Avg. Test Loss: 0.0004313794197514653\n",
      "Epoch: 1078, Avg. Train Loss: 0.00041546533154973456, Avg. Test Loss: 0.0004322027962189168\n",
      "Epoch: 1079, Avg. Train Loss: 0.00041512120244374803, Avg. Test Loss: 0.0004291420918889344\n",
      "Epoch: 1080, Avg. Train Loss: 0.0004128813046453044, Avg. Test Loss: 0.00042622885666787624\n",
      "Epoch: 1081, Avg. Train Loss: 0.0004137002668061922, Avg. Test Loss: 0.00042591182864271104\n",
      "Epoch: 1082, Avg. Train Loss: 0.00041261512710344655, Avg. Test Loss: 0.00042681224294938147\n",
      "Epoch: 1083, Avg. Train Loss: 0.00041129342537524915, Avg. Test Loss: 0.0004259134875610471\n",
      "Epoch: 1084, Avg. Train Loss: 0.00041292847044830923, Avg. Test Loss: 0.00042584899347275496\n",
      "Epoch: 1085, Avg. Train Loss: 0.00041214560922018666, Avg. Test Loss: 0.00042569811921566725\n",
      "Epoch: 1086, Avg. Train Loss: 0.00041217492151528944, Avg. Test Loss: 0.00042539299465715885\n",
      "Epoch: 1087, Avg. Train Loss: 0.00041193447514372165, Avg. Test Loss: 0.0004268476041033864\n",
      "Epoch: 1088, Avg. Train Loss: 0.0004117558960705389, Avg. Test Loss: 0.00042456050869077444\n",
      "Epoch: 1089, Avg. Train Loss: 0.0004128753762627237, Avg. Test Loss: 0.0004332734097260982\n",
      "Epoch: 1090, Avg. Train Loss: 0.00041276575499322527, Avg. Test Loss: 0.00042696509626694024\n",
      "Epoch: 1091, Avg. Train Loss: 0.0004121110162719391, Avg. Test Loss: 0.00042465439764782786\n",
      "Epoch: 1092, Avg. Train Loss: 0.000412119752158909, Avg. Test Loss: 0.0004249619669280946\n",
      "Epoch: 1093, Avg. Train Loss: 0.00041291451346952207, Avg. Test Loss: 0.000427586812293157\n",
      "Epoch: 1094, Avg. Train Loss: 0.00041268830022471415, Avg. Test Loss: 0.0004256715765222907\n",
      "Epoch: 1095, Avg. Train Loss: 0.0004131039435336323, Avg. Test Loss: 0.0004263659648131579\n",
      "Epoch: 1096, Avg. Train Loss: 0.00041170308886225834, Avg. Test Loss: 0.00043042414472438395\n",
      "Epoch: 1097, Avg. Train Loss: 0.0004145732341702421, Avg. Test Loss: 0.00044102600077167153\n",
      "Epoch: 1098, Avg. Train Loss: 0.00041296908315162844, Avg. Test Loss: 0.00042489072075113654\n",
      "Epoch: 1099, Avg. Train Loss: 0.00041355870915901695, Avg. Test Loss: 0.000430666608735919\n",
      "Epoch: 1100, Avg. Train Loss: 0.00041164143679685197, Avg. Test Loss: 0.00042547236080281436\n",
      "Epoch: 1101, Avg. Train Loss: 0.0004112785079700569, Avg. Test Loss: 0.0004257585678715259\n",
      "Epoch: 1102, Avg. Train Loss: 0.0004126556348976094, Avg. Test Loss: 0.0004252061771694571\n",
      "Epoch: 1103, Avg. Train Loss: 0.00041346391189172, Avg. Test Loss: 0.00043023069156333804\n",
      "Epoch: 1104, Avg. Train Loss: 0.0004113728896617283, Avg. Test Loss: 0.0004270221688784659\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1105, Avg. Train Loss: 0.00041330482087877774, Avg. Test Loss: 0.0004259580164216459\n",
      "Epoch: 1106, Avg. Train Loss: 0.00041204828330380623, Avg. Test Loss: 0.0004284977912902832\n",
      "Epoch: 1107, Avg. Train Loss: 0.0004107219960302288, Avg. Test Loss: 0.0004257952095940709\n",
      "Epoch: 1108, Avg. Train Loss: 0.0004118638205190384, Avg. Test Loss: 0.0004275264509487897\n",
      "Epoch: 1109, Avg. Train Loss: 0.00041203929428119474, Avg. Test Loss: 0.00042542870505712926\n",
      "Epoch: 1110, Avg. Train Loss: 0.0004126103073737562, Avg. Test Loss: 0.0004295306862331927\n",
      "Epoch: 1111, Avg. Train Loss: 0.0004136479997108582, Avg. Test Loss: 0.00042424723505973816\n",
      "Epoch: 1112, Avg. Train Loss: 0.00041180149094353235, Avg. Test Loss: 0.00042511013452894986\n",
      "Epoch: 1113, Avg. Train Loss: 0.00041108881935563894, Avg. Test Loss: 0.00042352580931037664\n",
      "Epoch: 1114, Avg. Train Loss: 0.00041155774162562436, Avg. Test Loss: 0.00043026305502280593\n",
      "Epoch: 1115, Avg. Train Loss: 0.00041203854570360203, Avg. Test Loss: 0.0004257524851709604\n",
      "Epoch: 1116, Avg. Train Loss: 0.00041179516458299096, Avg. Test Loss: 0.0004246524185873568\n",
      "Epoch: 1117, Avg. Train Loss: 0.00041139007716569617, Avg. Test Loss: 0.00042984154424630105\n",
      "Epoch: 1118, Avg. Train Loss: 0.00041219036752726274, Avg. Test Loss: 0.000425425183493644\n",
      "Epoch: 1119, Avg. Train Loss: 0.00041164526293530713, Avg. Test Loss: 0.000425664649810642\n",
      "Epoch: 1120, Avg. Train Loss: 0.0004113244811928463, Avg. Test Loss: 0.00042831714381463826\n",
      "Epoch: 1121, Avg. Train Loss: 0.0004105701451027376, Avg. Test Loss: 0.00042730889981612563\n",
      "Epoch: 1122, Avg. Train Loss: 0.0004119430661883725, Avg. Test Loss: 0.00042663299245759845\n",
      "Epoch: 1123, Avg. Train Loss: 0.0004117303652428957, Avg. Test Loss: 0.0004342678003013134\n",
      "Epoch: 1124, Avg. Train Loss: 0.000412874111938182, Avg. Test Loss: 0.0004256347892805934\n",
      "Epoch: 1125, Avg. Train Loss: 0.00041121980419035916, Avg. Test Loss: 0.00042805643170140684\n",
      "Epoch: 1126, Avg. Train Loss: 0.000412379470004072, Avg. Test Loss: 0.00042546639451757073\n",
      "Epoch: 1127, Avg. Train Loss: 0.0004112545771762555, Avg. Test Loss: 0.00042403722181916237\n",
      "Epoch: 1128, Avg. Train Loss: 0.00041088100446951253, Avg. Test Loss: 0.0004264468152541667\n",
      "Epoch: 1129, Avg. Train Loss: 0.0004113682716283514, Avg. Test Loss: 0.0004254078376106918\n",
      "Epoch: 1130, Avg. Train Loss: 0.0004104512911506517, Avg. Test Loss: 0.00042459164978936315\n",
      "Epoch: 1131, Avg. Train Loss: 0.00041124447950075356, Avg. Test Loss: 0.00042819412192329764\n",
      "Epoch: 1132, Avg. Train Loss: 0.00041178853297064647, Avg. Test Loss: 0.00042565836338326335\n",
      "Epoch: 1133, Avg. Train Loss: 0.0004106634858248452, Avg. Test Loss: 0.00042762450175359845\n",
      "Epoch: 1134, Avg. Train Loss: 0.0004105639608771822, Avg. Test Loss: 0.0004256393585819751\n",
      "Epoch: 1135, Avg. Train Loss: 0.00041061820906348697, Avg. Test Loss: 0.0004260272835381329\n",
      "Epoch: 1136, Avg. Train Loss: 0.00041069456803893975, Avg. Test Loss: 0.00042634294368326664\n",
      "Epoch: 1137, Avg. Train Loss: 0.0004109521037736518, Avg. Test Loss: 0.0004289071657694876\n",
      "Epoch: 1138, Avg. Train Loss: 0.00041152085691993667, Avg. Test Loss: 0.0004250320780556649\n",
      "Epoch: 1139, Avg. Train Loss: 0.0004104613583686567, Avg. Test Loss: 0.0004252144426573068\n",
      "Epoch: 1140, Avg. Train Loss: 0.00041215729339286514, Avg. Test Loss: 0.0004275416140444577\n",
      "Epoch: 1141, Avg. Train Loss: 0.0004109048520128221, Avg. Test Loss: 0.0004272444057278335\n",
      "Epoch: 1142, Avg. Train Loss: 0.0004128783888475926, Avg. Test Loss: 0.0004257974505890161\n",
      "Epoch: 1143, Avg. Train Loss: 0.000409716279327133, Avg. Test Loss: 0.00042441958794370294\n",
      "Epoch: 1144, Avg. Train Loss: 0.00040932372212409973, Avg. Test Loss: 0.00042385136475786567\n",
      "Epoch: 1145, Avg. Train Loss: 0.00040987027310874575, Avg. Test Loss: 0.00042370945448055863\n",
      "Epoch: 1146, Avg. Train Loss: 0.00041062871825361496, Avg. Test Loss: 0.0004260465793777257\n",
      "Epoch: 1147, Avg. Train Loss: 0.0004120118080822448, Avg. Test Loss: 0.00042320278589613736\n",
      "Epoch: 1148, Avg. Train Loss: 0.00040989070602822617, Avg. Test Loss: 0.00042647848022170365\n",
      "Epoch: 1149, Avg. Train Loss: 0.00040926270425146403, Avg. Test Loss: 0.00042510367347858846\n",
      "Epoch: 1150, Avg. Train Loss: 0.0004103025529793529, Avg. Test Loss: 0.00042917279643006623\n",
      "Epoch: 1151, Avg. Train Loss: 0.00041119643246083587, Avg. Test Loss: 0.00042542858864180744\n",
      "Epoch: 1152, Avg. Train Loss: 0.0004125555556235012, Avg. Test Loss: 0.00042700464837253094\n",
      "Epoch: 1153, Avg. Train Loss: 0.0004105750149180896, Avg. Test Loss: 0.00042684198706410825\n",
      "Epoch: 1154, Avg. Train Loss: 0.00041102941505351037, Avg. Test Loss: 0.00042337525519542396\n",
      "Epoch: 1155, Avg. Train Loss: 0.00040991911475091826, Avg. Test Loss: 0.00042594983824528754\n",
      "Epoch: 1156, Avg. Train Loss: 0.00041042865716938885, Avg. Test Loss: 0.000427266291808337\n",
      "Epoch: 1157, Avg. Train Loss: 0.0004099810916962925, Avg. Test Loss: 0.0004249155754223466\n",
      "Epoch: 1158, Avg. Train Loss: 0.0004097802745893078, Avg. Test Loss: 0.00042398503865115345\n",
      "Epoch: 1159, Avg. Train Loss: 0.00041064654604185287, Avg. Test Loss: 0.0004237357643432915\n",
      "Epoch: 1160, Avg. Train Loss: 0.0004095694904356415, Avg. Test Loss: 0.00042334714089520276\n",
      "Epoch: 1161, Avg. Train Loss: 0.0004094386883459032, Avg. Test Loss: 0.00042680048500187695\n",
      "Epoch: 1162, Avg. Train Loss: 0.0004106339989067597, Avg. Test Loss: 0.00042454179492779076\n",
      "Epoch: 1163, Avg. Train Loss: 0.00040971174792841424, Avg. Test Loss: 0.00042279064655303955\n",
      "Epoch: 1164, Avg. Train Loss: 0.00040964324834085136, Avg. Test Loss: 0.00042402386316098273\n",
      "Epoch: 1165, Avg. Train Loss: 0.00041071398097068765, Avg. Test Loss: 0.0004239082336425781\n",
      "Epoch: 1166, Avg. Train Loss: 0.0004099307637282669, Avg. Test Loss: 0.00042429380118846893\n",
      "Epoch: 1167, Avg. Train Loss: 0.0004100172623428841, Avg. Test Loss: 0.00042562937596812844\n",
      "Epoch: 1168, Avg. Train Loss: 0.00040987777039083804, Avg. Test Loss: 0.00042368730646558106\n",
      "Epoch: 1169, Avg. Train Loss: 0.00041030346061276315, Avg. Test Loss: 0.00042245007352903485\n",
      "Epoch: 1170, Avg. Train Loss: 0.0004123070847167265, Avg. Test Loss: 0.00042390439193695784\n",
      "Epoch: 1171, Avg. Train Loss: 0.00041027297468877635, Avg. Test Loss: 0.0004313677200116217\n",
      "Epoch: 1172, Avg. Train Loss: 0.0004109914237254321, Avg. Test Loss: 0.0004230980121064931\n",
      "Epoch: 1173, Avg. Train Loss: 0.0004102890068383584, Avg. Test Loss: 0.0004235555825289339\n",
      "Epoch: 1174, Avg. Train Loss: 0.00040920280247688464, Avg. Test Loss: 0.0004238453693687916\n",
      "Epoch: 1175, Avg. Train Loss: 0.00041001439392350096, Avg. Test Loss: 0.0004236192617099732\n",
      "Epoch: 1176, Avg. Train Loss: 0.0004106249076823249, Avg. Test Loss: 0.00042492718785069883\n",
      "Epoch: 1177, Avg. Train Loss: 0.00040965786590890655, Avg. Test Loss: 0.0004243912408128381\n",
      "Epoch: 1178, Avg. Train Loss: 0.0004092071470696219, Avg. Test Loss: 0.00042241200571879745\n",
      "Epoch: 1179, Avg. Train Loss: 0.00041074355520026454, Avg. Test Loss: 0.0004269487108103931\n",
      "Epoch: 1180, Avg. Train Loss: 0.0004113188567084022, Avg. Test Loss: 0.00042439450044184923\n",
      "Epoch: 1181, Avg. Train Loss: 0.0004115341993341179, Avg. Test Loss: 0.00042620900785550475\n",
      "Epoch: 1182, Avg. Train Loss: 0.0004096510637345789, Avg. Test Loss: 0.00043324404396116734\n",
      "Epoch: 1183, Avg. Train Loss: 0.0004107531411898171, Avg. Test Loss: 0.00042337513878010213\n",
      "Epoch: 1184, Avg. Train Loss: 0.000411122745623119, Avg. Test Loss: 0.0004243358562234789\n",
      "Epoch: 1185, Avg. Train Loss: 0.00040952760866994775, Avg. Test Loss: 0.0004232642240822315\n",
      "Epoch: 1186, Avg. Train Loss: 0.0004082838652742117, Avg. Test Loss: 0.00042350898729637265\n",
      "Epoch: 1187, Avg. Train Loss: 0.0004085670110260591, Avg. Test Loss: 0.00042518950067460537\n",
      "Epoch: 1188, Avg. Train Loss: 0.0004097228574696495, Avg. Test Loss: 0.0004230561025906354\n",
      "Epoch: 1189, Avg. Train Loss: 0.0004093264788659939, Avg. Test Loss: 0.00042561598820611835\n",
      "Epoch: 1190, Avg. Train Loss: 0.0004115722021683617, Avg. Test Loss: 0.0004229747282806784\n",
      "Epoch: 1191, Avg. Train Loss: 0.00040895773536460693, Avg. Test Loss: 0.0004221638082526624\n",
      "Epoch: 1192, Avg. Train Loss: 0.0004097441777175422, Avg. Test Loss: 0.0004270168428774923\n",
      "Epoch: 1193, Avg. Train Loss: 0.0004097067630514069, Avg. Test Loss: 0.0004230337217450142\n",
      "Epoch: 1194, Avg. Train Loss: 0.00040906422492658154, Avg. Test Loss: 0.000424408121034503\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1195, Avg. Train Loss: 0.000408112637963969, Avg. Test Loss: 0.00042168167419731617\n",
      "Epoch: 1196, Avg. Train Loss: 0.00040916992123996796, Avg. Test Loss: 0.00042395907803438604\n",
      "Epoch: 1197, Avg. Train Loss: 0.00040953649616756933, Avg. Test Loss: 0.00042577245039865375\n",
      "Epoch: 1198, Avg. Train Loss: 0.0004097966268810249, Avg. Test Loss: 0.0004230277263559401\n",
      "Epoch: 1199, Avg. Train Loss: 0.0004087903050889889, Avg. Test Loss: 0.0004227290628477931\n",
      "Epoch: 1200, Avg. Train Loss: 0.0004088748361493006, Avg. Test Loss: 0.00042493335786275566\n",
      "Epoch: 1201, Avg. Train Loss: 0.00040911351395554323, Avg. Test Loss: 0.0004240259004291147\n",
      "Epoch: 1202, Avg. Train Loss: 0.00040890848626880797, Avg. Test Loss: 0.0004223474534228444\n",
      "Epoch: 1203, Avg. Train Loss: 0.0004082450387338826, Avg. Test Loss: 0.0004273125668987632\n",
      "Epoch: 1204, Avg. Train Loss: 0.00040881510019887153, Avg. Test Loss: 0.0004219881375320256\n",
      "Epoch: 1205, Avg. Train Loss: 0.00040981632679007777, Avg. Test Loss: 0.0004264794697519392\n",
      "Epoch: 1206, Avg. Train Loss: 0.0004098585652469029, Avg. Test Loss: 0.0004220588889438659\n",
      "Epoch: 1207, Avg. Train Loss: 0.00040966008795252027, Avg. Test Loss: 0.00042250080150552094\n",
      "Epoch: 1208, Avg. Train Loss: 0.00041041387986868273, Avg. Test Loss: 0.00042499671690165997\n",
      "Epoch: 1209, Avg. Train Loss: 0.0004090934593858587, Avg. Test Loss: 0.0004256226820871234\n",
      "Epoch: 1210, Avg. Train Loss: 0.0004090031535841178, Avg. Test Loss: 0.000422782963141799\n",
      "Epoch: 1211, Avg. Train Loss: 0.0004097724639334131, Avg. Test Loss: 0.00042736862087622285\n",
      "Epoch: 1212, Avg. Train Loss: 0.0004092320511496604, Avg. Test Loss: 0.0004225450393278152\n",
      "Epoch: 1213, Avg. Train Loss: 0.00040862352592697324, Avg. Test Loss: 0.0004227730387356132\n",
      "Epoch: 1214, Avg. Train Loss: 0.00040796972935759396, Avg. Test Loss: 0.0004226993187330663\n",
      "Epoch: 1215, Avg. Train Loss: 0.00040811100950312996, Avg. Test Loss: 0.000422974640969187\n",
      "Epoch: 1216, Avg. Train Loss: 0.00040844478915163943, Avg. Test Loss: 0.00042628872324712574\n",
      "Epoch: 1217, Avg. Train Loss: 0.000407413459047242, Avg. Test Loss: 0.00042241308256052434\n",
      "Epoch: 1218, Avg. Train Loss: 0.0004097588419870928, Avg. Test Loss: 0.00042098219273611903\n",
      "Epoch: 1219, Avg. Train Loss: 0.00040822774970492476, Avg. Test Loss: 0.0004244633310008794\n",
      "Epoch: 1220, Avg. Train Loss: 0.0004100789164387903, Avg. Test Loss: 0.00042333093006163836\n",
      "Epoch: 1221, Avg. Train Loss: 0.0004086997847311025, Avg. Test Loss: 0.0004259387496858835\n",
      "Epoch: 1222, Avg. Train Loss: 0.00040870170219974635, Avg. Test Loss: 0.00042222271440550685\n",
      "Epoch: 1223, Avg. Train Loss: 0.00040869881347536523, Avg. Test Loss: 0.00042322726221755147\n",
      "Epoch: 1224, Avg. Train Loss: 0.00040883814637159363, Avg. Test Loss: 0.00042297341860830784\n",
      "Epoch: 1225, Avg. Train Loss: 0.00040788763151287515, Avg. Test Loss: 0.0004324014880694449\n",
      "Epoch: 1226, Avg. Train Loss: 0.00040901462658481715, Avg. Test Loss: 0.000424135330831632\n",
      "Epoch: 1227, Avg. Train Loss: 0.00040891053571993875, Avg. Test Loss: 0.0004241506103426218\n",
      "Epoch: 1228, Avg. Train Loss: 0.0004083904644831755, Avg. Test Loss: 0.0004232828796375543\n",
      "Epoch: 1229, Avg. Train Loss: 0.000409770080803482, Avg. Test Loss: 0.0004267253680154681\n",
      "Epoch: 1230, Avg. Train Loss: 0.000412018665080067, Avg. Test Loss: 0.000424106401624158\n",
      "Epoch: 1231, Avg. Train Loss: 0.0004085434903932172, Avg. Test Loss: 0.0004260391870047897\n",
      "Epoch: 1232, Avg. Train Loss: 0.0004074793311680645, Avg. Test Loss: 0.0004220018454361707\n",
      "Epoch: 1233, Avg. Train Loss: 0.00040845055712473603, Avg. Test Loss: 0.000426825019530952\n",
      "Epoch: 1234, Avg. Train Loss: 0.0004097613814655085, Avg. Test Loss: 0.00042394472984597087\n",
      "Epoch: 1235, Avg. Train Loss: 0.00040696912139199327, Avg. Test Loss: 0.0004219666006974876\n",
      "Epoch: 1236, Avg. Train Loss: 0.00040775441380520893, Avg. Test Loss: 0.00042262027272954583\n",
      "Epoch: 1237, Avg. Train Loss: 0.000407645103879013, Avg. Test Loss: 0.0004231238563079387\n",
      "Epoch: 1238, Avg. Train Loss: 0.0004079418228451856, Avg. Test Loss: 0.00042253005085512996\n",
      "Epoch: 1239, Avg. Train Loss: 0.0004085435425093787, Avg. Test Loss: 0.00042466731974855065\n",
      "Epoch: 1240, Avg. Train Loss: 0.00040800295645630985, Avg. Test Loss: 0.0004235711239743978\n",
      "Epoch: 1241, Avg. Train Loss: 0.0004082108735442595, Avg. Test Loss: 0.00042341137304902077\n",
      "Epoch: 1242, Avg. Train Loss: 0.0004078788421560772, Avg. Test Loss: 0.00042534389649517834\n",
      "Epoch: 1243, Avg. Train Loss: 0.0004085150092493656, Avg. Test Loss: 0.00042219937313348055\n",
      "Epoch: 1244, Avg. Train Loss: 0.00040902253605836874, Avg. Test Loss: 0.00042454368667677045\n",
      "Epoch: 1245, Avg. Train Loss: 0.0004081139503436726, Avg. Test Loss: 0.00042145774932578206\n",
      "Epoch: 1246, Avg. Train Loss: 0.00040777262603474215, Avg. Test Loss: 0.00042245021904818714\n",
      "Epoch: 1247, Avg. Train Loss: 0.0004069162431162197, Avg. Test Loss: 0.0004221436392981559\n",
      "Epoch: 1248, Avg. Train Loss: 0.00040842551497071117, Avg. Test Loss: 0.0004210667684674263\n",
      "Epoch: 1249, Avg. Train Loss: 0.0004081370262970585, Avg. Test Loss: 0.00042657129233703017\n",
      "Epoch: 1250, Avg. Train Loss: 0.00040758158646112436, Avg. Test Loss: 0.00042141854646615684\n",
      "Epoch: 1251, Avg. Train Loss: 0.0004073506996826117, Avg. Test Loss: 0.0004216871166136116\n",
      "Epoch: 1252, Avg. Train Loss: 0.00040768547359918957, Avg. Test Loss: 0.00042385418782941997\n",
      "Epoch: 1253, Avg. Train Loss: 0.00040981095882544166, Avg. Test Loss: 0.00042181264143437147\n",
      "Epoch: 1254, Avg. Train Loss: 0.0004068101258125416, Avg. Test Loss: 0.0004219956463202834\n",
      "Epoch: 1255, Avg. Train Loss: 0.00040781685167403764, Avg. Test Loss: 0.00042254594154655933\n",
      "Epoch: 1256, Avg. Train Loss: 0.0004066648618263994, Avg. Test Loss: 0.0004209721810184419\n",
      "Epoch: 1257, Avg. Train Loss: 0.0004066564562340635, Avg. Test Loss: 0.00042117288103327155\n",
      "Epoch: 1258, Avg. Train Loss: 0.00040740541691437017, Avg. Test Loss: 0.000420968746766448\n",
      "Epoch: 1259, Avg. Train Loss: 0.0004078132218172297, Avg. Test Loss: 0.0004217124078422785\n",
      "Epoch: 1260, Avg. Train Loss: 0.0004075018527950052, Avg. Test Loss: 0.00042297158506698906\n",
      "Epoch: 1261, Avg. Train Loss: 0.0004085326014996268, Avg. Test Loss: 0.00042565929470583797\n",
      "Epoch: 1262, Avg. Train Loss: 0.00040767784365777705, Avg. Test Loss: 0.00042191240936517715\n",
      "Epoch: 1263, Avg. Train Loss: 0.0004077089130120395, Avg. Test Loss: 0.0004254148225300014\n",
      "Epoch: 1264, Avg. Train Loss: 0.0004073890849276511, Avg. Test Loss: 0.0004213252104818821\n",
      "Epoch: 1265, Avg. Train Loss: 0.0004072936812177474, Avg. Test Loss: 0.00042071242933161557\n",
      "Epoch: 1266, Avg. Train Loss: 0.00040823886872182576, Avg. Test Loss: 0.0004216415109112859\n",
      "Epoch: 1267, Avg. Train Loss: 0.00040795712401483987, Avg. Test Loss: 0.00042107992339879274\n",
      "Epoch: 1268, Avg. Train Loss: 0.0004076917546119021, Avg. Test Loss: 0.00042353017488494515\n",
      "Epoch: 1269, Avg. Train Loss: 0.0004063640981046266, Avg. Test Loss: 0.00042189061059616506\n",
      "Epoch: 1270, Avg. Train Loss: 0.00040784784725347406, Avg. Test Loss: 0.0004214390064589679\n",
      "Epoch: 1271, Avg. Train Loss: 0.00040830518687577096, Avg. Test Loss: 0.0004221063863951713\n",
      "Epoch: 1272, Avg. Train Loss: 0.00040700686499909607, Avg. Test Loss: 0.00042203464545309544\n",
      "Epoch: 1273, Avg. Train Loss: 0.00040855412750483253, Avg. Test Loss: 0.0004266139294486493\n",
      "Epoch: 1274, Avg. Train Loss: 0.0004070120569870829, Avg. Test Loss: 0.0004233673680573702\n",
      "Epoch: 1275, Avg. Train Loss: 0.0004070570325576375, Avg. Test Loss: 0.000423769757617265\n",
      "Epoch: 1276, Avg. Train Loss: 0.00040714486588745615, Avg. Test Loss: 0.0004208566970191896\n",
      "Epoch: 1277, Avg. Train Loss: 0.0004067995279572558, Avg. Test Loss: 0.00042313471203669906\n",
      "Epoch: 1278, Avg. Train Loss: 0.00040684652319827744, Avg. Test Loss: 0.0004231703351251781\n",
      "Epoch: 1279, Avg. Train Loss: 0.0004066983014507609, Avg. Test Loss: 0.00042303805821575224\n",
      "Epoch: 1280, Avg. Train Loss: 0.0004068321655341966, Avg. Test Loss: 0.0004231881757732481\n",
      "Epoch: 1281, Avg. Train Loss: 0.00040671900781088095, Avg. Test Loss: 0.000421742326579988\n",
      "Epoch: 1282, Avg. Train Loss: 0.00040611731115901885, Avg. Test Loss: 0.0004217230889480561\n",
      "Epoch: 1283, Avg. Train Loss: 0.00040638365993969313, Avg. Test Loss: 0.000421946810092777\n",
      "Epoch: 1284, Avg. Train Loss: 0.0004064267261636032, Avg. Test Loss: 0.00042243272764608264\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1285, Avg. Train Loss: 0.00040601465856483163, Avg. Test Loss: 0.00042000546818599105\n",
      "Epoch: 1286, Avg. Train Loss: 0.0004067644030180608, Avg. Test Loss: 0.0004257034743204713\n",
      "Epoch: 1287, Avg. Train Loss: 0.000407642179959302, Avg. Test Loss: 0.0004204052675049752\n",
      "Epoch: 1288, Avg. Train Loss: 0.00040631252679389056, Avg. Test Loss: 0.0004196251684334129\n",
      "Epoch: 1289, Avg. Train Loss: 0.0004068885247634594, Avg. Test Loss: 0.00042184069752693176\n",
      "Epoch: 1290, Avg. Train Loss: 0.00040716211092225167, Avg. Test Loss: 0.0004212773928884417\n",
      "Epoch: 1291, Avg. Train Loss: 0.0004059978088006637, Avg. Test Loss: 0.00042194509296678007\n",
      "Epoch: 1292, Avg. Train Loss: 0.0004056346011185629, Avg. Test Loss: 0.0004214716318529099\n",
      "Epoch: 1293, Avg. Train Loss: 0.00040885976171879055, Avg. Test Loss: 0.00042504406883381307\n",
      "Epoch: 1294, Avg. Train Loss: 0.0004069550094183881, Avg. Test Loss: 0.00041968151344917715\n",
      "Epoch: 1295, Avg. Train Loss: 0.00040613508073959585, Avg. Test Loss: 0.0004232247592881322\n",
      "Epoch: 1296, Avg. Train Loss: 0.0004075786131325849, Avg. Test Loss: 0.0004223558644298464\n",
      "Epoch: 1297, Avg. Train Loss: 0.0004078909019712185, Avg. Test Loss: 0.00042462191777303815\n",
      "Epoch: 1298, Avg. Train Loss: 0.000406415403419889, Avg. Test Loss: 0.00042060294072143734\n",
      "Epoch: 1299, Avg. Train Loss: 0.0004069551143275444, Avg. Test Loss: 0.00042493760702200234\n",
      "Epoch: 1300, Avg. Train Loss: 0.00040803571857057165, Avg. Test Loss: 0.0004204088181722909\n",
      "Epoch: 1301, Avg. Train Loss: 0.00040570196362623817, Avg. Test Loss: 0.0004224585136398673\n",
      "Epoch: 1302, Avg. Train Loss: 0.00040683295404495196, Avg. Test Loss: 0.00042023666901513934\n",
      "Epoch: 1303, Avg. Train Loss: 0.00040676003473615925, Avg. Test Loss: 0.0004226212331559509\n",
      "Epoch: 1304, Avg. Train Loss: 0.00040753271842245445, Avg. Test Loss: 0.0004300622676964849\n",
      "Epoch: 1305, Avg. Train Loss: 0.00040800371857056784, Avg. Test Loss: 0.0004198365786578506\n",
      "Epoch: 1306, Avg. Train Loss: 0.0004063129295096841, Avg. Test Loss: 0.0004208811733406037\n",
      "Epoch: 1307, Avg. Train Loss: 0.00040632339605931625, Avg. Test Loss: 0.00042284862138330936\n",
      "Epoch: 1308, Avg. Train Loss: 0.00040601341183795484, Avg. Test Loss: 0.0004210805054754019\n",
      "Epoch: 1309, Avg. Train Loss: 0.0004061465402036299, Avg. Test Loss: 0.0004198139940854162\n",
      "Epoch: 1310, Avg. Train Loss: 0.00040634781620356924, Avg. Test Loss: 0.0004217055975459516\n",
      "Epoch: 1311, Avg. Train Loss: 0.000406346105845905, Avg. Test Loss: 0.00042420264799147844\n",
      "Epoch: 1312, Avg. Train Loss: 0.0004071057347721572, Avg. Test Loss: 0.0004209170292597264\n",
      "Epoch: 1313, Avg. Train Loss: 0.00040617056643092183, Avg. Test Loss: 0.00042072319774888456\n",
      "Epoch: 1314, Avg. Train Loss: 0.00040673851617611945, Avg. Test Loss: 0.00042458687676116824\n",
      "Epoch: 1315, Avg. Train Loss: 0.0004070413002451925, Avg. Test Loss: 0.00042010884499177337\n",
      "Epoch: 1316, Avg. Train Loss: 0.0004058016300320539, Avg. Test Loss: 0.0004225067386869341\n",
      "Epoch: 1317, Avg. Train Loss: 0.0004052678996231407, Avg. Test Loss: 0.00041976949432864785\n",
      "Epoch: 1318, Avg. Train Loss: 0.00040693795254324064, Avg. Test Loss: 0.00042683587525971234\n",
      "Epoch: 1319, Avg. Train Loss: 0.00040646148832016734, Avg. Test Loss: 0.0004212511994410306\n",
      "Epoch: 1320, Avg. Train Loss: 0.000407243950893496, Avg. Test Loss: 0.0004205169389024377\n",
      "Epoch: 1321, Avg. Train Loss: 0.0004057164248458088, Avg. Test Loss: 0.00042092319927178323\n",
      "Epoch: 1322, Avg. Train Loss: 0.00040470610499966804, Avg. Test Loss: 0.00042213339474983513\n",
      "Epoch: 1323, Avg. Train Loss: 0.0004056926314491605, Avg. Test Loss: 0.00042435398790985346\n",
      "Epoch: 1324, Avg. Train Loss: 0.00040664619544174437, Avg. Test Loss: 0.00042161517194472253\n",
      "Epoch: 1325, Avg. Train Loss: 0.0004061918210259877, Avg. Test Loss: 0.00042656681034713984\n",
      "Epoch: 1326, Avg. Train Loss: 0.00040507508065486546, Avg. Test Loss: 0.0004213809152133763\n",
      "Epoch: 1327, Avg. Train Loss: 0.0004060292023580608, Avg. Test Loss: 0.0004202979616820812\n",
      "Epoch: 1328, Avg. Train Loss: 0.0004069341385877843, Avg. Test Loss: 0.00042274611769244075\n",
      "Epoch: 1329, Avg. Train Loss: 0.00040579669321020846, Avg. Test Loss: 0.00042149159708060324\n",
      "Epoch: 1330, Avg. Train Loss: 0.00040609290184409814, Avg. Test Loss: 0.0004202153068035841\n",
      "Epoch: 1331, Avg. Train Loss: 0.00040641913615535336, Avg. Test Loss: 0.00042117878911085427\n",
      "Epoch: 1332, Avg. Train Loss: 0.0004052122334711427, Avg. Test Loss: 0.0004200274997856468\n",
      "Epoch: 1333, Avg. Train Loss: 0.00040507790101908665, Avg. Test Loss: 0.0004213014035485685\n",
      "Epoch: 1334, Avg. Train Loss: 0.00040468932765665963, Avg. Test Loss: 0.00041912434971891344\n",
      "Epoch: 1335, Avg. Train Loss: 0.00040504887434762233, Avg. Test Loss: 0.00041885144310072064\n",
      "Epoch: 1336, Avg. Train Loss: 0.0004036969107272493, Avg. Test Loss: 0.000418437528423965\n",
      "Epoch: 1337, Avg. Train Loss: 0.00040411504275208814, Avg. Test Loss: 0.0004195872461423278\n",
      "Epoch: 1338, Avg. Train Loss: 0.00040395288568444897, Avg. Test Loss: 0.00041888264240697026\n",
      "Epoch: 1339, Avg. Train Loss: 0.0004050486205351474, Avg. Test Loss: 0.0004254892119206488\n",
      "Epoch: 1340, Avg. Train Loss: 0.0004047673218612841, Avg. Test Loss: 0.00042020497494377196\n",
      "Epoch: 1341, Avg. Train Loss: 0.0004043264868181892, Avg. Test Loss: 0.0004186090372968465\n",
      "Epoch: 1342, Avg. Train Loss: 0.00040381023901254803, Avg. Test Loss: 0.00042630149982869625\n",
      "Epoch: 1343, Avg. Train Loss: 0.00040392675179836535, Avg. Test Loss: 0.00041956276982091367\n",
      "Epoch: 1344, Avg. Train Loss: 0.0004034572609884361, Avg. Test Loss: 0.00042351914453320205\n",
      "Epoch: 1345, Avg. Train Loss: 0.0004047022720928802, Avg. Test Loss: 0.0004190805193502456\n",
      "Epoch: 1346, Avg. Train Loss: 0.0004059442577526233, Avg. Test Loss: 0.00041879803757183254\n",
      "Epoch: 1347, Avg. Train Loss: 0.0004046980391776319, Avg. Test Loss: 0.00041933765169233084\n",
      "Epoch: 1348, Avg. Train Loss: 0.00040422540989184624, Avg. Test Loss: 0.00041877233888953924\n",
      "Epoch: 1349, Avg. Train Loss: 0.00040350300679524795, Avg. Test Loss: 0.0004184469871688634\n",
      "Epoch: 1350, Avg. Train Loss: 0.00040308095928996284, Avg. Test Loss: 0.0004193191125523299\n",
      "Epoch: 1351, Avg. Train Loss: 0.0004043748634759077, Avg. Test Loss: 0.00041868584230542183\n",
      "Epoch: 1352, Avg. Train Loss: 0.00040335599048777897, Avg. Test Loss: 0.0004245367308612913\n",
      "Epoch: 1353, Avg. Train Loss: 0.0004047116563861193, Avg. Test Loss: 0.00042014464270323515\n",
      "Epoch: 1354, Avg. Train Loss: 0.0004043385094075009, Avg. Test Loss: 0.00041977062937803566\n",
      "Epoch: 1355, Avg. Train Loss: 0.00040370804801864854, Avg. Test Loss: 0.0004205579461995512\n",
      "Epoch: 1356, Avg. Train Loss: 0.0004036047104691957, Avg. Test Loss: 0.00041826252709142864\n",
      "Epoch: 1357, Avg. Train Loss: 0.00040208184644904767, Avg. Test Loss: 0.00041686033364385366\n",
      "Epoch: 1358, Avg. Train Loss: 0.0004021092609036714, Avg. Test Loss: 0.0004210296901874244\n",
      "Epoch: 1359, Avg. Train Loss: 0.0004040621725983138, Avg. Test Loss: 0.0004170481115579605\n",
      "Epoch: 1360, Avg. Train Loss: 0.00040245174868898685, Avg. Test Loss: 0.00041862705256789923\n",
      "Epoch: 1361, Avg. Train Loss: 0.0004027454503324576, Avg. Test Loss: 0.0004200597759336233\n",
      "Epoch: 1362, Avg. Train Loss: 0.0004023218264824949, Avg. Test Loss: 0.0004181729455012828\n",
      "Epoch: 1363, Avg. Train Loss: 0.00040233838114735865, Avg. Test Loss: 0.00041682287701405585\n",
      "Epoch: 1364, Avg. Train Loss: 0.00040147938700609427, Avg. Test Loss: 0.0004220776609145105\n",
      "Epoch: 1365, Avg. Train Loss: 0.0004027870166938492, Avg. Test Loss: 0.0004186050209682435\n",
      "Epoch: 1366, Avg. Train Loss: 0.0004017653788418271, Avg. Test Loss: 0.00042206142097711563\n",
      "Epoch: 1367, Avg. Train Loss: 0.00040316848872164483, Avg. Test Loss: 0.00041684811003506184\n",
      "Epoch: 1368, Avg. Train Loss: 0.00040211985808212395, Avg. Test Loss: 0.00041874838643707335\n",
      "Epoch: 1369, Avg. Train Loss: 0.000402581031288042, Avg. Test Loss: 0.0004202369600534439\n",
      "Epoch: 1370, Avg. Train Loss: 0.00040295510485140217, Avg. Test Loss: 0.00041622959543019533\n",
      "Epoch: 1371, Avg. Train Loss: 0.00040288799344886874, Avg. Test Loss: 0.00042038061656057835\n",
      "Epoch: 1372, Avg. Train Loss: 0.00040257249709738547, Avg. Test Loss: 0.00041875787428580225\n",
      "Epoch: 1373, Avg. Train Loss: 0.00040153039992938555, Avg. Test Loss: 0.0004184126737527549\n",
      "Epoch: 1374, Avg. Train Loss: 0.00040245193549496834, Avg. Test Loss: 0.0004191978950984776\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1375, Avg. Train Loss: 0.00040534677235734497, Avg. Test Loss: 0.0004236761014908552\n",
      "Epoch: 1376, Avg. Train Loss: 0.0004021931855213763, Avg. Test Loss: 0.00041810391121543944\n",
      "Epoch: 1377, Avg. Train Loss: 0.00040238688098873164, Avg. Test Loss: 0.0004238672845531255\n",
      "Epoch: 1378, Avg. Train Loss: 0.0004019983780169643, Avg. Test Loss: 0.0004165402497164905\n",
      "Epoch: 1379, Avg. Train Loss: 0.0004022568545499167, Avg. Test Loss: 0.0004179336247034371\n",
      "Epoch: 1380, Avg. Train Loss: 0.00040193749821831496, Avg. Test Loss: 0.0004161484830547124\n",
      "Epoch: 1381, Avg. Train Loss: 0.0004029160522487621, Avg. Test Loss: 0.0004161676042713225\n",
      "Epoch: 1382, Avg. Train Loss: 0.000402450179112642, Avg. Test Loss: 0.00041800629696808755\n",
      "Epoch: 1383, Avg. Train Loss: 0.00040057679938780533, Avg. Test Loss: 0.0004169938911218196\n",
      "Epoch: 1384, Avg. Train Loss: 0.00040222252285931, Avg. Test Loss: 0.0004166175494901836\n",
      "Epoch: 1385, Avg. Train Loss: 0.0004029884558106058, Avg. Test Loss: 0.00041675177635625005\n",
      "Epoch: 1386, Avg. Train Loss: 0.0004018812513433743, Avg. Test Loss: 0.0004157536313869059\n",
      "Epoch: 1387, Avg. Train Loss: 0.00040110022501023705, Avg. Test Loss: 0.00041702386806719005\n",
      "Epoch: 1388, Avg. Train Loss: 0.0004030972087030234, Avg. Test Loss: 0.0004235469677951187\n",
      "Epoch: 1389, Avg. Train Loss: 0.00040081196510622844, Avg. Test Loss: 0.0004177336231805384\n",
      "Epoch: 1390, Avg. Train Loss: 0.0004017320332972896, Avg. Test Loss: 0.000416325667174533\n",
      "Epoch: 1391, Avg. Train Loss: 0.0004011521333839398, Avg. Test Loss: 0.00041613588109612465\n",
      "Epoch: 1392, Avg. Train Loss: 0.00040005352334552554, Avg. Test Loss: 0.00041776750003919005\n",
      "Epoch: 1393, Avg. Train Loss: 0.00040118819912137506, Avg. Test Loss: 0.0004181870026513934\n",
      "Epoch: 1394, Avg. Train Loss: 0.000400244221795177, Avg. Test Loss: 0.0004172836779616773\n",
      "Epoch: 1395, Avg. Train Loss: 0.0004035821502627588, Avg. Test Loss: 0.0004177453520242125\n",
      "Epoch: 1396, Avg. Train Loss: 0.0004008819334219795, Avg. Test Loss: 0.00041612214408814907\n",
      "Epoch: 1397, Avg. Train Loss: 0.0004025620643894166, Avg. Test Loss: 0.00042002720874734223\n",
      "Epoch: 1398, Avg. Train Loss: 0.000402359448936443, Avg. Test Loss: 0.00042034333455376327\n",
      "Epoch: 1399, Avg. Train Loss: 0.00040222325993073715, Avg. Test Loss: 0.00041673454688861966\n",
      "Epoch: 1400, Avg. Train Loss: 0.00040078186971503633, Avg. Test Loss: 0.0004157883522566408\n",
      "Epoch: 1401, Avg. Train Loss: 0.00040198468229581797, Avg. Test Loss: 0.0004163054400123656\n",
      "Epoch: 1402, Avg. Train Loss: 0.00040038983096628517, Avg. Test Loss: 0.0004172400222159922\n",
      "Epoch: 1403, Avg. Train Loss: 0.00040272458627018645, Avg. Test Loss: 0.00041571573819965124\n",
      "Epoch: 1404, Avg. Train Loss: 0.00040039120019998316, Avg. Test Loss: 0.0004213458742015064\n",
      "Epoch: 1405, Avg. Train Loss: 0.0004013662380816112, Avg. Test Loss: 0.0004165017744526267\n",
      "Epoch: 1406, Avg. Train Loss: 0.0004012921031802719, Avg. Test Loss: 0.00041680753929540515\n",
      "Epoch: 1407, Avg. Train Loss: 0.0003999455772383615, Avg. Test Loss: 0.00041639996925368905\n",
      "Epoch: 1408, Avg. Train Loss: 0.0004002257131126731, Avg. Test Loss: 0.00041667657205834985\n",
      "Epoch: 1409, Avg. Train Loss: 0.00040041713442025317, Avg. Test Loss: 0.00041867431718856096\n",
      "Epoch: 1410, Avg. Train Loss: 0.0004000852268925586, Avg. Test Loss: 0.0004190752515569329\n",
      "Epoch: 1411, Avg. Train Loss: 0.0004008302937510835, Avg. Test Loss: 0.00041858418262563646\n",
      "Epoch: 1412, Avg. Train Loss: 0.0004006349684692226, Avg. Test Loss: 0.00041780885658226907\n",
      "Epoch: 1413, Avg. Train Loss: 0.0004013687971881916, Avg. Test Loss: 0.0004184081335552037\n",
      "Epoch: 1414, Avg. Train Loss: 0.0004008956223747931, Avg. Test Loss: 0.00042149348882958293\n",
      "Epoch: 1415, Avg. Train Loss: 0.0004009995183116908, Avg. Test Loss: 0.00041589082684367895\n",
      "Epoch: 1416, Avg. Train Loss: 0.00040121410017681503, Avg. Test Loss: 0.00041564012644812465\n",
      "Epoch: 1417, Avg. Train Loss: 0.00039978575253815847, Avg. Test Loss: 0.00041572394547984004\n",
      "Epoch: 1418, Avg. Train Loss: 0.00039911753062137165, Avg. Test Loss: 0.00041491870069876313\n",
      "Epoch: 1419, Avg. Train Loss: 0.0004028238648505405, Avg. Test Loss: 0.0004160113458056003\n",
      "Epoch: 1420, Avg. Train Loss: 0.00040096672709359854, Avg. Test Loss: 0.00041614403016865253\n",
      "Epoch: 1421, Avg. Train Loss: 0.0004002643271273565, Avg. Test Loss: 0.00041848543332889676\n",
      "Epoch: 1422, Avg. Train Loss: 0.00040113149741447944, Avg. Test Loss: 0.0004181746335234493\n",
      "Epoch: 1423, Avg. Train Loss: 0.0004009789554402232, Avg. Test Loss: 0.0004180819378234446\n",
      "Epoch: 1424, Avg. Train Loss: 0.0004017670540041615, Avg. Test Loss: 0.0004236000240780413\n",
      "Epoch: 1425, Avg. Train Loss: 0.0004006951883554372, Avg. Test Loss: 0.0004146336286794394\n",
      "Epoch: 1426, Avg. Train Loss: 0.00039981419984034676, Avg. Test Loss: 0.0004201707779429853\n",
      "Epoch: 1427, Avg. Train Loss: 0.00040145426363207747, Avg. Test Loss: 0.0004187367740087211\n",
      "Epoch: 1428, Avg. Train Loss: 0.0004014801619801844, Avg. Test Loss: 0.000415694375988096\n",
      "Epoch: 1429, Avg. Train Loss: 0.0004005009446531361, Avg. Test Loss: 0.0004146867140661925\n",
      "Epoch: 1430, Avg. Train Loss: 0.00039953618786882524, Avg. Test Loss: 0.00041691306978464127\n",
      "Epoch: 1431, Avg. Train Loss: 0.00040153501322492957, Avg. Test Loss: 0.00041909265564754605\n",
      "Epoch: 1432, Avg. Train Loss: 0.0004014565553895176, Avg. Test Loss: 0.00042025031871162355\n",
      "Epoch: 1433, Avg. Train Loss: 0.00040120063051797967, Avg. Test Loss: 0.0004141523677390069\n",
      "Epoch: 1434, Avg. Train Loss: 0.0003995515601059725, Avg. Test Loss: 0.0004149096494074911\n",
      "Epoch: 1435, Avg. Train Loss: 0.0003998401191702849, Avg. Test Loss: 0.000414264271967113\n",
      "Epoch: 1436, Avg. Train Loss: 0.0004005407329735368, Avg. Test Loss: 0.0004160654207225889\n",
      "Epoch: 1437, Avg. Train Loss: 0.00040017410863710695, Avg. Test Loss: 0.00041677994886413217\n",
      "Epoch: 1438, Avg. Train Loss: 0.000401530954932664, Avg. Test Loss: 0.00041725373012013733\n",
      "Epoch: 1439, Avg. Train Loss: 0.0004007594408142532, Avg. Test Loss: 0.0004170433967374265\n",
      "Epoch: 1440, Avg. Train Loss: 0.00039962689638635966, Avg. Test Loss: 0.00041944283293560147\n",
      "Epoch: 1441, Avg. Train Loss: 0.0003998524517492326, Avg. Test Loss: 0.0004145588318351656\n",
      "Epoch: 1442, Avg. Train Loss: 0.0004003156419182846, Avg. Test Loss: 0.00041469212737865746\n",
      "Epoch: 1443, Avg. Train Loss: 0.00039961087100511027, Avg. Test Loss: 0.00041810853872448206\n",
      "Epoch: 1444, Avg. Train Loss: 0.0003993904115199003, Avg. Test Loss: 0.0004144632548559457\n",
      "Epoch: 1445, Avg. Train Loss: 0.00039998530938160107, Avg. Test Loss: 0.0004164610872976482\n",
      "Epoch: 1446, Avg. Train Loss: 0.00040233387614513723, Avg. Test Loss: 0.00041419421904720366\n",
      "Epoch: 1447, Avg. Train Loss: 0.00039973586789592236, Avg. Test Loss: 0.0004155731585342437\n",
      "Epoch: 1448, Avg. Train Loss: 0.00040020855606620224, Avg. Test Loss: 0.0004149191954638809\n",
      "Epoch: 1449, Avg. Train Loss: 0.00040038347144091374, Avg. Test Loss: 0.0004175317590124905\n",
      "Epoch: 1450, Avg. Train Loss: 0.000400151995140626, Avg. Test Loss: 0.0004142877587582916\n",
      "Epoch: 1451, Avg. Train Loss: 0.0004001377647211992, Avg. Test Loss: 0.00041407725075259805\n",
      "Epoch: 1452, Avg. Train Loss: 0.000398978159145647, Avg. Test Loss: 0.0004150625900365412\n",
      "Epoch: 1453, Avg. Train Loss: 0.00040046160710369085, Avg. Test Loss: 0.0004155183560214937\n",
      "Epoch: 1454, Avg. Train Loss: 0.00040029960503086965, Avg. Test Loss: 0.0004232444625813514\n",
      "Epoch: 1455, Avg. Train Loss: 0.0004014314976683276, Avg. Test Loss: 0.00041651047649793327\n",
      "Epoch: 1456, Avg. Train Loss: 0.00039931678965817705, Avg. Test Loss: 0.00041392355342395604\n",
      "Epoch: 1457, Avg. Train Loss: 0.0003998386084784342, Avg. Test Loss: 0.0004190300533082336\n",
      "Epoch: 1458, Avg. Train Loss: 0.0003993546496806017, Avg. Test Loss: 0.0004147814470343292\n",
      "Epoch: 1459, Avg. Train Loss: 0.0003983170534538235, Avg. Test Loss: 0.0004146148276049644\n",
      "Epoch: 1460, Avg. Train Loss: 0.00039965234328667785, Avg. Test Loss: 0.00041800763574428856\n",
      "Epoch: 1461, Avg. Train Loss: 0.00040031455966189157, Avg. Test Loss: 0.00041581859113648534\n",
      "Epoch: 1462, Avg. Train Loss: 0.000398437826905053, Avg. Test Loss: 0.00041410126141272485\n",
      "Epoch: 1463, Avg. Train Loss: 0.0003991479488620318, Avg. Test Loss: 0.00041742532630451024\n",
      "Epoch: 1464, Avg. Train Loss: 0.00039910695374791705, Avg. Test Loss: 0.0004149357264395803\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1465, Avg. Train Loss: 0.00039903885822981425, Avg. Test Loss: 0.00041589440661482513\n",
      "Epoch: 1466, Avg. Train Loss: 0.0003994327163063856, Avg. Test Loss: 0.00041459506610408425\n",
      "Epoch: 1467, Avg. Train Loss: 0.000398236328226969, Avg. Test Loss: 0.0004210273618809879\n",
      "Epoch: 1468, Avg. Train Loss: 0.0003999917575721304, Avg. Test Loss: 0.0004149273154325783\n",
      "Epoch: 1469, Avg. Train Loss: 0.0003997070808234343, Avg. Test Loss: 0.0004142917459830642\n",
      "Epoch: 1470, Avg. Train Loss: 0.00040002095818974425, Avg. Test Loss: 0.0004211042250972241\n",
      "Epoch: 1471, Avg. Train Loss: 0.00040125896677721377, Avg. Test Loss: 0.0004182544944342226\n",
      "Epoch: 1472, Avg. Train Loss: 0.0003999898658231507, Avg. Test Loss: 0.0004159582022111863\n",
      "Epoch: 1473, Avg. Train Loss: 0.0004005257499155177, Avg. Test Loss: 0.00042520754504948854\n",
      "Epoch: 1474, Avg. Train Loss: 0.0004002935507573014, Avg. Test Loss: 0.00041426660027354956\n",
      "Epoch: 1475, Avg. Train Loss: 0.0003994571411884715, Avg. Test Loss: 0.0004167034931015223\n",
      "Epoch: 1476, Avg. Train Loss: 0.00039931962491273015, Avg. Test Loss: 0.00041363618220202625\n",
      "Epoch: 1477, Avg. Train Loss: 0.0003996317750005441, Avg. Test Loss: 0.000414081325288862\n",
      "Epoch: 1478, Avg. Train Loss: 0.00039793155156075954, Avg. Test Loss: 0.00041418912587687373\n",
      "Epoch: 1479, Avg. Train Loss: 0.00039809059925637275, Avg. Test Loss: 0.00041758143925108016\n",
      "Epoch: 1480, Avg. Train Loss: 0.00039990069439396433, Avg. Test Loss: 0.0004138648509979248\n",
      "Epoch: 1481, Avg. Train Loss: 0.00039828580609241196, Avg. Test Loss: 0.00041455714381299913\n",
      "Epoch: 1482, Avg. Train Loss: 0.0003985587580584336, Avg. Test Loss: 0.00041501459782011807\n",
      "Epoch: 1483, Avg. Train Loss: 0.00039952207927938636, Avg. Test Loss: 0.00042421245598234236\n",
      "Epoch: 1484, Avg. Train Loss: 0.0004004841111329666, Avg. Test Loss: 0.00041314924601465464\n",
      "Epoch: 1485, Avg. Train Loss: 0.0003986179017797546, Avg. Test Loss: 0.0004147540021222085\n",
      "Epoch: 1486, Avg. Train Loss: 0.0003990167860201625, Avg. Test Loss: 0.00041617389069870114\n",
      "Epoch: 1487, Avg. Train Loss: 0.00039994704461288316, Avg. Test Loss: 0.00041693588718771935\n",
      "Epoch: 1488, Avg. Train Loss: 0.0003997506194769643, Avg. Test Loss: 0.0004169249441474676\n",
      "Epoch: 1489, Avg. Train Loss: 0.0003989399031757615, Avg. Test Loss: 0.00041567732114344835\n",
      "Epoch: 1490, Avg. Train Loss: 0.00039906975296109397, Avg. Test Loss: 0.0004143966070841998\n",
      "Epoch: 1491, Avg. Train Loss: 0.00039869208676675553, Avg. Test Loss: 0.00041741400491446257\n",
      "Epoch: 1492, Avg. Train Loss: 0.00040096550879371894, Avg. Test Loss: 0.0004205101286061108\n",
      "Epoch: 1493, Avg. Train Loss: 0.00039929737875692893, Avg. Test Loss: 0.0004141598765272647\n",
      "Epoch: 1494, Avg. Train Loss: 0.0003986922275480749, Avg. Test Loss: 0.00041735798004083335\n",
      "Epoch: 1495, Avg. Train Loss: 0.00039786191353964254, Avg. Test Loss: 0.0004151401808485389\n",
      "Epoch: 1496, Avg. Train Loss: 0.00039800147452868174, Avg. Test Loss: 0.00041451945435255766\n",
      "Epoch: 1497, Avg. Train Loss: 0.00039812468796383675, Avg. Test Loss: 0.00041413301369175315\n",
      "Epoch: 1498, Avg. Train Loss: 0.0003981669650001581, Avg. Test Loss: 0.0004132207250222564\n",
      "Epoch: 1499, Avg. Train Loss: 0.00039754349935994764, Avg. Test Loss: 0.000413591944379732\n",
      "Epoch: 1500, Avg. Train Loss: 0.0003989920091847781, Avg. Test Loss: 0.00041531247552484274\n",
      "Epoch: 1501, Avg. Train Loss: 0.00039828446393204463, Avg. Test Loss: 0.00041201483691111207\n",
      "Epoch: 1502, Avg. Train Loss: 0.00039774711991032196, Avg. Test Loss: 0.0004201583215035498\n",
      "Epoch: 1503, Avg. Train Loss: 0.00039911616680233977, Avg. Test Loss: 0.00041494215838611126\n",
      "Epoch: 1504, Avg. Train Loss: 0.00039821128607294413, Avg. Test Loss: 0.0004123563121538609\n",
      "Epoch: 1505, Avg. Train Loss: 0.0003979662196374996, Avg. Test Loss: 0.00041421057539992034\n",
      "Epoch: 1506, Avg. Train Loss: 0.00039838306229496594, Avg. Test Loss: 0.00041599510586820543\n",
      "Epoch: 1507, Avg. Train Loss: 0.0003983905534855588, Avg. Test Loss: 0.0004153392219450325\n",
      "Epoch: 1508, Avg. Train Loss: 0.0003986404680776908, Avg. Test Loss: 0.00041412003338336945\n",
      "Epoch: 1509, Avg. Train Loss: 0.0003985907208326078, Avg. Test Loss: 0.0004146269930060953\n",
      "Epoch: 1510, Avg. Train Loss: 0.0003978068653364168, Avg. Test Loss: 0.00041305716149508953\n",
      "Epoch: 1511, Avg. Train Loss: 0.0003974112447860196, Avg. Test Loss: 0.00041319956653751433\n",
      "Epoch: 1512, Avg. Train Loss: 0.0003975335871367607, Avg. Test Loss: 0.00041369491373188794\n",
      "Epoch: 1513, Avg. Train Loss: 0.00040086837983581907, Avg. Test Loss: 0.00041520758531987667\n",
      "Epoch: 1514, Avg. Train Loss: 0.00039889680243335494, Avg. Test Loss: 0.0004127242718823254\n",
      "Epoch: 1515, Avg. Train Loss: 0.00039726729453324754, Avg. Test Loss: 0.0004131017776671797\n",
      "Epoch: 1516, Avg. Train Loss: 0.0003974003315264316, Avg. Test Loss: 0.00041593951755203307\n",
      "Epoch: 1517, Avg. Train Loss: 0.00039871818410384274, Avg. Test Loss: 0.00041738414438441396\n",
      "Epoch: 1518, Avg. Train Loss: 0.00039747621807226436, Avg. Test Loss: 0.0004126301791984588\n",
      "Epoch: 1519, Avg. Train Loss: 0.0003980655361205166, Avg. Test Loss: 0.00041214984958060086\n",
      "Epoch: 1520, Avg. Train Loss: 0.0003974502405346653, Avg. Test Loss: 0.0004141817335039377\n",
      "Epoch: 1521, Avg. Train Loss: 0.0003977390980824482, Avg. Test Loss: 0.00041374520515091717\n",
      "Epoch: 1522, Avg. Train Loss: 0.00039862761366029465, Avg. Test Loss: 0.00041304700425826013\n",
      "Epoch: 1523, Avg. Train Loss: 0.00039824158045311653, Avg. Test Loss: 0.0004132675821892917\n",
      "Epoch: 1524, Avg. Train Loss: 0.0003976156382799842, Avg. Test Loss: 0.000411953660659492\n",
      "Epoch: 1525, Avg. Train Loss: 0.00039769149030732034, Avg. Test Loss: 0.0004133752954658121\n",
      "Epoch: 1526, Avg. Train Loss: 0.00039667248330620483, Avg. Test Loss: 0.00041379366302862763\n",
      "Epoch: 1527, Avg. Train Loss: 0.00039761744948580514, Avg. Test Loss: 0.00042000654502771795\n",
      "Epoch: 1528, Avg. Train Loss: 0.0003984123184129076, Avg. Test Loss: 0.0004163073899690062\n",
      "Epoch: 1529, Avg. Train Loss: 0.0003976338268203531, Avg. Test Loss: 0.00041237729601562023\n",
      "Epoch: 1530, Avg. Train Loss: 0.0003982097645517612, Avg. Test Loss: 0.0004117889911867678\n",
      "Epoch: 1531, Avg. Train Loss: 0.0003981885018346961, Avg. Test Loss: 0.0004190421896055341\n",
      "Epoch: 1532, Avg. Train Loss: 0.00039705000601189083, Avg. Test Loss: 0.0004154462949372828\n",
      "Epoch: 1533, Avg. Train Loss: 0.0003975369679189265, Avg. Test Loss: 0.00041923177195712924\n",
      "Epoch: 1534, Avg. Train Loss: 0.00039943467167769236, Avg. Test Loss: 0.00041835239971987903\n",
      "Epoch: 1535, Avg. Train Loss: 0.00039857622171037417, Avg. Test Loss: 0.0004110861918888986\n",
      "Epoch: 1536, Avg. Train Loss: 0.00039732351433485746, Avg. Test Loss: 0.00041942298412323\n",
      "Epoch: 1537, Avg. Train Loss: 0.00039804196878617934, Avg. Test Loss: 0.00041142929694615304\n",
      "Epoch: 1538, Avg. Train Loss: 0.0003970552352257073, Avg. Test Loss: 0.00041274228715337813\n",
      "Epoch: 1539, Avg. Train Loss: 0.0003975503685407687, Avg. Test Loss: 0.00041571399196982384\n",
      "Epoch: 1540, Avg. Train Loss: 0.0003969289435528565, Avg. Test Loss: 0.0004135617346037179\n",
      "Epoch: 1541, Avg. Train Loss: 0.0003962840926887597, Avg. Test Loss: 0.0004112635215278715\n",
      "Epoch: 1542, Avg. Train Loss: 0.0003965668817494758, Avg. Test Loss: 0.0004116166091989726\n",
      "Epoch: 1543, Avg. Train Loss: 0.0004006558453913258, Avg. Test Loss: 0.0004140636883676052\n",
      "Epoch: 1544, Avg. Train Loss: 0.0003969666661781281, Avg. Test Loss: 0.0004120172234252095\n",
      "Epoch: 1545, Avg. Train Loss: 0.00039669711326877045, Avg. Test Loss: 0.0004141635727137327\n",
      "Epoch: 1546, Avg. Train Loss: 0.00039673715404797954, Avg. Test Loss: 0.000412352557759732\n",
      "Epoch: 1547, Avg. Train Loss: 0.00039691801337243685, Avg. Test Loss: 0.0004146859282627702\n",
      "Epoch: 1548, Avg. Train Loss: 0.0003984830062024209, Avg. Test Loss: 0.0004132914764340967\n",
      "Epoch: 1549, Avg. Train Loss: 0.00039834581277614764, Avg. Test Loss: 0.0004160899843554944\n",
      "Epoch: 1550, Avg. Train Loss: 0.00039682179475528036, Avg. Test Loss: 0.0004114211187697947\n",
      "Epoch: 1551, Avg. Train Loss: 0.00039587391142430174, Avg. Test Loss: 0.00041574810165911913\n",
      "Epoch: 1552, Avg. Train Loss: 0.0003968617319789997, Avg. Test Loss: 0.0004112715250812471\n",
      "Epoch: 1553, Avg. Train Loss: 0.0003966050422858707, Avg. Test Loss: 0.0004154849739279598\n",
      "Epoch: 1554, Avg. Train Loss: 0.00039747601502228443, Avg. Test Loss: 0.0004107313579879701\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1555, Avg. Train Loss: 0.0003972666698161426, Avg. Test Loss: 0.0004156919603701681\n",
      "Epoch: 1556, Avg. Train Loss: 0.0003964037852372628, Avg. Test Loss: 0.0004109771107323468\n",
      "Epoch: 1557, Avg. Train Loss: 0.0003978046446464696, Avg. Test Loss: 0.00041169775067828596\n",
      "Epoch: 1558, Avg. Train Loss: 0.0003975647634306793, Avg. Test Loss: 0.00041610447806306183\n",
      "Epoch: 1559, Avg. Train Loss: 0.0003954343156629177, Avg. Test Loss: 0.00041157600935548544\n",
      "Epoch: 1560, Avg. Train Loss: 0.0003956601938752587, Avg. Test Loss: 0.00041233704541809857\n",
      "Epoch: 1561, Avg. Train Loss: 0.0003962138556702019, Avg. Test Loss: 0.00041090924059972167\n",
      "Epoch: 1562, Avg. Train Loss: 0.0003970397648477364, Avg. Test Loss: 0.00041410556877963245\n",
      "Epoch: 1563, Avg. Train Loss: 0.00039766206836522837, Avg. Test Loss: 0.00041077969945035875\n",
      "Epoch: 1564, Avg. Train Loss: 0.0003964574317187937, Avg. Test Loss: 0.00041658972622826695\n",
      "Epoch: 1565, Avg. Train Loss: 0.00039680541268289954, Avg. Test Loss: 0.00041059553041122854\n",
      "Epoch: 1566, Avg. Train Loss: 0.0003979345099989671, Avg. Test Loss: 0.000415435730246827\n",
      "Epoch: 1567, Avg. Train Loss: 0.00039737938556733517, Avg. Test Loss: 0.0004222584830131382\n",
      "Epoch: 1568, Avg. Train Loss: 0.00039819598151912347, Avg. Test Loss: 0.0004158850642852485\n",
      "Epoch: 1569, Avg. Train Loss: 0.00039671867446930604, Avg. Test Loss: 0.0004110184672754258\n",
      "Epoch: 1570, Avg. Train Loss: 0.0003964955489378596, Avg. Test Loss: 0.00041178608080372214\n",
      "Epoch: 1571, Avg. Train Loss: 0.0003959588167734098, Avg. Test Loss: 0.00041784747736528516\n",
      "Epoch: 1572, Avg. Train Loss: 0.0003974398125645293, Avg. Test Loss: 0.000412082503316924\n",
      "Epoch: 1573, Avg. Train Loss: 0.0003975084921897411, Avg. Test Loss: 0.00041351933032274246\n",
      "Epoch: 1574, Avg. Train Loss: 0.00039569457497469387, Avg. Test Loss: 0.0004143358382862061\n",
      "Epoch: 1575, Avg. Train Loss: 0.00039505487278125486, Avg. Test Loss: 0.0004134393238928169\n",
      "Epoch: 1576, Avg. Train Loss: 0.00039654782415519274, Avg. Test Loss: 0.00041367902304045856\n",
      "Epoch: 1577, Avg. Train Loss: 0.0003976357422584971, Avg. Test Loss: 0.0004120788653381169\n",
      "Epoch: 1578, Avg. Train Loss: 0.00039628236879443013, Avg. Test Loss: 0.00041104445699602365\n",
      "Epoch: 1579, Avg. Train Loss: 0.0003960449769713938, Avg. Test Loss: 0.00041108959703706205\n",
      "Epoch: 1580, Avg. Train Loss: 0.0003961487842431335, Avg. Test Loss: 0.00041100982343778014\n",
      "Epoch: 1581, Avg. Train Loss: 0.00039581731598022893, Avg. Test Loss: 0.00041089070145972073\n",
      "Epoch: 1582, Avg. Train Loss: 0.0003949482789869572, Avg. Test Loss: 0.00041285721817985177\n",
      "Epoch: 1583, Avg. Train Loss: 0.000395366040107166, Avg. Test Loss: 0.0004102980310562998\n",
      "Epoch: 1584, Avg. Train Loss: 0.0003951454242734715, Avg. Test Loss: 0.0004103679093532264\n",
      "Epoch: 1585, Avg. Train Loss: 0.0003950794973291543, Avg. Test Loss: 0.00041525127016939223\n",
      "Epoch: 1586, Avg. Train Loss: 0.0003954097039748503, Avg. Test Loss: 0.00041095263441093266\n",
      "Epoch: 1587, Avg. Train Loss: 0.0003949978793592214, Avg. Test Loss: 0.00041040393989533186\n",
      "Epoch: 1588, Avg. Train Loss: 0.00039490600871896846, Avg. Test Loss: 0.00041525467531755567\n",
      "Epoch: 1589, Avg. Train Loss: 0.0003955016470362627, Avg. Test Loss: 0.000413401605328545\n",
      "Epoch: 1590, Avg. Train Loss: 0.00039593620580447795, Avg. Test Loss: 0.0004120595403946936\n",
      "Epoch: 1591, Avg. Train Loss: 0.00039643117803322194, Avg. Test Loss: 0.0004125327686779201\n",
      "Epoch: 1592, Avg. Train Loss: 0.00039561622340210476, Avg. Test Loss: 0.00041239726124331355\n",
      "Epoch: 1593, Avg. Train Loss: 0.00039573124038640324, Avg. Test Loss: 0.00041507615242153406\n",
      "Epoch: 1594, Avg. Train Loss: 0.00039654491038798074, Avg. Test Loss: 0.00041295867413282394\n",
      "Epoch: 1595, Avg. Train Loss: 0.00039783220191291253, Avg. Test Loss: 0.0004121771489735693\n",
      "Epoch: 1596, Avg. Train Loss: 0.000395206073271977, Avg. Test Loss: 0.0004124571569263935\n",
      "Epoch: 1597, Avg. Train Loss: 0.00039489941297878706, Avg. Test Loss: 0.00040929697570391\n",
      "Epoch: 1598, Avg. Train Loss: 0.00039487451363658143, Avg. Test Loss: 0.0004150533932261169\n",
      "Epoch: 1599, Avg. Train Loss: 0.0003952473235522332, Avg. Test Loss: 0.0004123389080632478\n",
      "Epoch: 1600, Avg. Train Loss: 0.0003949709745600473, Avg. Test Loss: 0.00041008496191352606\n",
      "Epoch: 1601, Avg. Train Loss: 0.0003958703323299888, Avg. Test Loss: 0.00040892287506721914\n",
      "Epoch: 1602, Avg. Train Loss: 0.0003944187720176266, Avg. Test Loss: 0.00040922488551586866\n",
      "Epoch: 1603, Avg. Train Loss: 0.0003954509596697726, Avg. Test Loss: 0.00041348417289555073\n",
      "Epoch: 1604, Avg. Train Loss: 0.00039554147664349265, Avg. Test Loss: 0.00040889036608859897\n",
      "Epoch: 1605, Avg. Train Loss: 0.00039499288297604855, Avg. Test Loss: 0.0004094490432180464\n",
      "Epoch: 1606, Avg. Train Loss: 0.0003939982575396899, Avg. Test Loss: 0.00040941318729892373\n",
      "Epoch: 1607, Avg. Train Loss: 0.0003951150351366418, Avg. Test Loss: 0.0004096152260899544\n",
      "Epoch: 1608, Avg. Train Loss: 0.00039599634717803363, Avg. Test Loss: 0.00041139221866615117\n",
      "Epoch: 1609, Avg. Train Loss: 0.00039499338518633227, Avg. Test Loss: 0.0004104164836462587\n",
      "Epoch: 1610, Avg. Train Loss: 0.0003958548111895229, Avg. Test Loss: 0.0004121199599467218\n",
      "Epoch: 1611, Avg. Train Loss: 0.00039487990122938224, Avg. Test Loss: 0.0004087670531589538\n",
      "Epoch: 1612, Avg. Train Loss: 0.00039527783790321716, Avg. Test Loss: 0.00040909217204898596\n",
      "Epoch: 1613, Avg. Train Loss: 0.0003956714008804844, Avg. Test Loss: 0.000411230546887964\n",
      "Epoch: 1614, Avg. Train Loss: 0.00039338659587164604, Avg. Test Loss: 0.0004084214451722801\n",
      "Epoch: 1615, Avg. Train Loss: 0.0003939542349503744, Avg. Test Loss: 0.00040979598998092115\n",
      "Epoch: 1616, Avg. Train Loss: 0.00039531120916741876, Avg. Test Loss: 0.0004181182594038546\n",
      "Epoch: 1617, Avg. Train Loss: 0.0003955774198741067, Avg. Test Loss: 0.0004091018345206976\n",
      "Epoch: 1618, Avg. Train Loss: 0.0003948855196223269, Avg. Test Loss: 0.00041035551112145185\n",
      "Epoch: 1619, Avg. Train Loss: 0.0003937131334042047, Avg. Test Loss: 0.0004097539640497416\n",
      "Epoch: 1620, Avg. Train Loss: 0.00039423267129635396, Avg. Test Loss: 0.00040868145879358053\n",
      "Epoch: 1621, Avg. Train Loss: 0.0003947705946873527, Avg. Test Loss: 0.0004101686645299196\n",
      "Epoch: 1622, Avg. Train Loss: 0.00039520845369457505, Avg. Test Loss: 0.00041056404006667435\n",
      "Epoch: 1623, Avg. Train Loss: 0.00039597106948603206, Avg. Test Loss: 0.00041300320299342275\n",
      "Epoch: 1624, Avg. Train Loss: 0.00039552580592287485, Avg. Test Loss: 0.00040949866524897516\n",
      "Epoch: 1625, Avg. Train Loss: 0.00039503053588749366, Avg. Test Loss: 0.0004105519619770348\n",
      "Epoch: 1626, Avg. Train Loss: 0.0003941220456062881, Avg. Test Loss: 0.00040872138924896717\n",
      "Epoch: 1627, Avg. Train Loss: 0.0003927406478608244, Avg. Test Loss: 0.0004074315947946161\n",
      "Epoch: 1628, Avg. Train Loss: 0.0003950893168261838, Avg. Test Loss: 0.00041246425826102495\n",
      "Epoch: 1629, Avg. Train Loss: 0.000394764059185332, Avg. Test Loss: 0.00041018842603079975\n",
      "Epoch: 1630, Avg. Train Loss: 0.00039382499160764867, Avg. Test Loss: 0.0004108774883206934\n",
      "Epoch: 1631, Avg. Train Loss: 0.0003939445677408299, Avg. Test Loss: 0.00041132979094982147\n",
      "Epoch: 1632, Avg. Train Loss: 0.00039475662755606653, Avg. Test Loss: 0.0004081804654560983\n",
      "Epoch: 1633, Avg. Train Loss: 0.00039451041321140215, Avg. Test Loss: 0.0004134582995902747\n",
      "Epoch: 1634, Avg. Train Loss: 0.00039343287299257204, Avg. Test Loss: 0.000409683067118749\n",
      "Epoch: 1635, Avg. Train Loss: 0.0003937575729228123, Avg. Test Loss: 0.0004088002897333354\n",
      "Epoch: 1636, Avg. Train Loss: 0.0003930292800231295, Avg. Test Loss: 0.0004102179373148829\n",
      "Epoch: 1637, Avg. Train Loss: 0.000394067537516009, Avg. Test Loss: 0.0004097632772754878\n",
      "Epoch: 1638, Avg. Train Loss: 0.00039384872476613624, Avg. Test Loss: 0.00041217185207642615\n",
      "Epoch: 1639, Avg. Train Loss: 0.0003936406269637045, Avg. Test Loss: 0.00040902491309680045\n",
      "Epoch: 1640, Avg. Train Loss: 0.0003938576467822544, Avg. Test Loss: 0.000408995954785496\n",
      "Epoch: 1641, Avg. Train Loss: 0.00039584212665727666, Avg. Test Loss: 0.0004077861085534096\n",
      "Epoch: 1642, Avg. Train Loss: 0.00039460402128265, Avg. Test Loss: 0.0004076212353538722\n",
      "Epoch: 1643, Avg. Train Loss: 0.00039401587144861564, Avg. Test Loss: 0.0004104750696569681\n",
      "Epoch: 1644, Avg. Train Loss: 0.00039459414560845944, Avg. Test Loss: 0.0004073838936164975\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1645, Avg. Train Loss: 0.0003940538113373657, Avg. Test Loss: 0.0004090914153493941\n",
      "Epoch: 1646, Avg. Train Loss: 0.0003945865725210413, Avg. Test Loss: 0.0004127880383748561\n",
      "Epoch: 1647, Avg. Train Loss: 0.000394721983845324, Avg. Test Loss: 0.00040701933903619647\n",
      "Epoch: 1648, Avg. Train Loss: 0.000393138068110877, Avg. Test Loss: 0.00040867680218070745\n",
      "Epoch: 1649, Avg. Train Loss: 0.00039242817356987576, Avg. Test Loss: 0.00041075347689911723\n",
      "Epoch: 1650, Avg. Train Loss: 0.0003933463236154599, Avg. Test Loss: 0.000407739746151492\n",
      "Epoch: 1651, Avg. Train Loss: 0.00039365752004520146, Avg. Test Loss: 0.0004069376736879349\n",
      "Epoch: 1652, Avg. Train Loss: 0.0003934007795895775, Avg. Test Loss: 0.0004070661962032318\n",
      "Epoch: 1653, Avg. Train Loss: 0.0003926224903701696, Avg. Test Loss: 0.0004083043895661831\n",
      "Epoch: 1654, Avg. Train Loss: 0.00039280935117520045, Avg. Test Loss: 0.0004124258121009916\n",
      "Epoch: 1655, Avg. Train Loss: 0.0003926247212126158, Avg. Test Loss: 0.00040986089152283967\n",
      "Epoch: 1656, Avg. Train Loss: 0.00039280867975660015, Avg. Test Loss: 0.00040611831354908645\n",
      "Epoch: 1657, Avg. Train Loss: 0.00039197608888105946, Avg. Test Loss: 0.0004078051424585283\n",
      "Epoch: 1658, Avg. Train Loss: 0.00039369343417198507, Avg. Test Loss: 0.00040660376544110477\n",
      "Epoch: 1659, Avg. Train Loss: 0.000393299094190128, Avg. Test Loss: 0.00041024808888323605\n",
      "Epoch: 1660, Avg. Train Loss: 0.0003931665005227334, Avg. Test Loss: 0.00041068284190259874\n",
      "Epoch: 1661, Avg. Train Loss: 0.00039251359534276607, Avg. Test Loss: 0.0004063991364091635\n",
      "Epoch: 1662, Avg. Train Loss: 0.00039282345434997316, Avg. Test Loss: 0.00040573751903139055\n",
      "Epoch: 1663, Avg. Train Loss: 0.0003923720647689215, Avg. Test Loss: 0.00040621234802529216\n",
      "Epoch: 1664, Avg. Train Loss: 0.0003942347735404795, Avg. Test Loss: 0.0004145564162172377\n",
      "Epoch: 1665, Avg. Train Loss: 0.00039241657332452233, Avg. Test Loss: 0.0004112044698558748\n",
      "Epoch: 1666, Avg. Train Loss: 0.00039334074921667747, Avg. Test Loss: 0.00040651255403645337\n",
      "Epoch: 1667, Avg. Train Loss: 0.00039230470361491276, Avg. Test Loss: 0.00040610169526189566\n",
      "Epoch: 1668, Avg. Train Loss: 0.0003912437735612742, Avg. Test Loss: 0.00040927581721916795\n",
      "Epoch: 1669, Avg. Train Loss: 0.000392009902117384, Avg. Test Loss: 0.00040914592682383955\n",
      "Epoch: 1670, Avg. Train Loss: 0.0003924230526493819, Avg. Test Loss: 0.00041041080839931965\n",
      "Epoch: 1671, Avg. Train Loss: 0.00039151426862253874, Avg. Test Loss: 0.0004075691394973546\n",
      "Epoch: 1672, Avg. Train Loss: 0.00039114273115342787, Avg. Test Loss: 0.0004057335027027875\n",
      "Epoch: 1673, Avg. Train Loss: 0.0003931676931029489, Avg. Test Loss: 0.00040754477959126234\n",
      "Epoch: 1674, Avg. Train Loss: 0.00039200889701998336, Avg. Test Loss: 0.0004077707417309284\n",
      "Epoch: 1675, Avg. Train Loss: 0.00039091135773179663, Avg. Test Loss: 0.00040598222403787076\n",
      "Epoch: 1676, Avg. Train Loss: 0.000391990092561342, Avg. Test Loss: 0.0004068741691298783\n",
      "Epoch: 1677, Avg. Train Loss: 0.00039079635496099674, Avg. Test Loss: 0.0004058880440425128\n",
      "Epoch: 1678, Avg. Train Loss: 0.00039098435149224865, Avg. Test Loss: 0.0004052651929669082\n",
      "Epoch: 1679, Avg. Train Loss: 0.0003919272682207182, Avg. Test Loss: 0.00040586822433397174\n",
      "Epoch: 1680, Avg. Train Loss: 0.00039183921356642144, Avg. Test Loss: 0.0004053453158121556\n",
      "Epoch: 1681, Avg. Train Loss: 0.0003917888903362287, Avg. Test Loss: 0.0004058110644109547\n",
      "Epoch: 1682, Avg. Train Loss: 0.00039170129457488656, Avg. Test Loss: 0.0004086764238309115\n",
      "Epoch: 1683, Avg. Train Loss: 0.0003921627953681055, Avg. Test Loss: 0.00040598202031105757\n",
      "Epoch: 1684, Avg. Train Loss: 0.00039125380761444916, Avg. Test Loss: 0.00041044523823074996\n",
      "Epoch: 1685, Avg. Train Loss: 0.0003910196253347622, Avg. Test Loss: 0.00040624983375892043\n",
      "Epoch: 1686, Avg. Train Loss: 0.00039160452975328403, Avg. Test Loss: 0.00040537031600251794\n",
      "Epoch: 1687, Avg. Train Loss: 0.0003905992590833109, Avg. Test Loss: 0.00040453654946759343\n",
      "Epoch: 1688, Avg. Train Loss: 0.0003912041544491902, Avg. Test Loss: 0.0004047468537464738\n",
      "Epoch: 1689, Avg. Train Loss: 0.0003908523344867971, Avg. Test Loss: 0.0004040398052893579\n",
      "Epoch: 1690, Avg. Train Loss: 0.0003913477351509988, Avg. Test Loss: 0.00041732145473361015\n",
      "Epoch: 1691, Avg. Train Loss: 0.0003927766540369322, Avg. Test Loss: 0.0004082518571522087\n",
      "Epoch: 1692, Avg. Train Loss: 0.0003929891661459277, Avg. Test Loss: 0.0004119915538467467\n",
      "Epoch: 1693, Avg. Train Loss: 0.0003920054993169859, Avg. Test Loss: 0.0004050400748383254\n",
      "Epoch: 1694, Avg. Train Loss: 0.0003925905790353237, Avg. Test Loss: 0.00040507782250642776\n",
      "Epoch: 1695, Avg. Train Loss: 0.0003921223220924392, Avg. Test Loss: 0.0004058163322042674\n",
      "Epoch: 1696, Avg. Train Loss: 0.0003927604472643674, Avg. Test Loss: 0.0004046963877044618\n",
      "Epoch: 1697, Avg. Train Loss: 0.00039054211743479205, Avg. Test Loss: 0.0004034900339320302\n",
      "Epoch: 1698, Avg. Train Loss: 0.0003910491494786774, Avg. Test Loss: 0.00040467502549290657\n",
      "Epoch: 1699, Avg. Train Loss: 0.0003902014246112992, Avg. Test Loss: 0.0004049832932651043\n",
      "Epoch: 1700, Avg. Train Loss: 0.00039182082806757195, Avg. Test Loss: 0.00040400170837529004\n",
      "Epoch: 1701, Avg. Train Loss: 0.0003904104131263096, Avg. Test Loss: 0.0004051521245855838\n",
      "Epoch: 1702, Avg. Train Loss: 0.00039029095882311634, Avg. Test Loss: 0.00040368546615354717\n",
      "Epoch: 1703, Avg. Train Loss: 0.0003929802204406452, Avg. Test Loss: 0.0004078464990016073\n",
      "Epoch: 1704, Avg. Train Loss: 0.0003921650383935505, Avg. Test Loss: 0.0004055671743117273\n",
      "Epoch: 1705, Avg. Train Loss: 0.00039045244514898853, Avg. Test Loss: 0.000403936835937202\n",
      "Epoch: 1706, Avg. Train Loss: 0.0003895632317560443, Avg. Test Loss: 0.00040592762525193393\n",
      "Epoch: 1707, Avg. Train Loss: 0.00038958047069934045, Avg. Test Loss: 0.0004080169601365924\n",
      "Epoch: 1708, Avg. Train Loss: 0.0003926348385162825, Avg. Test Loss: 0.00040763593278825283\n",
      "Epoch: 1709, Avg. Train Loss: 0.000390475484553378, Avg. Test Loss: 0.00040747146704234183\n",
      "Epoch: 1710, Avg. Train Loss: 0.00039116708429118746, Avg. Test Loss: 0.0004033586592413485\n",
      "Epoch: 1711, Avg. Train Loss: 0.00038947593515500597, Avg. Test Loss: 0.00040456216083839536\n",
      "Epoch: 1712, Avg. Train Loss: 0.0003905914003722543, Avg. Test Loss: 0.0004044131492264569\n",
      "Epoch: 1713, Avg. Train Loss: 0.000390146616683883, Avg. Test Loss: 0.0004074233875144273\n",
      "Epoch: 1714, Avg. Train Loss: 0.00039070260543159623, Avg. Test Loss: 0.0004043481021653861\n",
      "Epoch: 1715, Avg. Train Loss: 0.000389932137020582, Avg. Test Loss: 0.00040846120100468397\n",
      "Epoch: 1716, Avg. Train Loss: 0.00039003092625048444, Avg. Test Loss: 0.00040521996561437845\n",
      "Epoch: 1717, Avg. Train Loss: 0.00039021910484988504, Avg. Test Loss: 0.0004029284173157066\n",
      "Epoch: 1718, Avg. Train Loss: 0.0003900608531101932, Avg. Test Loss: 0.0004065509419888258\n",
      "Epoch: 1719, Avg. Train Loss: 0.00039078429040802253, Avg. Test Loss: 0.0004034938756376505\n",
      "Epoch: 1720, Avg. Train Loss: 0.00039038035428411394, Avg. Test Loss: 0.00040512444684281945\n",
      "Epoch: 1721, Avg. Train Loss: 0.0003913393985956561, Avg. Test Loss: 0.0004054874589201063\n",
      "Epoch: 1722, Avg. Train Loss: 0.00039088022407837383, Avg. Test Loss: 0.0004065591492690146\n",
      "Epoch: 1723, Avg. Train Loss: 0.00039182261084639577, Avg. Test Loss: 0.0004025150847155601\n",
      "Epoch: 1724, Avg. Train Loss: 0.0003912844959115826, Avg. Test Loss: 0.00040832263766787946\n",
      "Epoch: 1725, Avg. Train Loss: 0.00038950353641561123, Avg. Test Loss: 0.0004059762286487967\n",
      "Epoch: 1726, Avg. Train Loss: 0.00039092698919608495, Avg. Test Loss: 0.0004068876733072102\n",
      "Epoch: 1727, Avg. Train Loss: 0.0003915440486094286, Avg. Test Loss: 0.0004069991409778595\n",
      "Epoch: 1728, Avg. Train Loss: 0.0003915151728717827, Avg. Test Loss: 0.0004054952005390078\n",
      "Epoch: 1729, Avg. Train Loss: 0.0003887681685777944, Avg. Test Loss: 0.0004033248114865273\n",
      "Epoch: 1730, Avg. Train Loss: 0.00038901211688468275, Avg. Test Loss: 0.0004022787616122514\n",
      "Epoch: 1731, Avg. Train Loss: 0.0003905667602571897, Avg. Test Loss: 0.00040990920388139784\n",
      "Epoch: 1732, Avg. Train Loss: 0.00038900972224858614, Avg. Test Loss: 0.00040360441198572516\n",
      "Epoch: 1733, Avg. Train Loss: 0.0003895753518093464, Avg. Test Loss: 0.0004035903257317841\n",
      "Epoch: 1734, Avg. Train Loss: 0.00038776462180215086, Avg. Test Loss: 0.00040404751780442894\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1735, Avg. Train Loss: 0.0003894638983521957, Avg. Test Loss: 0.00040634366450831294\n",
      "Epoch: 1736, Avg. Train Loss: 0.00038869310167704733, Avg. Test Loss: 0.00040692745824344456\n",
      "Epoch: 1737, Avg. Train Loss: 0.000389342540117024, Avg. Test Loss: 0.0004070582799613476\n",
      "Epoch: 1738, Avg. Train Loss: 0.0003911934604835805, Avg. Test Loss: 0.00040226761484518647\n",
      "Epoch: 1739, Avg. Train Loss: 0.00038880813625901073, Avg. Test Loss: 0.0004025604866910726\n",
      "Epoch: 1740, Avg. Train Loss: 0.0003884903034790917, Avg. Test Loss: 0.0004029145638924092\n",
      "Epoch: 1741, Avg. Train Loss: 0.00038930201878619575, Avg. Test Loss: 0.00040217392961494625\n",
      "Epoch: 1742, Avg. Train Loss: 0.0003880860411215487, Avg. Test Loss: 0.00040292597259394825\n",
      "Epoch: 1743, Avg. Train Loss: 0.0003878027877532119, Avg. Test Loss: 0.00040285021532326937\n",
      "Epoch: 1744, Avg. Train Loss: 0.00038885481406523043, Avg. Test Loss: 0.00040937247104011476\n",
      "Epoch: 1745, Avg. Train Loss: 0.00039137874426710054, Avg. Test Loss: 0.0004066589171998203\n",
      "Epoch: 1746, Avg. Train Loss: 0.0003920801885447703, Avg. Test Loss: 0.0004049543058499694\n",
      "Epoch: 1747, Avg. Train Loss: 0.0003887555456373754, Avg. Test Loss: 0.00040121618076227605\n",
      "Epoch: 1748, Avg. Train Loss: 0.00038811523903182945, Avg. Test Loss: 0.00040210882434621453\n",
      "Epoch: 1749, Avg. Train Loss: 0.00038910181015231756, Avg. Test Loss: 0.00040453101973980665\n",
      "Epoch: 1750, Avg. Train Loss: 0.0003882173968608989, Avg. Test Loss: 0.00040234741754829884\n",
      "Epoch: 1751, Avg. Train Loss: 0.0003881341849486235, Avg. Test Loss: 0.0004025607486255467\n",
      "Epoch: 1752, Avg. Train Loss: 0.00038846611075081625, Avg. Test Loss: 0.00040411262307316065\n",
      "Epoch: 1753, Avg. Train Loss: 0.00038904025216673525, Avg. Test Loss: 0.0004050068964716047\n",
      "Epoch: 1754, Avg. Train Loss: 0.00039209902819874155, Avg. Test Loss: 0.0004032182914670557\n",
      "Epoch: 1755, Avg. Train Loss: 0.0003896984305546814, Avg. Test Loss: 0.0004069189017172903\n",
      "Epoch: 1756, Avg. Train Loss: 0.000389265171983171, Avg. Test Loss: 0.00040461868047714233\n",
      "Epoch: 1757, Avg. Train Loss: 0.00038851869121995256, Avg. Test Loss: 0.0004012619610875845\n",
      "Epoch: 1758, Avg. Train Loss: 0.0003885644776367604, Avg. Test Loss: 0.0004021798959001899\n",
      "Epoch: 1759, Avg. Train Loss: 0.0003879958557961292, Avg. Test Loss: 0.00040640507359057665\n",
      "Epoch: 1760, Avg. Train Loss: 0.0003886090464305219, Avg. Test Loss: 0.000402359088184312\n",
      "Epoch: 1761, Avg. Train Loss: 0.00038834702599858646, Avg. Test Loss: 0.0004025491653010249\n",
      "Epoch: 1762, Avg. Train Loss: 0.00038775325709477414, Avg. Test Loss: 0.00040050953975878656\n",
      "Epoch: 1763, Avg. Train Loss: 0.00038729534216420074, Avg. Test Loss: 0.0004011330893263221\n",
      "Epoch: 1764, Avg. Train Loss: 0.0003875028335240258, Avg. Test Loss: 0.00040380831342190504\n",
      "Epoch: 1765, Avg. Train Loss: 0.00038874328209542085, Avg. Test Loss: 0.00040359937702305615\n",
      "Epoch: 1766, Avg. Train Loss: 0.0003864772395815614, Avg. Test Loss: 0.0004034621815662831\n",
      "Epoch: 1767, Avg. Train Loss: 0.00038825594183858916, Avg. Test Loss: 0.00040260760579258204\n",
      "Epoch: 1768, Avg. Train Loss: 0.00038880981683601126, Avg. Test Loss: 0.0004003606445621699\n",
      "Epoch: 1769, Avg. Train Loss: 0.00038809869722679775, Avg. Test Loss: 0.00040412682574242353\n",
      "Epoch: 1770, Avg. Train Loss: 0.0003874716281262768, Avg. Test Loss: 0.0004042015934828669\n",
      "Epoch: 1771, Avg. Train Loss: 0.0003884141658281171, Avg. Test Loss: 0.0004020742780994624\n",
      "Epoch: 1772, Avg. Train Loss: 0.0003866128519253242, Avg. Test Loss: 0.0004005584050901234\n",
      "Epoch: 1773, Avg. Train Loss: 0.0003859249971059779, Avg. Test Loss: 0.00040150858694687486\n",
      "Epoch: 1774, Avg. Train Loss: 0.00038781115273555175, Avg. Test Loss: 0.000405505154049024\n",
      "Epoch: 1775, Avg. Train Loss: 0.00038795579403508887, Avg. Test Loss: 0.0004012762801721692\n",
      "Epoch: 1776, Avg. Train Loss: 0.00038853906457810553, Avg. Test Loss: 0.0004026198002975434\n",
      "Epoch: 1777, Avg. Train Loss: 0.0003869320268656105, Avg. Test Loss: 0.00040441786404699087\n",
      "Epoch: 1778, Avg. Train Loss: 0.00038839929647808676, Avg. Test Loss: 0.00039937352994456887\n",
      "Epoch: 1779, Avg. Train Loss: 0.0003869092243528643, Avg. Test Loss: 0.0004006533126812428\n",
      "Epoch: 1780, Avg. Train Loss: 0.0003872248621625003, Avg. Test Loss: 0.0004001073830295354\n",
      "Epoch: 1781, Avg. Train Loss: 0.00038987353747320727, Avg. Test Loss: 0.00040551254642196\n",
      "Epoch: 1782, Avg. Train Loss: 0.0003869604667226329, Avg. Test Loss: 0.0004003442300017923\n",
      "Epoch: 1783, Avg. Train Loss: 0.00038845581205583415, Avg. Test Loss: 0.0004048336995765567\n",
      "Epoch: 1784, Avg. Train Loss: 0.00038656106673527594, Avg. Test Loss: 0.00040246613207273185\n",
      "Epoch: 1785, Avg. Train Loss: 0.00038719394983355564, Avg. Test Loss: 0.0004038003389723599\n",
      "Epoch: 1786, Avg. Train Loss: 0.0003868103085551411, Avg. Test Loss: 0.00040313322097063065\n",
      "Epoch: 1787, Avg. Train Loss: 0.00038593162871832247, Avg. Test Loss: 0.0004000020562671125\n",
      "Epoch: 1788, Avg. Train Loss: 0.0003865795415761166, Avg. Test Loss: 0.00040184412500821054\n",
      "Epoch: 1789, Avg. Train Loss: 0.0003870876024065669, Avg. Test Loss: 0.0004018687759526074\n",
      "Epoch: 1790, Avg. Train Loss: 0.000388344504794669, Avg. Test Loss: 0.0004033699806313962\n",
      "Epoch: 1791, Avg. Train Loss: 0.0003851269815810198, Avg. Test Loss: 0.0003989502147305757\n",
      "Epoch: 1792, Avg. Train Loss: 0.00038700376239302026, Avg. Test Loss: 0.000398693373426795\n",
      "Epoch: 1793, Avg. Train Loss: 0.00038662221997456497, Avg. Test Loss: 0.00040201476076617837\n",
      "Epoch: 1794, Avg. Train Loss: 0.00038699324440405984, Avg. Test Loss: 0.0004062905500177294\n",
      "Epoch: 1795, Avg. Train Loss: 0.0003862725895677888, Avg. Test Loss: 0.00039882626151666045\n",
      "Epoch: 1796, Avg. Train Loss: 0.00038711085027560245, Avg. Test Loss: 0.0004009061667602509\n",
      "Epoch: 1797, Avg. Train Loss: 0.00038609753476542445, Avg. Test Loss: 0.0004007713287137449\n",
      "Epoch: 1798, Avg. Train Loss: 0.0003861780792777968, Avg. Test Loss: 0.00039924561860971153\n",
      "Epoch: 1799, Avg. Train Loss: 0.000386596956496062, Avg. Test Loss: 0.00040015377453528345\n",
      "Epoch: 1800, Avg. Train Loss: 0.0003853112636513055, Avg. Test Loss: 0.0003999711771029979\n",
      "Epoch: 1801, Avg. Train Loss: 0.00038563816802749453, Avg. Test Loss: 0.0004009057010989636\n",
      "Epoch: 1802, Avg. Train Loss: 0.00038587689050473273, Avg. Test Loss: 0.0004015272716060281\n",
      "Epoch: 1803, Avg. Train Loss: 0.0003850174083666833, Avg. Test Loss: 0.0003997553722001612\n",
      "Epoch: 1804, Avg. Train Loss: 0.0003867875994453856, Avg. Test Loss: 0.0004062119696754962\n",
      "Epoch: 1805, Avg. Train Loss: 0.000387678365493843, Avg. Test Loss: 0.0004102453531231731\n",
      "Epoch: 1806, Avg. Train Loss: 0.00038637277916571947, Avg. Test Loss: 0.00040053256088867784\n",
      "Epoch: 1807, Avg. Train Loss: 0.0003845855366265358, Avg. Test Loss: 0.0003988382522948086\n",
      "Epoch: 1808, Avg. Train Loss: 0.00038493408748425196, Avg. Test Loss: 0.00040387758053839207\n",
      "Epoch: 1809, Avg. Train Loss: 0.0003882360679833868, Avg. Test Loss: 0.0004025534726679325\n",
      "Epoch: 1810, Avg. Train Loss: 0.00038559267332582454, Avg. Test Loss: 0.00039962164009921253\n",
      "Epoch: 1811, Avg. Train Loss: 0.0003863913169520539, Avg. Test Loss: 0.000398254138417542\n",
      "Epoch: 1812, Avg. Train Loss: 0.0003859273741444096, Avg. Test Loss: 0.00040399108547717333\n",
      "Epoch: 1813, Avg. Train Loss: 0.0003861764014081293, Avg. Test Loss: 0.00040170556167140603\n",
      "Epoch: 1814, Avg. Train Loss: 0.0003854163528452519, Avg. Test Loss: 0.00039872268098406494\n",
      "Epoch: 1815, Avg. Train Loss: 0.0003859434523186538, Avg. Test Loss: 0.0004009126278106123\n",
      "Epoch: 1816, Avg. Train Loss: 0.000386177089070728, Avg. Test Loss: 0.00039788056164979935\n",
      "Epoch: 1817, Avg. Train Loss: 0.00038518532257808677, Avg. Test Loss: 0.00039761027437634766\n",
      "Epoch: 1818, Avg. Train Loss: 0.00038533008909177814, Avg. Test Loss: 0.0003999073232989758\n",
      "Epoch: 1819, Avg. Train Loss: 0.0003844051788355289, Avg. Test Loss: 0.00040437342249788344\n",
      "Epoch: 1820, Avg. Train Loss: 0.0003894172719853042, Avg. Test Loss: 0.00039806251879781485\n",
      "Epoch: 1821, Avg. Train Loss: 0.00038365151957868665, Avg. Test Loss: 0.0003986540250480175\n",
      "Epoch: 1822, Avg. Train Loss: 0.0003852671056953367, Avg. Test Loss: 0.00040135139715857804\n",
      "Epoch: 1823, Avg. Train Loss: 0.0003844413853542836, Avg. Test Loss: 0.0003974268038291484\n",
      "Epoch: 1824, Avg. Train Loss: 0.0003834235858237154, Avg. Test Loss: 0.0003975027648266405\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1825, Avg. Train Loss: 0.0003849577096420838, Avg. Test Loss: 0.0003983905480708927\n",
      "Epoch: 1826, Avg. Train Loss: 0.00038508274443555885, Avg. Test Loss: 0.000396332994569093\n",
      "Epoch: 1827, Avg. Train Loss: 0.0003832492559097794, Avg. Test Loss: 0.0003963619819842279\n",
      "Epoch: 1828, Avg. Train Loss: 0.0003843200156129463, Avg. Test Loss: 0.00039804770494811237\n",
      "Epoch: 1829, Avg. Train Loss: 0.0003849397133223626, Avg. Test Loss: 0.0003988771350122988\n",
      "Epoch: 1830, Avg. Train Loss: 0.000385319838451958, Avg. Test Loss: 0.0003992599085904658\n",
      "Epoch: 1831, Avg. Train Loss: 0.0003827726495517201, Avg. Test Loss: 0.0003993240534327924\n",
      "Epoch: 1832, Avg. Train Loss: 0.00038368358929251686, Avg. Test Loss: 0.00039693203871138394\n",
      "Epoch: 1833, Avg. Train Loss: 0.00038326432221829027, Avg. Test Loss: 0.0003992697747889906\n",
      "Epoch: 1834, Avg. Train Loss: 0.0003839033103526332, Avg. Test Loss: 0.00040175809408538043\n",
      "Epoch: 1835, Avg. Train Loss: 0.00038433213498941513, Avg. Test Loss: 0.00039977621054276824\n",
      "Epoch: 1836, Avg. Train Loss: 0.00038341258931363567, Avg. Test Loss: 0.0003957742010243237\n",
      "Epoch: 1837, Avg. Train Loss: 0.0003836562208625553, Avg. Test Loss: 0.00039658264722675085\n",
      "Epoch: 1838, Avg. Train Loss: 0.0003835451464320338, Avg. Test Loss: 0.0003973775019403547\n",
      "Epoch: 1839, Avg. Train Loss: 0.00038393767994590274, Avg. Test Loss: 0.00039942815783433616\n",
      "Epoch: 1840, Avg. Train Loss: 0.0003854950597553059, Avg. Test Loss: 0.00040946039371192455\n",
      "Epoch: 1841, Avg. Train Loss: 0.00038649413875455773, Avg. Test Loss: 0.00039534250390715897\n",
      "Epoch: 1842, Avg. Train Loss: 0.000384561404136421, Avg. Test Loss: 0.00040032685501500964\n",
      "Epoch: 1843, Avg. Train Loss: 0.00038329071871568126, Avg. Test Loss: 0.000395816721720621\n",
      "Epoch: 1844, Avg. Train Loss: 0.0003839916736428994, Avg. Test Loss: 0.0003992488491348922\n",
      "Epoch: 1845, Avg. Train Loss: 0.00038369404365915026, Avg. Test Loss: 0.00040449347579851747\n",
      "Epoch: 1846, Avg. Train Loss: 0.00038556430792046145, Avg. Test Loss: 0.00039570964872837067\n",
      "Epoch: 1847, Avg. Train Loss: 0.00038264967774604124, Avg. Test Loss: 0.00039543540333397686\n",
      "Epoch: 1848, Avg. Train Loss: 0.00038172313564478657, Avg. Test Loss: 0.00039594501140527427\n",
      "Epoch: 1849, Avg. Train Loss: 0.0003840068502752327, Avg. Test Loss: 0.0003972234553657472\n",
      "Epoch: 1850, Avg. Train Loss: 0.0003843996836262387, Avg. Test Loss: 0.0003967771481256932\n",
      "Epoch: 1851, Avg. Train Loss: 0.0003822771493930283, Avg. Test Loss: 0.00039506630855612457\n",
      "Epoch: 1852, Avg. Train Loss: 0.0003820427065325338, Avg. Test Loss: 0.00039416796062141657\n",
      "Epoch: 1853, Avg. Train Loss: 0.0003822394003712594, Avg. Test Loss: 0.000395027338527143\n",
      "Epoch: 1854, Avg. Train Loss: 0.00038291669726848255, Avg. Test Loss: 0.00039477794780395925\n",
      "Epoch: 1855, Avg. Train Loss: 0.0003829781889244048, Avg. Test Loss: 0.0004015771846752614\n",
      "Epoch: 1856, Avg. Train Loss: 0.00038295715497698373, Avg. Test Loss: 0.00039486688910983503\n",
      "Epoch: 1857, Avg. Train Loss: 0.00038142298987178607, Avg. Test Loss: 0.00039568106876686215\n",
      "Epoch: 1858, Avg. Train Loss: 0.0003825420822385092, Avg. Test Loss: 0.0003971201949752867\n",
      "Epoch: 1859, Avg. Train Loss: 0.0003827364897344608, Avg. Test Loss: 0.00039382794057019055\n",
      "Epoch: 1860, Avg. Train Loss: 0.000382358726076132, Avg. Test Loss: 0.00039956995169632137\n",
      "Epoch: 1861, Avg. Train Loss: 0.00038259265589701054, Avg. Test Loss: 0.00039456895319744945\n",
      "Epoch: 1862, Avg. Train Loss: 0.000382093213861375, Avg. Test Loss: 0.0003935029963031411\n",
      "Epoch: 1863, Avg. Train Loss: 0.0003835161610473987, Avg. Test Loss: 0.00039344248943962157\n",
      "Epoch: 1864, Avg. Train Loss: 0.00038222926546992777, Avg. Test Loss: 0.00039632522384636104\n",
      "Epoch: 1865, Avg. Train Loss: 0.0003811614425463039, Avg. Test Loss: 0.00039596855640411377\n",
      "Epoch: 1866, Avg. Train Loss: 0.00038274314571280294, Avg. Test Loss: 0.00039427413139492273\n",
      "Epoch: 1867, Avg. Train Loss: 0.0003809750027315648, Avg. Test Loss: 0.00039579314761795104\n",
      "Epoch: 1868, Avg. Train Loss: 0.0003815839550360431, Avg. Test Loss: 0.0003981198533438146\n",
      "Epoch: 1869, Avg. Train Loss: 0.00038222848778850466, Avg. Test Loss: 0.00040233178879134357\n",
      "Epoch: 1870, Avg. Train Loss: 0.00038193236105144024, Avg. Test Loss: 0.0003936571883969009\n",
      "Epoch: 1871, Avg. Train Loss: 0.00038124603655210934, Avg. Test Loss: 0.00039288506377488375\n",
      "Epoch: 1872, Avg. Train Loss: 0.0003816713748207359, Avg. Test Loss: 0.00039455853402614594\n",
      "Epoch: 1873, Avg. Train Loss: 0.00038119965790619337, Avg. Test Loss: 0.00039713174919597805\n",
      "Epoch: 1874, Avg. Train Loss: 0.00038108686567284167, Avg. Test Loss: 0.0003939254384022206\n",
      "Epoch: 1875, Avg. Train Loss: 0.0003807872897934515, Avg. Test Loss: 0.0003979987814091146\n",
      "Epoch: 1876, Avg. Train Loss: 0.0003851255818898248, Avg. Test Loss: 0.00039972152444534004\n",
      "Epoch: 1877, Avg. Train Loss: 0.0003803255378950907, Avg. Test Loss: 0.00039370666490867734\n",
      "Epoch: 1878, Avg. Train Loss: 0.0003809289130934536, Avg. Test Loss: 0.000393193302443251\n",
      "Epoch: 1879, Avg. Train Loss: 0.0003817053477897114, Avg. Test Loss: 0.0003949850215576589\n",
      "Epoch: 1880, Avg. Train Loss: 0.0003814452441495865, Avg. Test Loss: 0.00039387663127854466\n",
      "Epoch: 1881, Avg. Train Loss: 0.0003816602402366698, Avg. Test Loss: 0.0003922106116078794\n",
      "Epoch: 1882, Avg. Train Loss: 0.0003802711137321366, Avg. Test Loss: 0.00039700360503047705\n",
      "Epoch: 1883, Avg. Train Loss: 0.00038201215901671976, Avg. Test Loss: 0.0003971254627685994\n",
      "Epoch: 1884, Avg. Train Loss: 0.00037977454553055035, Avg. Test Loss: 0.0003926932404283434\n",
      "Epoch: 1885, Avg. Train Loss: 0.00038180110480658016, Avg. Test Loss: 0.0003950651444029063\n",
      "Epoch: 1886, Avg. Train Loss: 0.00038121875475680584, Avg. Test Loss: 0.00039594806730747223\n",
      "Epoch: 1887, Avg. Train Loss: 0.0003796764263655817, Avg. Test Loss: 0.00039117271080613136\n",
      "Epoch: 1888, Avg. Train Loss: 0.0003794714318436765, Avg. Test Loss: 0.00039237734745256603\n",
      "Epoch: 1889, Avg. Train Loss: 0.00038115110527182564, Avg. Test Loss: 0.0003915050474461168\n",
      "Epoch: 1890, Avg. Train Loss: 0.0003810932008322155, Avg. Test Loss: 0.00039605400525033474\n",
      "Epoch: 1891, Avg. Train Loss: 0.0003796787194766884, Avg. Test Loss: 0.0003929660888388753\n",
      "Epoch: 1892, Avg. Train Loss: 0.0003794952854784855, Avg. Test Loss: 0.0003910067898686975\n",
      "Epoch: 1893, Avg. Train Loss: 0.000379145875042521, Avg. Test Loss: 0.0003920784220099449\n",
      "Epoch: 1894, Avg. Train Loss: 0.0003806084833042913, Avg. Test Loss: 0.00039407450822182\n",
      "Epoch: 1895, Avg. Train Loss: 0.00038085517955424136, Avg. Test Loss: 0.00039182978798635304\n",
      "Epoch: 1896, Avg. Train Loss: 0.0003791953393712986, Avg. Test Loss: 0.00039060626295395195\n",
      "Epoch: 1897, Avg. Train Loss: 0.00038000317777745255, Avg. Test Loss: 0.000391353911254555\n",
      "Epoch: 1898, Avg. Train Loss: 0.00037870101351832405, Avg. Test Loss: 0.0003912054526153952\n",
      "Epoch: 1899, Avg. Train Loss: 0.0003786779382417715, Avg. Test Loss: 0.0003902836178895086\n",
      "Epoch: 1900, Avg. Train Loss: 0.000378595084374294, Avg. Test Loss: 0.0003917120338883251\n",
      "Epoch: 1901, Avg. Train Loss: 0.00037991231900293295, Avg. Test Loss: 0.00039101880975067616\n",
      "Epoch: 1902, Avg. Train Loss: 0.0003790147013713194, Avg. Test Loss: 0.00038996795774437487\n",
      "Epoch: 1903, Avg. Train Loss: 0.00037896108805461853, Avg. Test Loss: 0.0003914498956874013\n",
      "Epoch: 1904, Avg. Train Loss: 0.00037961663559165807, Avg. Test Loss: 0.0003931340470444411\n",
      "Epoch: 1905, Avg. Train Loss: 0.0003791565358433006, Avg. Test Loss: 0.0003906729107256979\n",
      "Epoch: 1906, Avg. Train Loss: 0.00037883488301642586, Avg. Test Loss: 0.0003942374896723777\n",
      "Epoch: 1907, Avg. Train Loss: 0.00037872414767937084, Avg. Test Loss: 0.0003932432155124843\n",
      "Epoch: 1908, Avg. Train Loss: 0.00037983692316121835, Avg. Test Loss: 0.0003922689938917756\n",
      "Epoch: 1909, Avg. Train Loss: 0.00037983819357725944, Avg. Test Loss: 0.00039077969267964363\n",
      "Epoch: 1910, Avg. Train Loss: 0.0003786414366237126, Avg. Test Loss: 0.00038974997005425394\n",
      "Epoch: 1911, Avg. Train Loss: 0.00037836604264326564, Avg. Test Loss: 0.00038999784737825394\n",
      "Epoch: 1912, Avg. Train Loss: 0.0003791338666667079, Avg. Test Loss: 0.0003910101659130305\n",
      "Epoch: 1913, Avg. Train Loss: 0.0003778910207518831, Avg. Test Loss: 0.0003960243775509298\n",
      "Epoch: 1914, Avg. Train Loss: 0.00037838750231881127, Avg. Test Loss: 0.0003887708007823676\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1915, Avg. Train Loss: 0.0003791139434026771, Avg. Test Loss: 0.00039221299812197685\n",
      "Epoch: 1916, Avg. Train Loss: 0.00037907755143160737, Avg. Test Loss: 0.00039170897798612714\n",
      "Epoch: 1917, Avg. Train Loss: 0.00037932352143946256, Avg. Test Loss: 0.0003896659763995558\n",
      "Epoch: 1918, Avg. Train Loss: 0.0003776504681174925, Avg. Test Loss: 0.0003888600040227175\n",
      "Epoch: 1919, Avg. Train Loss: 0.00037744619848401566, Avg. Test Loss: 0.00038888573180884123\n",
      "Epoch: 1920, Avg. Train Loss: 0.0003775746885113158, Avg. Test Loss: 0.0003907394129782915\n",
      "Epoch: 1921, Avg. Train Loss: 0.00037845928116355006, Avg. Test Loss: 0.00039007121813483536\n",
      "Epoch: 1922, Avg. Train Loss: 0.000379095099010873, Avg. Test Loss: 0.00038854748709127307\n",
      "Epoch: 1923, Avg. Train Loss: 0.0003776163983613599, Avg. Test Loss: 0.0003915869165211916\n",
      "Epoch: 1924, Avg. Train Loss: 0.0003787728850892203, Avg. Test Loss: 0.0003931152168661356\n",
      "Epoch: 1925, Avg. Train Loss: 0.00037775029222545926, Avg. Test Loss: 0.0003904206387232989\n",
      "Epoch: 1926, Avg. Train Loss: 0.00037759210884592733, Avg. Test Loss: 0.0003907656646333635\n",
      "Epoch: 1927, Avg. Train Loss: 0.00037854269680263864, Avg. Test Loss: 0.0003891811356879771\n",
      "Epoch: 1928, Avg. Train Loss: 0.00037620293428623227, Avg. Test Loss: 0.0003880792937707156\n",
      "Epoch: 1929, Avg. Train Loss: 0.00037639046041836396, Avg. Test Loss: 0.0003885483311023563\n",
      "Epoch: 1930, Avg. Train Loss: 0.00037688030969611436, Avg. Test Loss: 0.00038885639514774084\n",
      "Epoch: 1931, Avg. Train Loss: 0.0003773256741074282, Avg. Test Loss: 0.0003888072678819299\n",
      "Epoch: 1932, Avg. Train Loss: 0.00037738191421403616, Avg. Test Loss: 0.0003899951989296824\n",
      "Epoch: 1933, Avg. Train Loss: 0.0003778401120609149, Avg. Test Loss: 0.0003889991494361311\n",
      "Epoch: 1934, Avg. Train Loss: 0.0003771921538552919, Avg. Test Loss: 0.0003893365792464465\n",
      "Epoch: 1935, Avg. Train Loss: 0.0003768803611354426, Avg. Test Loss: 0.00039145787013694644\n",
      "Epoch: 1936, Avg. Train Loss: 0.0003762401871892169, Avg. Test Loss: 0.00039235688745975494\n",
      "Epoch: 1937, Avg. Train Loss: 0.0003758080616365945, Avg. Test Loss: 0.0003891832020599395\n",
      "Epoch: 1938, Avg. Train Loss: 0.0003768333679249207, Avg. Test Loss: 0.00038795117870904505\n",
      "Epoch: 1939, Avg. Train Loss: 0.0003771774855247417, Avg. Test Loss: 0.00039126077899709344\n",
      "Epoch: 1940, Avg. Train Loss: 0.0003765132636925595, Avg. Test Loss: 0.00038881151704117656\n",
      "Epoch: 1941, Avg. Train Loss: 0.0003787531872106673, Avg. Test Loss: 0.00039896724047139287\n",
      "Epoch: 1942, Avg. Train Loss: 0.0003773249025175045, Avg. Test Loss: 0.0003884999605361372\n",
      "Epoch: 1943, Avg. Train Loss: 0.000376388217392919, Avg. Test Loss: 0.00038810179103165865\n",
      "Epoch: 1944, Avg. Train Loss: 0.0003758862690436979, Avg. Test Loss: 0.000387907144613564\n",
      "Epoch: 1945, Avg. Train Loss: 0.000376014573618683, Avg. Test Loss: 0.0003901204909197986\n",
      "Epoch: 1946, Avg. Train Loss: 0.00037698706999139556, Avg. Test Loss: 0.0003883614845108241\n",
      "Epoch: 1947, Avg. Train Loss: 0.0003783510474022478, Avg. Test Loss: 0.0003882321179844439\n",
      "Epoch: 1948, Avg. Train Loss: 0.00037653111720046157, Avg. Test Loss: 0.00038915532059036195\n",
      "Epoch: 1949, Avg. Train Loss: 0.00037687105738536217, Avg. Test Loss: 0.0003890199586749077\n",
      "Epoch: 1950, Avg. Train Loss: 0.00037826084786332973, Avg. Test Loss: 0.00038967200089246035\n",
      "Epoch: 1951, Avg. Train Loss: 0.00037745788739452704, Avg. Test Loss: 0.00039005567668937147\n",
      "Epoch: 1952, Avg. Train Loss: 0.0003751336257135885, Avg. Test Loss: 0.0003884730685967952\n",
      "Epoch: 1953, Avg. Train Loss: 0.00037693814712923105, Avg. Test Loss: 0.00038791922270320356\n",
      "Epoch: 1954, Avg. Train Loss: 0.00037574375164695084, Avg. Test Loss: 0.0003872932866215706\n",
      "Epoch: 1955, Avg. Train Loss: 0.000378180947696227, Avg. Test Loss: 0.0003898887080140412\n",
      "Epoch: 1956, Avg. Train Loss: 0.00037533494503085696, Avg. Test Loss: 0.0003872539382427931\n",
      "Epoch: 1957, Avg. Train Loss: 0.00037682741991417525, Avg. Test Loss: 0.0003910786472260952\n",
      "Epoch: 1958, Avg. Train Loss: 0.00037783825956826464, Avg. Test Loss: 0.00039540030411444604\n",
      "Epoch: 1959, Avg. Train Loss: 0.0003784070397878802, Avg. Test Loss: 0.0003886472259182483\n",
      "Epoch: 1960, Avg. Train Loss: 0.0003752723501367105, Avg. Test Loss: 0.00039139887667261064\n",
      "Epoch: 1961, Avg. Train Loss: 0.0003759028128792294, Avg. Test Loss: 0.0003907875798176974\n",
      "Epoch: 1962, Avg. Train Loss: 0.0003775170446525133, Avg. Test Loss: 0.0003878998395521194\n",
      "Epoch: 1963, Avg. Train Loss: 0.00037556367744908254, Avg. Test Loss: 0.00038561952533200383\n",
      "Epoch: 1964, Avg. Train Loss: 0.00037502379394894423, Avg. Test Loss: 0.0003865949111059308\n",
      "Epoch: 1965, Avg. Train Loss: 0.00037432358150781936, Avg. Test Loss: 0.000386559113394469\n",
      "Epoch: 1966, Avg. Train Loss: 0.00037489210250029383, Avg. Test Loss: 0.0003884652687702328\n",
      "Epoch: 1967, Avg. Train Loss: 0.0003750785111807027, Avg. Test Loss: 0.00038680285797454417\n",
      "Epoch: 1968, Avg. Train Loss: 0.00037486671177713675, Avg. Test Loss: 0.0003877921844832599\n",
      "Epoch: 1969, Avg. Train Loss: 0.0003762307717616475, Avg. Test Loss: 0.00039002919220365584\n",
      "Epoch: 1970, Avg. Train Loss: 0.0003748297688637882, Avg. Test Loss: 0.0003911943349521607\n",
      "Epoch: 1971, Avg. Train Loss: 0.00037609376784868885, Avg. Test Loss: 0.0003914021363016218\n",
      "Epoch: 1972, Avg. Train Loss: 0.00037588685247397354, Avg. Test Loss: 0.0003900617593899369\n",
      "Epoch: 1973, Avg. Train Loss: 0.00037684832729377546, Avg. Test Loss: 0.0003911864187102765\n",
      "Epoch: 1974, Avg. Train Loss: 0.0003754629592443708, Avg. Test Loss: 0.0003872581000905484\n",
      "Epoch: 1975, Avg. Train Loss: 0.0003751258130271941, Avg. Test Loss: 0.0003864110913127661\n",
      "Epoch: 1976, Avg. Train Loss: 0.00037425640106829273, Avg. Test Loss: 0.0003863289311993867\n",
      "Epoch: 1977, Avg. Train Loss: 0.0003752433498617435, Avg. Test Loss: 0.0003864854807034135\n",
      "Epoch: 1978, Avg. Train Loss: 0.000375549188479348, Avg. Test Loss: 0.00038559126551263034\n",
      "Epoch: 1979, Avg. Train Loss: 0.00037415815398183675, Avg. Test Loss: 0.0003872604575008154\n",
      "Epoch: 1980, Avg. Train Loss: 0.00037650336839020423, Avg. Test Loss: 0.00038649156340397894\n",
      "Epoch: 1981, Avg. Train Loss: 0.0003752321536858501, Avg. Test Loss: 0.00038747244980186224\n",
      "Epoch: 1982, Avg. Train Loss: 0.0003764889416891302, Avg. Test Loss: 0.00038620157283730805\n",
      "Epoch: 1983, Avg. Train Loss: 0.00037529288864218045, Avg. Test Loss: 0.00038969097658991814\n",
      "Epoch: 1984, Avg. Train Loss: 0.00037638399801433604, Avg. Test Loss: 0.0003892397799063474\n",
      "Epoch: 1985, Avg. Train Loss: 0.0003770435808313101, Avg. Test Loss: 0.00038872670847922564\n",
      "Epoch: 1986, Avg. Train Loss: 0.00037458416705322994, Avg. Test Loss: 0.0003880448639392853\n",
      "Epoch: 1987, Avg. Train Loss: 0.0003750605778064752, Avg. Test Loss: 0.0003864424943458289\n",
      "Epoch: 1988, Avg. Train Loss: 0.00037430493881232866, Avg. Test Loss: 0.000384791346732527\n",
      "Epoch: 1989, Avg. Train Loss: 0.0003739561706911339, Avg. Test Loss: 0.0003861051518470049\n",
      "Epoch: 1990, Avg. Train Loss: 0.000374825724108188, Avg. Test Loss: 0.00038710114313289523\n",
      "Epoch: 1991, Avg. Train Loss: 0.00037322684968171945, Avg. Test Loss: 0.00038414387381635606\n",
      "Epoch: 1992, Avg. Train Loss: 0.0003735523800863776, Avg. Test Loss: 0.00038510916056111455\n",
      "Epoch: 1993, Avg. Train Loss: 0.0003738091239261679, Avg. Test Loss: 0.0003842251608148217\n",
      "Epoch: 1994, Avg. Train Loss: 0.00037592866452584086, Avg. Test Loss: 0.00039111304795369506\n",
      "Epoch: 1995, Avg. Train Loss: 0.00037585250724670154, Avg. Test Loss: 0.00038664598832838237\n",
      "Epoch: 1996, Avg. Train Loss: 0.00037497720548471564, Avg. Test Loss: 0.0003870930231641978\n",
      "Epoch: 1997, Avg. Train Loss: 0.0003755691855182048, Avg. Test Loss: 0.0003855134127661586\n",
      "Epoch: 1998, Avg. Train Loss: 0.00037390546301964585, Avg. Test Loss: 0.0003861179284285754\n",
      "Epoch: 1999, Avg. Train Loss: 0.00037448738192662944, Avg. Test Loss: 0.0003857734554912895\n",
      "Epoch: 2000, Avg. Train Loss: 0.00037379102540462345, Avg. Test Loss: 0.00038849253905937076\n",
      "Epoch: 2001, Avg. Train Loss: 0.00037512121800614825, Avg. Test Loss: 0.0003862813173327595\n",
      "Epoch: 2002, Avg. Train Loss: 0.00037401775778054673, Avg. Test Loss: 0.00038542901165783405\n",
      "Epoch: 2003, Avg. Train Loss: 0.0003758932769753385, Avg. Test Loss: 0.00038955462514422834\n",
      "Epoch: 2004, Avg. Train Loss: 0.00037323166331991036, Avg. Test Loss: 0.00038507540011778474\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2005, Avg. Train Loss: 0.0003738178692888035, Avg. Test Loss: 0.00038877304177731276\n",
      "Epoch: 2006, Avg. Train Loss: 0.00037393586569314086, Avg. Test Loss: 0.00038625815068371594\n",
      "Epoch: 2007, Avg. Train Loss: 0.0003738105500138603, Avg. Test Loss: 0.0003866905753966421\n",
      "Epoch: 2008, Avg. Train Loss: 0.0003742519468285663, Avg. Test Loss: 0.0003891638480126858\n",
      "Epoch: 2009, Avg. Train Loss: 0.00037548316407104047, Avg. Test Loss: 0.00038448639679700136\n",
      "Epoch: 2010, Avg. Train Loss: 0.0003742169667316904, Avg. Test Loss: 0.00038320125895552337\n",
      "Epoch: 2011, Avg. Train Loss: 0.00037296683470675247, Avg. Test Loss: 0.0003889866638928652\n",
      "Epoch: 2012, Avg. Train Loss: 0.0003740985222637307, Avg. Test Loss: 0.0003847831685561687\n",
      "Epoch: 2013, Avg. Train Loss: 0.00037248300383040724, Avg. Test Loss: 0.00038642107392661273\n",
      "Epoch: 2014, Avg. Train Loss: 0.0003755621830012303, Avg. Test Loss: 0.00038578876410610974\n",
      "Epoch: 2015, Avg. Train Loss: 0.0003756837693292128, Avg. Test Loss: 0.00038358886376954615\n",
      "Epoch: 2016, Avg. Train Loss: 0.00037365409662015736, Avg. Test Loss: 0.0003846934996545315\n",
      "Epoch: 2017, Avg. Train Loss: 0.00037289388020262987, Avg. Test Loss: 0.0003863750025629997\n",
      "Epoch: 2018, Avg. Train Loss: 0.0003728696400960258, Avg. Test Loss: 0.00038521396345458925\n",
      "Epoch: 2019, Avg. Train Loss: 0.00037313230013539796, Avg. Test Loss: 0.00038344389759004116\n",
      "Epoch: 2020, Avg. Train Loss: 0.00037411005550259073, Avg. Test Loss: 0.00038383380160667\n",
      "Epoch: 2021, Avg. Train Loss: 0.0003738741831702375, Avg. Test Loss: 0.0003864078316837549\n",
      "Epoch: 2022, Avg. Train Loss: 0.0003735061205631165, Avg. Test Loss: 0.0003921718744095415\n",
      "Epoch: 2023, Avg. Train Loss: 0.00037284596446836586, Avg. Test Loss: 0.00038408348336815834\n",
      "Epoch: 2024, Avg. Train Loss: 0.0003745017964447047, Avg. Test Loss: 0.00038599877734668553\n",
      "Epoch: 2025, Avg. Train Loss: 0.00037368260416050636, Avg. Test Loss: 0.00038549851160496473\n",
      "Epoch: 2026, Avg. Train Loss: 0.0003732103410415178, Avg. Test Loss: 0.000383335689548403\n",
      "Epoch: 2027, Avg. Train Loss: 0.00037249755709930214, Avg. Test Loss: 0.00038278705324046314\n",
      "Epoch: 2028, Avg. Train Loss: 0.0003737712239705806, Avg. Test Loss: 0.00038456596666947007\n",
      "Epoch: 2029, Avg. Train Loss: 0.00037344494972616263, Avg. Test Loss: 0.00038513311301358044\n",
      "Epoch: 2030, Avg. Train Loss: 0.00037325236223486447, Avg. Test Loss: 0.000386180414352566\n",
      "Epoch: 2031, Avg. Train Loss: 0.000372190672774301, Avg. Test Loss: 0.00038289392250590026\n",
      "Epoch: 2032, Avg. Train Loss: 0.0003722284529304002, Avg. Test Loss: 0.0003835207025986165\n",
      "Epoch: 2033, Avg. Train Loss: 0.00037208468542261006, Avg. Test Loss: 0.00038375414442270994\n",
      "Epoch: 2034, Avg. Train Loss: 0.00037295251765266755, Avg. Test Loss: 0.00038631289498880506\n",
      "Epoch: 2035, Avg. Train Loss: 0.00037350557165133743, Avg. Test Loss: 0.00038530465099029243\n",
      "Epoch: 2036, Avg. Train Loss: 0.00037232453956506976, Avg. Test Loss: 0.000387904467061162\n",
      "Epoch: 2037, Avg. Train Loss: 0.0003729175253727928, Avg. Test Loss: 0.0003826521278824657\n",
      "Epoch: 2038, Avg. Train Loss: 0.00037184378828008683, Avg. Test Loss: 0.000387604784918949\n",
      "Epoch: 2039, Avg. Train Loss: 0.00037159522193982156, Avg. Test Loss: 0.000384499755455181\n",
      "Epoch: 2040, Avg. Train Loss: 0.00037176419133428746, Avg. Test Loss: 0.00038844579830765724\n",
      "Epoch: 2041, Avg. Train Loss: 0.00037259464070937316, Avg. Test Loss: 0.00038779128226451576\n",
      "Epoch: 2042, Avg. Train Loss: 0.0003726036554516488, Avg. Test Loss: 0.0003859812277369201\n",
      "Epoch: 2043, Avg. Train Loss: 0.00037281621087797333, Avg. Test Loss: 0.00038728778599761426\n",
      "Epoch: 2044, Avg. Train Loss: 0.00037261384179230865, Avg. Test Loss: 0.0003843180602416396\n",
      "Epoch: 2045, Avg. Train Loss: 0.0003724050658029439, Avg. Test Loss: 0.0003855183604173362\n",
      "Epoch: 2046, Avg. Train Loss: 0.00037268468728397303, Avg. Test Loss: 0.0003836434334516525\n",
      "Epoch: 2047, Avg. Train Loss: 0.0003731658724190797, Avg. Test Loss: 0.00039157186984084547\n",
      "Epoch: 2048, Avg. Train Loss: 0.00037176057975197777, Avg. Test Loss: 0.00038334951386787\n",
      "Epoch: 2049, Avg. Train Loss: 0.00037121875983186413, Avg. Test Loss: 0.0003820501733571291\n",
      "Epoch: 2050, Avg. Train Loss: 0.0003726727404999872, Avg. Test Loss: 0.0003837643307633698\n",
      "Epoch: 2051, Avg. Train Loss: 0.00037289867827365564, Avg. Test Loss: 0.0003838317352347076\n",
      "Epoch: 2052, Avg. Train Loss: 0.0003719411825566271, Avg. Test Loss: 0.0003843917220365256\n",
      "Epoch: 2053, Avg. Train Loss: 0.00037278147985573943, Avg. Test Loss: 0.0003862615267280489\n",
      "Epoch: 2054, Avg. Train Loss: 0.00037266316263243385, Avg. Test Loss: 0.00038386284722946584\n",
      "Epoch: 2055, Avg. Train Loss: 0.00037275480314937615, Avg. Test Loss: 0.00039489587652496994\n",
      "Epoch: 2056, Avg. Train Loss: 0.0003738491586138776, Avg. Test Loss: 0.00038238472188822925\n",
      "Epoch: 2057, Avg. Train Loss: 0.0003717337933986253, Avg. Test Loss: 0.00038526751450262964\n",
      "Epoch: 2058, Avg. Train Loss: 0.00037136298487894237, Avg. Test Loss: 0.00038330318056978285\n",
      "Epoch: 2059, Avg. Train Loss: 0.00037206022128419476, Avg. Test Loss: 0.00038332180702127516\n",
      "Epoch: 2060, Avg. Train Loss: 0.00037181299710429687, Avg. Test Loss: 0.0003833007940556854\n",
      "Epoch: 2061, Avg. Train Loss: 0.00037164972258493475, Avg. Test Loss: 0.0003831469512078911\n",
      "Epoch: 2062, Avg. Train Loss: 0.00037113210486876237, Avg. Test Loss: 0.0003847788611892611\n",
      "Epoch: 2063, Avg. Train Loss: 0.0003722484919329196, Avg. Test Loss: 0.00038328306982293725\n",
      "Epoch: 2064, Avg. Train Loss: 0.0003712550076374481, Avg. Test Loss: 0.0003822773287538439\n",
      "Epoch: 2065, Avg. Train Loss: 0.0003738353322639108, Avg. Test Loss: 0.00038251111982390285\n",
      "Epoch: 2066, Avg. Train Loss: 0.0003717523372764591, Avg. Test Loss: 0.0003817424876615405\n",
      "Epoch: 2067, Avg. Train Loss: 0.00037117073242011114, Avg. Test Loss: 0.0003833549271803349\n",
      "Epoch: 2068, Avg. Train Loss: 0.0003709479080794682, Avg. Test Loss: 0.0003834885428659618\n",
      "Epoch: 2069, Avg. Train Loss: 0.00037186337448115095, Avg. Test Loss: 0.0003878137213177979\n",
      "Epoch: 2070, Avg. Train Loss: 0.0003741261126950037, Avg. Test Loss: 0.0003820099518634379\n",
      "Epoch: 2071, Avg. Train Loss: 0.0003717542209034396, Avg. Test Loss: 0.00038842149660922587\n",
      "Epoch: 2072, Avg. Train Loss: 0.00037457535739143403, Avg. Test Loss: 0.00038219569250941277\n",
      "Epoch: 2073, Avg. Train Loss: 0.00037221522625470753, Avg. Test Loss: 0.00038184065488167107\n",
      "Epoch: 2074, Avg. Train Loss: 0.0003704896513480953, Avg. Test Loss: 0.00038160287658683956\n",
      "Epoch: 2075, Avg. Train Loss: 0.0003725935990629761, Avg. Test Loss: 0.0003864960453938693\n",
      "Epoch: 2076, Avg. Train Loss: 0.0003717176123457246, Avg. Test Loss: 0.0003876188420690596\n",
      "Epoch: 2077, Avg. Train Loss: 0.00037227323695714044, Avg. Test Loss: 0.0003848893102258444\n",
      "Epoch: 2078, Avg. Train Loss: 0.0003717320207723005, Avg. Test Loss: 0.00038727003266103566\n",
      "Epoch: 2079, Avg. Train Loss: 0.0003714866754815502, Avg. Test Loss: 0.00038351566763594747\n",
      "Epoch: 2080, Avg. Train Loss: 0.00037136842797207104, Avg. Test Loss: 0.0003832549264188856\n",
      "Epoch: 2081, Avg. Train Loss: 0.0003710254880621336, Avg. Test Loss: 0.00038350760587491095\n",
      "Epoch: 2082, Avg. Train Loss: 0.0003712571897478991, Avg. Test Loss: 0.0003828144690487534\n",
      "Epoch: 2083, Avg. Train Loss: 0.00037100908636158807, Avg. Test Loss: 0.00038389937253668904\n",
      "Epoch: 2084, Avg. Train Loss: 0.00037140463449082575, Avg. Test Loss: 0.000381849444238469\n",
      "Epoch: 2085, Avg. Train Loss: 0.0003702273297253563, Avg. Test Loss: 0.00038098706863820553\n",
      "Epoch: 2086, Avg. Train Loss: 0.0003702677874338575, Avg. Test Loss: 0.00038407003739848733\n",
      "Epoch: 2087, Avg. Train Loss: 0.0003720330613188792, Avg. Test Loss: 0.0003851095971185714\n",
      "Epoch: 2088, Avg. Train Loss: 0.00037021312570242686, Avg. Test Loss: 0.0003805999585893005\n",
      "Epoch: 2089, Avg. Train Loss: 0.00037112494532647, Avg. Test Loss: 0.00038237168337218463\n",
      "Epoch: 2090, Avg. Train Loss: 0.0003713905035658891, Avg. Test Loss: 0.0003807414323091507\n",
      "Epoch: 2091, Avg. Train Loss: 0.00037116614890523084, Avg. Test Loss: 0.0003801999846473336\n",
      "Epoch: 2092, Avg. Train Loss: 0.00037027087379355245, Avg. Test Loss: 0.0003842953301500529\n",
      "Epoch: 2093, Avg. Train Loss: 0.0003718422396855732, Avg. Test Loss: 0.00038508418947458267\n",
      "Epoch: 2094, Avg. Train Loss: 0.0003738783132068293, Avg. Test Loss: 0.0003860082069877535\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2095, Avg. Train Loss: 0.0003701021250467314, Avg. Test Loss: 0.0003867075720336288\n",
      "Epoch: 2096, Avg. Train Loss: 0.0003722629497683239, Avg. Test Loss: 0.00038374587893486023\n",
      "Epoch: 2097, Avg. Train Loss: 0.00036979806717745095, Avg. Test Loss: 0.00038359497557394207\n",
      "Epoch: 2098, Avg. Train Loss: 0.00036966958324165017, Avg. Test Loss: 0.00038075027987360954\n",
      "Epoch: 2099, Avg. Train Loss: 0.0003691976964419578, Avg. Test Loss: 0.00037997931940481067\n",
      "Epoch: 2100, Avg. Train Loss: 0.00037075022335684055, Avg. Test Loss: 0.0003819945268332958\n",
      "Epoch: 2101, Avg. Train Loss: 0.00037116862679181925, Avg. Test Loss: 0.0003807587781921029\n",
      "Epoch: 2102, Avg. Train Loss: 0.0003691103057610954, Avg. Test Loss: 0.00038401797064580023\n",
      "Epoch: 2103, Avg. Train Loss: 0.0003707384092321749, Avg. Test Loss: 0.0003839832788798958\n",
      "Epoch: 2104, Avg. Train Loss: 0.00036997085255787294, Avg. Test Loss: 0.00038130010943859816\n",
      "Epoch: 2105, Avg. Train Loss: 0.00036940692590961105, Avg. Test Loss: 0.000382978847483173\n",
      "Epoch: 2106, Avg. Train Loss: 0.00036907568303218416, Avg. Test Loss: 0.0003800858394242823\n",
      "Epoch: 2107, Avg. Train Loss: 0.00037003842826802716, Avg. Test Loss: 0.0003829739289358258\n",
      "Epoch: 2108, Avg. Train Loss: 0.00037190608807492916, Avg. Test Loss: 0.0003832596121355891\n",
      "Epoch: 2109, Avg. Train Loss: 0.0003701241661220529, Avg. Test Loss: 0.0003802588616963476\n",
      "Epoch: 2110, Avg. Train Loss: 0.0003703764712892819, Avg. Test Loss: 0.0003804362495429814\n",
      "Epoch: 2111, Avg. Train Loss: 0.0003698610965985545, Avg. Test Loss: 0.00038121320540085435\n",
      "Epoch: 2112, Avg. Train Loss: 0.0003692085555548845, Avg. Test Loss: 0.0003810500493273139\n",
      "Epoch: 2113, Avg. Train Loss: 0.0003704035689859369, Avg. Test Loss: 0.0003835080424323678\n",
      "Epoch: 2114, Avg. Train Loss: 0.00036914231185259863, Avg. Test Loss: 0.00038792664417997\n",
      "Epoch: 2115, Avg. Train Loss: 0.0003704605048771428, Avg. Test Loss: 0.0003796536475419998\n",
      "Epoch: 2116, Avg. Train Loss: 0.00036868307574348914, Avg. Test Loss: 0.00038019224302843213\n",
      "Epoch: 2117, Avg. Train Loss: 0.0003705760734805534, Avg. Test Loss: 0.000385132065275684\n",
      "Epoch: 2118, Avg. Train Loss: 0.00036934139558958797, Avg. Test Loss: 0.00038035219768062234\n",
      "Epoch: 2119, Avg. Train Loss: 0.0003702105300468501, Avg. Test Loss: 0.00038211196078918874\n",
      "Epoch: 2120, Avg. Train Loss: 0.00036985810093451724, Avg. Test Loss: 0.0003817295946646482\n",
      "Epoch: 2121, Avg. Train Loss: 0.0003689634640766091, Avg. Test Loss: 0.0003812344220932573\n",
      "Epoch: 2122, Avg. Train Loss: 0.00036997360997660043, Avg. Test Loss: 0.00038150561158545315\n",
      "Epoch: 2123, Avg. Train Loss: 0.00036972524600948183, Avg. Test Loss: 0.00038158486131578684\n",
      "Epoch: 2124, Avg. Train Loss: 0.00036825601764153257, Avg. Test Loss: 0.0003849730419460684\n",
      "Epoch: 2125, Avg. Train Loss: 0.0003697916690725833, Avg. Test Loss: 0.00038273277459666133\n",
      "Epoch: 2126, Avg. Train Loss: 0.00036899559064443375, Avg. Test Loss: 0.0003797895333264023\n",
      "Epoch: 2127, Avg. Train Loss: 0.00036827147854383773, Avg. Test Loss: 0.00037979689659550786\n",
      "Epoch: 2128, Avg. Train Loss: 0.00036999287941969584, Avg. Test Loss: 0.0003860746219288558\n",
      "Epoch: 2129, Avg. Train Loss: 0.0003708409684233714, Avg. Test Loss: 0.00038483800017274916\n",
      "Epoch: 2130, Avg. Train Loss: 0.00037011786345067586, Avg. Test Loss: 0.00038262089947238564\n",
      "Epoch: 2131, Avg. Train Loss: 0.0003704115414049823, Avg. Test Loss: 0.00038475263863801956\n",
      "Epoch: 2132, Avg. Train Loss: 0.00037072559001010867, Avg. Test Loss: 0.00038712332025170326\n",
      "Epoch: 2133, Avg. Train Loss: 0.00036875131407341117, Avg. Test Loss: 0.0003824855375569314\n",
      "Epoch: 2134, Avg. Train Loss: 0.0003702302881635639, Avg. Test Loss: 0.0003826167667284608\n",
      "Epoch: 2135, Avg. Train Loss: 0.0003696481377796032, Avg. Test Loss: 0.00038063968531787395\n",
      "Epoch: 2136, Avg. Train Loss: 0.00036910487214363247, Avg. Test Loss: 0.000385394407203421\n",
      "Epoch: 2137, Avg. Train Loss: 0.00037053908928037554, Avg. Test Loss: 0.00038120688986964524\n",
      "Epoch: 2138, Avg. Train Loss: 0.00036870481021334094, Avg. Test Loss: 0.0003807041794061661\n",
      "Epoch: 2139, Avg. Train Loss: 0.0003682915480038541, Avg. Test Loss: 0.00038321397732943296\n",
      "Epoch: 2140, Avg. Train Loss: 0.0003690847404149556, Avg. Test Loss: 0.00038302119355648756\n",
      "Epoch: 2141, Avg. Train Loss: 0.0003690286370286675, Avg. Test Loss: 0.0003787784371525049\n",
      "Epoch: 2142, Avg. Train Loss: 0.00036942835918865927, Avg. Test Loss: 0.00037928743404336274\n",
      "Epoch: 2143, Avg. Train Loss: 0.00036927555527992893, Avg. Test Loss: 0.00037994133890606463\n",
      "Epoch: 2144, Avg. Train Loss: 0.0003686957020680745, Avg. Test Loss: 0.00038097085780464113\n",
      "Epoch: 2145, Avg. Train Loss: 0.00036825339017479224, Avg. Test Loss: 0.0003815997624769807\n",
      "Epoch: 2146, Avg. Train Loss: 0.00036935332816007523, Avg. Test Loss: 0.0003900899610016495\n",
      "Epoch: 2147, Avg. Train Loss: 0.00037133309659872983, Avg. Test Loss: 0.00037992457509972155\n",
      "Epoch: 2148, Avg. Train Loss: 0.00036823744601353485, Avg. Test Loss: 0.0003799123805947602\n",
      "Epoch: 2149, Avg. Train Loss: 0.00036907321868226103, Avg. Test Loss: 0.00038227011100389063\n",
      "Epoch: 2150, Avg. Train Loss: 0.00036913835034749014, Avg. Test Loss: 0.00037978222826495767\n",
      "Epoch: 2151, Avg. Train Loss: 0.00036863954521195835, Avg. Test Loss: 0.000382505648303777\n",
      "Epoch: 2152, Avg. Train Loss: 0.00037026655627414584, Avg. Test Loss: 0.0003788586473092437\n",
      "Epoch: 2153, Avg. Train Loss: 0.0003692923536047686, Avg. Test Loss: 0.0003801815619226545\n",
      "Epoch: 2154, Avg. Train Loss: 0.00036821508411924507, Avg. Test Loss: 0.00037900140159763396\n",
      "Epoch: 2155, Avg. Train Loss: 0.0003686508848765042, Avg. Test Loss: 0.000379524048184976\n",
      "Epoch: 2156, Avg. Train Loss: 0.0003678566386360069, Avg. Test Loss: 0.00037895707646384835\n",
      "Epoch: 2157, Avg. Train Loss: 0.00036789979217140826, Avg. Test Loss: 0.0003836298128589988\n",
      "Epoch: 2158, Avg. Train Loss: 0.0003695552620419496, Avg. Test Loss: 0.0003831702924799174\n",
      "Epoch: 2159, Avg. Train Loss: 0.0003685776589622418, Avg. Test Loss: 0.000380782614229247\n",
      "Epoch: 2160, Avg. Train Loss: 0.00036967284422432785, Avg. Test Loss: 0.00038167356979101896\n",
      "Epoch: 2161, Avg. Train Loss: 0.0003683862193801635, Avg. Test Loss: 0.0003789104230236262\n",
      "Epoch: 2162, Avg. Train Loss: 0.0003677858567666696, Avg. Test Loss: 0.00038010734715498984\n",
      "Epoch: 2163, Avg. Train Loss: 0.00036955806277800613, Avg. Test Loss: 0.0003793913929257542\n",
      "Epoch: 2164, Avg. Train Loss: 0.0003681334187709835, Avg. Test Loss: 0.00037809915374964476\n",
      "Epoch: 2165, Avg. Train Loss: 0.00036785022225664107, Avg. Test Loss: 0.00037869904190301895\n",
      "Epoch: 2166, Avg. Train Loss: 0.00036825653203481504, Avg. Test Loss: 0.000379471224732697\n",
      "Epoch: 2167, Avg. Train Loss: 0.0003684456148834596, Avg. Test Loss: 0.00037791451904922724\n",
      "Epoch: 2168, Avg. Train Loss: 0.00036641910095525863, Avg. Test Loss: 0.0003758741950150579\n",
      "Epoch: 2169, Avg. Train Loss: 0.00036642814615503124, Avg. Test Loss: 0.00037718896055594087\n",
      "Epoch: 2170, Avg. Train Loss: 0.0003657948055174635, Avg. Test Loss: 0.00037645440897904336\n",
      "Epoch: 2171, Avg. Train Loss: 0.00036785474417969414, Avg. Test Loss: 0.000378823111532256\n",
      "Epoch: 2172, Avg. Train Loss: 0.0003665142231025235, Avg. Test Loss: 0.00037612905725836754\n",
      "Epoch: 2173, Avg. Train Loss: 0.00036485278694673855, Avg. Test Loss: 0.000375840492779389\n",
      "Epoch: 2174, Avg. Train Loss: 0.00036442366856431893, Avg. Test Loss: 0.00037688814336434007\n",
      "Epoch: 2175, Avg. Train Loss: 0.00036461223160501484, Avg. Test Loss: 0.0003745469730347395\n",
      "Epoch: 2176, Avg. Train Loss: 0.00036405797893463007, Avg. Test Loss: 0.0003730778116732836\n",
      "Epoch: 2177, Avg. Train Loss: 0.0003633679839684953, Avg. Test Loss: 0.0003738198720384389\n",
      "Epoch: 2178, Avg. Train Loss: 0.0003642742982307492, Avg. Test Loss: 0.00037592669832520187\n",
      "Epoch: 2179, Avg. Train Loss: 0.00036356799361339314, Avg. Test Loss: 0.0003742205735761672\n",
      "Epoch: 2180, Avg. Train Loss: 0.00036287399044065456, Avg. Test Loss: 0.0003713229380082339\n",
      "Epoch: 2181, Avg. Train Loss: 0.00036196425478623876, Avg. Test Loss: 0.00037181764491833746\n",
      "Epoch: 2182, Avg. Train Loss: 0.0003622146336859915, Avg. Test Loss: 0.00037034868728369474\n",
      "Epoch: 2183, Avg. Train Loss: 0.0003613626765801983, Avg. Test Loss: 0.00037100230110809207\n",
      "Epoch: 2184, Avg. Train Loss: 0.00036324164153314956, Avg. Test Loss: 0.00037295438232831657\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2185, Avg. Train Loss: 0.00036281472285884585, Avg. Test Loss: 0.0003705320705194026\n",
      "Epoch: 2186, Avg. Train Loss: 0.0003629714138210253, Avg. Test Loss: 0.00037036105641163886\n",
      "Epoch: 2187, Avg. Train Loss: 0.00036134344842393213, Avg. Test Loss: 0.0003690374724101275\n",
      "Epoch: 2188, Avg. Train Loss: 0.00036088219332118884, Avg. Test Loss: 0.00036972181987948716\n",
      "Epoch: 2189, Avg. Train Loss: 0.0003628616368798756, Avg. Test Loss: 0.00037293211789801717\n",
      "Epoch: 2190, Avg. Train Loss: 0.00036092539152758586, Avg. Test Loss: 0.000370252673747018\n",
      "Epoch: 2191, Avg. Train Loss: 0.0003625212872108488, Avg. Test Loss: 0.00037259404780343175\n",
      "Epoch: 2192, Avg. Train Loss: 0.000361036132279307, Avg. Test Loss: 0.00036850603646598756\n",
      "Epoch: 2193, Avg. Train Loss: 0.0003602370344979559, Avg. Test Loss: 0.00037276005605235696\n",
      "Epoch: 2194, Avg. Train Loss: 0.00036143326419838814, Avg. Test Loss: 0.0003683208196889609\n",
      "Epoch: 2195, Avg. Train Loss: 0.00035885798739442644, Avg. Test Loss: 0.0003736398939508945\n",
      "Epoch: 2196, Avg. Train Loss: 0.0003601569651225365, Avg. Test Loss: 0.00036921969149261713\n",
      "Epoch: 2197, Avg. Train Loss: 0.0003600927126637205, Avg. Test Loss: 0.00037479866296052933\n",
      "Epoch: 2198, Avg. Train Loss: 0.00035904480014429537, Avg. Test Loss: 0.00036898039979860187\n",
      "Epoch: 2199, Avg. Train Loss: 0.00036011943133374633, Avg. Test Loss: 0.0003745770372916013\n",
      "Epoch: 2200, Avg. Train Loss: 0.00035936940193371196, Avg. Test Loss: 0.00037239425000734627\n",
      "Epoch: 2201, Avg. Train Loss: 0.00035874352541340643, Avg. Test Loss: 0.0003721800458151847\n",
      "Epoch: 2202, Avg. Train Loss: 0.00035941578531746083, Avg. Test Loss: 0.0003716245118994266\n",
      "Epoch: 2203, Avg. Train Loss: 0.00035815977364193733, Avg. Test Loss: 0.0003668811987154186\n",
      "Epoch: 2204, Avg. Train Loss: 0.0003583684711186432, Avg. Test Loss: 0.00036713306326419115\n",
      "Epoch: 2205, Avg. Train Loss: 0.00035935386928708055, Avg. Test Loss: 0.00037129202974028885\n",
      "Epoch: 2206, Avg. Train Loss: 0.00036184376898914746, Avg. Test Loss: 0.0003703382099047303\n",
      "Epoch: 2207, Avg. Train Loss: 0.0003570206842363574, Avg. Test Loss: 0.000367951113730669\n",
      "Epoch: 2208, Avg. Train Loss: 0.00035821972144117883, Avg. Test Loss: 0.0003752874908968806\n",
      "Epoch: 2209, Avg. Train Loss: 0.0003589456359487633, Avg. Test Loss: 0.00036780908703804016\n",
      "Epoch: 2210, Avg. Train Loss: 0.00035809385481961936, Avg. Test Loss: 0.00037132028955966234\n",
      "Epoch: 2211, Avg. Train Loss: 0.0003615675066316197, Avg. Test Loss: 0.0003687466087285429\n",
      "Epoch: 2212, Avg. Train Loss: 0.0003584700475479368, Avg. Test Loss: 0.0003701495297718793\n",
      "Epoch: 2213, Avg. Train Loss: 0.00035750585659623664, Avg. Test Loss: 0.00036793158506043255\n",
      "Epoch: 2214, Avg. Train Loss: 0.0003582730924515703, Avg. Test Loss: 0.00036702805664390326\n",
      "Epoch: 2215, Avg. Train Loss: 0.0003578395238904239, Avg. Test Loss: 0.00037304917350411415\n",
      "Epoch: 2216, Avg. Train Loss: 0.000358253272066196, Avg. Test Loss: 0.00037126452662050724\n",
      "Epoch: 2217, Avg. Train Loss: 0.00035656682962854935, Avg. Test Loss: 0.0003655214386526495\n",
      "Epoch: 2218, Avg. Train Loss: 0.000357572152414684, Avg. Test Loss: 0.00036721964715979993\n",
      "Epoch: 2219, Avg. Train Loss: 0.00035818941081700804, Avg. Test Loss: 0.0003692306054290384\n",
      "Epoch: 2220, Avg. Train Loss: 0.0003570686385501176, Avg. Test Loss: 0.0003665416734293103\n",
      "Epoch: 2221, Avg. Train Loss: 0.00035660929888551836, Avg. Test Loss: 0.00036666422965936363\n",
      "Epoch: 2222, Avg. Train Loss: 0.0003556908314051323, Avg. Test Loss: 0.0003664080868475139\n",
      "Epoch: 2223, Avg. Train Loss: 0.00035645833054860664, Avg. Test Loss: 0.00036687642568722367\n",
      "Epoch: 2224, Avg. Train Loss: 0.00035598958899310334, Avg. Test Loss: 0.0003659182693809271\n",
      "Epoch: 2225, Avg. Train Loss: 0.00035756188823819854, Avg. Test Loss: 0.0003642098745331168\n",
      "Epoch: 2226, Avg. Train Loss: 0.0003586218050724372, Avg. Test Loss: 0.0003666702250484377\n",
      "Epoch: 2227, Avg. Train Loss: 0.00035705634861166565, Avg. Test Loss: 0.0003643070231191814\n",
      "Epoch: 2228, Avg. Train Loss: 0.00035562064785640254, Avg. Test Loss: 0.0003652493469417095\n",
      "Epoch: 2229, Avg. Train Loss: 0.00035709186611415514, Avg. Test Loss: 0.00036459360853768885\n",
      "Epoch: 2230, Avg. Train Loss: 0.00035735287264985745, Avg. Test Loss: 0.0003656538901850581\n",
      "Epoch: 2231, Avg. Train Loss: 0.0003550008371158308, Avg. Test Loss: 0.00036460530827753246\n",
      "Epoch: 2232, Avg. Train Loss: 0.00035712210905499927, Avg. Test Loss: 0.00036616023862734437\n",
      "Epoch: 2233, Avg. Train Loss: 0.00035690256464836553, Avg. Test Loss: 0.0003685998381115496\n",
      "Epoch: 2234, Avg. Train Loss: 0.0003550024229361741, Avg. Test Loss: 0.00037054091808386147\n",
      "Epoch: 2235, Avg. Train Loss: 0.0003572188962120996, Avg. Test Loss: 0.0003685085102915764\n",
      "Epoch: 2236, Avg. Train Loss: 0.00035544764724300176, Avg. Test Loss: 0.0003652626182883978\n",
      "Epoch: 2237, Avg. Train Loss: 0.000356086133167061, Avg. Test Loss: 0.00036405670107342303\n",
      "Epoch: 2238, Avg. Train Loss: 0.00035584977283792266, Avg. Test Loss: 0.000364765030099079\n",
      "Epoch: 2239, Avg. Train Loss: 0.000355097908542903, Avg. Test Loss: 0.0003682165697682649\n",
      "Epoch: 2240, Avg. Train Loss: 0.00035550470158002924, Avg. Test Loss: 0.0003636893816292286\n",
      "Epoch: 2241, Avg. Train Loss: 0.0003551802283889332, Avg. Test Loss: 0.00036647432716563344\n",
      "Epoch: 2242, Avg. Train Loss: 0.0003557283225534267, Avg. Test Loss: 0.0003645334218163043\n",
      "Epoch: 2243, Avg. Train Loss: 0.0003546949869920608, Avg. Test Loss: 0.0003740177198778838\n",
      "Epoch: 2244, Avg. Train Loss: 0.00035652159821502, Avg. Test Loss: 0.00036849218304269016\n",
      "Epoch: 2245, Avg. Train Loss: 0.0003556111464710083, Avg. Test Loss: 0.0003666761622298509\n",
      "Epoch: 2246, Avg. Train Loss: 0.0003552927268766473, Avg. Test Loss: 0.00036499154521152377\n",
      "Epoch: 2247, Avg. Train Loss: 0.00035443338958091687, Avg. Test Loss: 0.00036240380723029375\n",
      "Epoch: 2248, Avg. Train Loss: 0.00035371772503631926, Avg. Test Loss: 0.0003632967418525368\n",
      "Epoch: 2249, Avg. Train Loss: 0.00035544047957871024, Avg. Test Loss: 0.00036377296783030033\n",
      "Epoch: 2250, Avg. Train Loss: 0.0003542220280884743, Avg. Test Loss: 0.0003674478211905807\n",
      "Epoch: 2251, Avg. Train Loss: 0.0003545409864421154, Avg. Test Loss: 0.0003656409971881658\n",
      "Epoch: 2252, Avg. Train Loss: 0.0003545020035533018, Avg. Test Loss: 0.00036388597800396383\n",
      "Epoch: 2253, Avg. Train Loss: 0.0003546744457792577, Avg. Test Loss: 0.0003649787977337837\n",
      "Epoch: 2254, Avg. Train Loss: 0.0003548044837242382, Avg. Test Loss: 0.00036228130920790136\n",
      "Epoch: 2255, Avg. Train Loss: 0.0003546503796188031, Avg. Test Loss: 0.0003633074229583144\n",
      "Epoch: 2256, Avg. Train Loss: 0.0003537728145263743, Avg. Test Loss: 0.0003644496900960803\n",
      "Epoch: 2257, Avg. Train Loss: 0.0003555322446329736, Avg. Test Loss: 0.00036918348632752895\n",
      "Epoch: 2258, Avg. Train Loss: 0.0003561061593097483, Avg. Test Loss: 0.0003681389207486063\n",
      "Epoch: 2259, Avg. Train Loss: 0.00035790311440630536, Avg. Test Loss: 0.0003625847166404128\n",
      "Epoch: 2260, Avg. Train Loss: 0.0003543817316355227, Avg. Test Loss: 0.0003627215919550508\n",
      "Epoch: 2261, Avg. Train Loss: 0.0003559676379366063, Avg. Test Loss: 0.0003664927207864821\n",
      "Epoch: 2262, Avg. Train Loss: 0.000353511264493559, Avg. Test Loss: 0.00036727002589032054\n",
      "Epoch: 2263, Avg. Train Loss: 0.0003537389383445559, Avg. Test Loss: 0.000363307713996619\n",
      "Epoch: 2264, Avg. Train Loss: 0.0003556125779733668, Avg. Test Loss: 0.00036611544783227146\n",
      "Epoch: 2265, Avg. Train Loss: 0.000353771124473708, Avg. Test Loss: 0.00036907746107317507\n",
      "Epoch: 2266, Avg. Train Loss: 0.0003540757921697615, Avg. Test Loss: 0.00036270153941586614\n",
      "Epoch: 2267, Avg. Train Loss: 0.0003537385667630926, Avg. Test Loss: 0.00036505432217381895\n",
      "Epoch: 2268, Avg. Train Loss: 0.00035269272806079583, Avg. Test Loss: 0.0003653006860986352\n",
      "Epoch: 2269, Avg. Train Loss: 0.0003525895272316628, Avg. Test Loss: 0.0003628473205026239\n",
      "Epoch: 2270, Avg. Train Loss: 0.00035251114926257627, Avg. Test Loss: 0.00036345061380416155\n",
      "Epoch: 2271, Avg. Train Loss: 0.00035445725336822486, Avg. Test Loss: 0.0003688837168738246\n",
      "Epoch: 2272, Avg. Train Loss: 0.0003577069329303624, Avg. Test Loss: 0.00036369592999108136\n",
      "Epoch: 2273, Avg. Train Loss: 0.0003534566528477901, Avg. Test Loss: 0.0003689541481435299\n",
      "Epoch: 2274, Avg. Train Loss: 0.0003545729370332908, Avg. Test Loss: 0.0003618462651502341\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2275, Avg. Train Loss: 0.0003538913131409953, Avg. Test Loss: 0.0003625427489168942\n",
      "Epoch: 2276, Avg. Train Loss: 0.0003525248023432268, Avg. Test Loss: 0.0003612021973822266\n",
      "Epoch: 2277, Avg. Train Loss: 0.0003521962234815366, Avg. Test Loss: 0.0003656101180240512\n",
      "Epoch: 2278, Avg. Train Loss: 0.0003530296177581646, Avg. Test Loss: 0.00036367247230373323\n",
      "Epoch: 2279, Avg. Train Loss: 0.00035287147431179534, Avg. Test Loss: 0.0003615451860241592\n",
      "Epoch: 2280, Avg. Train Loss: 0.0003531907013682432, Avg. Test Loss: 0.0003670839359983802\n",
      "Epoch: 2281, Avg. Train Loss: 0.00035371992339076864, Avg. Test Loss: 0.0003618716436903924\n",
      "Epoch: 2282, Avg. Train Loss: 0.00035217111702835145, Avg. Test Loss: 0.0003637251502368599\n",
      "Epoch: 2283, Avg. Train Loss: 0.000352494285961743, Avg. Test Loss: 0.0003620471397880465\n",
      "Epoch: 2284, Avg. Train Loss: 0.0003529613814587423, Avg. Test Loss: 0.000363681378075853\n",
      "Epoch: 2285, Avg. Train Loss: 0.0003532042481860709, Avg. Test Loss: 0.0003625677200034261\n",
      "Epoch: 2286, Avg. Train Loss: 0.0003526305000102797, Avg. Test Loss: 0.00036113426904194057\n",
      "Epoch: 2287, Avg. Train Loss: 0.0003527854176693011, Avg. Test Loss: 0.0003623887605499476\n",
      "Epoch: 2288, Avg. Train Loss: 0.0003541295022736195, Avg. Test Loss: 0.0003657229244709015\n",
      "Epoch: 2289, Avg. Train Loss: 0.0003525369927871886, Avg. Test Loss: 0.0003620644856709987\n",
      "Epoch: 2290, Avg. Train Loss: 0.0003528146338540801, Avg. Test Loss: 0.00036085909232497215\n",
      "Epoch: 2291, Avg. Train Loss: 0.0003525710124576594, Avg. Test Loss: 0.00036234143772162497\n",
      "Epoch: 2292, Avg. Train Loss: 0.00035275486000098806, Avg. Test Loss: 0.00036157676368020475\n",
      "Epoch: 2293, Avg. Train Loss: 0.0003526760292304463, Avg. Test Loss: 0.00036190488026477396\n",
      "Epoch: 2294, Avg. Train Loss: 0.00035287735802338045, Avg. Test Loss: 0.00036487984471023083\n",
      "Epoch: 2295, Avg. Train Loss: 0.00035394404792811636, Avg. Test Loss: 0.00036213407292962074\n",
      "Epoch: 2296, Avg. Train Loss: 0.0003526222304614304, Avg. Test Loss: 0.0003621359064709395\n",
      "Epoch: 2297, Avg. Train Loss: 0.0003523616740198503, Avg. Test Loss: 0.0003695397172123194\n",
      "Epoch: 2298, Avg. Train Loss: 0.00035308560269863107, Avg. Test Loss: 0.0003645085671450943\n",
      "Epoch: 2299, Avg. Train Loss: 0.0003545487524270145, Avg. Test Loss: 0.0003755261714104563\n",
      "Epoch: 2300, Avg. Train Loss: 0.0003558580782589351, Avg. Test Loss: 0.0003635097818914801\n",
      "Epoch: 2301, Avg. Train Loss: 0.0003526459385770871, Avg. Test Loss: 0.00036463100695982575\n",
      "Epoch: 2302, Avg. Train Loss: 0.00035199304896428487, Avg. Test Loss: 0.00036430134787224233\n",
      "Epoch: 2303, Avg. Train Loss: 0.00035276140565550777, Avg. Test Loss: 0.00036081564030610025\n",
      "Epoch: 2304, Avg. Train Loss: 0.0003530098325681201, Avg. Test Loss: 0.00036102949525229633\n",
      "Epoch: 2305, Avg. Train Loss: 0.000352868320945607, Avg. Test Loss: 0.0003619509225245565\n",
      "Epoch: 2306, Avg. Train Loss: 0.0003524934737618233, Avg. Test Loss: 0.00036163031472824514\n",
      "Epoch: 2307, Avg. Train Loss: 0.0003534633968144569, Avg. Test Loss: 0.0003649483260232955\n",
      "Epoch: 2308, Avg. Train Loss: 0.0003511541222525371, Avg. Test Loss: 0.0003616180329117924\n",
      "Epoch: 2309, Avg. Train Loss: 0.00035217741631556217, Avg. Test Loss: 0.0003650978906080127\n",
      "Epoch: 2310, Avg. Train Loss: 0.0003523711185512501, Avg. Test Loss: 0.000361144746420905\n",
      "Epoch: 2311, Avg. Train Loss: 0.00035227966619395584, Avg. Test Loss: 0.0003611966094467789\n",
      "Epoch: 2312, Avg. Train Loss: 0.00035273840956844736, Avg. Test Loss: 0.0003610277781262994\n",
      "Epoch: 2313, Avg. Train Loss: 0.0003527385808072638, Avg. Test Loss: 0.00035984243731945753\n",
      "Epoch: 2314, Avg. Train Loss: 0.0003513842340569597, Avg. Test Loss: 0.0003609207342378795\n",
      "Epoch: 2315, Avg. Train Loss: 0.0003511203550408746, Avg. Test Loss: 0.00036033865762874484\n",
      "Epoch: 2316, Avg. Train Loss: 0.0003509983436616008, Avg. Test Loss: 0.0003602928190957755\n",
      "Epoch: 2317, Avg. Train Loss: 0.0003521090575093187, Avg. Test Loss: 0.0003607082471717149\n",
      "Epoch: 2318, Avg. Train Loss: 0.000353228785422479, Avg. Test Loss: 0.0003619131457526237\n",
      "Epoch: 2319, Avg. Train Loss: 0.00035181973362341523, Avg. Test Loss: 0.00036113898386247456\n",
      "Epoch: 2320, Avg. Train Loss: 0.0003534711316650257, Avg. Test Loss: 0.00036219292087480426\n",
      "Epoch: 2321, Avg. Train Loss: 0.00035015038122574604, Avg. Test Loss: 0.0003635723842307925\n",
      "Epoch: 2322, Avg. Train Loss: 0.00035185301960662525, Avg. Test Loss: 0.0003616300818976015\n",
      "Epoch: 2323, Avg. Train Loss: 0.00035077672205367235, Avg. Test Loss: 0.0003607792314141989\n",
      "Epoch: 2324, Avg. Train Loss: 0.0003501023071124976, Avg. Test Loss: 0.0003608692204579711\n",
      "Epoch: 2325, Avg. Train Loss: 0.00035196783218727727, Avg. Test Loss: 0.0003624694363679737\n",
      "Epoch: 2326, Avg. Train Loss: 0.00035222577469878246, Avg. Test Loss: 0.0003631403378676623\n",
      "Epoch: 2327, Avg. Train Loss: 0.00035345587042853407, Avg. Test Loss: 0.0003620708594098687\n",
      "Epoch: 2328, Avg. Train Loss: 0.0003513026709105213, Avg. Test Loss: 0.0003631799481809139\n",
      "Epoch: 2329, Avg. Train Loss: 0.0003533163527568239, Avg. Test Loss: 0.00036053944495506585\n",
      "Epoch: 2330, Avg. Train Loss: 0.00035119994521834127, Avg. Test Loss: 0.00036452049971558154\n",
      "Epoch: 2331, Avg. Train Loss: 0.0003509164055495328, Avg. Test Loss: 0.0003601488715503365\n",
      "Epoch: 2332, Avg. Train Loss: 0.000349427678968844, Avg. Test Loss: 0.00035993545316159725\n",
      "Epoch: 2333, Avg. Train Loss: 0.0003501483026707848, Avg. Test Loss: 0.0003597494796849787\n",
      "Epoch: 2334, Avg. Train Loss: 0.00035175556982975715, Avg. Test Loss: 0.0003642900846898556\n",
      "Epoch: 2335, Avg. Train Loss: 0.00035103536914860787, Avg. Test Loss: 0.0003659047360997647\n",
      "Epoch: 2336, Avg. Train Loss: 0.00035189462590117963, Avg. Test Loss: 0.00036212673876434565\n",
      "Epoch: 2337, Avg. Train Loss: 0.00035095841049888105, Avg. Test Loss: 0.00036026397719979286\n",
      "Epoch: 2338, Avg. Train Loss: 0.00035130660195813277, Avg. Test Loss: 0.000359229656169191\n",
      "Epoch: 2339, Avg. Train Loss: 0.00035163211002729315, Avg. Test Loss: 0.0003606400568969548\n",
      "Epoch: 2340, Avg. Train Loss: 0.00035181353856852753, Avg. Test Loss: 0.0003611865104176104\n",
      "Epoch: 2341, Avg. Train Loss: 0.00035239694583186405, Avg. Test Loss: 0.0003592924040276557\n",
      "Epoch: 2342, Avg. Train Loss: 0.0003520773099681233, Avg. Test Loss: 0.00036403685226105154\n",
      "Epoch: 2343, Avg. Train Loss: 0.00035122420562994344, Avg. Test Loss: 0.00036514378734864295\n",
      "Epoch: 2344, Avg. Train Loss: 0.0003546138340065819, Avg. Test Loss: 0.0003616328467614949\n",
      "Epoch: 2345, Avg. Train Loss: 0.00035031083199672054, Avg. Test Loss: 0.00035910456790588796\n",
      "Epoch: 2346, Avg. Train Loss: 0.0003499929477774733, Avg. Test Loss: 0.0003616440517362207\n",
      "Epoch: 2347, Avg. Train Loss: 0.0003498781027088245, Avg. Test Loss: 0.0003622888762038201\n",
      "Epoch: 2348, Avg. Train Loss: 0.0003519951701597419, Avg. Test Loss: 0.00036563887260854244\n",
      "Epoch: 2349, Avg. Train Loss: 0.00035328127384229107, Avg. Test Loss: 0.00036451753112487495\n",
      "Epoch: 2350, Avg. Train Loss: 0.0003521985829223034, Avg. Test Loss: 0.0003621676005423069\n",
      "Epoch: 2351, Avg. Train Loss: 0.0003511491935526909, Avg. Test Loss: 0.00036171384272165596\n",
      "Epoch: 2352, Avg. Train Loss: 0.00034991374542546824, Avg. Test Loss: 0.0003592083521652967\n",
      "Epoch: 2353, Avg. Train Loss: 0.00035071193557340913, Avg. Test Loss: 0.00036772151361219585\n",
      "Epoch: 2354, Avg. Train Loss: 0.0003537771746862766, Avg. Test Loss: 0.0003597658942453563\n",
      "Epoch: 2355, Avg. Train Loss: 0.0003508690928737091, Avg. Test Loss: 0.0003629282582551241\n",
      "Epoch: 2356, Avg. Train Loss: 0.00035022947934542807, Avg. Test Loss: 0.0003635517496149987\n",
      "Epoch: 2357, Avg. Train Loss: 0.00035283026802570145, Avg. Test Loss: 0.000359132798621431\n",
      "Epoch: 2358, Avg. Train Loss: 0.00035023291901208807, Avg. Test Loss: 0.0003617357579059899\n",
      "Epoch: 2359, Avg. Train Loss: 0.00035349766352906994, Avg. Test Loss: 0.0003607364487834275\n",
      "Epoch: 2360, Avg. Train Loss: 0.00035052027669735253, Avg. Test Loss: 0.0003613114240579307\n",
      "Epoch: 2361, Avg. Train Loss: 0.0003506364862618665, Avg. Test Loss: 0.00036054555675946176\n",
      "Epoch: 2362, Avg. Train Loss: 0.00035126891926602394, Avg. Test Loss: 0.000365667772712186\n",
      "Epoch: 2363, Avg. Train Loss: 0.0003509739411150127, Avg. Test Loss: 0.0003604925877880305\n",
      "Epoch: 2364, Avg. Train Loss: 0.0003497975033729575, Avg. Test Loss: 0.00036141322925686836\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2365, Avg. Train Loss: 0.00035070560379820163, Avg. Test Loss: 0.0003614422457758337\n",
      "Epoch: 2366, Avg. Train Loss: 0.00035034101131523765, Avg. Test Loss: 0.00036476398236118257\n",
      "Epoch: 2367, Avg. Train Loss: 0.00035274028913442825, Avg. Test Loss: 0.00036305285175330937\n",
      "Epoch: 2368, Avg. Train Loss: 0.0003504266902847692, Avg. Test Loss: 0.0003592024149838835\n",
      "Epoch: 2369, Avg. Train Loss: 0.00035004658410650526, Avg. Test Loss: 0.0003660929505713284\n",
      "Epoch: 2370, Avg. Train Loss: 0.00035005811531486555, Avg. Test Loss: 0.00036017625825479627\n",
      "Epoch: 2371, Avg. Train Loss: 0.00035071240326519623, Avg. Test Loss: 0.0003617141046561301\n",
      "Epoch: 2372, Avg. Train Loss: 0.00035093351454084173, Avg. Test Loss: 0.00035870802821591496\n",
      "Epoch: 2373, Avg. Train Loss: 0.0003497328759485119, Avg. Test Loss: 0.0003588729596231133\n",
      "Epoch: 2374, Avg. Train Loss: 0.00034989132600035086, Avg. Test Loss: 0.0003598952025640756\n",
      "Epoch: 2375, Avg. Train Loss: 0.0003495440367598433, Avg. Test Loss: 0.00036203651688992977\n",
      "Epoch: 2376, Avg. Train Loss: 0.00035215070509070226, Avg. Test Loss: 0.0003635096945799887\n",
      "Epoch: 2377, Avg. Train Loss: 0.00035017313771383015, Avg. Test Loss: 0.0003584199585020542\n",
      "Epoch: 2378, Avg. Train Loss: 0.00035108091325910634, Avg. Test Loss: 0.0003615132300183177\n",
      "Epoch: 2379, Avg. Train Loss: 0.0003502757205941909, Avg. Test Loss: 0.0003585203376132995\n",
      "Epoch: 2380, Avg. Train Loss: 0.0003503860958559482, Avg. Test Loss: 0.00036097061820328236\n",
      "Epoch: 2381, Avg. Train Loss: 0.0003508455668262011, Avg. Test Loss: 0.00036209289100952446\n",
      "Epoch: 2382, Avg. Train Loss: 0.00034932099989355475, Avg. Test Loss: 0.00035920427762903273\n",
      "Epoch: 2383, Avg. Train Loss: 0.0003505498475427631, Avg. Test Loss: 0.00035884499084204435\n",
      "Epoch: 2384, Avg. Train Loss: 0.0003513585164233349, Avg. Test Loss: 0.0003657774068415165\n",
      "Epoch: 2385, Avg. Train Loss: 0.000352355680661276, Avg. Test Loss: 0.00036422593984752893\n",
      "Epoch: 2386, Avg. Train Loss: 0.00034933133919853285, Avg. Test Loss: 0.0003596701135393232\n",
      "Epoch: 2387, Avg. Train Loss: 0.0003493016194498037, Avg. Test Loss: 0.0003588513354770839\n",
      "Epoch: 2388, Avg. Train Loss: 0.00034979477844222686, Avg. Test Loss: 0.0003618045593611896\n",
      "Epoch: 2389, Avg. Train Loss: 0.00034930907476823345, Avg. Test Loss: 0.0003608202387113124\n",
      "Epoch: 2390, Avg. Train Loss: 0.0003498736606520969, Avg. Test Loss: 0.00036099753924645483\n",
      "Epoch: 2391, Avg. Train Loss: 0.00035032964051636155, Avg. Test Loss: 0.00036279819323681295\n",
      "Epoch: 2392, Avg. Train Loss: 0.0003511732746034774, Avg. Test Loss: 0.00036232624552212656\n",
      "Epoch: 2393, Avg. Train Loss: 0.00034941692002724077, Avg. Test Loss: 0.00036239155451767147\n",
      "Epoch: 2394, Avg. Train Loss: 0.0003490965599519049, Avg. Test Loss: 0.0003589807893149555\n",
      "Epoch: 2395, Avg. Train Loss: 0.00034880505260188394, Avg. Test Loss: 0.00035957922227680683\n",
      "Epoch: 2396, Avg. Train Loss: 0.0003504490758682233, Avg. Test Loss: 0.0003605040838010609\n",
      "Epoch: 2397, Avg. Train Loss: 0.0003497943967082646, Avg. Test Loss: 0.0003583138168323785\n",
      "Epoch: 2398, Avg. Train Loss: 0.00034954265737364634, Avg. Test Loss: 0.0003630025021266192\n",
      "Epoch: 2399, Avg. Train Loss: 0.0003500976132737949, Avg. Test Loss: 0.00035817036405205727\n",
      "Epoch: 2400, Avg. Train Loss: 0.0003485797652649845, Avg. Test Loss: 0.00036070376518182456\n",
      "Finished Training\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2af300f44278>"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Now let's train the initial network \n",
    "\n",
    "model = offCenterLineNet()\n",
    "model = model.to(dev)\n",
    "model.apply(weights_init_uniform)\n",
    "\n",
    "model.train();\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=.01) \n",
    "# scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=500, gamma=0.1)\n",
    "\n",
    "n_epochs = 2400\n",
    "\n",
    "mse_loss = nn.MSELoss()\n",
    "ce_loss = nn.CrossEntropyLoss()\n",
    "\n",
    "for epoch in range(0,n_epochs):  # loop over the dataset multiple times\n",
    "    \n",
    "    if epoch == 0:\n",
    "        train_loss_over_time = [] # to track the loss as the network trains\n",
    "        test_loss_over_time = []\n",
    "        \n",
    "    if epoch == 10:\n",
    "        optimizer = torch.optim.Adam(model.parameters(),lr=.001) \n",
    "        \n",
    "        \n",
    "    running_loss = 0\n",
    "    num_batches = 0\n",
    "    \n",
    "    for batch_i, data in enumerate(train_loader):\n",
    "        \n",
    "        # get the input images and their corresponding labels\n",
    "        num_batches += 1\n",
    "\n",
    "        inputs, output_gt, _, _ = data\n",
    "        inputs, output_gt = inputs.to(dev), output_gt.to(dev)\n",
    "        \n",
    "        # zero the parameter (weight) gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # forward pass to get outputs\n",
    "        output_line_params = model(inputs)\n",
    "        \n",
    "\n",
    "        # make the ground truth\n",
    "        c = -output_gt[:,2]*torch.cos(output_gt[:,0]) + output_gt[:,1]*torch.sin(output_gt[:,0])\n",
    "        gt_line_params = torch.stack((-torch.sin(output_gt[:,0]),torch.cos(output_gt[:,0]),c),dim=1)\n",
    "        \n",
    "        # calculate the loss\n",
    "#         print(output_line_params[:,:,0,50])\n",
    "        \n",
    "        loss = mse_loss(output_line_params,gt_line_params)\n",
    "        \n",
    "        # backward pass to calculate the parameter gradients\n",
    "        loss.backward()\n",
    "\n",
    "        # update the parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        # to convert loss into a scalar and add it to running_loss, we use .item()\n",
    "        running_loss += loss.item()\n",
    "      \n",
    "\n",
    "#     scheduler.step()\n",
    "    \n",
    "    # Calculate test data loss after each epoch\n",
    "    with torch.no_grad():\n",
    "        test_loss = 0\n",
    "        num_batches_test = 0\n",
    "        for batch_i, data in enumerate(test_loader):\n",
    "            num_batches_test += 1\n",
    "\n",
    "            # Add code here\n",
    "            inputs, output_gt, _, _ = data\n",
    "            inputs, output_gt = inputs.to(dev), output_gt.to(dev)\n",
    "\n",
    "\n",
    "            # zero the parameter (weight) gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward pass to get outputs\n",
    "            output_line_params = model(inputs)\n",
    "\n",
    "            # make the ground truth\n",
    "            c = -output_gt[:,2]*torch.cos(output_gt[:,0]) + output_gt[:,1]*torch.sin(output_gt[:,0])\n",
    "            gt_line_params = torch.stack((-torch.sin(output_gt[:,0]),torch.cos(output_gt[:,0]),c),dim=1)\n",
    "    \n",
    "\n",
    "            # calculate the loss\n",
    "    #         print(output_line_params[:,:,0,50])\n",
    "\n",
    "            loss = mse_loss(output_line_params,gt_line_params)\n",
    "            \n",
    "            test_loss += loss\n",
    "                    \n",
    "        test_loss_over_time.append(test_loss/num_batches_test)\n",
    "\n",
    "    # Calculate model loss:\n",
    "    avg_loss = running_loss/num_batches\n",
    "    train_loss_over_time.append(avg_loss)\n",
    "    \n",
    "#     print('Epoch: {}, Avg. Train Loss: {},'.format(epoch + 1, train_loss_over_time[-1]))\n",
    "\n",
    "\n",
    "    print('Epoch: {}, Avg. Train Loss: {}, Avg. Test Loss: {}'.format(epoch + 1, train_loss_over_time[-1], test_loss_over_time[-1]))\n",
    "    \n",
    "print('Finished Training')\n",
    "\n",
    "plt.figure()\n",
    "plt.semilogy(np.arange(0,n_epochs),train_loss_over_time[0:])\n",
    "plt.semilogy(np.arange(0,n_epochs),test_loss_over_time[0:])\n",
    "plt.legend(['Training loss', 'Testing loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "28aa28e8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor(1.1741), tensor(1.1577), tensor(1.0646), tensor(1.1119), tensor(1.0726), tensor(1.1662), tensor(1.1699), tensor(1.1647), tensor(1.1409), tensor(1.1444), tensor(1.1469), tensor(1.1610), tensor(1.0430), tensor(1.2330), tensor(1.1172)]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1080 with 9 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the Results\n",
    "\n",
    "model.eval();\n",
    "\n",
    "ang_loss_all = []\n",
    "\n",
    "for batch_i, data in enumerate(test_loader):\n",
    "    # get the input images and their corresponding labels\n",
    "    inputs, output_gt, _, _ = data\n",
    "    inputs, output_gt = inputs.to(dev), output_gt.to(dev)\n",
    "    \n",
    "\n",
    "    # forward pass to get outputs\n",
    "    outputs = model(inputs).squeeze().detach().cpu()\n",
    "    \n",
    "    gt = output_gt.cpu().squeeze()\n",
    "    \n",
    "    c = -output_gt[:,2]*torch.cos(output_gt[:,0]) + output_gt[:,1]*torch.sin(output_gt[:,0])\n",
    "    angle_params = torch.stack((-torch.sin(output_gt[:,0]),torch.cos(output_gt[:,0]),c),axis=1).detach().cpu()\n",
    "  \n",
    "    # Calculate angular loss\n",
    "    ang_loss = torch.mean(torch.abs(torch.rad2deg(torch.atan2(-angle_params[:,0]*outputs[:,1] + angle_params[:,1]*outputs[:,0]\n",
    "                                         ,angle_params[:,1]*outputs[:,1]+angle_params[:,0]*outputs[:,0]).cpu())))\n",
    "\n",
    "    ang_loss_all.append(ang_loss)\n",
    "\n",
    "    \n",
    "print(ang_loss_all)\n",
    "\n",
    "plt.figure(figsize=[15, 15])\n",
    "\n",
    "for ii in range(9):\n",
    "    \n",
    "    plt.subplot(3,3,ii+1)\n",
    "    plt.imshow(inputs[ii].cpu().squeeze(),cmap='gray', vmin=0, vmax=1)\n",
    "    \n",
    "    # Plot the ground truth lines\n",
    "    x_sample = torch.linspace(-1,1,inputs.shape[-1])\n",
    "    y_sample = -angle_params[ii,0]/angle_params[ii,1]*x_sample - angle_params[ii,2]/angle_params[ii,1]\n",
    "    \n",
    "    plt.plot(x_sample*W/2+W/2,y_sample*W/2+W/2,'b')\n",
    "    plt.xlim([0,W])\n",
    "    plt.ylim(([0,W]))\n",
    "    \n",
    "    # Plot the estimated lines\n",
    "    y_est = -outputs[ii,0]/outputs[ii,1]*x_sample - outputs[ii,2]/outputs[ii,1]\n",
    "    plt.plot(x_sample*W/2+W/2,y_est*W/2+W/2,'r')\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "542bf0b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
